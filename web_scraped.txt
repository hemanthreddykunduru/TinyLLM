Artificial intelligence - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk Contents move to sidebar hide (Top) 1 Goals Toggle Goals subsection 1.1 Reasoning and problem-solving 1.2 Knowledge representation 1.3 Planning and decision-making 1.4 Learning 1.5 Natural language processing 1.6 Perception 1.7 Social intelligence 1.8 General intelligence 2 Techniques Toggle Techniques subsection 2.1 Search and optimization 2.1.1 State space search 2.1.2 Local search 2.2 Logic 2.3 Probabilistic methods for uncertain reasoning 2.4 Classifiers and statistical learning methods 2.5 Artificial neural networks 2.6 Deep learning 2.7 GPT 2.8 Hardware and software 3 Applications Toggle Applications subsection 3.1 Health and medicine 3.2 Games 3.3 Mathematics 3.4 Finance 3.5 Military 3.6 Generative AI 3.7 Agents 3.8 Sexuality 3.9 Other industry-specific tasks 4 Ethics Toggle Ethics subsection 4.1 Risks and harm 4.1.1 Privacy and copyright 4.1.2 Dominance by tech giants 4.1.3 Power needs and environmental impacts 4.1.4 Misinformation 4.1.5 Algorithmic bias and fairness 4.1.6 Lack of transparency 4.1.7 Bad actors and weaponized AI 4.1.8 Technological unemployment 4.1.9 Existential risk 4.2 Ethical machines and alignment 4.3 Open source 4.4 Frameworks 4.5 Regulation 5 History 6 Philosophy Toggle Philosophy subsection 6.1 Defining artificial intelligence 6.2 Evaluating approaches to AI 6.2.1 Symbolic AI and its limits 6.2.2 Neat vs. scruffy 6.2.3 Soft vs. hard computing 6.2.4 Narrow vs. general AI 6.3 Machine consciousness, sentience, and mind 6.3.1 Consciousness 6.3.2 Computationalism and functionalism 6.3.3 AI welfare and rights 7 Future Toggle Future subsection 7.1 Superintelligence and the singularity 7.2 Transhumanism 8 In fiction 9 See also 10 Explanatory notes 11 References Toggle References subsection 11.1 AI textbooks 11.2 History of AI 11.3 Other sources 12 Further reading 13 External links Toggle the table of contents Artificial intelligence 167 languages Afrikaans Alemannisch አማርኛ العربية Aragonés Արեւմտահայերէն অসমীয়া Asturianu Avañe'ẽ Azərbaycanca تۆرکجه বাংলা 閩南語 / Bân-lâm-gú Башҡортса Беларуская Беларуская (тарашкевіца) भोजपुरी Bikol Central Български Boarisch བོད་ཡིག Bosanski Brezhoneg Буряад Català Чӑвашла Cebuano Čeština Cymraeg Dansk الدارجة Deutsch Eesti Ελληνικά Español Esperanto Estremeñu Euskara فارسی Fiji Hindi Français Furlan Gaeilge Gaelg Gàidhlig Galego 贛語 Gĩkũyũ गोंयची कोंकणी / Gõychi Konknni 한국어 Hausa Հայերեն हिन्दी Hrvatski Ido Igbo Ilokano Bahasa Indonesia Interlingua Interlingue IsiZulu Íslenska Italiano עברית Jawa ಕನ್ನಡ ქართული کٲشُر Қазақша Kiswahili Kreyòl ayisyen Kriyòl gwiyannen Kurdî Кыргызча ລາວ Latina Latviešu Lëtzebuergesch Lietuvių Ligure Limburgs La .lojban. Lombard Magyar Madhurâ Македонски Malagasy മലയാളം Malti मराठी მარგალური مصرى Bahasa Melayu Minangkabau Монгол မြန်မာဘာသာ Nederlands Nedersaksies नेपाली नेपाल भाषा 日本語 Nordfriisk Norsk bokmål Norsk nynorsk Occitan ଓଡ଼ିଆ Oʻzbekcha / ўзбекча ਪੰਜਾਬੀ پنجابی ပအိုဝ်ႏဘာႏသာႏ پښتو Patois ភាសាខ្មែរ Picard Piemontèis Plattdüütsch Polski Português Qaraqalpaqsha Qırımtatarca Reo tahiti Ripoarisch Română Runa Simi Русиньскый Русский Саха тыла Scots Shqip සිංහල Simple English سنڌي Slovenčina Slovenščina Ślůnski کوردی Српски / srpski Srpskohrvatski / српскохрватски Suomi Svenska Tagalog தமிழ் Татарча / tatarça తెలుగు ไทย Тоҷикӣ Türkçe Türkmençe Українська اردو ئۇيغۇرچە / Uyghurche Vèneto Tiếng Việt Võro Walon Winaray 吴语 ייִדיש 粵語 Zazaki Žemaitėška 中文 Betawi Kadazandusun Fɔ̀ngbè ꠍꠤꠟꠐꠤ ⵜⴰⵎⴰⵣⵉⵖⵜ ⵜⴰⵏⴰⵡⴰⵢⵜ Edit links Article Talk English Read View source View history Tools Tools move to sidebar hide Actions Read View source View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Meta-Wiki Wikibooks Wikinews Wikiquote Wikiversity Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Intelligence of machines "AI" redirects here. For other uses, see AI (disambiguation) and Artificial intelligence (disambiguation) . Part of a series on Artificial intelligence (AI) Major goals Artificial general intelligence Intelligent agent Recursive self-improvement Planning Computer vision General game playing Knowledge representation Natural language processing Robotics AI safety Approaches Machine learning Symbolic Deep learning Bayesian networks Evolutionary algorithms Hybrid intelligent systems Systems integration Applications Bioinformatics Deepfake Earth sciences Finance Generative AI Art Audio Music Government Healthcare Mental health Industry Translation Military Physics Projects Philosophy Artificial consciousness Chinese room Friendly AI Control problem / Takeover Ethics Existential risk Turing test Uncanny valley History Timeline Progress AI winter AI boom Glossary Glossary v t e Artificial intelligence ( AI ) is the capability of computational systems to perform tasks typically associated with human intelligence , such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. [ 1 ] High-profile applications of AI include advanced web search engines (e.g., Google Search ); recommendation systems (used by YouTube , Amazon , and Netflix ); virtual assistants (e.g., Google Assistant , Siri , and Alexa ); autonomous vehicles (e.g., Waymo ); generative and creative tools (e.g., language models and AI art ); and superhuman play and analysis in strategy games (e.g., chess and Go ). However, many AI applications are not perceived as AI: "A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore ." [ 2 ] [ 3 ] Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning , knowledge representation , planning , natural language processing , perception , and support for robotics . [ a ] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization , formal logic , artificial neural networks , and methods based on statistics , operations research , and economics . [ b ] AI also draws upon psychology , linguistics , philosophy , neuroscience , and other fields. [ 4 ] Some companies, such as OpenAI , Google DeepMind and Meta , [ 5 ] aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human. Artificial intelligence was founded as an academic discipline in 1956, [ 6 ] and the field went through multiple cycles of optimism throughout its history , [ 7 ] [ 8 ] followed by periods of disappointment and loss of funding, known as AI winters . [ 9 ] [ 10 ] Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques. [ 11 ] This growth accelerated further after 2017 with the transformer architecture . [ 12 ] In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom . Generative AI's ability to create and modify content has led to several unintended consequences and harms, while raising ethical concerns about AI's long-term effects and potential existential risks , prompting discussions about regulatory policies to ensure the safety and benefits of the technology. Goals The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research. [ a ] Reasoning and problem-solving Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions . [ 13 ] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics . [ 14 ] Many of these algorithms are insufficient for solving large reasoning problems because they experience a "combinatorial explosion": They become exponentially slower as the problems grow. [ 15 ] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. [ 16 ] Accurate and efficient reasoning is an unsolved problem. Knowledge representation An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts. Knowledge representation and knowledge engineering [ 17 ] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, [ 18 ] scene interpretation, [ 19 ] clinical decision support, [ 20 ] knowledge discovery (mining "interesting" and actionable inferences from large databases ), [ 21 ] and other areas. [ 22 ] A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. [ 23 ] Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; [ 24 ] situations, events, states, and time; [ 25 ] causes and effects; [ 26 ] knowledge about knowledge (what we know about what other people know); [ 27 ] default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); [ 28 ] and many other aspects and domains of knowledge. Among the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); [ 29 ] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as "facts" or "statements" that they could express verbally). [ 16 ] There is also the difficulty of knowledge acquisition , the problem of obtaining knowledge for AI applications. [ c ] Planning and decision-making An "agent" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. [ d ] [ 32 ] In automated planning , the agent has a specific goal. [ 33 ] In automated decision-making , the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the " utility ") that measures how much the agent prefers it. For each possible action, it can calculate the " expected utility ": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility. [ 34 ] In classical planning , the agent knows exactly what the effect of any action will be. [ 35 ] In most real-world problems, however, the agent may not be certain about the situation they are in (it is "unknown" or "unobservable") and it may not know for certain what will happen after each possible action (it is not "deterministic"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked. [ 36 ] In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning ), or the agent can seek information to improve its preferences. [ 37 ] Information value theory can be used to weigh the value of exploratory or experimental actions. [ 38 ] The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be. A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration ), be heuristic , or it can be learned. [ 39 ] Game theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents. [ 40 ] Learning Machine learning is the study of programs that can improve their performance on a given task automatically. [ 41 ] It has been a part of AI from the beginning. [ e ] In supervised learning , the training data is labelled with the expected answers, while in unsupervised learning , the model identifies patterns or structures in unlabelled data. There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. [ 44 ] Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input). [ 45 ] In reinforcement learning , the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as "good". [ 46 ] Transfer learning is when the knowledge gained from one problem is applied to a new problem. [ 47 ] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning. [ 48 ] Computational learning theory can assess learners by computational complexity , by sample complexity (how much data is required), or by other notions of optimization . [ 49 ] Natural language processing Natural language processing (NLP) allows programs to read, write and communicate in human languages. [ 50 ] Specific problems include speech recognition , speech synthesis , machine translation , information extraction , information retrieval and question answering . [ 51 ] Early work, based on Noam Chomsky 's generative grammar and semantic networks , had difficulty with word-sense disambiguation [ f ] unless restricted to small domains called " micro-worlds " (due to the common sense knowledge problem [ 29 ] ). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure. Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), [ 52 ] transformers (a deep learning architecture using an attention mechanism), [ 53 ] and others. [ 54 ] In 2019, generative pre-trained transformer (or "GPT") language models began to generate coherent text, [ 55 ] [ 56 ] and by 2023, these models were able to get human-level scores on the bar exam , SAT test, GRE test, and many other real-world applications. [ 57 ] Perception Machine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar , sonar, radar, and tactile sensors ) to deduce aspects of the world. Computer vision is the ability to analyze visual input. [ 58 ] The field includes speech recognition , [ 59 ] image classification , [ 60 ] facial recognition , object recognition , [ 61 ] object tracking , [ 62 ] and robotic perception . [ 63 ] Social intelligence Kismet , a robot head which was made in the 1990s; it is a machine that can recognize and simulate emotions. [ 64 ] Affective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood . [ 65 ] For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction . However, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents. [ 66 ] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis , wherein AI classifies the effects displayed by a videotaped subject. [ 67 ] General intelligence A machine with artificial general intelligence would be able to solve a wide variety of problems with breadth and versatility similar to human intelligence . [ 68 ] Techniques AI research uses a wide variety of techniques to accomplish the goals above. [ b ] Search and optimization AI can solve many problems by intelligently searching through many possible solutions. [ 69 ] There are two very different kinds of search used in AI: state space search and local search . State space search State space search searches through a tree of possible states to try to find a goal state. [ 70 ] For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis . [ 71 ] Simple exhaustive searches [ 72 ] are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers . The result is a search that is too slow or never completes. [ 15 ] " Heuristics " or "rules of thumb" can help prioritize choices that are more likely to reach a goal. [ 73 ] Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position. [ 74 ] Local search Illustration of gradient descent for 3 different starting points; two parameters (represented by the plan coordinates) are adjusted in order to minimize the loss function (the height) Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally. [ 75 ] Gradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function . Variants of gradient descent are commonly used to train neural networks , [ 76 ] through the backpropagation algorithm. Another type of local search is evolutionary computation , which aims to iteratively improve a set of candidate solutions by "mutating" and "recombining" them, selecting only the fittest to survive each generation. [ 77 ] Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking ) and ant colony optimization (inspired by ant trails ). [ 78 ] Logic Formal logic is used for reasoning and knowledge representation . [ 79 ] Formal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as "and", "or", "not" and "implies") [ 80 ] and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as " Every X is a Y " and "There are some X s that are Y s"). [ 81 ] Deductive reasoning in logic is the process of proving a new statement ( conclusion ) from other statements that are given and assumed to be true (the premises ). [ 82 ] Proofs can be structured as proof trees , in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules . Given a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms . In the case of Horn clauses , problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem. [ 83 ] In the more general case of the clausal form of first-order logic , resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved. [ 84 ] Inference in both Horn clause logic and first-order logic is undecidable , and therefore intractable . However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog , is Turing complete . Moreover, its efficiency is competitive with computation in other symbolic programming languages. [ 85 ] Fuzzy logic assigns a "degree of truth" between 0 and 1. It can therefore handle propositions that are vague and partially true. [ 86 ] Non-monotonic logics , including logic programming with negation as failure , are designed to handle default reasoning . [ 28 ] Other specialized versions of logic have been developed to describe many complex domains. Probabilistic methods for uncertain reasoning A simple Bayesian network , with the associated conditional probability tables Many problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics. [ 87 ] Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory , decision analysis , [ 88 ] and information value theory . [ 89 ] These tools include models such as Markov decision processes , [ 90 ] dynamic decision networks , [ 91 ] game theory and mechanism design . [ 92 ] Bayesian networks [ 93 ] are a tool that can be used for reasoning (using the Bayesian inference algorithm), [ g ] [ 95 ] learning (using the expectation–maximization algorithm ), [ h ] [ 97 ] planning (using decision networks ) [ 98 ] and perception (using dynamic Bayesian networks ). [ 91 ] Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters ). [ 91 ] Expectation–maximization clustering of Old Faithful eruption data starts from a random guess but then successfully converges on an accurate clustering of the two physically distinct modes of eruption. Classifiers and statistical learning methods The simplest AI applications can be divided into two types: classifiers (e.g., "if shiny then diamond"), on one hand, and controllers (e.g., "if diamond then pick up"), on the other hand. Classifiers [ 99 ] are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning . Each pattern (also called an " observation ") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set . When a new observation is received, that observation is classified based on previous experience. [ 45 ] There are many kinds of classifiers in use. [ 100 ] The decision tree is the simplest and most widely used symbolic machine learning algorithm. [ 101 ] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s. [ 102 ] The naive Bayes classifier is reportedly the "most widely used learner" [ 103 ] at Google, due in part to its scalability. [ 104 ] Neural networks are also used as classifiers. [ 105 ] Artificial neural networks A neural network is an interconnected group of nodes, akin to the vast network of neurons in the human brain . An artificial neural network is based on a collection of nodes also known as artificial neurons , which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers. [ 105 ] Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm. [ 106 ] Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function. [ 107 ] In feedforward neural networks the signal passes in only one direction. [ 108 ] Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful architecture for recurrent neural networks. [ 109 ] Perceptrons [ 110 ] use only a single layer of neurons; deep learning [ 111 ] uses multiple layers. Convolutional neural networks strengthen the connection between neurons that are "close" to each other—this is especially important in image processing , where a local set of neurons must identify an "edge" before the network can identify an object. [ 112 ] Deep learning Deep learning is a subset of machine learning , which is itself a subset of artificial intelligence. [ 113 ] Deep learning uses several layers of neurons between the network's inputs and outputs. [ 111 ] The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing , lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces. [ 114 ] Deep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision , speech recognition , natural language processing , image classification , [ 115 ] and others. The reason that deep learning performs so well in so many applications is not known as of 2021. [ 116 ] The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s) [ i ] but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs ) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet . [ j ] GPT Generative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called " hallucinations ". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems. [ 124 ] Such systems are used in chatbots , which allow people to ask a question or request a task in simple text. [ 125 ] [ 126 ] Current models and services include ChatGPT , Claude , Gemini (formerly Bard), Copilot , and Meta AI . [ 127 ] Multimodal GPT models can process different types of data ( modalities ) such as images, videos, sound, and text. [ 128 ] Hardware and software Main articles: Programming languages for artificial intelligence and Hardware for artificial intelligence In the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training. [ 129 ] Specialized programming languages such as Prolog were used in early AI research, [ 130 ] but general-purpose programming languages like Python have become predominant. [ 131 ] The transistor density in integrated circuits has been observed to roughly double every 18 months—a trend known as Moore's law , named after the Intel co-founder Gordon Moore , who first identified it. Improvements in GPUs have been even faster, [ 132 ] a trend sometimes called Huang's law , [ 133 ] named after Nvidia co-founder and CEO Jensen Huang . Applications Main article: Applications of artificial intelligence AI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search ), targeting online advertisements , recommendation systems (offered by Netflix , YouTube or Amazon ), driving internet traffic , targeted advertising ( AdSense , Facebook ), virtual assistants (such as Siri or Alexa ), autonomous vehicles (including drones , ADAS and self-driving cars ), automatic language translation ( Microsoft Translator , Google Translate ), facial recognition ( Apple 's FaceID or Microsoft 's DeepFace and Google 's FaceNet ) and image labeling (used by Facebook , Apple's Photos and TikTok ). The deployment of AI may be overseen by a chief automation officer (CAO). Health and medicine Main article: Artificial intelligence in healthcare The application of AI in medicine and medical research has the potential to increase patient care and quality of life. [ 134 ] Through the lens of the Hippocratic Oath , medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients. [ 135 ] [ 136 ] For medical research, AI is an important tool for processing and integrating big data . This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication. [ 137 ] It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research. [ 137 ] [ 138 ] New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein . [ 139 ] In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria. [ 140 ] In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold. [ 141 ] [ 142 ] Games Main article: Artificial intelligence in video games Game playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. [ 143 ] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov , on 11 May 1997. [ 144 ] In 2011, in a Jeopardy! quiz show exhibition match, IBM 's question answering system , Watson , defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings , by a significant margin. [ 145 ] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol , becoming the first computer Go -playing system to beat a professional Go player without handicaps . Then, in 2017, it defeated Ke Jie , who was the best Go player in the world. [ 146 ] Other programs handle imperfect-information games, such as the poker -playing program Pluribus . [ 147 ] DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero , which could be trained to play chess, Go, or Atari games. [ 148 ] In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II , a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map. [ 149 ] In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning. [ 150 ] In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions. [ 151 ] Mathematics Large language models, such as GPT-4 , Gemini , Claude , Llama or Mistral , are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of hallucinations . They sometimes need a large database of mathematical problems to learn from, but also methods such as supervised fine-tuning [ 152 ] or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections. [ 153 ] A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data. [ 154 ] One technique to improve their performance involves training the models to produce correct reasoning steps, rather than just the correct result. [ 155 ] The Alibaba Group developed a version of its Qwen models called Qwen2-Math , that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems. [ 156 ] In January 2025, Microsoft proposed the technique rStar-Math that leverages Monte Carlo tree search and step-by-step reasoning, enabling a relatively small language model like Qwen-7B to solve 53% of the AIME 2024 and 90% of the MATH benchmark problems. [ 157 ] Alternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as AlphaTensor , AlphaGeometry , AlphaProof and AlphaEvolve [ 158 ] all from Google DeepMind , [ 159 ] Llemma from EleutherAI [ 160 ] or Julius . [ 161 ] When natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as Lean to define mathematical tasks. Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics. [ 162 ] Topological deep learning integrates various topological approaches. Finance Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated "robot advisers" have been in use for some years. [ 163 ] According to Nicolas Firzli, director of the World Pensions & Investments Forum , it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that "the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation." [ 164 ] Military Main article: Military applications of artificial intelligence Various countries are deploying AI military applications. [ 165 ] The main applications enhance command and control , communications, sensors, integration and interoperability. [ 166 ] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles . [ 165 ] AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition , coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human-operated and autonomous . [ 166 ] AI has been used in military operations in Iraq, Syria, Israel and Ukraine. [ 165 ] [ 167 ] [ 168 ] [ 169 ] Generative AI Vincent van Gogh in watercolour created by generative AI software These paragraphs are an excerpt from Generative artificial intelligence . [ edit ] Generative artificial intelligence (Generative AI, GenAI, [ 170 ] or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. [ 171 ] [ 172 ] [ 173 ] These models learn the underlying patterns and structures of their training data and use them to produce new data [ 174 ] [ 175 ] based on the input, which often comes in the form of natural language prompts . [ 176 ] [ 177 ] Generative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer -based deep neural networks , particularly large language models (LLMs). Major tools include chatbots such as ChatGPT , Claude , Gemini , Copilot , and Meta AI ; text-to-image models such as Stable Diffusion , Midjourney , and DALL-E ; and text-to-video models such as Veo and Sora . [ 178 ] [ 179 ] [ 180 ] [ 181 ] Technology companies developing generative AI include OpenAI , Anthropic , Meta AI , Microsoft , Google , DeepSeek , and Baidu . [ 176 ] [ 182 ] [ 183 ] Generative AI has raised many ethical questions as it can be used for cybercrime , or to deceive or manipulate people through fake news or deepfakes . [ 184 ] Even if used ethically, it may lead to mass replacement of human jobs . [ 185 ] The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works. [ 186 ] Agents Main article: Agentic AI AI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants , chatbots , autonomous vehicles , game-playing systems , and industrial robotics . AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks. [ 187 ] [ 188 ] [ 189 ] Sexuality Applications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions, [ 190 ] AI-integrated sex toys (e.g., teledildonics ), [ 191 ] AI-generated sexual education content, [ 192 ] and AI agents that simulate sexual and romantic partners (e.g., Replika ). [ 193 ] AI is also used for the production of non-consensual deepfake pornography , raising significant ethical and legal concerns. [ 194 ] AI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors. [ 195 ] [ 196 ] Other industry-specific tasks There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated "AI" in some offerings or processes. [ 197 ] A few examples are energy storage , medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy , or supply chain management. AI applications for evacuation and disaster management are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions. [ 198 ] [ 199 ] [ 200 ] In agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics , classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water. Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for "classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights." For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation. During the 2024 Indian elections , US$50 million was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages. [ 201 ] Ethics Main article: Ethics of artificial intelligence AI has potential benefits and potential risks. [ 202 ] AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to "solve intelligence, and then use that to solve everything else". [ 203 ] However, as the use of AI has become widespread, several unintended consequences and risks have been identified. [ 204 ] In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning. [ 205 ] Risks and harm Privacy and copyright Further information: Information privacy and Artificial intelligence and copyright Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy , surveillance and copyright . AI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency. Sensitive user data collected may include online activity records, geolocation data, video, or audio. [ 206 ] For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them. [ 207 ] Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy . [ 208 ] AI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation , de-identification and differential privacy . [ 209 ] Since 2016, some privacy experts, such as Cynthia Dwork , have begun to view privacy in terms of fairness . Brian Christian wrote that experts have pivoted "from the question of 'what they know' to the question of 'what they're doing with it'." [ 210 ] Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of " fair use ". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include "the purpose and character of the use of the copyrighted work" and "the effect upon the potential market for the copyrighted work". [ 211 ] [ 212 ] Website owners who do not wish to have their content scraped can indicate it in a " robots.txt " file. [ 213 ] In 2023, leading authors (including John Grisham and Jonathan Franzen ) sued AI companies for using their work to train generative AI. [ 214 ] [ 215 ] Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors. [ 216 ] Dominance by tech giants The commercial AI scene is dominated by Big Tech companies such as Alphabet Inc. , Amazon , Apple Inc. , Meta Platforms , and Microsoft . [ 217 ] [ 218 ] [ 219 ] Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers , allowing them to entrench further in the marketplace. [ 220 ] [ 221 ] Power needs and environmental impacts See also: Environmental impacts of artificial intelligence In January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026 , forecasting electric power use. [ 222 ] This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation. [ 223 ] Prodigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and "intelligent", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms. [ 224 ] A 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge , found "US power demand (is) likely to experience growth not seen in a generation...." and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means. [ 225 ] Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all. [ 226 ] In 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million. [ 227 ] Nvidia CEO Jensen Huang said nuclear power is a good option for the data centers. [ 228 ] In September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission . If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act . [ 229 ] The US government and the state of Michigan are investing almost US$2 billion to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon's spinoff of Constellation. [ 230 ] After the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages. [ 231 ] Taiwan aims to phase out nuclear power by 2025. [ 231 ] On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban. [ 231 ] Although most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident , according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near nuclear power plant for a new data center for generative AI. [ 232 ] Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI. [ 232 ] On 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center. [ 233 ] According to the Commission Chairman Willie L. Phillips , it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors. [ 233 ] In 2025, a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300-500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people switch from public transport to autonomous cars) can reduce it. [ 234 ] Misinformation See also: YouTube § Moderation and offensive content YouTube , Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation , conspiracy theories , and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. [ 235 ] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. [ 236 ] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem. [ 237 ] In the early 2020s, generative AI began to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing, [ 238 ] while realistic AI-generated videos became feasible in the mid-2020s. [ 239 ] [ 240 ] [ 241 ] It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda; [ 242 ] one such potential malicious use is deepfakes for computational propaganda . [ 243 ] AI pioneer Geoffrey Hinton expressed concern about AI enabling "authoritarian leaders to manipulate their electorates" on a large scale, among other risks. [ 244 ] AI researchers at Microsoft , OpenAI , universities and other organisations have suggested using " personhood credentials " as a way to overcome online deception enabled by AI models. [ 245 ] Algorithmic bias and fairness Main articles: Algorithmic bias and Fairness (machine learning) Machine learning applications will be biased [ k ] if they learn from biased data. [ 247 ] The developers may not be aware that the bias exists. [ 248 ] Bias can be introduced by the way training data is selected and by the way a model is deployed. [ 249 ] [ 247 ] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine , finance , recruitment , housing or policing ) then the algorithm may cause discrimination . [ 250 ] The field of fairness studies how to prevent harms from algorithmic biases. On June 28, 2015, Google Photos 's new image labeling feature mistakenly identified Jacky Alcine and a friend as "gorillas" because they were black. The system was trained on a dataset that contained very few images of black people, [ 251 ] a problem called "sample size disparity". [ 252 ] Google "fixed" this problem by preventing the system from labelling anything as a "gorilla". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon. [ 253 ] COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist . In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. [ 254 ] In 2017, several researchers [ l ] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data. [ 256 ] A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as "race" or "gender"). The feature will correlate with other features (like "address", "shopping history" or "first name"), and the program will make the same decisions based on these features as it would on "race" or "gender". [ 257 ] Moritz Hardt said "the most robust fact in this research area is that fairness through blindness doesn't work." [ 258 ] Criticism of COMPAS highlighted that machine learning models are designed to make "predictions" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations , some of these "recommendations" will likely be racist. [ 259 ] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive. [ m ] Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women. [ 252 ] There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness , which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws . [ 246 ] At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery , in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed. [ dubious – discuss ] [ 261 ] Lack of transparency See also: Explainable AI , Algorithmic transparency , and Right to explanation Many AI systems are so complex that their designers cannot explain how they reach their decisions. [ 262 ] Particularly with deep neural networks , in which there are many non- linear relationships between inputs and outputs. But some popular explainability techniques exist. [ 263 ] It is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as "cancerous", because pictures of malignancies typically include a ruler to show the scale. [ 264 ] Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at "low risk" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading. [ 265 ] People who have been harmed by an algorithm's decision have a right to an explanation. [ 266 ] Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists. [ n ] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used. [ 267 ] DARPA established the XAI ("Explainable Artificial Intelligence") program in 2014 to try to solve these problems. [ 268 ] Several approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output. [ 269 ] LIME can locally approximate a model's outputs with a simpler, interpretable model. [ 270 ] Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. [ 271 ] Deconvolution , DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning. [ 272 ] For generative pre-trained transformers , Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts. [ 273 ] Bad actors and weaponized AI Main articles: Lethal autonomous weapon , Artificial intelligence arms race , and AI safety Artificial intelligence provides a number of tools that are useful to bad actors , such as authoritarian governments , terrorists , criminals or rogue states . A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. [ o ] Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction . [ 275 ] Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person . [ 275 ] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations ' Convention on Certain Conventional Weapons , however the United States and others disagreed. [ 276 ] By 2015, over fifty countries were reported to be researching battlefield robots. [ 277 ] AI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance . Machine learning , operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision-making more competitive than liberal and decentralized systems such as markets . It lowers the cost and difficulty of digital warfare and advanced spyware . [ 278 ] All these technologies have been available since 2020 or earlier—AI facial recognition systems are already being used for mass surveillance in China. [ 279 ] [ 280 ] There are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours. [ 281 ] Technological unemployment Main articles: Workplace impact of artificial intelligence and Technological unemployment Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment. [ 282 ] In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that "we're in uncharted territory" with AI. [ 283 ] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment , but they generally agree that it could be a net benefit if productivity gains are redistributed . [ 284 ] Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classified only 9% of U.S. jobs as "high risk". [ p ] [ 286 ] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies. [ 282 ] In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence. [ 287 ] [ 288 ] Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously". [ 289 ] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. [ 290 ] From the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum , about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement. [ 291 ] Existential risk Main article: Existential risk from artificial intelligence It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, " spell the end of the human race ". [ 292 ] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like "self-awareness" (or "sentience" or "consciousness") and becomes a malevolent character. [ q ] These sci-fi scenarios are misleading in several ways. First, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip maximizer ). [ 294 ] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that "you can't fetch the coffee if you're dead." [ 295 ] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is "fundamentally on our side". [ 296 ] Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies , law , government , money and the economy are built on language ; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive. [ 297 ] The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. [ 298 ] Personalities such as Stephen Hawking , Bill Gates , and Elon Musk , [ 299 ] as well as AI pioneers such as Yoshua Bengio , Stuart Russell , Demis Hassabis , and Sam Altman , have expressed concerns about existential risk from AI. In May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to "freely speak out about the risks of AI" without "considering how this impacts Google". [ 300 ] He notably mentioned risks of an AI takeover , [ 301 ] and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI. [ 302 ] In 2023, many leading AI experts endorsed the joint statement that "Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war". [ 303 ] Some other researchers were more optimistic. AI pioneer Jürgen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making "human lives longer and healthier and easier." [ 304 ] While the tools that are now being used to improve lives can also be used by bad actors, "they can also be used against the bad actors." [ 305 ] [ 306 ] Andrew Ng also argued that "it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests." [ 307 ] Yann LeCun "scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction." [ 308 ] In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine. [ 309 ] However, after 2016, the study of current and future risks and possible solutions became a serious area of research. [ 310 ] Ethical machines and alignment Main articles: Machine ethics , AI safety , Friendly artificial intelligence , Artificial moral agents , and Human Compatible Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky , who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk. [ 311 ] Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas. [ 312 ] The field of machine ethics is also called computational morality, [ 312 ] and was founded at an AAAI symposium in 2005. [ 313 ] Other approaches include Wendell Wallach 's "artificial moral agents" [ 314 ] and Stuart J. Russell 's three principles for developing provably beneficial machines. [ 315 ] Open source Active organizations in the AI open-source community include Hugging Face , [ 316 ] Google , [ 317 ] EleutherAI and Meta . [ 318 ] Various AI models, such as Llama 2 , Mistral or Stable Diffusion , have been made open-weight, [ 319 ] [ 320 ] meaning that their architecture and trained parameters (the "weights") are publicly available. Open-weight models can be freely fine-tuned , which allows companies to specialize them with their own data and for their own use-case. [ 321 ] Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism ) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses. [ 322 ] Frameworks Artificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the Alan Turing Institute and based on the SUM values, outlines four main ethical dimensions, defined as follows: [ 323 ] [ 324 ] Respect the dignity of individual people Connect with other people sincerely, openly, and inclusively Care for the wellbeing of everyone Protect social values, justice, and the public interest Other developments in ethical frameworks include those decided upon during the Asilomar Conference , the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others; [ 325 ] however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks. [ 326 ] Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers. [ 327 ] The UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities. [ 328 ] Regulation Main articles: Regulation of artificial intelligence , Regulation of algorithms , and AI safety The first global AI Safety Summit was held in the United Kingdom in November 2023 with a declaration calling for international cooperation. The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms. [ 329 ] The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. [ 330 ] According to AI Index at Stanford , the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone. [ 331 ] [ 332 ] Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI. [ 333 ] Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia. [ 333 ] The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. [ 333 ] Henry Kissinger , Eric Schmidt , and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI. [ 334 ] In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. [ 335 ] In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics. [ 336 ] In 2024, the Council of Europe created the first international legally binding treaty on AI, called the " Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law ". It was adopted by the European Union, the United States, the United Kingdom, and other signatories. [ 337 ] In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that "products and services using AI have more benefits than drawbacks". [ 331 ] A 2023 Reuters /Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity. [ 338 ] In a 2023 Fox News poll, 35% of Americans thought it "very important", and an additional 41% thought it "somewhat important", for the federal government to regulate AI, versus 13% responding "not very important" and 8% responding "not at all important". [ 339 ] [ 340 ] In November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks. [ 341 ] 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence. [ 342 ] [ 343 ] In May 2024 at the AI Seoul Summit , 16 global AI tech companies agreed to safety commitments on the development of AI. [ 344 ] [ 345 ] History Main article: History of artificial intelligence For a chronological guide, see Timeline of artificial intelligence . In 2024, AI patents in China and the US numbered more than three-fourths of AI patents worldwide. [ 346 ] Though China had more AI patents, the US had 35% more patents per AI patent-applicant company than China. [ 346 ] The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing 's theory of computation , which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable form of mathematical reasoning. [ 347 ] [ 348 ] This, along with concurrent discoveries in cybernetics , information theory and neurobiology , led researchers to consider the possibility of building an "electronic brain". [ r ] They developed several areas of research that would become part of AI, [ 350 ] such as McCulloch and Pitts design for "artificial neurons" in 1943, [ 117 ] and Turing's influential 1950 paper ' Computing Machinery and Intelligence ', which introduced the Turing test and showed that "machine intelligence" was plausible. [ 351 ] [ 348 ] The field of AI research was founded at a workshop at Dartmouth College in 1956. [ s ] [ 6 ] The attendees became the leaders of AI research in the 1960s. [ t ] They and their students produced programs that the press described as "astonishing": [ u ] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. [ v ] [ 7 ] Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s. [ 348 ] Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field. [ 355 ] In 1965 Herbert Simon predicted, "machines will be capable, within twenty years, of doing any work a man can do". [ 356 ] In 1967 Marvin Minsky agreed, writing that "within a generation ... the problem of creating 'artificial intelligence' will substantially be solved". [ 357 ] They had, however, underestimated the difficulty of the problem. [ w ] In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill [ 359 ] and ongoing pressure from the U.S. Congress to fund more productive projects . [ 360 ] Minsky and Papert 's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. [ 361 ] The " AI winter ", a period when obtaining funding for AI projects was difficult, followed. [ 9 ] In the early 1980s, AI research was revived by the commercial success of expert systems , [ 362 ] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research . [ 8 ] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began. [ 10 ] Up to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception , robotics , learning and pattern recognition , [ 363 ] and began to look into "sub-symbolic" approaches. [ 364 ] Rodney Brooks rejected "representation" in general and focussed directly on engineering machines that move and survive. [ x ] Judea Pearl , Lotfi Zadeh , and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. [ 87 ] [ 369 ] But the most important development was the revival of " connectionism ", including neural network research, by Geoffrey Hinton and others. [ 370 ] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks. [ 371 ] AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This " narrow " and "formal" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics , economics and mathematics ). [ 372 ] By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as "artificial intelligence" (a tendency known as the AI effect ). [ 373 ] However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or "AGI"), which had several well-funded institutions by the 2010s. [ 68 ] Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field. [ 11 ] For many specific tasks, other methods were abandoned. [ y ] Deep learning's success was based on both hardware improvements ( faster computers , [ 375 ] graphics processing units , cloud computing [ 376 ] ) and access to large amounts of data [ 377 ] (including curated datasets, [ 376 ] such as ImageNet ). Deep learning's success led to an enormous increase in interest and funding in AI. [ z ] The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019. [ 333 ] The number of Google searches for the term "AI" accelerated in 2022. In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study. [ 310 ] In the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo , developed by DeepMind , beat the world champion Go player . The program taught only the game's rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text. [ 378 ] ChatGPT , launched on November 30, 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months. [ 379 ] It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness. [ 380 ] These programs, and others, inspired an aggressive AI boom , where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in "AI" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in "AI". [ 381 ] About 800,000 "AI"-related U.S. job openings existed in 2022. [ 382 ] According to PitchBook research, 22% of newly funded startups in 2024 claimed to be AI companies. [ 383 ] Philosophy Main article: Philosophy of artificial intelligence Philosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines. [ 384 ] Another major focus has been whether machines can be conscious, and the associated ethical implications. [ 385 ] Many other topics in philosophy are relevant to AI, such as epistemology and free will . [ 386 ] Rapid advancements have intensified public discussions on the philosophy and ethics of AI . [ 385 ] Defining artificial intelligence See also: Turing test , Intelligent agent , Dartmouth workshop , and Synthetic intelligence Alan Turing wrote in 1950 "I propose to consider the question 'can machines think'?" [ 387 ] He advised changing the question from whether a machine "thinks", to "whether or not it is possible for machinery to show intelligent behaviour". [ 387 ] He devised the Turing test, which measures the ability of a machine to simulate human conversation. [ 351 ] Since we can only observe the behavior of the machine, it does not matter if it is "actually" thinking or literally has a "mind". Turing notes that we can not determine these things about other people but "it is usual to have a polite convention that everyone thinks." [ 388 ] The Turing test can provide some evidence of intelligence, but it penalizes non-human intelligent behavior. [ 389 ] Russell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure. [ 1 ] However, they are critical that the test requires the machine to imitate humans. " Aeronautical engineering texts", they wrote, "do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons. ' " [ 390 ] AI founder John McCarthy agreed, writing that "Artificial intelligence is not, by definition, simulation of human intelligence". [ 391 ] McCarthy defines intelligence as "the computational part of the ability to achieve goals in the world". [ 392 ] Another AI founder, Marvin Minsky , similarly describes it as "the ability to solve hard problems". [ 393 ] The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals. [ 1 ] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the "intelligence" of the machine—and no other philosophical discussion is required, or may not even be possible. Another definition has been adopted by Google, [ 394 ] a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence. Some authors have suggested in practice, that the definition of AI is vague and difficult to define, with contention as to whether classical algorithms should be categorised as AI, [ 395 ] with many companies during the early 2020s AI boom using the term as a marketing buzzword , often even if they did "not actually use AI in a material way". [ 396 ] Evaluating approaches to AI No established unifying theory or paradigm has guided AI research for most of its history. [ aa ] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term "artificial intelligence" to mean "machine learning with neural networks"). This approach is mostly sub-symbolic , soft and narrow . Critics argue that these questions may have to be revisited by future generations of AI researchers. Symbolic AI and its limits Symbolic AI (or " GOFAI ") [ 398 ] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at "intelligent" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis : "A physical symbol system has the necessary and sufficient means of general intelligent action." [ 399 ] However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning . Moravec's paradox is the discovery that high-level "intelligent" tasks were easy for AI, but low level "instinctive" tasks were extremely difficult. [ 400 ] Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a "feel" for the situation, rather than explicit symbolic knowledge. [ 401 ] Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him. [ ab ] [ 16 ] The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias . Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, [ 403 ] [ 404 ] in part because sub-symbolic AI is a move away from explainable AI : it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches. Neat vs. scruffy Main article: Neats and scruffies "Neats" hope that intelligent behavior is described using simple, elegant principles (such as logic , optimization , or neural networks ). "Scruffies" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s, [ 405 ] but eventually was seen as irrelevant. Modern AI has elements of both. Soft vs. hard computing Main article: Soft computing Finding a provably correct or optimal solution is intractable for many important problems. [ 15 ] Soft computing is a set of techniques, including genetic algorithms , fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks. Narrow vs. general AI Main articles: Weak artificial intelligence and Artificial general intelligence AI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals. [ 406 ] [ 407 ] General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively. Machine consciousness, sentience, and mind Main articles: Philosophy of artificial intelligence and Artificial consciousness There is no settled consensus in philosophy of mind on whether a machine can have a mind , consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that "[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on." [ 408 ] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction . Consciousness Main articles: Hard problem of consciousness and Theory of mind David Chalmers identified two problems in understanding the mind, which he named the "hard" and "easy" problems of consciousness. [ 409 ] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like . [ 410 ] Computationalism and functionalism Main articles: Computational theory of mind and Functionalism (philosophy of mind) Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem . This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam . [ 411 ] Philosopher John Searle characterized this position as " strong AI ": "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds." [ ac ] Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind. [ 415 ] AI welfare and rights It is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree. [ 416 ] But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals. [ 417 ] [ 418 ] Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness ) may provide another moral basis for AI rights. [ 417 ] Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society. [ 419 ] In 2017, the European Union considered granting "electronic personhood" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities. [ 420 ] Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights , and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own. [ 421 ] [ 422 ] Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming , which could lead to large-scale suffering if sentient AI is created and carelessly exploited. [ 418 ] [ 417 ] Future Superintelligence and the singularity A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. [ 407 ] If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself . The improved software would be even better at improving itself, leading to what I. J. Good called an " intelligence explosion " and Vernor Vinge called a " singularity ". [ 423 ] However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve , slowing when they reach the physical limits of what the technology can do. [ 424 ] Transhumanism Main article: Transhumanism Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger . [ 425 ] Edward Fredkin argues that "artificial intelligence is the next step in evolution", an idea first proposed by Samuel Butler 's " Darwin among the Machines " as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence . [ 426 ] In fiction Main article: Artificial intelligence in fiction The word "robot" itself was coined by Karel Čapek in his 1921 play R.U.R. , the title standing for "Rossum's Universal Robots". Thought-capable artificial beings have appeared as storytelling devices since antiquity, [ 427 ] and have been a persistent theme in science fiction . [ 428 ] A common trope in these works began with Mary Shelley 's Frankenstein , where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000 , the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture. [ 429 ] Isaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the " Multivac " super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics; [ 430 ] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity. [ 431 ] Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel , and thus to suffer. This appears in Karel Čapek 's R.U.R. , the films A.I. Artificial Intelligence and Ex Machina , as well as the novel Do Androids Dream of Electric Sheep? , by Philip K. Dick . Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence. [ 432 ] See also Artificial consciousness – Field in cognitive science Artificial intelligence and elections – Use and impact of AI on political elections Artificial intelligence content detection – Software to detect AI-generated content Behavior selection algorithm – Algorithm that selects actions for intelligent agents Business process automation – Automation of business processes Case-based reasoning – Process of solving new problems based on the solutions of similar past problems Computational intelligence – Ability of a computer to learn a specific task from data or experimental observation Digital immortality – Hypothetical concept of storing a personality in digital form Emergent algorithm – Algorithm exhibiting emergent behavior Female gendering of AI technologies – Gender biases in digital technology Pages displaying short descriptions of redirect targets Glossary of artificial intelligence – List of definitions of terms and concepts commonly used in the study of artificial intelligence Intelligence amplification – Use of information technology to augment human intelligence Intelligent agent – Software agent which acts autonomously Intelligent automation – Software process that combines robotic process automation and artificial intelligence Mind uploading – Hypothetical process of digitally emulating a brain Organoid intelligence – Use of brain cells and brain organoids for intelligent computing Robotic process automation – Form of business process automation technology The Last Day – 1967 Welsh science fiction novel Wetware computer – Computer composed of organic material DARWIN EU - A European Union initiative coordinated by the European Medicines Agency (EMA) to generate and utilize real-world evidence (RWE) to support the evaluation and supervision of medicines across the EU. Explanatory notes ^ a b This list of intelligent traits is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2021) , Luger & Stubblefield (2004) , Poole, Mackworth & Goebel (1998) and Nilsson (1998) ^ a b This list of tools is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2021) , Luger & Stubblefield (2004) , Poole, Mackworth & Goebel (1998) and Nilsson (1998) ^ It is among the reasons that expert systems proved to be inefficient for capturing knowledge. [ 30 ] [ 31 ] ^ "Rational agent" is general term used in economics , philosophy and theoretical artificial intelligence. It can refer to anything that directs its behavior to accomplish goals, such as a person, an animal, a corporation, a nation, or in the case of AI, a computer program. ^ Alan Turing discussed the centrality of learning as early as 1950, in his classic paper " Computing Machinery and Intelligence ". [ 42 ] In 1956, at the original Dartmouth AI summer conference, Ray Solomonoff wrote a report on unsupervised probabilistic machine learning: "An Inductive Inference Machine". [ 43 ] ^ See AI winter § Machine translation and the ALPAC report of 1966 ^ Compared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be conditionally independent of one another. AdSense uses a Bayesian network with over 300 million edges to learn which ads to serve. [ 94 ] ^ Expectation–maximization, one of the most popular algorithms in machine learning, allows clustering in the presence of unknown latent variables . [ 96 ] ^ Some form of deep neural networks (without a specific learning algorithm) were described by: Warren S. McCulloch and Walter Pitts (1943) [ 117 ] Alan Turing (1948); [ 118 ] Karl Steinbuch and Roger David Joseph (1961). [ 119 ] Deep or recurrent networks that learned (or used gradient descent) were developed by: Frank Rosenblatt (1957); [ 118 ] Oliver Selfridge (1959); [ 119 ] Alexey Ivakhnenko and Valentin Lapa (1965); [ 120 ] Kaoru Nakano (1971); [ 121 ] Shun-Ichi Amari (1972); [ 121 ] John Joseph Hopfield (1982). [ 121 ] Precursors to backpropagation were developed by: Henry J. Kelley (1960); [ 118 ] Arthur E. Bryson (1962); [ 118 ] Stuart Dreyfus (1962); [ 118 ] Arthur E. Bryson and Yu-Chi Ho (1969); [ 118 ] Backpropagation was independently developed by: Seppo Linnainmaa (1970); [ 122 ] Paul Werbos (1974). [ 118 ] ^ Geoffrey Hinton said, of his work on neural networks in the 1990s, "our labeled datasets were thousands of times too small. [And] our computers were millions of times too slow." [ 123 ] ^ In statistics, a bias is a systematic error or deviation from the correct value. But in the context of fairness , it refers to a tendency in favor or against a certain group or individual characteristic, usually in a way that is considered unfair or harmful. A statistically unbiased AI system that produces disparate outcomes for different demographic groups may thus be viewed as biased in the ethical sense. [ 246 ] ^ Including Jon Kleinberg ( Cornell University ), Sendhil Mullainathan ( University of Chicago ), Cynthia Chouldechova ( Carnegie Mellon ) and Sam Corbett-Davis ( Stanford ) [ 255 ] ^ Moritz Hardt (a director at the Max Planck Institute for Intelligent Systems ) argues that machine learning "is fundamentally the wrong tool for a lot of domains, where you're trying to design interventions and mechanisms that change the world." [ 260 ] ^ When the law was passed in 2018, it still contained a form of this provision. ^ This is the United Nations ' definition, and includes things like land mines as well. [ 274 ] ^ See table 4; 9% is both the OECD average and the U.S. average. [ 285 ] ^ Sometimes called a " robopocalypse " [ 293 ] ^ "Electronic brain" was the term used by the press around this time. [ 347 ] [ 349 ] ^ Daniel Crevier wrote, "the conference is generally recognized as the official birthdate of the new science." [ 352 ] Russell and Norvig called the conference "the inception of artificial intelligence." [ 117 ] ^ Russell and Norvig wrote "for the next 20 years the field would be dominated by these people and their students." [ 353 ] ^ Russell and Norvig wrote, "it was astonishing whenever a computer did anything kind of smartish". [ 354 ] ^ The programs described are Arthur Samuel 's checkers program for the IBM 701 , Daniel Bobrow 's STUDENT , Newell and Simon 's Logic Theorist and Terry Winograd 's SHRDLU . ^ Russell and Norvig write: "in almost all cases, these early systems failed on more difficult problems" [ 358 ] ^ Embodied approaches to AI [ 365 ] were championed by Hans Moravec [ 366 ] and Rodney Brooks [ 367 ] and went by many names: Nouvelle AI . [ 367 ] Developmental robotics . [ 368 ] ^ Matteo Wong wrote in The Atlantic : "Whereas for decades, computer-science fields such as natural-language processing, computer vision, and robotics used extremely different methods, now they all use a programming method called "deep learning". As a result, their code and approaches have become more similar, and their models are easier to integrate into one another." [ 374 ] ^ Jack Clark wrote in Bloomberg : "After a half-decade of quiet breakthroughs in artificial intelligence, 2015 has been a landmark year. Computers are smarter and learning faster than ever", and noted that the number of software projects that use machine learning at Google increased from a "sporadic usage" in 2012 to more than 2,700 projects in 2015. [ 376 ] ^ Nils Nilsson wrote in 1983: "Simply put, there is wide disagreement in the field about what AI is all about." [ 397 ] ^ Daniel Crevier wrote that "time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier." [ 402 ] ^ Searle presented this definition of "Strong AI" in 1999. [ 412 ] Searle's original formulation was "The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states." [ 413 ] Strong AI is defined similarly by Russell and Norvig : "Stong AI – the assertion that machines that do so are actually thinking (as opposed to simulating thinking)." [ 414 ] References ^ a b c Russell & Norvig (2021) , pp. 1–4. ^ AI set to exceed human brain power Archived 2008-02-19 at the Wayback Machine CNN.com (July 26, 2006) ^ Kaplan, Andreas; Haenlein, Michael (2019). "Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence". Business Horizons . 62 : 15– 25. doi : 10.1016/j.bushor.2018.08.004 . ISSN 0007-6813 . S2CID 158433736 . ^ Russell & Norvig (2021 , §1.2). ^ "Tech companies want to build artificial general intelligence. But who decides when AGI is attained?" . AP News . 4 April 2024 . Retrieved 20 May 2025 . ^ a b Dartmouth workshop : Russell & Norvig (2021 , p. 18), McCorduck (2004 , pp. 111–136), NRC (1999 , pp. 200–201) The proposal: McCarthy et al. (1955) ^ a b Successful programs of the 1960s: McCorduck (2004 , pp. 243–252), Crevier (1993 , pp. 52–107), Moravec (1988 , p. 9), Russell & Norvig (2021 , pp. 19–21) ^ a b Funding initiatives in the early 1980s: Fifth Generation Project (Japan), Alvey (UK), Microelectronics and Computer Technology Corporation (US), Strategic Computing Initiative (US): McCorduck (2004 , pp. 426–441), Crevier (1993 , pp. 161–162, 197–203, 211, 240), Russell & Norvig (2021 , p. 23), NRC (1999 , pp. 210–211), Newquist (1994 , pp. 235–248) ^ a b First AI Winter , Lighthill report , Mansfield Amendment : Crevier (1993 , pp. 115–117), Russell & Norvig (2021 , pp. 21–22), NRC (1999 , pp. 212–213), Howe (1994) , Newquist (1994 , pp. 189–201) ^ a b Second AI Winter : Russell & Norvig (2021 , p. 24), McCorduck (2004 , pp. 430–435), Crevier (1993 , pp. 209–210), NRC (1999 , pp. 214–216), Newquist (1994 , pp. 301–318) ^ a b Deep learning revolution, AlexNet : Goldman (2022) , Russell & Norvig (2021 , p. 26), McKinsey (2018) ^ Toews (2023) . ^ Problem-solving, puzzle solving, game playing, and deduction: Russell & Norvig (2021 , chpt. 3–5), Russell & Norvig (2021 , chpt. 6) ( constraint satisfaction ), Poole, Mackworth & Goebel (1998 , chpt. 2, 3, 7, 9), Luger & Stubblefield (2004 , chpt. 3, 4, 6, 8), Nilsson (1998 , chpt. 7–12) ^ Uncertain reasoning: Russell & Norvig (2021 , chpt. 12–18), Poole, Mackworth & Goebel (1998 , pp. 345–395), Luger & Stubblefield (2004 , pp. 333–381), Nilsson (1998 , chpt. 7–12) ^ a b c Intractability and efficiency and the combinatorial explosion : Russell & Norvig (2021 , p. 21) ^ a b c Psychological evidence of the prevalence of sub-symbolic reasoning and knowledge: Kahneman (2011) , Dreyfus & Dreyfus (1986) , Wason & Shapiro (1966) , Kahneman, Slovic & Tversky (1982) ^ Knowledge representation and knowledge engineering : Russell & Norvig (2021 , chpt. 10), Poole, Mackworth & Goebel (1998 , pp. 23–46, 69–81, 169–233, 235–277, 281–298, 319–345), Luger & Stubblefield (2004 , pp. 227–243), Nilsson (1998 , chpt. 17.1–17.4, 18) ^ Smoliar & Zhang (1994) . ^ Neumann & Möller (2008) . ^ Kuperman, Reichley & Bailey (2006) . ^ McGarry (2005) . ^ Bertini, Del Bimbo & Torniai (2006) . ^ Russell & Norvig (2021) , pp. 272. ^ Representing categories and relations: Semantic networks , description logics , inheritance (including frames , and scripts ): Russell & Norvig (2021 , §10.2 & 10.5), Poole, Mackworth & Goebel (1998 , pp. 174–177), Luger & Stubblefield (2004 , pp. 248–258), Nilsson (1998 , chpt. 18.3) ^ Representing events and time: Situation calculus , event calculus , fluent calculus (including solving the frame problem ): Russell & Norvig (2021 , §10.3), Poole, Mackworth & Goebel (1998 , pp. 281–298), Nilsson (1998 , chpt. 18.2) ^ Causal calculus : Poole, Mackworth & Goebel (1998 , pp. 335–337) ^ Representing knowledge about knowledge: Belief calculus, modal logics : Russell & Norvig (2021 , §10.4), Poole, Mackworth & Goebel (1998 , pp. 275–277) ^ a b Default reasoning , Frame problem , default logic , non-monotonic logics , circumscription , closed world assumption , abduction : Russell & Norvig (2021 , §10.6), Poole, Mackworth & Goebel (1998 , pp. 248–256, 323–335), Luger & Stubblefield (2004 , pp. 335–363), Nilsson (1998 , ~18.3.3) (Poole et al. places abduction under "default reasoning". Luger et al. places this under "uncertain reasoning"). ^ a b Breadth of commonsense knowledge: Lenat & Guha (1989 , Introduction), Crevier (1993 , pp. 113–114), Moravec (1988 , p. 13), Russell & Norvig (2021 , pp. 241, 385, 982) ( qualification problem ) ^ Newquist (1994) , p. 296. ^ Crevier (1993) , pp. 204–208. ^ Russell & Norvig (2021) , p. 528. ^ Automated planning : Russell & Norvig (2021 , chpt. 11). ^ Automated decision making , Decision theory : Russell & Norvig (2021 , chpt. 16–18). ^ Classical planning : Russell & Norvig (2021 , Section 11.2). ^ Sensorless or "conformant" planning, contingent planning, replanning (a.k.a. online planning): Russell & Norvig (2021 , Section 11.5). ^ Uncertain preferences: Russell & Norvig (2021 , Section 16.7) Inverse reinforcement learning : Russell & Norvig (2021 , Section 22.6) ^ Information value theory : Russell & Norvig (2021 , Section 16.6). ^ Markov decision process : Russell & Norvig (2021 , chpt. 17). ^ Game theory and multi-agent decision theory: Russell & Norvig (2021 , chpt. 18). ^ Learning : Russell & Norvig (2021 , chpt. 19–22), Poole, Mackworth & Goebel (1998 , pp. 397–438), Luger & Stubblefield (2004 , pp. 385–542), Nilsson (1998 , chpt. 3.3, 10.3, 17.5, 20) ^ Turing (1950) . ^ Solomonoff (1956) . ^ Unsupervised learning : Russell & Norvig (2021 , pp. 653) (definition), Russell & Norvig (2021 , pp. 738–740) ( cluster analysis ), Russell & Norvig (2021 , pp. 846–860) ( word embedding ) ^ a b Supervised learning : Russell & Norvig (2021 , §19.2) (Definition), Russell & Norvig (2021 , Chpt. 19–20) (Techniques) ^ Reinforcement learning : Russell & Norvig (2021 , chpt. 22), Luger & Stubblefield (2004 , pp. 442–449) ^ Transfer learning : Russell & Norvig (2021 , pp. 281), The Economist (2016) ^ "Artificial Intelligence (AI): What Is AI and How Does It Work? | Built In" . builtin.com . Retrieved 30 October 2023 . ^ Computational learning theory : Russell & Norvig (2021 , pp. 672–674), Jordan & Mitchell (2015) ^ Natural language processing (NLP): Russell & Norvig (2021 , chpt. 23–24), Poole, Mackworth & Goebel (1998 , pp. 91–104), Luger & Stubblefield (2004 , pp. 591–632) ^ Subproblems of NLP : Russell & Norvig (2021 , pp. 849–850) ^ Russell & Norvig (2021) , pp. 856–858. ^ Dickson (2022) . ^ Modern statistical and deep learning approaches to NLP : Russell & Norvig (2021 , chpt. 24), Cambria & White (2014) ^ Vincent (2019) . ^ Russell & Norvig (2021) , pp. 875–878. ^ Bushwick (2023) . ^ Computer vision : Russell & Norvig (2021 , chpt. 25), Nilsson (1998 , chpt. 6) ^ Russell & Norvig (2021) , pp. 849–850. ^ Russell & Norvig (2021) , pp. 895–899. ^ Russell & Norvig (2021) , pp. 899–901. ^ Challa et al. (2011) . ^ Russell & Norvig (2021) , pp. 931–938. ^ MIT AIL (2014) . ^ Affective computing : Thro (1993) , Edelson (1991) , Tao & Tan (2005) , Scassellati (2002) ^ Waddell (2018) . ^ Poria et al. (2017) . ^ a b Artificial general intelligence : Russell & Norvig (2021 , pp. 32–33, 1020–1021) Proposal for the modern version: Pennachin & Goertzel (2007) Warnings of overspecialization in AI from leading researchers: Nilsson (1995) , McCarthy (2007) , Beal & Winston (2009) ^ Search algorithms : Russell & Norvig (2021 , chpts. 3–5), Poole, Mackworth & Goebel (1998 , pp. 113–163), Luger & Stubblefield (2004 , pp. 79–164, 193–219), Nilsson (1998 , chpts. 7–12) ^ State space search : Russell & Norvig (2021 , chpt. 3) ^ Russell & Norvig (2021) , sect. 11.2. ^ Uninformed searches ( breadth first search , depth-first search and general state space search ): Russell & Norvig (2021 , sect. 3.4), Poole, Mackworth & Goebel (1998 , pp. 113–132), Luger & Stubblefield (2004 , pp. 79–121), Nilsson (1998 , chpt. 8) ^ Heuristic or informed searches (e.g., greedy best first and A* ): Russell & Norvig (2021 , sect. 3.5), Poole, Mackworth & Goebel (1998 , pp. 132–147), Poole & Mackworth (2017 , sect. 3.6), Luger & Stubblefield (2004 , pp. 133–150) ^ Adversarial search : Russell & Norvig (2021 , chpt. 5) ^ Local or " optimization " search: Russell & Norvig (2021 , chpt. 4) ^ Singh Chauhan, Nagesh (18 December 2020). "Optimization Algorithms in Neural Networks" . KDnuggets . Retrieved 13 January 2024 . ^ Evolutionary computation : Russell & Norvig (2021 , sect. 4.1.2) ^ Merkle & Middendorf (2013) . ^ Logic : Russell & Norvig (2021 , chpts. 6–9), Luger & Stubblefield (2004 , pp. 35–77), Nilsson (1998 , chpt. 13–16) ^ Propositional logic : Russell & Norvig (2021 , chpt. 6), Luger & Stubblefield (2004 , pp. 45–50), Nilsson (1998 , chpt. 13) ^ First-order logic and features such as equality : Russell & Norvig (2021 , chpt. 7), Poole, Mackworth & Goebel (1998 , pp. 268–275), Luger & Stubblefield (2004 , pp. 50–62), Nilsson (1998 , chpt. 15) ^ Logical inference : Russell & Norvig (2021 , chpt. 10) ^ logical deduction as search: Russell & Norvig (2021 , sects. 9.3, 9.4), Poole, Mackworth & Goebel (1998 , pp. ~46–52), Luger & Stubblefield (2004 , pp. 62–73), Nilsson (1998 , chpt. 4.2, 7.2) ^ Resolution and unification : Russell & Norvig (2021 , sections 7.5.2, 9.2, 9.5) ^ Warren, D.H.; Pereira, L.M.; Pereira, F. (1977). "Prolog-the language and its implementation compared with Lisp". ACM SIGPLAN Notices . 12 (8): 109– 115. doi : 10.1145/872734.806939 . ^ Fuzzy logic: Russell & Norvig (2021 , pp. 214, 255, 459), Scientific American (1999) ^ a b Stochastic methods for uncertain reasoning: Russell & Norvig (2021 , chpt. 12–18, 20), Poole, Mackworth & Goebel (1998 , pp. 345–395), Luger & Stubblefield (2004 , pp. 165–191, 333–381), Nilsson (1998 , chpt. 19) ^ decision theory and decision analysis : Russell & Norvig (2021 , chpt. 16–18), Poole, Mackworth & Goebel (1998 , pp. 381–394) ^ Information value theory : Russell & Norvig (2021 , sect. 16.6) ^ Markov decision processes and dynamic decision networks : Russell & Norvig (2021 , chpt. 17) ^ a b c Stochastic temporal models: Russell & Norvig (2021 , chpt. 14) Hidden Markov model : Russell & Norvig (2021 , sect. 14.3) Kalman filters : Russell & Norvig (2021 , sect. 14.4) Dynamic Bayesian networks : Russell & Norvig (2021 , sect. 14.5) ^ Game theory and mechanism design : Russell & Norvig (2021 , chpt. 18) ^ Bayesian networks : Russell & Norvig (2021 , sects. 12.5–12.6, 13.4–13.5, 14.3–14.5, 16.5, 20.2–20.3), Poole, Mackworth & Goebel (1998 , pp. 361–381), Luger & Stubblefield (2004 , pp. ~182–190, ≈363–379), Nilsson (1998 , chpt. 19.3–19.4) ^ Domingos (2015) , chpt. 6. ^ Bayesian inference algorithm: Russell & Norvig (2021 , sect. 13.3–13.5), Poole, Mackworth & Goebel (1998 , pp. 361–381), Luger & Stubblefield (2004 , pp. ~363–379), Nilsson (1998 , chpt. 19.4 & 7) ^ Domingos (2015) , p. 210. ^ Bayesian learning and the expectation–maximization algorithm : Russell & Norvig (2021 , chpt. 20), Poole, Mackworth & Goebel (1998 , pp. 424–433), Nilsson (1998 , chpt. 20), Domingos (2015 , p. 210) ^ Bayesian decision theory and Bayesian decision networks : Russell & Norvig (2021 , sect. 16.5) ^ Statistical learning methods and classifiers : Russell & Norvig (2021 , chpt. 20), ^ Ciaramella, Alberto ; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI . Intellisemantic Editions. ISBN 978-8-8947-8760-3 . ^ Decision trees : Russell & Norvig (2021 , sect. 19.3), Domingos (2015 , p. 88) ^ Non-parameteric learning models such as K-nearest neighbor and support vector machines : Russell & Norvig (2021 , sect. 19.7), Domingos (2015 , p. 187) (k-nearest neighbor) Domingos (2015 , p. 88) (kernel methods) ^ Domingos (2015) , p. 152. ^ Naive Bayes classifier : Russell & Norvig (2021 , sect. 12.6), Domingos (2015 , p. 152) ^ a b Neural networks: Russell & Norvig (2021 , chpt. 21), Domingos (2015 , Chapter 4) ^ Gradient calculation in computational graphs, backpropagation , automatic differentiation : Russell & Norvig (2021 , sect. 21.2), Luger & Stubblefield (2004 , pp. 467–474), Nilsson (1998 , chpt. 3.3) ^ Universal approximation theorem : Russell & Norvig (2021 , p. 752) The theorem: Cybenko (1988) , Hornik, Stinchcombe & White (1989) ^ Feedforward neural networks : Russell & Norvig (2021 , sect. 21.1) ^ Recurrent neural networks : Russell & Norvig (2021 , sect. 21.6) ^ Perceptrons : Russell & Norvig (2021 , pp. 21, 22, 683, 22) ^ a b Deep learning : Russell & Norvig (2021 , chpt. 21), Goodfellow, Bengio & Courville (2016) , Hinton et al. (2016) , Schmidhuber (2015) ^ Convolutional neural networks : Russell & Norvig (2021 , sect. 21.3) ^ Sindhu V, Nivedha S, Prakash M (February 2020). "An Empirical Science Research on Bioinformatics in Machine Learning" . Journal of Mechanics of Continua and Mathematical Sciences (7). doi : 10.26782/jmcms.spl.7/2020.02.00006 . ^ Deng & Yu (2014) , pp. 199–200. ^ Ciresan, Meier & Schmidhuber (2012) . ^ Russell & Norvig (2021) , p. 750. ^ a b c Russell & Norvig (2021) , p. 17. ^ a b c d e f g Russell & Norvig (2021) , p. 785. ^ a b Schmidhuber (2022) , sect. 5. ^ Schmidhuber (2022) , sect. 6. ^ a b c Schmidhuber (2022) , sect. 7. ^ Schmidhuber (2022) , sect. 8. ^ Quoted in Christian (2020 , p. 22) ^ Metz, Cade; Weise, Karen (5 May 2025). "A.I. Hallucinations Are Getting Worse, Even as New Systems Become More Powerful" . The New York Times . ISSN 0362-4331 . Retrieved 6 May 2025 . ^ Smith (2023) . ^ "Explained: Generative AI" . 9 November 2023. ^ "AI Writing and Content Creation Tools" . MIT Sloan Teaching & Learning Technologies. Archived from the original on 25 December 2023 . Retrieved 25 December 2023 . ^ Marmouyet (2023) . ^ Kobielus (2019) . ^ Thomason, James (21 May 2024). "Mojo Rising: The resurgence of AI-first programming languages" . VentureBeat . Archived from the original on 27 June 2024 . Retrieved 26 May 2024 . ^ Wodecki, Ben (5 May 2023). "7 AI Programming Languages You Need to Know" . AI Business . Archived from the original on 25 July 2024 . Retrieved 5 October 2024 . ^ Plumb, Taryn (18 September 2024). "Why Jensen Huang and Marc Benioff see 'gigantic' opportunity for agentic AI" . VentureBeat . Archived from the original on 5 October 2024 . Retrieved 4 October 2024 . ^ Mims, Christopher (19 September 2020). "Huang's Law Is the New Moore's Law, and Explains Why Nvidia Wants Arm" . Wall Street Journal . ISSN 0099-9660 . Archived from the original on 2 October 2023 . Retrieved 19 January 2025 . ^ Davenport, T; Kalakota, R (June 2019). "The potential for artificial intelligence in healthcare" . Future Healthc J . 6 (2): 94– 98. doi : 10.7861/futurehosp.6-2-94 . PMC 6616181 . PMID 31363513 . ^ Lyakhova, U.A.; Lyakhov, P.A. (2024). "Systematic review of approaches to detection and classification of skin cancer using artificial intelligence: Development and prospects" . Computers in Biology and Medicine . 178 : 108742. doi : 10.1016/j.compbiomed.2024.108742 . PMID 38875908 . Archived from the original on 3 December 2024 . Retrieved 10 October 2024 . ^ Alqudaihi, Kawther S.; Aslam, Nida; Khan, Irfan Ullah; Almuhaideb, Abdullah M.; Alsunaidi, Shikah J.; Ibrahim, Nehad M. Abdel Rahman; Alhaidari, Fahd A.; Shaikh, Fatema S.; Alsenbel, Yasmine M.; Alalharith, Dima M.; Alharthi, Hajar M.; Alghamdi, Wejdan M.; Alshahrani, Mohammed S. (2021). "Cough Sound Detection and Diagnosis Using Artificial Intelligence Techniques: Challenges and Opportunities" . IEEE Access . 9 : 102327– 102344. Bibcode : 2021IEEEA...9j2327A . doi : 10.1109/ACCESS.2021.3097559 . ISSN 2169-3536 . PMC 8545201 . PMID 34786317 . ^ a b Bax, Monique; Thorpe, Jordan; Romanov, Valentin (December 2023). "The future of personalized cardiovascular medicine demands 3D and 4D printing, stem cells, and artificial intelligence" . Frontiers in Sensors . 4 . doi : 10.3389/fsens.2023.1294721 . ISSN 2673-5067 . ^ Dankwa-Mullan, Irene (2024). "Health Equity and Ethical Considerations in Using Artificial Intelligence in Public Health and Medicine" . Preventing Chronic Disease . 21 : E64. doi : 10.5888/pcd21.240245 . ISSN 1545-1151 . PMC 11364282 . PMID 39173183 . ^ Jumper, J; Evans, R; Pritzel, A (2021). "Highly accurate protein structure prediction with AlphaFold" . Nature . 596 (7873): 583– 589. Bibcode : 2021Natur.596..583J . doi : 10.1038/s41586-021-03819-2 . PMC 8371605 . PMID 34265844 . ^ "AI discovers new class of antibiotics to kill drug-resistant bacteria" . 20 December 2023. Archived from the original on 16 September 2024 . Retrieved 5 October 2024 . ^ "AI speeds up drug design for Parkinson's ten-fold" . Cambridge University. 17 April 2024. Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ Horne, Robert I.; Andrzejewska, Ewa A.; Alam, Parvez; Brotzakis, Z. Faidon; Srivastava, Ankit; Aubert, Alice; Nowinska, Magdalena; Gregory, Rebecca C.; Staats, Roxine; Possenti, Andrea; Chia, Sean; Sormanni, Pietro; Ghetti, Bernardino; Caughey, Byron; Knowles, Tuomas P. J.; Vendruscolo, Michele (17 April 2024). "Discovery of potent inhibitors of α-synuclein aggregation using structure-based iterative learning" . Nature Chemical Biology . 20 (5). Nature: 634– 645. doi : 10.1038/s41589-024-01580-x . PMC 11062903 . PMID 38632492 . ^ Grant, Eugene F.; Lardner, Rex (25 July 1952). "The Talk of the Town – It" . The New Yorker . ISSN 0028-792X . Archived from the original on 16 February 2020 . Retrieved 28 January 2024 . ^ Anderson, Mark Robert (11 May 2017). "Twenty years on from Deep Blue vs Kasparov: how a chess match started the big data revolution" . The Conversation . Archived from the original on 17 September 2024 . Retrieved 28 January 2024 . ^ Markoff, John (16 February 2011). "Computer Wins on 'Jeopardy!': Trivial, It's Not" . The New York Times . ISSN 0362-4331 . Archived from the original on 22 October 2014 . Retrieved 28 January 2024 . ^ Byford, Sam (27 May 2017). "AlphaGo retires from competitive Go after defeating world number one 3–0" . The Verge . Archived from the original on 7 June 2017 . Retrieved 28 January 2024 . ^ Brown, Noam; Sandholm, Tuomas (30 August 2019). "Superhuman AI for multiplayer poker" . Science . 365 (6456): 885– 890. Bibcode : 2019Sci...365..885B . doi : 10.1126/science.aay2400 . ISSN 0036-8075 . PMID 31296650 . ^ "MuZero: Mastering Go, chess, shogi and Atari without rules" . Google DeepMind . 23 December 2020 . Retrieved 28 January 2024 . ^ Sample, Ian (30 October 2019). "AI becomes grandmaster in 'fiendishly complex' StarCraft II" . The Guardian . ISSN 0261-3077 . Archived from the original on 29 December 2020 . Retrieved 28 January 2024 . ^ Wurman, P. R.; Barrett, S.; Kawamoto, K. (2022). "Outracing champion Gran Turismo drivers with deep reinforcement learning" (PDF) . Nature . 602 (7896): 223– 228. Bibcode : 2022Natur.602..223W . doi : 10.1038/s41586-021-04357-7 . PMID 35140384 . ^ Wilkins, Alex (13 March 2024). "Google AI learns to play open-world video games by watching them" . New Scientist . Archived from the original on 26 July 2024 . Retrieved 21 July 2024 . ^ Wu, Zhengxuan; Arora, Aryaman; Wang, Zheng; Geiger, Atticus; Jurafsky, Dan; Manning, Christopher D.; Potts, Christopher (2024). "ReFT: Representation Finetuning for Language Models". NeurIPS . arXiv : 2404.03592 . ^ "Improving mathematical reasoning with process supervision" . OpenAI . 31 May 2023 . Retrieved 26 January 2025 . ^ Srivastava, Saurabh (29 February 2024). "Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap". arXiv : 2402.19450 [ cs.AI ]. ^ Lightman, Hunter; Kosaraju, Vineet; Burda, Yura; Edwards, Harri; Baker, Bowen; Lee, Teddy; Leike, Jan; Schulman, John; Sutskever, Ilya; Cobbe, Karl (2023). "Let's Verify Step by Step". arXiv : 2305.20050v1 [ cs.LG ]. ^ Franzen, Carl (8 August 2024). "Alibaba claims no. 1 spot in AI math models with Qwen2-Math" . VentureBeat . Retrieved 16 February 2025 . ^ Franzen, Carl (9 January 2025). "Microsoft's new rStar-Math technique upgrades small models to outperform OpenAI's o1-preview at math problems" . VentureBeat . Retrieved 26 January 2025 . ^ Gina Genkina: New AI Model Advances the “Kissing Problem” and More. AlphaEvolve made several mathematical discoveries and practical optimizations IEEE Spectrum 2025-05-14. Retrieved 2025-06-07 ^ Roberts, Siobhan (25 July 2024). "AI achieves silver-medal standard solving International Mathematical Olympiad problems" . The New York Times . Archived from the original on 26 September 2024 . Retrieved 7 August 2024 . ^ Azerbayev, Zhangir; Schoelkopf, Hailey; Paster, Keiran; Santos, Marco Dos; McAleer', Stephen; Jiang, Albert Q.; Deng, Jia; Biderman, Stella; Welleck, Sean (16 October 2023). "Llemma: An Open Language Model For Mathematics" . EleutherAI Blog . Retrieved 26 January 2025 . ^ "Julius AI" . julius.ai . ^ McFarland, Alex (12 July 2024). "8 Best AI for Math Tools (January 2025)" . Unite.AI . Retrieved 26 January 2025 . ^ Matthew Finio & Amanda Downie: IBM Think 2024 Primer, "What is Artificial Intelligence (AI) in Finance?" 8 Dec. 2023 ^ M. Nicolas, J. Firzli: Pensions Age / European Pensions magazine, "Artificial Intelligence: Ask the Industry", May–June 2024. https://videovoice.org/ai-in-finance-innovation-entrepreneurship-vs-over-regulation-with-the-eus-artificial-intelligence-act-wont-work-as-intended/ Archived 11 September 2024 at the Wayback Machine . ^ a b c Congressional Research Service (2019). Artificial Intelligence and National Security (PDF) . Washington, DC: Congressional Research Service. Archived (PDF) from the original on 8 May 2020 . Retrieved 25 February 2024 . PD-notice ^ a b Slyusar, Vadym (2019). Artificial intelligence as the basis of future control networks (Preprint). doi : 10.13140/RG.2.2.30247.50087 . ^ Iraqi, Amjad (3 April 2024). " 'Lavender': The AI machine directing Israel's bombing spree in Gaza" . +972 Magazine . Archived from the original on 10 October 2024 . Retrieved 6 April 2024 . ^ Davies, Harry; McKernan, Bethan; Sabbagh, Dan (1 December 2023). " 'The Gospel': how Israel uses AI to select bombing targets in Gaza" . The Guardian . Archived from the original on 6 December 2023 . Retrieved 4 December 2023 . ^ Marti, J Werner (10 August 2024). "Drohnen haben den Krieg in der Ukraine revolutioniert, doch sie sind empfindlich auf Störsender – deshalb sollen sie jetzt autonom operieren" . Neue Zürcher Zeitung (in German). Archived from the original on 10 August 2024 . Retrieved 10 August 2024 . ^ Newsom, Gavin; Weber, Shirley N. (5 September 2023). "Executive Order N-12-23" (PDF) . Executive Department, State of California. Archived (PDF) from the original on 21 February 2024 . Retrieved 7 September 2023 . ^ Pinaya, Walter H. L.; Graham, Mark S.; Kerfoot, Eric; Tudosiu, Petru-Daniel; Dafflon, Jessica; Fernandez, Virginia; Sanchez, Pedro; Wolleb, Julia; da Costa, Pedro F.; Patel, Ashay (2023). "Generative AI for Medical Imaging: extending the MONAI Framework". arXiv : 2307.15208 [ eess.IV ]. ^ "What is ChatGPT, DALL-E, and generative AI?" . McKinsey . Archived from the original on 23 April 2023 . Retrieved 14 December 2024 . ^ "What is generative AI?" . IBM . 22 March 2024. Archived from the original on 13 December 2024 . Retrieved 13 December 2024 . ^ Pasick, Adam (27 March 2023). "Artificial Intelligence Glossary: Neural Networks and Other Terms Explained" . The New York Times . ISSN 0362-4331 . Archived from the original on 1 September 2023 . Retrieved 22 April 2023 . ^ Karpathy, Andrej; Abbeel, Pieter; Brockman, Greg; Chen, Peter; Cheung, Vicki; Duan, Yan; Goodfellow, Ian; Kingma, Durk; Ho, Jonathan; Rein Houthooft; Tim Salimans; John Schulman; Ilya Sutskever; Wojciech Zaremba (16 June 2016). "Generative models" . OpenAI. Archived from the original on 17 November 2023 . Retrieved 15 March 2023 . ^ a b Griffith, Erin; Metz, Cade (27 January 2023). "Anthropic Said to Be Closing In on $300 Million in New A.I. Funding" . The New York Times . Archived from the original on 9 December 2023 . Retrieved 14 March 2023 . ^ Lanxon, Nate; Bass, Dina; Davalos, Jackie (10 March 2023). "A Cheat Sheet to AI Buzzwords and Their Meanings" . Bloomberg News . Archived from the original on 17 November 2023 . Retrieved 14 March 2023 . ^ Metz, Cade (14 March 2023). "OpenAI Plans to Up the Ante in Tech's A.I. Race" . The New York Times . ISSN 0362-4331 . Archived from the original on 31 March 2023 . Retrieved 31 March 2023 . ^ Thoppilan, Romal; De Freitas, Daniel; Hall, Jamie; Shazeer, Noam; Kulshreshtha, Apoorv (20 January 2022). "LaMDA: Language Models for Dialog Applications". arXiv : 2201.08239 [ cs.CL ]. ^ Roose, Kevin (21 October 2022). "A Coming-Out Party for Generative A.I., Silicon Valley's New Craze" . The New York Times . Archived from the original on 15 February 2023 . Retrieved 14 March 2023 . ^ Metz, Cade (15 February 2024). "OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos" . The New York Times . ISSN 0362-4331 . Archived from the original on 15 February 2024 . Retrieved 16 February 2024 . ^ "The race of the AI labs heats up" . The Economist . 30 January 2023. Archived from the original on 17 November 2023 . Retrieved 14 March 2023 . ^ Yang, June; Gokturk, Burak (14 March 2023). "Google Cloud brings generative AI to developers, businesses, and governments" . Archived from the original on 17 November 2023 . Retrieved 15 March 2023 . ^ Simon, Felix M.; Altay, Sacha; Mercier, Hugo (18 October 2023). "Misinformation reloaded? Fears about the impact of generative AI on misinformation are overblown" (PDF) . Harvard Kennedy School Misinformation Review . doi : 10.37016/mr-2020-127 . S2CID 264113883 . Retrieved 16 November 2023 . ^ Hendrix, Justin (16 May 2023). "Transcript: Senate Judiciary Subcommittee Hearing on Oversight of AI" . techpolicy.press . Archived from the original on 17 November 2023 . Retrieved 19 May 2023 . ^ "New AI systems collide with copyright law" . BBC News . 1 August 2023 . Retrieved 28 September 2024 . ^ Poole, David; Mackworth, Alan (2023). Artificial Intelligence, Foundations of Computational Agents (3rd ed.). Cambridge University Press. doi : 10.1017/9781009258227 . ISBN 978-1-0092-5819-7 . Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ Russell, Stuart; Norvig, Peter (2020). Artificial Intelligence: A Modern Approach (4th ed.). Pearson. ISBN 978-0-1346-1099-3 . ^ "Why agents are the next frontier of generative AI" . McKinsey Digital . 24 July 2024. Archived from the original on 3 October 2024 . Retrieved 10 August 2024 . ^ Figueiredo, Mayara Costa; Ankrah, Elizabeth; Powell, Jacquelyn E.; Epstein, Daniel A.; Chen, Yunan (12 January 2024). "Powered by AI: Examining How AI Descriptions Influence Perceptions of Fertility Tracking Applications" . Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies . 7 (4): 1– 24. doi : 10.1145/3631414 . ^ Power, Jennifer; Pym, Tinonee; James, Alexandra; Waling, Andrea (5 July 2024). "Smart Sex Toys: A Narrative Review of Recent Research on Cultural, Health and Safety Considerations" . Current Sexual Health Reports . 16 (3): 199– 215. doi : 10.1007/s11930-024-00392-3 . ISSN 1548-3592 . ^ Marcantonio, Tiffany L.; Avery, Gracie; Thrash, Anna; Leone, Ruschelle M. (10 September 2024). "Large Language Models in an App: Conducting a Qualitative Synthetic Data Analysis of How Snapchat's "My AI" Responds to Questions About Sexual Consent, Sexual Refusals, Sexual Assault, and Sexting" . The Journal of Sex Research : 1– 15. doi : 10.1080/00224499.2024.2396457 . ISSN 0022-4499 . PMC 11891083. PMID 39254628 . Archived from the original on 9 December 2024 . Retrieved 9 December 2024 . ^ Hanson, Kenneth R.; Bolthouse, Hannah (2024). " "Replika Removing Erotic Role-Play Is Like Grand Theft Auto Removing Guns or Cars": Reddit Discourse on Artificial Intelligence Chatbots and Sexual Technologies" . Socius: Sociological Research for a Dynamic World . 10 . doi : 10.1177/23780231241259627 . ISSN 2378-0231 . ^ Mania, Karolina (1 January 2024). "Legal Protection of Revenge and Deepfake Porn Victims in the European Union: Findings From a Comparative Legal Study" . Trauma, Violence, & Abuse . 25 (1): 117– 129. doi : 10.1177/15248380221143772 . ISSN 1524-8380 . PMID 36565267 . ^ Singh, Suyesha; Nambiar, Vaishnavi (2024). "Role of Artificial Intelligence in the Prevention of Online Child Sexual Abuse: A Systematic Review of Literature" . Journal of Applied Security Research . 19 (4): 586– 627. doi : 10.1080/19361610.2024.2331885 . ISSN 1936-1610 . Archived from the original on 9 December 2024 . Retrieved 9 December 2024 . ^ Razi, Afsaneh; Kim, Seunghyun; Alsoubai, Ashwaq; Stringhini, Gianluca; Solorio, Thamar; De Choudhury, Munmun ; Wisniewski, Pamela J. (13 October 2021). "A Human-Centered Systematic Literature Review of the Computational Approaches for Online Sexual Risk Detection" . Proceedings of the ACM on Human-Computer Interaction . 5 (CSCW2): 1– 38. doi : 10.1145/3479609 . ISSN 2573-0142 . Archived from the original on 9 December 2024 . Retrieved 9 December 2024 . ^ Ransbotham, Sam; Kiron, David; Gerbert, Philipp; Reeves, Martin (6 September 2017). "Reshaping Business With Artificial Intelligence" . MIT Sloan Management Review . Archived from the original on 13 February 2024. ^ Sun, Yuran; Zhao, Xilei; Lovreglio, Ruggiero; Kuligowski, Erica (1 January 2024), Naser, M. Z. (ed.), "8 – AI for large-scale evacuation modeling: promises and challenges" , Interpretable Machine Learning for the Analysis, Design, Assessment, and Informed Decision Making for Civil Infrastructure , Woodhead Publishing Series in Civil and Structural Engineering, Woodhead Publishing, pp. 185– 204, ISBN 978-0-1282-4073-1 , archived from the original on 19 May 2024 , retrieved 28 June 2024 . ^ Gomaa, Islam; Adelzadeh, Masoud; Gwynne, Steven; Spencer, Bruce; Ko, Yoon; Bénichou, Noureddine; Ma, Chunyun; Elsagan, Nour; Duong, Dana; Zalok, Ehab; Kinateder, Max (1 November 2021). "A Framework for Intelligent Fire Detection and Evacuation System" . Fire Technology . 57 (6): 3179– 3185. doi : 10.1007/s10694-021-01157-3 . ISSN 1572-8099 . Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ Zhao, Xilei; Lovreglio, Ruggiero; Nilsson, Daniel (1 May 2020). "Modelling and interpreting pre-evacuation decision-making using machine learning" . Automation in Construction . 113 : 103140. doi : 10.1016/j.autcon.2020.103140 . hdl : 10179/17315 . ISSN 0926-5805 . Archived from the original on 19 May 2024 . Retrieved 5 October 2024 . ^ "India's latest election embraced AI technology. Here are some ways it was used constructively" . PBS News . 12 June 2024. Archived from the original on 17 September 2024 . Retrieved 28 October 2024 . ^ Müller, Vincent C. (30 April 2020). "Ethics of Artificial Intelligence and Robotics" . Stanford Encyclopedia of Philosophy Archive . Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ Simonite (2016) . ^ Russell & Norvig (2021) , p. 987. ^ Laskowski (2023) . ^ GAO (2022) . ^ Valinsky (2019) . ^ Russell & Norvig (2021) , p. 991. ^ Russell & Norvig (2021) , pp. 991–992. ^ Christian (2020) , p. 63. ^ Vincent (2022) . ^ Kopel, Matthew. "Copyright Services: Fair Use" . Cornell University Library . Archived from the original on 26 September 2024 . Retrieved 26 April 2024 . ^ Burgess, Matt. "How to Stop Your Data From Being Used to Train AI" . Wired . ISSN 1059-1028 . Archived from the original on 3 October 2024 . Retrieved 26 April 2024 . ^ Reisner (2023) . ^ Alter & Harris (2023) . ^ "Getting the Innovation Ecosystem Ready for AI. An IP policy toolkit" (PDF) . WIPO . ^ Hammond, George (27 December 2023). "Big Tech is spending more than VC firms on AI startups" . Ars Technica . Archived from the original on 10 January 2024. ^ Wong, Matteo (24 October 2023). "The Future of AI Is GOMA" . The Atlantic . Archived from the original on 5 January 2024. ^ "Big tech and the pursuit of AI dominance" . The Economist . 26 March 2023. Archived from the original on 29 December 2023. ^ Fung, Brian (19 December 2023). "Where the battle to dominate AI may be won" . CNN Business . Archived from the original on 13 January 2024. ^ Metz, Cade (5 July 2023). "In the Age of A.I., Tech's Little Guys Need Big Friends" . The New York Times . Archived from the original on 8 July 2024 . Retrieved 5 October 2024 . ^ "Electricity 2024 – Analysis" . IEA . 24 January 2024 . Retrieved 13 July 2024 . ^ Calvert, Brian (28 March 2024). "AI already uses as much energy as a small country. It's only the beginning" . Vox . New York, New York. Archived from the original on 3 July 2024 . Retrieved 5 October 2024 . ^ Halper, Evan; O'Donovan, Caroline (21 June 2024). "AI is exhausting the power grid. Tech firms are seeking a miracle solution" . Washington Post . ^ Davenport, Carly. "AI Data Centers and the Coming YS Power Demand Surge" (PDF) . Goldman Sachs . Archived from the original (PDF) on 26 July 2024 . Retrieved 5 October 2024 . ^ Ryan, Carol (12 April 2024). "Energy-Guzzling AI Is Also the Future of Energy Savings" . Wall Street Journal . Dow Jones. ^ Hiller, Jennifer (1 July 2024). "Tech Industry Wants to Lock Up Nuclear Power for AI" . Wall Street Journal . Dow Jones. Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ Kendall, Tyler (28 September 2024). "Nvidia's Huang Says Nuclear Power an Option to Feed Data Centers" . Bloomberg . ^ Halper, Evan (20 September 2024). "Microsoft deal would reopen Three Mile Island nuclear plant to power AI" . Washington Post . ^ Hiller, Jennifer (20 September 2024). "Three Mile Island's Nuclear Plant to Reopen, Help Power Microsoft's AI Centers" . Wall Street Journal . Dow Jones. Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ a b c Niva Yadav (19 August 2024). "Taiwan to stop large data centers in the North, cites insufficient power" . DatacenterDynamics. Archived from the original on 8 November 2024 . Retrieved 7 November 2024 . ^ a b Mochizuki, Takashi; Oda, Shoko (18 October 2024). "エヌビディア出資の日本企業、原発近くでＡＩデータセンター新設検討" . Bloomberg (in Japanese). Archived from the original on 8 November 2024 . Retrieved 7 November 2024 . ^ a b Naureen S Malik and Will Wade (5 November 2024). "Nuclear-Hungry AI Campuses Need New Plan to Find Power Fast" . Bloomberg. ^ "Energy and AI Executive summary" . International Energy Agency . Retrieved 10 April 2025 . ^ Nicas (2018) . ^ Rainie, Lee; Keeter, Scott; Perrin, Andrew (22 July 2019). "Trust and Distrust in America" . Pew Research Center . Archived from the original on 22 February 2024. ^ Kosoff, Maya (8 February 2018). "YouTube Struggles to Contain Its Conspiracy Problem" . Vanity Fair . Retrieved 10 April 2025 . ^ Berry, David M. (19 March 2025). "Synthetic media and computational capitalism: towards a critical theory of artificial intelligence" . AI & Society . doi : 10.1007/s00146-025-02265-2 . ISSN 1435-5655 . ^ "Unreal: A quantum leap in AI video" . The Week . 17 June 2025 . Retrieved 20 June 2025 . ^ Snow, Jackie. "AI video is getting real. Beware what comes next" . Quartz . Retrieved 20 June 2025 . ^ Chow, Andrew R.; Perrigo, Billy (3 June 2025). "Google's Veo 3 Can Make Deepfakes of Riots, Election Fraud, Conflict" . Time . Retrieved 20 June 2025 . ^ Williams (2023) . ^ Olanipekun, Samson Olufemi (2025). "Computational propaganda and misinformation: AI technologies as tools of media manipulation" . World Journal of Advanced Research and Reviews . 25 (1): 911– 923. doi : 10.30574/wjarr.2025.25.1.0131 . ISSN 2581-9615 . ^ Taylor & Hern (2023) . ^ "To fight AI, we need 'personhood credentials,' say AI firms" . Archived from the original on 24 April 2025 . Retrieved 9 May 2025 . ^ a b Samuel, Sigal (19 April 2022). "Why it's so damn hard to make AI fair and unbiased" . Vox . Archived from the original on 5 October 2024 . Retrieved 24 July 2024 . ^ a b Rose (2023) . ^ CNA (2019) . ^ Goffrey (2008) , p. 17. ^ Berdahl et al. (2023) ; Goffrey (2008 , p. 17); Rose (2023) ; Russell & Norvig (2021 , p. 995) ^ Christian (2020) , p. 25. ^ a b Russell & Norvig (2021) , p. 995. ^ Grant & Hill (2023) . ^ Larson & Angwin (2016) . ^ Christian (2020) , p. 67–70. ^ Christian (2020 , pp. 67–70); Russell & Norvig (2021 , pp. 993–994) ^ Russell & Norvig (2021 , p. 995); Lipartito (2011 , p. 36); Goodman & Flaxman (2017 , p. 6); Christian (2020 , pp. 39–40, 65) ^ Quoted in Christian (2020 , p. 65). ^ Russell & Norvig (2021 , p. 994); Christian (2020 , pp. 40, 80–81) ^ Quoted in Christian (2020 , p. 80) ^ Dockrill (2022) . ^ Sample (2017) . ^ "Black Box AI" . 16 June 2023. Archived from the original on 15 June 2024 . Retrieved 5 October 2024 . ^ Christian (2020) , p. 110. ^ Christian (2020) , pp. 88–91. ^ Christian (2020 , p. 83); Russell & Norvig (2021 , p. 997) ^ Christian (2020) , p. 91. ^ Christian (2020) , p. 83. ^ Verma (2021) . ^ Rothman (2020) . ^ Christian (2020) , pp. 105–108. ^ Christian (2020) , pp. 108–112. ^ Ropek, Lucas (21 May 2024). "New Anthropic Research Sheds Light on AI's 'Black Box' " . Gizmodo . Archived from the original on 5 October 2024 . Retrieved 23 May 2024 . ^ Russell & Norvig (2021) , p. 989. ^ a b Russell & Norvig (2021) , pp. 987–990. ^ Russell & Norvig (2021) , p. 988. ^ Robitzski (2018) ; Sainato (2015) ^ Harari (2018) . ^ Buckley, Chris; Mozur, Paul (22 May 2019). "How China Uses High-Tech Surveillance to Subdue Minorities" . The New York Times . Archived from the original on 25 November 2019 . Retrieved 2 July 2019 . ^ "Security lapse exposed a Chinese smart city surveillance system" . 3 May 2019. Archived from the original on 7 March 2021 . Retrieved 14 September 2020 . ^ Urbina et al. (2022) . ^ a b E. McGaughey, 'Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy' (2022), 51(3) Industrial Law Journal 511–559 . Archived 27 May 2023 at the Wayback Machine . ^ Ford & Colvin (2015) ; McGaughey (2022) ^ IGM Chicago (2017) . ^ Arntz, Gregory & Zierahn (2016) , p. 33. ^ Lohr (2017) ; Frey & Osborne (2017) ; Arntz, Gregory & Zierahn (2016 , p. 33) ^ Zhou, Viola (11 April 2023). "AI is already taking video game illustrators' jobs in China" . Rest of World . Archived from the original on 21 February 2024 . Retrieved 17 August 2023 . ^ Carter, Justin (11 April 2023). "China's game art industry reportedly decimated by growing AI use" . Game Developer . Archived from the original on 17 August 2023 . Retrieved 17 August 2023 . ^ Morgenstern (2015) . ^ Mahdawi (2017) ; Thompson (2014) ^ Tarnoff, Ben (4 August 2023). "Lessons from Eliza". The Guardian Weekly . pp. 34– 39. ^ Cellan-Jones (2014) . ^ Russell & Norvig 2021 , p. 1001. ^ Bostrom (2014) . ^ Russell (2019) . ^ Bostrom (2014) ; Müller & Bostrom (2014) ; Bostrom (2015) . ^ Harari (2023) . ^ Müller & Bostrom (2014) . ^ Leaders' concerns about the existential risks of AI around 2015: Rawlinson (2015) , Holley (2015) , Gibbs (2014) , Sainato (2015) ^ " "Godfather of artificial intelligence" talks impact and potential of new AI" . CBS News . 25 March 2023. Archived from the original on 28 March 2023 . Retrieved 28 March 2023 . ^ Pittis, Don (4 May 2023). "Canadian artificial intelligence leader Geoffrey Hinton piles on fears of computer takeover" . CBC . Archived from the original on 7 July 2024 . Retrieved 5 October 2024 . ^ " '50–50 chance' that AI outsmarts humanity, Geoffrey Hinton says" . Bloomberg BNN . 14 June 2024. Archived from the original on 14 June 2024 . Retrieved 6 July 2024 . ^ Valance (2023) . ^ Taylor, Josh (7 May 2023). "Rise of artificial intelligence is inevitable but should not be feared, 'father of AI' says" . The Guardian . Archived from the original on 23 October 2023 . Retrieved 26 May 2023 . ^ Colton, Emma (7 May 2023). " 'Father of AI' says tech fears misplaced: 'You cannot stop it' " . Fox News . Archived from the original on 26 May 2023 . Retrieved 26 May 2023 . ^ Jones, Hessie (23 May 2023). "Juergen Schmidhuber, Renowned 'Father Of Modern AI,' Says His Life's Work Won't Lead To Dystopia" . Forbes . Archived from the original on 26 May 2023 . Retrieved 26 May 2023 . ^ McMorrow, Ryan (19 December 2023). "Andrew Ng: 'Do we think the world is better off with more or less intelligence?' " . Financial Times . Archived from the original on 25 January 2024 . Retrieved 30 December 2023 . ^ Levy, Steven (22 December 2023). "How Not to Be Stupid About AI, With Yann LeCun" . Wired . Archived from the original on 28 December 2023 . Retrieved 30 December 2023 . ^ Arguments that AI is not an imminent risk: Brooks (2014) , Geist (2015) , Madrigal (2015) , Lee (2014) ^ a b Christian (2020) , pp. 67, 73. ^ Yudkowsky (2008) . ^ a b Anderson & Anderson (2011) . ^ AAAI (2014) . ^ Wallach (2010) . ^ Russell (2019) , p. 173. ^ Stewart, Ashley; Melton, Monica. "Hugging Face CEO says he's focused on building a 'sustainable model' for the $4.5 billion open-source-AI startup" . Business Insider . Archived from the original on 25 September 2024 . Retrieved 14 April 2024 . ^ Wiggers, Kyle (9 April 2024). "Google open sources tools to support AI model development" . TechCrunch . Archived from the original on 10 September 2024 . Retrieved 14 April 2024 . ^ Heaven, Will Douglas (12 May 2023). "The open-source AI boom is built on Big Tech's handouts. How long will it last?" . MIT Technology Review . Retrieved 14 April 2024 . ^ Brodsky, Sascha (19 December 2023). "Mistral AI's New Language Model Aims for Open Source Supremacy" . AI Business . Archived from the original on 5 September 2024 . Retrieved 5 October 2024 . ^ Edwards, Benj (22 February 2024). "Stability announces Stable Diffusion 3, a next-gen AI image generator" . Ars Technica . Archived from the original on 5 October 2024 . Retrieved 14 April 2024 . ^ Marshall, Matt (29 January 2024). "How enterprises are using open source LLMs: 16 examples" . VentureBeat . Archived from the original on 26 September 2024 . Retrieved 5 October 2024 . ^ Piper, Kelsey (2 February 2024). "Should we make our most powerful AI models open source to all?" . Vox . Archived from the original on 5 October 2024 . Retrieved 14 April 2024 . ^ Alan Turing Institute (2019). "Understanding artificial intelligence ethics and safety" (PDF) . Archived (PDF) from the original on 11 September 2024 . Retrieved 5 October 2024 . ^ Alan Turing Institute (2023). "AI Ethics and Governance in Practice" (PDF) . Archived (PDF) from the original on 11 September 2024 . Retrieved 5 October 2024 . ^ Floridi, Luciano; Cowls, Josh (23 June 2019). "A Unified Framework of Five Principles for AI in Society" . Harvard Data Science Review . 1 (1). doi : 10.1162/99608f92.8cd550d1 . S2CID 198775713 . Archived from the original on 7 August 2019 . Retrieved 5 December 2023 . ^ Buruk, Banu; Ekmekci, Perihan Elif; Arda, Berna (1 September 2020). "A critical perspective on guidelines for responsible and trustworthy artificial intelligence" . Medicine, Health Care and Philosophy . 23 (3): 387– 399. doi : 10.1007/s11019-020-09948-1 . ISSN 1572-8633 . PMID 32236794 . S2CID 214766800 . Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ Kamila, Manoj Kumar; Jasrotia, Sahil Singh (1 January 2023). "Ethical issues in the development of artificial intelligence: recognizing the risks" . International Journal of Ethics and Systems . 41 (ahead-of-print): 45– 63. doi : 10.1108/IJOES-05-2023-0107 . ISSN 2514-9369 . S2CID 259614124 . Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ "AI Safety Institute releases new AI safety evaluations platform" . UK Government. 10 May 2024. Archived from the original on 5 October 2024 . Retrieved 14 May 2024 . ^ Regulation of AI to mitigate risks: Berryhill et al. (2019) , Barfield & Pagallo (2018) , Iphofen & Kritikos (2019) , Wirtz, Weyerer & Geyer (2018) , Buiten (2019) ^ Law Library of Congress (U.S.). Global Legal Research Directorate (2019) . ^ a b Vincent (2023) . ^ Stanford University (2023) . ^ a b c d UNESCO (2021) . ^ Kissinger (2021) . ^ Altman, Brockman & Sutskever (2023) . ^ VOA News (25 October 2023). "UN Announces Advisory Body on Artificial Intelligence" . Archived from the original on 18 September 2024 . Retrieved 5 October 2024 . ^ "Council of Europe opens first ever global treaty on AI for signature" . Council of Europe . 5 September 2024. Archived from the original on 17 September 2024 . Retrieved 17 September 2024 . ^ Edwards (2023) . ^ Kasperowicz (2023) . ^ Fox News (2023) . ^ Milmo, Dan (3 November 2023). "Hope or Horror? The great AI debate dividing its pioneers". The Guardian Weekly . pp. 10– 12. ^ "The Bletchley Declaration by Countries Attending the AI Safety Summit, 1–2 November 2023" . GOV.UK . 1 November 2023. Archived from the original on 1 November 2023 . Retrieved 2 November 2023 . ^ "Countries agree to safe and responsible development of frontier AI in landmark Bletchley Declaration" . GOV.UK (Press release). Archived from the original on 1 November 2023 . Retrieved 1 November 2023 . ^ "Second global AI summit secures safety commitments from companies" . Reuters. 21 May 2024 . Retrieved 23 May 2024 . ^ "Frontier AI Safety Commitments, AI Seoul Summit 2024" . gov.uk. 21 May 2024. Archived from the original on 23 May 2024 . Retrieved 23 May 2024 . ^ a b Buntz, Brian (3 November 2024). "Quality vs. quantity: US and China chart different paths in global AI patent race in 2024 / Geographical breakdown of AI patents in 2024" . R&D World. Archived from the original on 9 December 2024. ^ a b Russell & Norvig 2021 , p. 9. ^ a b c Copeland, J., ed. (2004). The Essential Turing: the ideas that gave birth to the computer age . Oxford, England: Clarendon Press. ISBN 0-1982-5079-7 . ^ "Google books ngram" . Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . ^ AI's immediate precursors: McCorduck (2004 , pp. 51–107), Crevier (1993 , pp. 27–32), Russell & Norvig (2021 , pp. 8–17), Moravec (1988 , p. 3) ^ a b Turing's original publication of the Turing test in " Computing machinery and intelligence ": Turing (1950) Historical influence and philosophical implications: Haugeland (1985 , pp. 6–9), Crevier (1993 , p. 24), McCorduck (2004 , pp. 70–71), Russell & Norvig (2021 , pp. 2, 984) ^ Crevier (1993) , pp. 47–49. ^ Russell & Norvig (2003) , p. 17. ^ Russell & Norvig (2003) , p. 18. ^ Newquist (1994) , pp. 86–86. ^ Simon (1965 , p. 96) quoted in Crevier (1993 , p. 109) ^ Minsky (1967 , p. 2) quoted in Crevier (1993 , p. 109) ^ Russell & Norvig (2021) , p. 21. ^ Lighthill (1973) . ^ NRC 1999 , pp. 212–213. ^ Russell & Norvig (2021) , p. 22. ^ Expert systems : Russell & Norvig (2021 , pp. 23, 292), Luger & Stubblefield (2004 , pp. 227–331), Nilsson (1998 , chpt. 17.4), McCorduck (2004 , pp. 327–335, 434–435), Crevier (1993 , pp. 145–162, 197–203), Newquist (1994 , pp. 155–183) ^ Russell & Norvig (2021) , p. 24. ^ Nilsson (1998) , p. 7. ^ McCorduck (2004) , pp. 454–462. ^ Moravec (1988) . ^ a b Brooks (1990) . ^ Developmental robotics : Weng et al. (2001) , Lungarella et al. (2003) , Asada et al. (2009) , Oudeyer (2010) ^ Russell & Norvig (2021) , p. 25. ^ Crevier (1993 , pp. 214–215), Russell & Norvig (2021 , pp. 24, 26) ^ Russell & Norvig (2021) , p. 26. ^ Formal and narrow methods adopted in the 1990s: Russell & Norvig (2021 , pp. 24–26), McCorduck (2004 , pp. 486–487) ^ AI widely used in the late 1990s: Kurzweil (2005 , p. 265), NRC (1999 , pp. 216–222), Newquist (1994 , pp. 189–201) ^ Wong (2023) . ^ Moore's Law and AI: Russell & Norvig (2021 , pp. 14, 27) ^ a b c Clark (2015b) . ^ Big data : Russell & Norvig (2021 , p. 26) ^ Sagar, Ram (3 June 2020). "OpenAI Releases GPT-3, The Largest Model So Far" . Analytics India Magazine . Archived from the original on 4 August 2020 . Retrieved 15 March 2023 . ^ Milmo, Dan (2 February 2023). "ChatGPT reaches 100 million users two months after launch" . The Guardian . ISSN 0261-3077 . Archived from the original on 3 February 2023 . Retrieved 31 December 2024 . ^ Gorichanaz, Tim (29 November 2023). "ChatGPT turns 1: AI chatbot's success says as much about humans as technology" . The Conversation . Archived from the original on 31 December 2024 . Retrieved 31 December 2024 . ^ DiFeliciantonio (2023) . ^ Goswami (2023) . ^ "Nearly 1 in 4 new startups is an AI company" . PitchBook . 24 December 2024 . Retrieved 3 January 2025 . ^ Grayling, Anthony; Ball, Brian (1 August 2024). "Philosophy is crucial in the age of AI" . The Conversation . Archived from the original on 5 October 2024 . Retrieved 4 October 2024 . ^ a b Jarow, Oshan (15 June 2024). "Will AI ever become conscious? It depends on how you think about biology" . Vox . Archived from the original on 21 September 2024 . Retrieved 4 October 2024 . ^ McCarthy, John. "The Philosophy of AI and the AI of Philosophy" . jmc.stanford.edu . Archived from the original on 23 October 2018 . Retrieved 3 October 2024 . ^ a b Turing (1950) , p. 1. ^ Turing (1950) , Under "The Argument from Consciousness". ^ Kirk-Giannini, Cameron Domenico; Goldstein, Simon (16 October 2023). "AI is closer than ever to passing the Turing test for 'intelligence'. What happens when it does?" . The Conversation . Archived from the original on 25 September 2024 . Retrieved 17 August 2024 . ^ Russell & Norvig (2021) , p. 3. ^ Maker (2006) . ^ McCarthy (1999) . ^ Minsky (1986) . ^ "What Is Artificial Intelligence (AI)?" . Google Cloud Platform . Archived from the original on 31 July 2023 . Retrieved 16 October 2023 . ^ "One of the Biggest Problems in Regulating AI Is Agreeing on a Definition" . Carnegie Endowment for International Peace . Retrieved 31 July 2024 . ^ "AI or BS? How to tell if a marketing tool really uses artificial intelligence" . The Drum . Retrieved 31 July 2024 . ^ Nilsson (1983) , p. 10. ^ Haugeland (1985) , pp. 112–117. ^ Physical symbol system hypothesis: Newell & Simon (1976 , p. 116) Historical significance: McCorduck (2004 , p. 153), Russell & Norvig (2021 , p. 19) ^ Moravec's paradox : Moravec (1988 , pp. 15–16), Minsky (1986 , p. 29), Pinker (2007 , pp. 190–191) ^ Dreyfus' critique of AI : Dreyfus (1972) , Dreyfus & Dreyfus (1986) Historical significance and philosophical implications: Crevier (1993 , pp. 120–132), McCorduck (2004 , pp. 211–239), Russell & Norvig (2021 , pp. 981–982), Fearn (2007 , chpt. 3) ^ Crevier (1993) , p. 125. ^ Langley (2011) . ^ Katz (2012) . ^ Neats vs. scruffies , the historic debate: McCorduck (2004 , pp. 421–424, 486–489), Crevier (1993 , p. 168), Nilsson (1983 , pp. 10–11), Russell & Norvig (2021 , p. 24) A classic example of the "scruffy" approach to intelligence: Minsky (1986) A modern example of neat AI and its aspirations in the 21st century: Domingos (2015) ^ Pennachin & Goertzel (2007) . ^ a b Roberts (2016) . ^ Russell & Norvig (2021) , p. 986. ^ Chalmers (1995) . ^ Dennett (1991) . ^ Horst (2005) . ^ Searle (1999) . ^ Searle (1980) , p. 1. ^ Russell & Norvig (2021) , p. 9817. ^ Searle's Chinese room argument: Searle (1980) . Searle's original presentation of the thought experiment., Searle (1999) . Discussion: Russell & Norvig (2021 , pp. 985), McCorduck (2004 , pp. 443–445), Crevier (1993 , pp. 269–271) ^ Leith, Sam (7 July 2022). "Nick Bostrom: How can we be certain a machine isn't conscious?" . The Spectator . Archived from the original on 26 September 2024 . Retrieved 23 February 2024 . ^ a b c Thomson, Jonny (31 October 2022). "Why don't robots have rights?" . Big Think . Archived from the original on 13 September 2024 . Retrieved 23 February 2024 . ^ a b Kateman, Brian (24 July 2023). "AI Should Be Terrified of Humans" . Time . Archived from the original on 25 September 2024 . Retrieved 23 February 2024 . ^ Wong, Jeff (10 July 2023). "What leaders need to know about robot rights" . Fast Company . ^ Hern, Alex (12 January 2017). "Give robots 'personhood' status, EU committee argues" . The Guardian . ISSN 0261-3077 . Archived from the original on 5 October 2024 . Retrieved 23 February 2024 . ^ Dovey, Dana (14 April 2018). "Experts Don't Think Robots Should Have Rights" . Newsweek . Archived from the original on 5 October 2024 . Retrieved 23 February 2024 . ^ Cuddy, Alice (13 April 2018). "Robot rights violate human rights, experts warn EU" . euronews . Archived from the original on 19 September 2024 . Retrieved 23 February 2024 . ^ The Intelligence explosion and technological singularity : Russell & Norvig (2021 , pp. 1004–1005), Omohundro (2008) , Kurzweil (2005) I. J. Good 's "intelligence explosion": Good (1965) Vernor Vinge 's "singularity": Vinge (1993) ^ Russell & Norvig (2021) , p. 1005. ^ Transhumanism : Moravec (1988) , Kurzweil (2005) , Russell & Norvig (2021 , p. 1005) ^ AI as evolution: Edward Fredkin is quoted in McCorduck (2004 , p. 401), Butler (1863) , Dyson (1998) ^ AI in myth: McCorduck (2004 , pp. 4–5) ^ McCorduck (2004) , pp. 340–400. ^ Buttazzo (2001) . ^ Anderson (2008) . ^ McCauley (2007) . ^ Galvan (1997) . AI textbooks The two most widely used textbooks in 2023 (see the Open Syllabus ): Russell, Stuart J. ; Norvig, Peter (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0-1346-1099-3 . LCCN 20190474 . Rich, Elaine ; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0-0700-8770-5 . The four most widely used AI textbooks in 2008: Luger, George ; Stubblefield, William (2004). Artificial Intelligence: Structures and Strategies for Complex Problem Solving (5th ed.). Benjamin/Cummings. ISBN 978-0-8053-4780-7 . Archived from the original on 26 July 2020 . Retrieved 17 December 2019 . Nilsson, Nils (1998). Artificial Intelligence: A New Synthesis . Morgan Kaufmann. ISBN 978-1-5586-0467-4 . Archived from the original on 26 July 2020 . Retrieved 18 November 2019 . Russell, Stuart J. ; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2 . Poole, David ; Mackworth, Alan ; Goebel, Randy (1998). Computational Intelligence: A Logical Approach . New York: Oxford University Press. ISBN 978-0-1951-0270-3 . Archived from the original on 26 July 2020 . Retrieved 22 August 2020 . Later edition: Poole, David; Mackworth, Alan (2017). Artificial Intelligence: Foundations of Computational Agents (2nd ed.). Cambridge University Press. ISBN 978-1-1071-9539-4 . Archived from the original on 7 December 2017 . Retrieved 6 December 2017 . Other textbooks: Ertel, Wolfgang (2017). Introduction to Artificial Intelligence (2nd ed.). Springer. ISBN 978-3-3195-8486-7 . Ciaramella, Alberto ; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI (1st ed.). Intellisemantic Editions. ISBN 978-8-8947-8760-3 . History of AI Crevier, Daniel (1993). AI: The Tumultuous Search for Artificial Intelligence . New York, NY: BasicBooks. ISBN 0-465-02997-3 . McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, Massachusetts: A. K. Peters, ISBN 1-5688-1205-1 Newquist, H. P. (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think . New York: Macmillan/SAMS. ISBN 978-0-6723-0412-5 . Harmon, Paul; Sawyer, Brian (1990). Creating Expert Systems for Business and Industry . New York: John Wiley & Sons. ISBN 0471614963 . Other sources AI & ML in Fusion AI & ML in Fusion, video lecture Archived 2 July 2023 at the Wayback Machine Alter, Alexandra; Harris, Elizabeth A. (20 September 2023), "Franzen, Grisham and Other Prominent Authors Sue OpenAI" , The New York Times , archived from the original on 14 September 2024 , retrieved 5 October 2024 Altman, Sam ; Brockman, Greg ; Sutskever, Ilya (22 May 2023). "Governance of Superintelligence" . openai.com . Archived from the original on 27 May 2023 . Retrieved 27 May 2023 . Anderson, Susan Leigh (2008). "Asimov's "three laws of robotics" and machine metaethics". AI & Society . 22 (4): 477– 493. doi : 10.1007/s00146-007-0094-5 . S2CID 1809459 . Anderson, Michael; Anderson, Susan Leigh (2011). Machine Ethics . Cambridge University Press. Arntz, Melanie; Gregory, Terry; Zierahn, Ulrich (2016), "The risk of automation for jobs in OECD countries: A comparative analysis", OECD Social, Employment, and Migration Working Papers 189 Asada, M.; Hosoda, K.; Kuniyoshi, Y.; Ishiguro, H.; Inui, T.; Yoshikawa, Y.; Ogino, M.; Yoshida, C. (2009). "Cognitive developmental robotics: a survey". IEEE Transactions on Autonomous Mental Development . 1 (1): 12– 34. doi : 10.1109/tamd.2009.2021702 . S2CID 10168773 . "Ask the AI experts: What's driving today's progress in AI?" . McKinsey & Company . Archived from the original on 13 April 2018 . Retrieved 13 April 2018 . Barfield, Woodrow; Pagallo, Ugo (2018). Research handbook on the law of artificial intelligence . Cheltenham, UK: Edward Elgar Publishing. ISBN 978-1-7864-3904-8 . OCLC 1039480085 . Beal, J.; Winston, Patrick (2009), "The New Frontier of Human-Level Artificial Intelligence", IEEE Intelligent Systems , vol. 24, pp. 21– 24, doi : 10.1109/MIS.2009.75 , hdl : 1721.1/52357 , S2CID 32437713 Berdahl, Carl Thomas; Baker, Lawrence; Mann, Sean; Osoba, Osonde; Girosi, Federico (7 February 2023). "Strategies to Improve the Impact of Artificial Intelligence on Health Equity: Scoping Review" . JMIR AI . 2 : e42936. doi : 10.2196/42936 . ISSN 2817-1705 . PMC 11041459 . PMID 38875587 . S2CID 256681439 . Berryhill, Jamie; Heang, Kévin Kok; Clogher, Rob; McBride, Keegan (2019). Hello, World: Artificial Intelligence and its Use in the Public Sector (PDF) . Paris: OECD Observatory of Public Sector Innovation. Archived (PDF) from the original on 20 December 2019 . Retrieved 9 August 2020 . Bertini, M; Del Bimbo, A; Torniai, C (2006). "Automatic annotation and semantic retrieval of video sequences using multimedia ontologies". MM '06 Proceedings of the 14th ACM international conference on Multimedia . 14th ACM international conference on Multimedia. Santa Barbara: ACM. pp. 679– 682. Bostrom, Nick (2014). Superintelligence: Paths, Dangers, Strategies . Oxford University Press. Bostrom, Nick (2015). "What happens when our computers get smarter than we are?" . TED (conference) . Archived from the original on 25 July 2020 . Retrieved 30 January 2020 . Brooks, Rodney (10 November 2014). "artificial intelligence is a tool, not a threat" . Archived from the original on 12 November 2014. Brooks, Rodney (1990). "Elephants Don't Play Chess" (PDF) . Robotics and Autonomous Systems . 6 ( 1– 2): 3– 15. CiteSeerX 10.1.1.588.7539 . doi : 10.1016/S0921-8890(05)80025-9 . Archived (PDF) from the original on 9 August 2007. Buiten, Miriam C (2019). "Towards Intelligent Regulation of Artificial Intelligence" . European Journal of Risk Regulation . 10 (1): 41– 59. doi : 10.1017/err.2019.8 . ISSN 1867-299X . Bushwick, Sophie (16 March 2023), "What the New GPT-4 AI Can Do" , Scientific American , archived from the original on 22 August 2023 , retrieved 5 October 2024 Butler, Samuel (13 June 1863). "Darwin among the Machines" . Letters to the Editor. The Press . Christchurch, New Zealand. Archived from the original on 19 September 2008 . Retrieved 16 October 2014 – via Victoria University of Wellington. Buttazzo, G. (July 2001). "Artificial consciousness: Utopia or real possibility?". Computer . 34 (7): 24– 30. doi : 10.1109/2.933500 . Cambria, Erik; White, Bebo (May 2014). "Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]". IEEE Computational Intelligence Magazine . 9 (2): 48– 57. doi : 10.1109/MCI.2014.2307227 . S2CID 206451986 . Cellan-Jones, Rory (2 December 2014). "Stephen Hawking warns artificial intelligence could end mankind" . BBC News . Archived from the original on 30 October 2015 . Retrieved 30 October 2015 . Chalmers, David (1995). "Facing up to the problem of consciousness" . Journal of Consciousness Studies . 2 (3): 200– 219. CiteSeerX 10.1.1.103.8362 . Archived from the original on 8 March 2005 . Retrieved 11 October 2018 . Challa, Subhash; Moreland, Mark R.; Mušicki, Darko; Evans, Robin J. (2011). Fundamentals of Object Tracking . Cambridge University Press. doi : 10.1017/CBO9780511975837 . ISBN 978-0-5218-7628-5 . Christian, Brian (2020). The Alignment Problem : Machine learning and human values . W. W. Norton & Company. ISBN 978-0-3938-6833-3 . OCLC 1233266753 . Ciresan, D.; Meier, U.; Schmidhuber, J. (2012). "Multi-column deep neural networks for image classification". 2012 IEEE Conference on Computer Vision and Pattern Recognition . pp. 3642– 3649. arXiv : 1202.2745 . doi : 10.1109/cvpr.2012.6248110 . ISBN 978-1-4673-1228-8 . S2CID 2161592 . Clark, Jack (2015b). "Why 2015 Was a Breakthrough Year in Artificial Intelligence" . Bloomberg.com . Archived from the original on 23 November 2016 . Retrieved 23 November 2016 . CNA (12 January 2019). "Commentary: Bad news. Artificial intelligence is biased" . CNA . Archived from the original on 12 January 2019 . Retrieved 19 June 2020 . Cybenko, G. (1988). Continuous valued neural networks with two hidden layers are sufficient (Report). Department of Computer Science, Tufts University. Deng, L.; Yu, D. (2014). "Deep Learning: Methods and Applications" (PDF) . Foundations and Trends in Signal Processing . 7 ( 3– 4): 197– 387. doi : 10.1561/2000000039 . Archived (PDF) from the original on 14 March 2016 . Retrieved 18 October 2014 . Dennett, Daniel (1991). Consciousness Explained . The Penguin Press. ISBN 978-0-7139-9037-9 . DiFeliciantonio, Chase (3 April 2023). "AI has already changed the world. This report shows how" . San Francisco Chronicle . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . Dickson, Ben (2 May 2022). "Machine learning: What is the transformer architecture?" . TechTalks . Archived from the original on 22 November 2023 . Retrieved 22 November 2023 . Dockrill, Peter (27 June 2022), "Robots With Flawed AI Make Sexist And Racist Decisions, Experiment Shows" , Science Alert , archived from the original on 27 June 2022 Domingos, Pedro (2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World . Basic Books . ISBN 978-0-4650-6570-7 . Dreyfus, Hubert (1972). What Computers Can't Do . New York: MIT Press. ISBN 978-0-0601-1082-6 . Dreyfus, Hubert ; Dreyfus, Stuart (1986). Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer . Oxford: Blackwell. ISBN 978-0-0290-8060-3 . Archived from the original on 26 July 2020 . Retrieved 22 August 2020 . Dyson, George (1998). Darwin among the Machines . Allan Lane Science. ISBN 978-0-7382-0030-9 . Archived from the original on 26 July 2020 . Retrieved 22 August 2020 . Edelson, Edward (1991). The Nervous System . New York: Chelsea House. ISBN 978-0-7910-0464-7 . Archived from the original on 26 July 2020 . Retrieved 18 November 2019 . Edwards, Benj (17 May 2023). "Poll: AI poses risk to humanity, according to majority of Americans" . Ars Technica . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . Fearn, Nicholas (2007). The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers . New York: Grove Press. ISBN 978-0-8021-1839-4 . Ford, Martin; Colvin, Geoff (6 September 2015). "Will robots create more jobs than they destroy?" . The Guardian . Archived from the original on 16 June 2018 . Retrieved 13 January 2018 . Fox News (2023). "Fox News Poll" (PDF) . Fox News. Archived (PDF) from the original on 12 May 2023 . Retrieved 19 June 2023 . Frey, Carl Benedikt; Osborne, Michael A (1 January 2017). "The future of employment: How susceptible are jobs to computerisation?". Technological Forecasting and Social Change . 114 : 254– 280. CiteSeerX 10.1.1.395.416 . doi : 10.1016/j.techfore.2016.08.019 . ISSN 0040-1625 . "From not working to neural networking" . The Economist . 2016. Archived from the original on 31 December 2016 . Retrieved 26 April 2018 . Galvan, Jill (1 January 1997). "Entering the Posthuman Collective in Philip K. Dick's "Do Androids Dream of Electric Sheep?" ". Science Fiction Studies . 24 (3): 413– 429. doi : 10.1525/sfs.24.3.0413 . JSTOR 4240644 . Geist, Edward Moore (9 August 2015). "Is artificial intelligence really an existential threat to humanity?" . Bulletin of the Atomic Scientists . Archived from the original on 30 October 2015 . Retrieved 30 October 2015 . Gibbs, Samuel (27 October 2014). "Elon Musk: artificial intelligence is our biggest existential threat" . The Guardian . Archived from the original on 30 October 2015 . Retrieved 30 October 2015 . Goffrey, Andrew (2008). "Algorithm". In Fuller, Matthew (ed.). Software studies: a lexicon . Cambridge, Mass.: MIT Press. pp. 15 –20. ISBN 978-1-4356-4787-9 . Goldman, Sharon (14 September 2022). "10 years later, deep learning 'revolution' rages on, say AI pioneers Hinton, LeCun and Li" . VentureBeat . Archived from the original on 5 October 2024 . Retrieved 8 December 2023 . Good, I. J. (1965), Speculations Concerning the First Ultraintelligent Machine , archived from the original on 10 July 2023 , retrieved 5 October 2024 Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016), Deep Learning , MIT Press., archived from the original on 16 April 2016 , retrieved 12 November 2017 Goodman, Bryce; Flaxman, Seth (2017). "EU regulations on algorithmic decision-making and a 'right to explanation' ". AI Magazine . 38 (3): 50. arXiv : 1606.08813 . doi : 10.1609/aimag.v38i3.2741 . S2CID 7373959 . Government Accountability Office (13 September 2022). Consumer Data: Increasing Use Poses Risks to Privacy . gao.gov (Report). Archived from the original on 13 September 2024 . Retrieved 5 October 2024 . Grant, Nico; Hill, Kashmir (22 May 2023). "Google's Photo App Still Can't Find Gorillas. And Neither Can Apple's" . The New York Times . Archived from the original on 14 September 2024 . Retrieved 5 October 2024 . Goswami, Rohan (5 April 2023). "Here's where the A.I. jobs are" . CNBC . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . Harari, Yuval Noah (October 2018). "Why Technology Favors Tyranny" . The Atlantic . Archived from the original on 25 September 2021 . Retrieved 23 September 2021 . Harari, Yuval Noah (2023). "AI and the future of humanity" . YouTube . Archived from the original on 30 September 2024 . Retrieved 5 October 2024 . Haugeland, John (1985). Artificial Intelligence: The Very Idea . Cambridge, Mass.: MIT Press. ISBN 978-0-2620-8153-5 . Hinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T. ; Kingsbury, B. (2012). "Deep Neural Networks for Acoustic Modeling in Speech Recognition – The shared views of four research groups". IEEE Signal Processing Magazine . 29 (6): 82– 97. Bibcode : 2012ISPM...29...82H . doi : 10.1109/msp.2012.2205597 . S2CID 206485943 . Holley, Peter (28 January 2015). "Bill Gates on dangers of artificial intelligence: 'I don't understand why some people are not concerned' " . The Washington Post . ISSN 0190-8286 . Archived from the original on 30 October 2015 . Retrieved 30 October 2015 . Hornik, Kurt; Stinchcombe, Maxwell; White, Halbert (1989). Multilayer Feedforward Networks are Universal Approximators (PDF) . Neural Networks . Vol. 2. Pergamon Press. pp. 359– 366. Archived (PDF) from the original on 21 April 2023 . Retrieved 5 October 2024 . Horst, Steven (2005). "The Computational Theory of Mind" . The Stanford Encyclopedia of Philosophy . Archived from the original on 6 March 2016 . Retrieved 7 March 2016 . Howe, J. (November 1994). "Artificial Intelligence at Edinburgh University: a Perspective" . Archived from the original on 15 May 2007 . Retrieved 30 August 2007 . IGM Chicago (30 June 2017). "Robots and Artificial Intelligence" . igmchicago.org . Archived from the original on 1 May 2019 . Retrieved 3 July 2019 . Iphofen, Ron; Kritikos, Mihalis (3 January 2019). "Regulating artificial intelligence and robotics: ethics by design in a digital society". Contemporary Social Science . 16 (2): 170– 184. doi : 10.1080/21582041.2018.1563803 . ISSN 2158-2041 . S2CID 59298502 . Jordan, M. I.; Mitchell, T. M. (16 July 2015). "Machine learning: Trends, perspectives, and prospects". Science . 349 (6245): 255– 260. Bibcode : 2015Sci...349..255J . doi : 10.1126/science.aaa8415 . PMID 26185243 . S2CID 677218 . Kahneman, Daniel (2011). Thinking, Fast and Slow . Macmillan. ISBN 978-1-4299-6935-2 . Archived from the original on 15 March 2023 . Retrieved 8 April 2012 . Kahneman, Daniel ; Slovic, D.; Tversky, Amos (1982). "Judgment under uncertainty: Heuristics and biases". Science . 185 (4157). New York: Cambridge University Press: 1124– 1131. Bibcode : 1974Sci...185.1124T . doi : 10.1126/science.185.4157.1124 . ISBN 978-0-5212-8414-1 . PMID 17835457 . S2CID 143452957 . Kasperowicz, Peter (1 May 2023). "Regulate AI? GOP much more skeptical than Dems that government can do it right: poll" . Fox News . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . Katz, Yarden (1 November 2012). "Noam Chomsky on Where Artificial Intelligence Went Wrong" . The Atlantic . Archived from the original on 28 February 2019 . Retrieved 26 October 2014 . "Kismet" . MIT Artificial Intelligence Laboratory, Humanoid Robotics Group. Archived from the original on 17 October 2014 . Retrieved 25 October 2014 . Kissinger, Henry (1 November 2021). "The Challenge of Being Human in the Age of AI" . The Wall Street Journal . Archived from the original on 4 November 2021 . Retrieved 4 November 2021 . Kobielus, James (27 November 2019). "GPUs Continue to Dominate the AI Accelerator Market for Now" . InformationWeek . Archived from the original on 19 October 2021 . Retrieved 11 June 2020 . Kuperman, G. J.; Reichley, R. M.; Bailey, T. C. (1 July 2006). "Using Commercial Knowledge Bases for Clinical Decision Support: Opportunities, Hurdles, and Recommendations" . Journal of the American Medical Informatics Association . 13 (4): 369– 371. doi : 10.1197/jamia.M2055 . PMC 1513681 . PMID 16622160 . Kurzweil, Ray (2005). The Singularity is Near . Penguin Books. ISBN 978-0-6700-3384-3 . Langley, Pat (2011). "The changing science of machine learning" . Machine Learning . 82 (3): 275– 279. doi : 10.1007/s10994-011-5242-y . Larson, Jeff; Angwin, Julia (23 May 2016). "How We Analyzed the COMPAS Recidivism Algorithm" . ProPublica . Archived from the original on 29 April 2019 . Retrieved 19 June 2020 . Laskowski, Nicole (November 2023). "What is Artificial Intelligence and How Does AI Work? TechTarget" . Enterprise AI . Archived from the original on 5 October 2024 . Retrieved 30 October 2023 . Law Library of Congress (U.S.). Global Legal Research Directorate, issuing body. (2019). Regulation of artificial intelligence in selected jurisdictions . LCCN 2019668143 . OCLC 1110727808 . Lee, Timothy B. (22 August 2014). "Will artificial intelligence destroy humanity? Here are 5 reasons not to worry" . Vox . Archived from the original on 30 October 2015 . Retrieved 30 October 2015 . Lenat, Douglas ; Guha, R. V. (1989). Building Large Knowledge-Based Systems . Addison-Wesley. ISBN 978-0-2015-1752-1 . Lighthill, James (1973). "Artificial Intelligence: A General Survey". Artificial Intelligence: a paper symposium . Science Research Council. Lipartito, Kenneth (6 January 2011), The Narrative and the Algorithm: Genres of Credit Reporting from the Nineteenth Century to Today (PDF) (Unpublished manuscript), doi : 10.2139/ssrn.1736283 , S2CID 166742927 , archived (PDF) from the original on 9 October 2022 Lohr, Steve (2017). "Robots Will Take Jobs, but Not as Fast as Some Fear, New Report Says" . The New York Times . Archived from the original on 14 January 2018 . Retrieved 13 January 2018 . Lungarella, M.; Metta, G.; Pfeifer, R.; Sandini, G. (2003). "Developmental robotics: a survey". Connection Science . 15 (4): 151– 190. Bibcode : 2003ConSc..15..151L . CiteSeerX 10.1.1.83.7615 . doi : 10.1080/09540090310001655110 . S2CID 1452734 . "Machine Ethics" . aaai.org . Archived from the original on 29 November 2014. Madrigal, Alexis C. (27 February 2015). "The case against killer robots, from a guy actually working on artificial intelligence" . Fusion.net . Archived from the original on 4 February 2016 . Retrieved 31 January 2016 . Mahdawi, Arwa (26 June 2017). "What jobs will still be around in 20 years? Read this to prepare your future" . The Guardian . Archived from the original on 14 January 2018 . Retrieved 13 January 2018 . Maker, Meg Houston (2006), AI@50: AI Past, Present, Future , Dartmouth College, archived from the original on 8 October 2008 , retrieved 16 October 2008 Marmouyet, Françoise (15 December 2023). "Google's Gemini: is the new AI model really better than ChatGPT?" . The Conversation . Archived from the original on 4 March 2024 . Retrieved 25 December 2023 . Minsky, Marvin (1986), The Society of Mind , Simon and Schuster McCarthy, John ; Minsky, Marvin ; Rochester, Nathan ; Shannon, Claude (1955). "A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence" . Archived from the original on 26 August 2007 . Retrieved 30 August 2007 . McCarthy, John (2007), "From Here to Human-Level AI", Artificial Intelligence , p. 171 McCarthy, John (1999), What is AI? , archived from the original on 4 December 2022 , retrieved 4 December 2022 McCauley, Lee (2007). "AI armageddon and the three laws of robotics". Ethics and Information Technology . 9 (2): 153– 164. CiteSeerX 10.1.1.85.8904 . doi : 10.1007/s10676-007-9138-2 . S2CID 37272949 . McGarry, Ken (1 December 2005). "A survey of interestingness measures for knowledge discovery". The Knowledge Engineering Review . 20 (1): 39– 61. doi : 10.1017/S0269888905000408 . S2CID 14987656 . McGaughey, E (2022), Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy , p. 51(3) Industrial Law Journal 511–559, doi : 10.2139/ssrn.3044448 , S2CID 219336439 , SSRN 3044448 , archived from the original on 31 January 2021 , retrieved 27 May 2023 Merkle, Daniel; Middendorf, Martin (2013). "Swarm Intelligence". In Burke, Edmund K.; Kendall, Graham (eds.). Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques . Springer Science & Business Media. ISBN 978-1-4614-6940-7 . Minsky, Marvin (1967), Computation: Finite and Infinite Machines , Englewood Cliffs, N.J.: Prentice-Hall Moravec, Hans (1988). Mind Children . Harvard University Press. ISBN 978-0-6745-7616-2 . Archived from the original on 26 July 2020 . Retrieved 18 November 2019 . Morgenstern, Michael (9 May 2015). "Automation and anxiety" . The Economist . Archived from the original on 12 January 2018 . Retrieved 13 January 2018 . Müller, Vincent C.; Bostrom, Nick (2014). "Future Progress in Artificial Intelligence: A Poll Among Experts" (PDF) . AI Matters . 1 (1): 9– 11. doi : 10.1145/2639475.2639478 . S2CID 8510016 . Archived (PDF) from the original on 15 January 2016. Neumann, Bernd; Möller, Ralf (January 2008). "On scene interpretation with description logics". Image and Vision Computing . 26 (1): 82– 101. doi : 10.1016/j.imavis.2007.08.013 . S2CID 10767011 . Nilsson, Nils (1995), "Eyes on the Prize", AI Magazine , vol. 16, pp. 9– 17 Newell, Allen ; Simon, H. A. (1976). "Computer Science as Empirical Inquiry: Symbols and Search" . Communications of the ACM . 19 (3): 113– 126. doi : 10.1145/360018.360022 . Nicas, Jack (7 February 2018). "How YouTube Drives People to the Internet's Darkest Corners" . The Wall Street Journal . ISSN 0099-9660 . Archived from the original on 5 October 2024 . Retrieved 16 June 2018 . Nilsson, Nils (1983). "Artificial Intelligence Prepares for 2001" (PDF) . AI Magazine . 1 (1). Archived (PDF) from the original on 17 August 2020 . Retrieved 22 August 2020 . Presidential Address to the Association for the Advancement of Artificial Intelligence . NRC (United States National Research Council) (1999). "Developments in Artificial Intelligence". Funding a Revolution: Government Support for Computing Research . National Academy Press. Omohundro, Steve (2008). The Nature of Self-Improving Artificial Intelligence . presented and distributed at the 2007 Singularity Summit, San Francisco, CA. Oudeyer, P-Y. (2010). "On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development" (PDF) . IEEE Transactions on Autonomous Mental Development . 2 (1): 2– 16. doi : 10.1109/tamd.2009.2039057 . S2CID 6362217 . Archived (PDF) from the original on 3 October 2018 . Retrieved 4 June 2013 . Pennachin, C.; Goertzel, B. (2007). "Contemporary Approaches to Artificial General Intelligence". Artificial General Intelligence . Cognitive Technologies. Berlin, Heidelberg: Springer. pp. 1– 30. doi : 10.1007/978-3-540-68677-4_1 . ISBN 978-3-5402-3733-4 . Pinker, Steven (2007) [1994], The Language Instinct , Perennial Modern Classics, Harper, ISBN 978-0-0613-3646-1 Poria, Soujanya; Cambria, Erik; Bajpai, Rajiv; Hussain, Amir (September 2017). "A review of affective computing: From unimodal analysis to multimodal fusion" . Information Fusion . 37 : 98– 125. doi : 10.1016/j.inffus.2017.02.003 . hdl : 1893/25490 . S2CID 205433041 . Archived from the original on 23 March 2023 . Retrieved 27 April 2021 . Rawlinson, Kevin (29 January 2015). "Microsoft's Bill Gates insists AI is a threat" . BBC News . Archived from the original on 29 January 2015 . Retrieved 30 January 2015 . Reisner, Alex (19 August 2023), "Revealed: The Authors Whose Pirated Books are Powering Generative AI" , The Atlantic , archived from the original on 3 October 2024 , retrieved 5 October 2024 Roberts, Jacob (2016). "Thinking Machines: The Search for Artificial Intelligence" . Distillations . Vol. 2, no. 2. pp. 14– 23. Archived from the original on 19 August 2018 . Retrieved 20 March 2018 . Robitzski, Dan (5 September 2018). "Five experts share what scares them the most about AI" . Archived from the original on 8 December 2019 . Retrieved 8 December 2019 . Rose, Steve (11 July 2023). "AI Utopia or dystopia?". The Guardian Weekly . pp. 42– 43. Russell, Stuart (2019). Human Compatible: Artificial Intelligence and the Problem of Control . United States: Viking. ISBN 978-0-5255-5861-3 . OCLC 1083694322 . Sainato, Michael (19 August 2015). "Stephen Hawking, Elon Musk, and Bill Gates Warn About Artificial Intelligence" . Observer . Archived from the original on 30 October 2015 . Retrieved 30 October 2015 . Sample, Ian (5 November 2017). "Computer says no: why making AIs fair, accountable and transparent is crucial" . The Guardian . Archived from the original on 10 October 2022 . Retrieved 30 January 2018 . Rothman, Denis (7 October 2020). "Exploring LIME Explanations and the Mathematics Behind It" . Codemotion . Archived from the original on 25 November 2023 . Retrieved 25 November 2023 . Scassellati, Brian (2002). "Theory of mind for a humanoid robot". Autonomous Robots . 12 (1): 13– 24. doi : 10.1023/A:1013298507114 . S2CID 1979315 . Schmidhuber, J. (2015). "Deep Learning in Neural Networks: An Overview". Neural Networks . 61 : 85– 117. arXiv : 1404.7828 . doi : 10.1016/j.neunet.2014.09.003 . PMID 25462637 . S2CID 11715509 . Schmidhuber, Jürgen (2022). "Annotated History of Modern AI and Deep Learning" . Archived from the original on 7 August 2023 . Retrieved 5 October 2024 . Searle, John (1980). "Minds, Brains and Programs" (PDF) . Behavioral and Brain Sciences . 3 (3): 417– 457. doi : 10.1017/S0140525X00005756 . S2CID 55303721 . Archived (PDF) from the original on 17 March 2019 . Retrieved 22 August 2020 . Searle, John (1999). Mind, language and society . New York: Basic Books. ISBN 978-0-4650-4521-1 . OCLC 231867665 . Archived from the original on 26 July 2020 . Retrieved 22 August 2020 . Simon, H. A. (1965), The Shape of Automation for Men and Management , New York: Harper & Row Simonite, Tom (31 March 2016). "How Google Plans to Solve Artificial Intelligence" . MIT Technology Review . Archived from the original on 16 September 2024 . Retrieved 5 October 2024 . Smith, Craig S. (15 March 2023). "ChatGPT-4 Creator Ilya Sutskever on AI Hallucinations and AI Democracy" . Forbes . Archived from the original on 18 September 2024 . Retrieved 25 December 2023 . Smoliar, Stephen W.; Zhang, HongJiang (1994). "Content based video indexing and retrieval". IEEE MultiMedia . 1 (2): 62– 72. doi : 10.1109/93.311653 . S2CID 32710913 . Solomonoff, Ray (1956). An Inductive Inference Machine (PDF) . Dartmouth Summer Research Conference on Artificial Intelligence. Archived (PDF) from the original on 26 April 2011 . Retrieved 22 March 2011 – via std.com, pdf scanned copy of the original. Later published as Solomonoff, Ray (1957). "An Inductive Inference Machine". IRE Convention Record . Vol. Section on Information Theory, part 2. pp. 56– 62. Stanford University (2023). "Artificial Intelligence Index Report 2023/Chapter 6: Policy and Governance" (PDF) . AI Index. Archived (PDF) from the original on 19 June 2023 . Retrieved 19 June 2023 . Tao, Jianhua; Tan, Tieniu (2005). Affective Computing and Intelligent Interaction . Affective Computing: A Review. Lecture Notes in Computer Science. Vol. 3784. Springer. pp. 981– 995. doi : 10.1007/11573548 . ISBN 978-3-5402-9621-8 . Taylor, Josh; Hern, Alex (2 May 2023). " 'Godfather of AI' Geoffrey Hinton quits Google and warns over dangers of misinformation" . The Guardian . Archived from the original on 5 October 2024 . Retrieved 5 October 2024 . Thompson, Derek (23 January 2014). "What Jobs Will the Robots Take?" . The Atlantic . Archived from the original on 24 April 2018 . Retrieved 24 April 2018 . Thro, Ellen (1993). Robotics: The Marriage of Computers and Machines . New York: Facts on File. ISBN 978-0-8160-2628-9 . Archived from the original on 26 July 2020 . Retrieved 22 August 2020 . Toews, Rob (3 September 2023). "Transformers Revolutionized AI. What Will Replace Them?" . Forbes . Archived from the original on 8 December 2023 . Retrieved 8 December 2023 . Turing, Alan (October 1950). "Computing Machinery and Intelligence" . Mind . 59 (236): 433– 460. doi : 10.1093/mind/LIX.236.433 . ISSN 1460-2113 . JSTOR 2251299 . S2CID 14636783 . UNESCO Science Report: the Race Against Time for Smarter Development . Paris: UNESCO. 2021. ISBN 978-9-2310-0450-6 . Archived from the original on 18 June 2022 . Retrieved 18 September 2021 . Urbina, Fabio; Lentzos, Filippa; Invernizzi, Cédric; Ekins, Sean (7 March 2022). "Dual use of artificial-intelligence-powered drug discovery" . Nature Machine Intelligence . 4 (3): 189– 191. doi : 10.1038/s42256-022-00465-9 . PMC 9544280 . PMID 36211133 . S2CID 247302391 . Valance, Christ (30 May 2023). "Artificial intelligence could lead to extinction, experts warn" . BBC News . Archived from the original on 17 June 2023 . Retrieved 18 June 2023 . Valinsky, Jordan (11 April 2019), "Amazon reportedly employs thousands of people to listen to your Alexa conversations" , CNN.com , archived from the original on 26 January 2024 , retrieved 5 October 2024 Verma, Yugesh (25 December 2021). "A Complete Guide to SHAP – SHAPley Additive exPlanations for Practitioners" . Analytics India Magazine . Archived from the original on 25 November 2023 . Retrieved 25 November 2023 . Vincent, James (7 November 2019). "OpenAI has published the text-generating AI it said was too dangerous to share" . The Verge . Archived from the original on 11 June 2020 . Retrieved 11 June 2020 . Vincent, James (15 November 2022). "The scary truth about AI copyright is nobody knows what will happen next" . The Verge . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . Vincent, James (3 April 2023). "AI is entering an era of corporate control" . The Verge . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . Vinge, Vernor (1993). "The Coming Technological Singularity: How to Survive in the Post-Human Era" . Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace : 11. Bibcode : 1993vise.nasa...11V . Archived from the original on 1 January 2007 . Retrieved 14 November 2011 . Waddell, Kaveh (2018). "Chatbots Have Entered the Uncanny Valley" . The Atlantic . Archived from the original on 24 April 2018 . Retrieved 24 April 2018 . Wallach, Wendell (2010). Moral Machines . Oxford University Press. Wason, P. C. ; Shapiro, D. (1966). "Reasoning" . In Foss, B. M. (ed.). New horizons in psychology . Harmondsworth: Penguin. Archived from the original on 26 July 2020 . Retrieved 18 November 2019 . Weng, J.; McClelland; Pentland, A.; Sporns, O.; Stockman, I.; Sur, M.; Thelen, E. (2001). "Autonomous mental development by robots and animals" (PDF) . Science . 291 (5504): 599– 600. doi : 10.1126/science.291.5504.599 . PMID 11229402 . S2CID 54131797 . Archived (PDF) from the original on 4 September 2013 . Retrieved 4 June 2013 – via msu.edu. "What is 'fuzzy logic'? Are there computers that are inherently fuzzy and do not apply the usual binary logic?" . Scientific American . 21 October 1999. Archived from the original on 6 May 2018 . Retrieved 5 May 2018 . Williams, Rhiannon (28 June 2023), "Humans may be more likely to believe disinformation generated by AI" , MIT Technology Review , archived from the original on 16 September 2024 , retrieved 5 October 2024 Wirtz, Bernd W.; Weyerer, Jan C.; Geyer, Carolin (24 July 2018). "Artificial Intelligence and the Public Sector – Applications and Challenges" . International Journal of Public Administration . 42 (7): 596– 615. doi : 10.1080/01900692.2018.1498103 . ISSN 0190-0692 . S2CID 158829602 . Archived from the original on 18 August 2020 . Retrieved 22 August 2020 . Wong, Matteo (19 May 2023), "ChatGPT Is Already Obsolete" , The Atlantic , archived from the original on 18 September 2024 , retrieved 5 October 2024 Yudkowsky, E (2008), "Artificial Intelligence as a Positive and Negative Factor in Global Risk" (PDF) , Global Catastrophic Risks , Oxford University Press, 2008, Bibcode : 2008gcr..book..303Y , archived (PDF) from the original on 19 October 2013 , retrieved 24 September 2021 Further reading Autor, David H. , "Why Are There Still So Many Jobs? The History and Future of Workplace Automation" (2015) 29(3) Journal of Economic Perspectives 3. Berlinski, David (2000). The Advent of the Algorithm . Harcourt Books. ISBN 978-0-1560-1391-8 . OCLC 46890682 . Archived from the original on 26 July 2020 . Retrieved 22 August 2020 . Boyle, James, The Line: AI and the Future of Personhood , MIT Press , 2024. Cukier, Kenneth , "Ready for Robots? How to Think about the Future of AI", Foreign Affairs , vol. 98, no. 4 (July/August 2019), pp. 192–198. George Dyson , historian of computing, writes (in what might be called "Dyson's Law") that "Any system simple enough to be understandable will not be complicated enough to behave intelligently, while any system complicated enough to behave intelligently will be too complicated to understand." (p. 197.) Computer scientist Alex Pentland writes: "Current AI machine-learning algorithms are, at their core, dead simple stupid. They work, but they work by brute force." (p. 198.) Evans, Woody (2015). "Posthuman Rights: Dimensions of Transhuman Worlds" . Teknokultura . 12 (2). doi : 10.5209/rev_TK.2015.v12.n2.49072 . S2CID 147612763 . Frank, Michael (22 September 2023). "US Leadership in Artificial Intelligence Can Shape the 21st Century Global Order" . The Diplomat . Archived from the original on 16 September 2024 . Retrieved 8 December 2023 . Instead, the United States has developed a new area of dominance that the rest of the world views with a mixture of awe, envy, and resentment: artificial intelligence... From AI models and research to cloud computing and venture capital, U.S. companies, universities, and research labs – and their affiliates in allied countries – appear to have an enormous lead in both developing cutting-edge AI and commercializing it. The value of U.S. venture capital investments in AI start-ups exceeds that of the rest of the world combined. Gertner, Jon. (2023) "Wikipedia's Moment of Truth: Can the online encyclopedia help teach A.I. chatbots to get their facts right — without destroying itself in the process?" New York Times Magazine (July 18, 2023) online Archived 20 July 2023 at the Wayback Machine Gleick, James , "The Fate of Free Will" (review of Kevin J. Mitchell, Free Agents: How Evolution Gave Us Free Will , Princeton University Press, 2023, 333 pp.), The New York Review of Books , vol. LXXI, no. 1 (18 January 2024), pp. 27–28, 30. " Agency is what distinguishes us from machines. For biological creatures, reason and purpose come from acting in the world and experiencing the consequences. Artificial intelligences – disembodied, strangers to blood, sweat, and tears – have no occasion for that." (p. 30.) Halpern, Sue, "The Coming Tech Autocracy" (review of Verity Harding , AI Needs You: How We Can Change AI's Future and Save Our Own , Princeton University Press, 274 pp.; Gary Marcus , Taming Silicon Valley: How We Can Ensure That AI Works for Us , MIT Press, 235 pp.; Daniela Rus and Gregory Mone , The Mind's Mirror: Risk and Reward in the Age of AI , Norton, 280 pp.; Madhumita Murgia , Code Dependent: Living in the Shadow of AI , Henry Holt, 311 pp.), The New York Review of Books , vol. LXXI, no. 17 (7 November 2024), pp. 44–46. "'We can't realistically expect that those who hope to get rich from AI are going to have the interests of the rest of us close at heart,' ... writes [Gary Marcus]. 'We can't count on governments driven by campaign finance contributions [from tech companies] to push back.'... Marcus details the demands that citizens should make of their governments and the tech companies . They include transparency on how AI systems work; compensation for individuals if their data [are] used to train LLMs ( large language model )s and the right to consent to this use; and the ability to hold tech companies liable for the harms they cause by eliminating Section 230 , imposing cash penalties, and passing stricter product liability laws... Marcus also suggests... that a new, AI-specific federal agency, akin to the FDA , the FCC , or the FTC , might provide the most robust oversight.... [T]he Fordham law professor Chinmayi Sharma ... suggests... establish[ing] a professional licensing regime for engineers that would function in a similar way to medical licenses , malpractice suits, and the Hippocratic oath in medicine. 'What if, like doctors,' she asks..., 'AI engineers also vowed to do no harm ?'" (p. 46.) Henderson, Mark (24 April 2007). "Human rights for robots? We're getting carried away" . The Times Online . London. Archived from the original on 31 May 2014 . Retrieved 31 May 2014 . Hughes-Castleberry, Kenna, "A Murder Mystery Puzzle: The literary puzzle Cain's Jawbone , which has stumped humans for decades, reveals the limitations of natural-language-processing algorithms", Scientific American , vol. 329, no. 4 (November 2023), pp. 81–82. "This murder mystery competition has revealed that although NLP ( natural-language processing ) models are capable of incredible feats, their abilities are very much limited by the amount of context they receive. This [...] could cause [difficulties] for researchers who hope to use them to do things such as analyze ancient languages . In some cases, there are few historical records on long-gone civilizations to serve as training data for such a purpose." (p. 82.) Immerwahr, Daniel , "Your Lying Eyes: People now use A.I. to generate fake videos indistinguishable from real ones. How much does it matter?", The New Yorker , 20 November 2023, pp. 54–59. "If by ' deepfakes ' we mean realistic videos produced using artificial intelligence that actually deceive people, then they barely exist. The fakes aren't deep, and the deeps aren't fake. [...] A.I.-generated videos are not, in general, operating in our media as counterfeited evidence. Their role better resembles that of cartoons , especially smutty ones." (p. 59.) Johnston, John (2008) The Allure of Machinic Life: Cybernetics, Artificial Life, and the New AI , MIT Press. Jumper, John; Evans, Richard; Pritzel, Alexander; et al. (26 August 2021). "Highly accurate protein structure prediction with AlphaFold" . Nature . 596 (7873): 583– 589. Bibcode : 2021Natur.596..583J . doi : 10.1038/s41586-021-03819-2 . PMC 8371605 . PMID 34265844 . S2CID 235959867 . LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (28 May 2015). "Deep learning" . Nature . 521 (7553): 436– 444. Bibcode : 2015Natur.521..436L . doi : 10.1038/nature14539 . PMID 26017442 . S2CID 3074096 . Archived from the original on 5 June 2023 . Retrieved 19 June 2023 . Leffer, Lauren, "The Risks of Trusting AI: We must avoid humanizing machine-learning models used in scientific research", Scientific American , vol. 330, no. 6 (June 2024), pp. 80–81. Lepore, Jill , "The Chit-Chatbot: Is talking with a machine a conversation?", The New Yorker , 7 October 2024, pp. 12–16. Maschafilm (2010). "Content: Plug & Pray Film – Artificial Intelligence – Robots" . plugandpray-film.de . Archived from the original on 12 February 2016. Marcus, Gary , "Artificial Confidence: Even the newest, buzziest systems of artificial general intelligence are stymmied by the same old problems", Scientific American , vol. 327, no. 4 (October 2022), pp. 42–45. Mitchell, Melanie (2019). Artificial intelligence: a guide for thinking humans . New York: Farrar, Straus and Giroux. ISBN 978-0-3742-5783-5 . Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; et al. (26 February 2015). "Human-level control through deep reinforcement learning" . Nature . 518 (7540): 529– 533. Bibcode : 2015Natur.518..529M . doi : 10.1038/nature14236 . PMID 25719670 . S2CID 205242740 . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . Introduced DQN , which produced human-level performance on some Atari games. Press, Eyal , "In Front of Their Faces: Does facial-recognition technology lead police to ignore contradictory evidence?", The New Yorker , 20 November 2023, pp. 20–26. "Robots could demand legal rights" . BBC News . 21 December 2006. Archived from the original on 15 October 2019 . Retrieved 3 February 2011 . Roivainen, Eka, "AI's IQ: ChatGPT aced a [standard intelligence] test but showed that intelligence cannot be measured by IQ alone", Scientific American , vol. 329, no. 1 (July/August 2023), p. 7. "Despite its high IQ, ChatGPT fails at tasks that require real humanlike reasoning or an understanding of the physical and social world.... ChatGPT seemed unable to reason logically and tried to rely on its vast database of... facts derived from online texts." Scharre, Paul, "Killer Apps: The Real Dangers of an AI Arms Race", Foreign Affairs , vol. 98, no. 3 (May/June 2019), pp. 135–144. "Today's AI technologies are powerful but unreliable. Rules-based systems cannot deal with circumstances their programmers did not anticipate. Learning systems are limited by the data on which they were trained. AI failures have already led to tragedy. Advanced autopilot features in cars, although they perform well in some circumstances, have driven cars without warning into trucks, concrete barriers, and parked cars. In the wrong situation, AI systems go from supersmart to superdumb in an instant. When an enemy is trying to manipulate and hack an AI system, the risks are even greater." (p. 140.) Schulz, Hannes; Behnke, Sven (1 November 2012). "Deep Learning" . KI – Künstliche Intelligenz . 26 (4): 357– 363. doi : 10.1007/s13218-012-0198-z . ISSN 1610-1987 . S2CID 220523562 . Serenko, Alexander; Michael Dohan (2011). "Comparing the expert survey and citation impact journal ranking methods: Example from the field of Artificial Intelligence" (PDF) . Journal of Informetrics . 5 (4): 629– 649. doi : 10.1016/j.joi.2011.06.002 . Archived (PDF) from the original on 4 October 2013 . Retrieved 12 September 2013 . Silver, David; Huang, Aja; Maddison, Chris J.; et al. (28 January 2016). "Mastering the game of Go with deep neural networks and tree search" . Nature . 529 (7587): 484– 489. Bibcode : 2016Natur.529..484S . doi : 10.1038/nature16961 . PMID 26819042 . S2CID 515925 . Archived from the original on 18 June 2023 . Retrieved 19 June 2023 . Tarnoff, Ben , "The Labor Theory of AI" (review of Matteo Pasquinelli , The Eye of the Master: A Social History of Artificial Intelligence , Verso, 2024, 264 pp.), The New York Review of Books , vol. LXXII, no. 5 (27 March 2025), pp. 30–32. The reviewer, Ben Tarnoff, writes: "The strangeness at the heart of the generative AI boom is that nobody really knows how the technology works. We know how the large language models within ChatGPT and its counterparts are trained, even if we don't always know which data they're being trained on: they are asked to predict the next string of characters in a sequence. But exactly how they arrive at any given prediction is a mystery. The computations that occur inside the model are simply too intricate for any human to comprehend." (p. 32.) Vaswani, Ashish , Noam Shazeer, Niki Parmar et al. " Attention is all you need ." Advances in neural information processing systems 30 (2017). Seminal paper on transformers . Vincent, James, "Horny Robot Baby Voice: James Vincent on AI chatbots", London Review of Books , vol. 46, no. 19 (10 October 2024), pp. 29–32. "[AI chatbot] programs are made possible by new technologies but rely on the timelelss human tendency to anthropomorphise ." (p. 29.) White Paper: On Artificial Intelligence – A European approach to excellence and trust (PDF) . Brussels: European Commission. 2020. Archived (PDF) from the original on 20 February 2020 . Retrieved 20 February 2020 . External links Artificial intelligence at Wikipedia's sister projects Definitions from Wiktionary Media from Commons Quotations from Wikiquote Textbooks from Wikibooks Resources from Wikiversity Data from Wikidata Scholia has a topic profile for Artificial intelligence . "Artificial Intelligence" . Internet Encyclopedia of Philosophy . v t e Artificial intelligence (AI) History ( timeline ) Concepts Parameter Hyperparameter Loss functions Regression Bias–variance tradeoff Double descent Overfitting Clustering Gradient descent SGD Quasi-Newton method Conjugate gradient method Backpropagation Attention Convolution Normalization Batchnorm Activation Softmax Sigmoid Rectifier Gating Weight initialization Regularization Datasets Augmentation Prompt engineering Reinforcement learning Q-learning SARSA Imitation Policy gradient Diffusion Latent diffusion model Autoregression Adversary RAG Uncanny valley RLHF Self-supervised learning Reflection Recursive self-improvement Hallucination Word embedding Vibe coding Applications Machine learning In-context learning Artificial neural network Deep learning Language model Large language model NMT Reasoning language model Model Context Protocol Intelligent agent Artificial human companion Humanity's Last Exam Artificial general intelligence (AGI) Implementations Audio–visual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis 15.ai ElevenLabs Speech recognition Whisper Facial recognition AlphaFold Text-to-image models Aurora DALL-E Firefly Flux Ideogram Imagen Midjourney Recraft Stable Diffusion Text-to-video models Dream Machine Runway Gen Hailuo AI Kling Sora Veo Music generation Suno AI Udio Text Word2vec Seq2seq GloVe BERT T5 Llama Chinchilla AI PaLM GPT 1 2 3 J ChatGPT 4 4o o1 o3 4.5 4.1 o4-mini Claude Gemini chatbot Grok LaMDA BLOOM Project Debater IBM Watson IBM Watsonx Granite PanGu-Σ DeepSeek Qwen Decisional AlphaGo AlphaZero OpenAI Five Self-driving car MuZero Action selection AutoGPT Robot control People Alan Turing Warren Sturgis McCulloch Walter Pitts John von Neumann Claude Shannon Marvin Minsky John McCarthy Nathaniel Rochester Allen Newell Cliff Shaw Herbert A. Simon Oliver Selfridge Frank Rosenblatt Bernard Widrow Joseph Weizenbaum Seymour Papert Seppo Linnainmaa Paul Werbos Jürgen Schmidhuber Yann LeCun Geoffrey Hinton John Hopfield Yoshua Bengio Lotfi A. Zadeh Stephen Grossberg Alex Graves James Goodnight Andrew Ng Fei-Fei Li Ilya Sutskever Alex Krizhevsky Ian Goodfellow Demis Hassabis David Silver Andrej Karpathy Ashish Vaswani Noam Shazeer Aidan Gomez Architectures Neural Turing machine Differentiable neural computer Transformer Vision transformer (ViT) Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network (CNN) Residual neural network (RNN) Highway network Mamba Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network (GNN) Portals Technology Category Artificial neural networks Machine learning List Companies Projects Articles related to Artificial intelligence v t e John McCarthy Artificial intelligence Circumscription Dartmouth workshop Frame problem Garbage collection Lisp ALGOL 60 McCarthy evaluation McCarthy Formalism McCarthy 91 function Situation calculus Space fountain v t e Philosophy of mind Philosophers G. E. M. Anscombe Aristotle Armstrong Thomas Aquinas J. L. Austin Alexander Bain George Berkeley Henri Bergson Ned Block Franz Brentano C. D. Broad Tyler Burge David Chalmers Patricia Churchland Paul Churchland Andy Clark Dharmakirti Donald Davidson Daniel Dennett René Descartes Fred Dretske Fodor Goldman Martin Heidegger David Hume Edmund Husserl William James Frank Cameron Jackson Immanuel Kant David Lewis (philosopher) John Locke Gottfried Wilhelm Leibniz Maurice Merleau-Ponty Marvin Minsky Thomas Nagel Alva Noë Derek Parfit Plato Hilary Putnam Richard Rorty Gilbert Ryle John Searle Wilfrid Sellars Baruch Spinoza Alan Turing Michael Tye Vasubandhu Ludwig Wittgenstein Stephen Yablo Zhuangzi more... Theories Behaviorism Biological naturalism Dualism Eliminative materialism Emergent materialism Epiphenomenalism Functionalism Interactionism Naïve realism Neurophenomenology Neutral monism New mysterianism Nondualism Occasionalism Parallelism Phenomenalism Phenomenology Physicalism Type physicalism Property dualism Representational Solipsism Substance dualism Concepts Abstract object Chinese room Creativity Cognition Cognitive closure Concept Consciousness Hard problem of consciousness Hypostatic abstraction Idea Identity Intelligence Artificial Human Intentionality Introspection Intuition Language of thought Mental event Mental image Mental process Mental property Mental representation Mind Mind–body problem Pain Problem of other minds Propositional attitude Qualia Tabula rasa Understanding Zombie Related Metaphysics Philosophy of artificial intelligence / information / perception / self Category Philosophers category Project Task Force v t e Philosophy of science Concepts Analysis Analytic–synthetic distinction A priori and a posteriori Causality Mill's Methods Commensurability Consilience Construct Correlation function Creative synthesis Demarcation problem Empirical evidence Experiment design Explanatory power Fact Falsifiability Feminist method Functional contextualism Hypothesis alternative null Ignoramus et ignorabimus Inductive reasoning Intertheoretic reduction Inquiry Measurement Nature Objectivity Observation Paradigm Problem of induction Scientific evidence Evidence-based practice Scientific law Scientific method Scientific pluralism Scientific Revolution Testability Theory choice ladenness scientific Underdetermination Unity of science Variable control dependent and independent Theories Coherentism Confirmation holism Constructive empiricism Constructive realism Constructivist epistemology Contextualism Conventionalism Deductive-nomological model Epistemological anarchism Evolutionism Fallibilism Foundationalism Hypothetico-deductive model Inductionism Instrumentalism Model-dependent realism Naturalism Physicalism Positivism / Reductionism / Determinism Pragmatism Rationalism / Empiricism Received view / Semantic view of theories Scientific essentialism Scientific formalism Scientific realism / Anti-realism Scientific skepticism Scientism Structuralism Uniformitarianism Verificationism Vitalism Philosophy of... Biology Chemistry Physics Space and time Social science Archaeology Economics Geography History Linguistics Psychology Related topics Criticism of science Descriptive science Epistemology Exact sciences Faith and rationality Hard and soft science History and philosophy of science Non-science Pseudoscience Normative science Protoscience Questionable cause Relationship between religion and science Rhetoric of science Science studies Sociology of scientific ignorance Sociology of scientific knowledge Philosophers of science Precursors Roger Bacon Francis Bacon Galileo Galilei Isaac Newton David Hume Auguste Comte Henri Poincaré Pierre Duhem Rudolf Steiner Karl Pearson Charles Sanders Peirce Wilhelm Windelband Alfred North Whitehead Bertrand Russell Otto Neurath C. D. Broad Michael Polanyi Hans Reichenbach Rudolf Carnap Karl Popper Carl Gustav Hempel W. V. O. Quine Thomas Kuhn Imre Lakatos Paul Feyerabend Ian Hacking Bas van Fraassen Larry Laudan Category Philosophy portal Science portal v t e Evolutionary computation Main Topics Evolutionary algorithm Evolutionary data mining Evolutionary multimodal optimization Human-based evolutionary computation Interactive evolutionary computation Algorithms Cellular evolutionary algorithm Covariance Matrix Adaptation Evolution Strategy (CMA-ES) Cultural algorithm Differential evolution Evolutionary programming Genetic algorithm Genetic programming Gene expression programming Evolution strategy Natural evolution strategy Neuroevolution Learning classifier system Related techniques Swarm intelligence Ant colony optimization Bees algorithm Cuckoo search Particle swarm optimization Bacterial Colony Optimization Metaheuristic methods Firefly algorithm Harmony search Gaussian adaptation Memetic algorithm Related topics Artificial development Artificial intelligence Artificial life Digital organism Evolutionary robotics Fitness function Fitness landscape Fitness approximation Genetic operators Interactive evolutionary computation No free lunch in search and optimization Machine learning Mating pool Premature convergence Program synthesis Journals Evolutionary Computation (journal) v t e Computer science Note: This template roughly follows the 2012 ACM Computing Classification System . Hardware Printed circuit board Peripheral Integrated circuit Very-large-scale integration System on a chip (SoC) Energy consumption (green computing) Electronic design automation Hardware acceleration Processor Size / Form Computer systems organization Computer architecture Computational complexity Dependability Embedded system Real-time computing Cyber-physical system Fault tolerance Wireless sensor network Networks Network architecture Network protocol Network components Network scheduler Network performance evaluation Network service Software organization Interpreter Middleware Virtual machine Operating system Software quality Software notations and tools Programming paradigm Programming language Compiler Domain-specific language Modeling language Software framework Integrated development environment Software configuration management Software library Software repository Software development Control variable Software development process Requirements analysis Software design Software construction Software deployment Software engineering Software maintenance Programming team Open-source model Theory of computation Model of computation Stochastic Formal language Automata theory Computability theory Computational complexity theory Logic Semantics Algorithms Algorithm design Analysis of algorithms Algorithmic efficiency Randomized algorithm Computational geometry Mathematics of computing Discrete mathematics Probability Statistics Mathematical software Information theory Mathematical analysis Numerical analysis Theoretical computer science Information systems Database management system Information storage systems Enterprise information system Social information systems Geographic information system Decision support system Process control system Multimedia information system Data mining Digital library Computing platform Digital marketing World Wide Web Information retrieval Security Cryptography Formal methods Security hacker Security services Intrusion detection system Hardware security Network security Information security Application security Human–centered computing Interaction design Augmented reality Virtual reality Social computing Ubiquitous computing Visualization Accessibility Human–computer interaction Mobile computing Concurrency Concurrent computing Parallel computing Distributed computing Multithreading Multiprocessing Artificial intelligence Natural language processing Knowledge representation and reasoning Computer vision Automated planning and scheduling Search methodology Control method Philosophy of artificial intelligence Distributed artificial intelligence Machine learning Supervised learning Unsupervised learning Reinforcement learning Multi-task learning Cross-validation Graphics Animation Rendering Photograph manipulation Graphics processing unit Image compression Solid modeling Applied computing Quantum computing E-commerce Enterprise software Computational mathematics Computational physics Computational chemistry Computational biology Computational social science Computational engineering Differentiable computing Computational healthcare Digital art Electronic publishing Cyberwarfare Electronic voting Video games Word processing Operations research Educational technology Document management Category Outline Glossaries v t e Emerging technologies Fields Information and communications Ambient intelligence Internet of things Artificial intelligence Applications of artificial intelligence Machine translation Machine vision Mobile translation Progress in artificial intelligence Semantic Web Speech recognition Atomtronics Carbon nanotube field-effect transistor Cybermethodology Augmented reality Fourth-generation optical discs 3D optical data storage Holographic data storage GPGPU Memory CBRAM ECRAM FRAM Millipede MRAM NRAM PRAM Racetrack memory RRAM SONOS UltraRAM Optical computing RFID Chipless RFID Software-defined radio Three-dimensional integrated circuit Topics Automation Collingridge dilemma Differential technological development Disruptive innovation Ephemeralization Ethics AI Bioethics Cyberethics Neuroethics Robot ethics Exploratory engineering Proactionary principle Technological change Technological unemployment Technological convergence Technological evolution Technological paradigm Technology forecasting Accelerating change Future-oriented technology analysis Horizon scanning Moore's law Technological singularity Technology scouting Technology in science fiction Technology readiness level Technology roadmap Transhumanism List v t e Robotics Main articles Outline Glossary Index History Geography Hall of Fame Ethics Laws Competitions AI competitions Types Aerobot Anthropomorphic Humanoid Android Cyborg Gynoid Claytronics Companion Automaton Animatronic Audio-Animatronics Industrial Articulated arm Domestic Educational Entertainment Juggling Military Medical Service Disability Agricultural Food service Retail BEAM robotics Soft robotics Classifications Biorobotics Cloud robotics Continuum robot Unmanned vehicle aerial ground Mobile robot Microbotics Nanorobotics Necrobotics Robotic spacecraft Space probe Swarm Telerobotics Underwater remotely-operated Robotic fish Locomotion Tracks Walking Hexapod Climbing Electric unicycle Robotic fins Navigation and mapping Motion planning Simultaneous localization and mapping Visual odometry Vision-guided robot systems Research Evolutionary Kits Simulator Suite Open-source Software Adaptable Developmental Human–robot interaction Paradigms Perceptual Situated Ubiquitous Companies ABB Amazon Robotics Anybots Barrett Technology Boston Dynamics Doosan Robotics Energid Technologies FarmWise FANUC Figure AI Foster-Miller Harvest Automation HD Hyundai Robotics Honeybee Robotics Intuitive Surgical IRobot KUKA Rainbow Robotics Starship Technologies Symbotic Universal Robotics Wolf Robotics Yaskawa Related Critique of work Powered exoskeleton Workplace robotics safety Robotic tech vest Technological unemployment Terrainability Fictional robots Category Outline v t e Existential risk from artificial intelligence Concepts AGI AI alignment AI boom AI capability control AI safety AI takeover Consequentialism Effective accelerationism Ethics of artificial intelligence Existential risk from artificial intelligence Friendly artificial intelligence Instrumental convergence Vulnerable world hypothesis Intelligence explosion Longtermism Machine ethics Suffering risks Superintelligence Technological singularity Organizations Alignment Research Center Center for AI Safety Center for Applied Rationality Center for Human-Compatible Artificial Intelligence Centre for the Study of Existential Risk EleutherAI Future of Humanity Institute Future of Life Institute Google DeepMind Humanity+ Institute for Ethics and Emerging Technologies Leverhulme Centre for the Future of Intelligence Machine Intelligence Research Institute OpenAI People Scott Alexander Sam Altman Yoshua Bengio Nick Bostrom Paul Christiano Eric Drexler Sam Harris Stephen Hawking Dan Hendrycks Geoffrey Hinton Bill Joy Shane Legg Elon Musk Steve Omohundro Huw Price Martin Rees Stuart J. Russell Jaan Tallinn Max Tegmark Frank Wilczek Roman Yampolskiy Eliezer Yudkowsky Other Roko's basilisk Statement on AI risk of extinction Human Compatible Open letter on artificial intelligence (2015) Our Final Invention The Precipice Superintelligence: Paths, Dangers, Strategies Do You Trust This Computer? Artificial Intelligence Act Category v t e Subfields of and cyberneticians involved in cybernetics Subfields Artificial intelligence Biological cybernetics Biomedical cybernetics Biorobotics Biosemiotics Neurocybernetics Catastrophe theory Computational neuroscience Connectionism Control theory Conversation theory Cybernetics in the Soviet Union Decision theory Emergence Engineering cybernetics Homeostasis Information theory Management cybernetics Medical cybernetics Second-order cybernetics Cybersemiotics Sociocybernetics Synergetics Cyberneticians Alexander Lerner Alexey Lyapunov Alfred Radcliffe-Brown Allenna Leonard Anthony Wilden Buckminster Fuller Charles François Genevieve Bell Margaret Boden Claude Bernard Cliff Joslyn Erich von Holst Ernst von Glasersfeld Francis Heylighen Francisco Varela Frederic Vester Charles Geoffrey Vickers Gordon Pask Gordon S. Brown Gregory Bateson Heinz von Foerster Humberto Maturana I. A. Richards Igor Aleksander Jacque Fresco Jakob von Uexküll Jason Jixuan Hu Jay Wright Forrester Jennifer Wilby John N. Warfield Kevin Warwick Ludwig von Bertalanffy Maleyka Abbaszadeh Manfred Clynes Margaret Mead Marian Mazur N. Katherine Hayles Natalia Bekhtereva Niklas Luhmann Norbert Wiener Pyotr Grigorenko Qian Xuesen Ranulph Glanville Robert Trappl Sergei P. Kurdyumov Anthony Stafford Beer Stuart Kauffman Stuart Umpleby Talcott Parsons Ulla Mitzdorf Valentin Turchin Valentin Braitenberg William Ross Ashby Walter Bradford Cannon Walter Pitts Warren McCulloch William Grey Walter v t e Glossaries of science and engineering Aerospace engineering Agriculture Archaeology Architecture Artificial intelligence Astronomy Biology Botany Calculus Cell biology Cellular and molecular biology 0–L M–Z Chemistry Civil engineering Clinical research Computer hardware Computer science Developmental and reproductive biology Ecology Economics Electrical and electronics engineering Engineering A–L M–Z Entomology Environmental science Genetics and evolutionary biology Geography A–M N–Z Arabic toponyms Hebrew toponyms Western and South Asia Geology Ichthyology Machine vision Mathematics Mechanical engineering Medicine Meteorology Mycology Nanotechnology Ornithology Physics Probability and statistics Psychiatry Quantum computing Robotics Scientific naming Structural engineering Virology Authority control databases : National Germany United States France BnF data Japan Czech Republic Spain Latvia Israel Retrieved from " https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&oldid=1297714683 " Categories : Artificial intelligence Computational fields of study Computational neuroscience Cybernetics Data science Formal sciences Intelligence by type Hidden categories: Webarchive template wayback links CS1 German-language sources (de) CS1 Japanese-language sources (ja) Articles with short description Short description is different from Wikidata Use dmy dates from July 2023 Wikipedia indefinitely semi-protected pages Articles with excerpts All accuracy disputes Articles with disputed statements from July 2024 Pages displaying short descriptions of redirect targets via Module:Annotated link CS1: long volume value Pages using Sister project links with hidden wikidata Articles with Internet Encyclopedia of Philosophy links This page was last edited on 28 June 2025, at 01:17 (UTC) . Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc. , a non-profit organization. Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Artificial intelligence 167 languages Add topic
====================================================================================================
Artificial intelligence (AI) | Definition, Examples, Types, Applications, Companies, & Facts | Britannica Search Britannica Click here to search Search Britannica Click here to search SUBSCRIBE SUBSCRIBE Login https://premium.britannica.com/premium-membership/?utm_source=premium&utm_medium=nav-login-box&utm_campaign=evergreen SUBSCRIBE Home History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Games & Quizzes Videos On This Day One Good Fact Dictionary New Articles History & Society Lifestyles & Social Issues Philosophy & Religion Politics, Law & Government World History Science & Tech Health & Medicine Science Technology Biographies Browse Biographies Animals & Nature Birds, Reptiles & Other Vertebrates Bugs, Mollusks & Other Invertebrates Environment Fossils & Geologic Time Mammals Plants Geography & Travel Geography & Travel Arts & Culture Entertainment & Pop Culture Literature Sports & Recreation Visual Arts Image Galleries Podcasts Summaries Top Questions Britannica Kids Ask the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Videos artificial intelligence Table of Contents Introduction & Top Questions What is intelligence? Learning Reasoning Problem solving Perception Language Methods and goals in AI Symbolic vs. connectionist approaches Artificial general intelligence (AGI), applied AI, and cognitive simulation AI technology Machine learning Large language models and natural language processing Autonomous vehicles Virtual assistants Risks Is artificial general intelligence (AGI) possible? Want to learn more? References & Edit History Quick Facts & Related Topics Images & Videos For Students artificial intelligence summary Quizzes Computers and Technology Quiz Related Questions What is artificial intelligence? Technology Computers artificial intelligence Image generated by the Stable Diffusion model from the prompt “the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings,” which is the definition of artificial intelligence (AI) in the Encyclopædia Britannica article on the subject. Stable Diffusion is trained on a large set of images paired with textual descriptions and uses natural language processing (NLP) to generate an image. (more) artificial intelligence Quick Summary Ask the Chatbot Print print Print Please select which sections you would like to print: Table Of Contents Cite verified Cite While every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions. Select Citation Style MLA APA Chicago Manual of Style Copy Citation Share Share Share to social media Facebook X URL https://www.britannica.com/technology/artificial-intelligence Feedback External Websites Feedback Corrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login). Feedback Type Select a type (Required) Factual Correction Spelling/Grammar Correction Link Correction Additional Information Other Your Feedback Submit Feedback Thank you for your feedback Our editors will review what you’ve submitted and determine whether to revise the article. External Websites National Center for Biotechnology Information - PubMed Central - The rise of artificial intelligence in healthcare applications Lifewire - What is artificial intelligence? Frontiers - Frontiers in Robotics and AI - A Review of Future and Ethical Perspectives of Robotics and AI Academia - Locomotive Optimization Using Artificial Intelligence Approach Computer History Museum - AI and Robotics Internet Encyclopedia of Philosophy - Artificial Intelligence IOPscience - Journal of Physics: Conference Series - Application of Artificial Intelligence in Integrated Circuits (PDF) Harvard University - Science in the News - The History of Artificial Intelligence Academia - History of Artificial Intelligence National Center for Biotechnology Information - PubMed Central - What is new in computer vision and artificial intelligence in medical image analysis applications Journal of Emerging Technologies and Innovative Research - A Study on the Robotics and Artificial Intelligence Britannica Websites Articles from Britannica Encyclopedias for elementary and high school students. artificial intelligence - Children's Encyclopedia (Ages 8-11) artificial intelligence (AI) - Student Encyclopedia (Ages 11 and up) Quick Summary Ask the Chatbot a Question Also known as: AI Written by B.J. Copeland Professor of Philosophy and Director of the Turing Archive for the History of Computing, University of Canterbury, Christchurch, New Zealand. Author of Artificial Intelligence and others. B.J. Copeland Fact-checked by The Editors of Encyclopaedia Britannica Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree. They write new content and verify and edit content received from contributors. The Editors of Encyclopaedia Britannica Last Updated: Jun 25, 2025 • Article History Table of Contents Table of Contents Quick Summary Ask the Chatbot a Question Key People: Geoffrey Hinton John M. Jumper Marvin Minsky Edward Albert Feigenbaum Allen Newell (Show more) Related Topics: history of artificial intelligence (AI) Logic Theorist General Problem Solver frame generative AI (Show more) On the Web: Frontiers - Frontiers in Robotics and AI - A Review of Future and Ethical Perspectives of Robotics and AI (June 04, 2025) (Show more) See all related content Top Questions What is artificial intelligence? Artificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the intellectual processes characteristic of humans , such as the ability to reason. Although there are as yet no AIs that match full human flexibility over wider domains or in tasks requiring much everyday knowledge, some AIs perform specific tasks as well as humans. Learn more. Are artificial intelligence and machine learning the same? No, artificial intelligence and machine learning are not the same, but they are closely related. Machine learning is the method to train a computer to learn from its inputs but without explicit programming for every circumstance. Machine learning helps a computer to achieve artificial intelligence. News • How ChatGPT and other AI tools are changing the teaching profession • June 25, 2025, 9:22 PM ET (AP) ... (Show more) Judge dismisses authors' copyright lawsuit against Meta over AI training • June 25, 2025, 8:55 PM ET (AP) Bipartisan bill seeks to ban Chinese AI from federal agencies, as U.S. vows to win the AI race • June 25, 2025, 12:47 PM ET (AP) Anthropic wins ruling on AI training in copyright lawsuit but must face trial on pirated books • June 24, 2025, 4:40 PM ET (AP) Music streaming service Deezer adds AI song tags in fight against fraud • June 20, 2025, 9:39 AM ET (AP) Show less artificial intelligence (AI) , the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience. Since their development in the 1940s, digital computers have been programmed to carry out very complex tasks—such as discovering proofs for mathematical theorems or playing chess —with great proficiency. Despite continuing advances in computer processing speed and memory capacity, there are as yet no programs that can match full human flexibility over wider domains or in tasks requiring much everyday knowledge. On the other hand, some programs have attained the performance levels of human experts and professionals in executing certain specific tasks, so that artificial intelligence in this limited sense is found in applications as diverse as medical diagnosis , computer search engines , voice or handwriting recognition, and chatbots . What is intelligence? What do you think? Is Artificial Intelligence Good for Society? Explore the ProCon debate All but the simplest human behavior is ascribed to intelligence, while even the most complicated insect behavior is usually not taken as an indication of intelligence. What is the difference? Consider the behavior of the digger wasp , Sphex ichneumoneus . When the female wasp returns to her burrow with food, she first deposits it on the threshold , checks for intruders inside her burrow, and only then, if the coast is clear, carries her food inside. The real nature of the wasp’s instinctual behavior is revealed if the food is moved a few inches away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as often as the food is displaced. Intelligence—conspicuously absent in the case of the wasp—must include the ability to adapt to new circumstances. Psychologists generally characterize human intelligence not by just one trait but by the combination of many diverse abilities. Research in AI has focused chiefly on the following components of intelligence: learning, reasoning, problem solving , perception , and using language. Learning There are a number of different forms of learning as applied to artificial intelligence. The simplest is learning by trial and error. For example, a simple computer program for solving mate-in-one chess problems might try moves at random until mate is found. The program might then store the solution with the position so that, the next time the computer encountered the same position, it would recall the solution. This simple memorizing of individual items and procedures—known as rote learning—is relatively easy to implement on a computer. More challenging is the problem of implementing what is called generalization . Generalization involves applying past experience to analogous new situations. For example, a program that learns the past tense of regular English verbs by rote will not be able to produce the past tense of a word such as jump unless the program was previously presented with jumped , whereas a program that is able to generalize can learn the “add -ed ” rule for regular verbs ending in a consonant and so form the past tense of jump on the basis of experience with similar verbs. (Read Ray Kurzweil’s Britannica essay on the future of “Nonbiological Man.”) Britannica Quiz Computers and Technology Quiz
====================================================================================================
What Is Artificial Intelligence? Definition, Uses, and Types | Coursera For Individuals For Businesses For Universities For Governments Explore Online Degrees Careers Log In Join for Free Data AI and Machine Learning What Is Artificial Intelligence? Definition, Uses, and Types What Is Artificial Intelligence? Definition, Uses, and Types Written by Coursera Staff • Updated on May 23, 2025 Learn what artificial intelligence actually is, how it’s used today, and what it may do in the future. Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do, such as reasoning, making decisions, or solving problems. Today, the term “AI” describes a wide range of technologies that power many of the services and goods we use every day – from apps that recommend TV shows to chatbots that provide customer support in real time. But do all of these really constitute artificial intelligence as most of us envision it? And if not, then why do we use the term so often? In this article, you’ll learn more about artificial intelligence, what it actually does, and different types of it. In the end, you’ll also learn about some of its benefits and dangers and explore flexible courses that can help you expand your knowledge of AI even further. Want to build your AI skills? Enroll in AI for Everyone , an online program offered by DeepLearning.AI. In just 6 hours , you'll gain foundational knowledge about AI terminology , strategy , and the workflow of machine learning projects . Your first week is free . What is artificial intelligence? Artificial intelligence (AI) is the theory and development of computer systems capable of performing tasks that historically required human intelligence, such as recognizing speech, making decisions, and identifying patterns. AI is an umbrella term that encompasses a wide variety of technologies, including machine learning , deep learning , and natural language processing (NLP) . Although the term is commonly used to describe a range of different technologies in use today, many disagree on whether these actually constitute artificial intelligence. Instead, some argue that much of the technology used in the real world today actually constitutes highly advanced machine learning that is simply a first step towards true artificial intelligence, or “general artificial intelligence” (GAI). Yet, despite the many philosophical disagreements over whether “true” intelligent machines actually exist, when most people use the term AI today, they’re referring to a suite of machine learning-powered technologies, such as Chat GPT or computer vision, that enable machines to perform tasks that previously only humans can do like generating written content, steering a car, or analyzing data. Read more: The History of AI: A Timeline of Artificial Intelligence What does AI stand for? AI stands for "artificial intelligence." Artificial intelligence is the simulation of human intelligence processes by machines, such as computer systems. AI powers many technology-driven industries, such as health care, finance, transportation, and much more. Artificial intelligence examples Though the humanoid robots often associated with AI (think Star Trek: The Next Generation’s Data or Terminator’s T-800) don’t exist yet, you’ve likely interacted with machine learning-powered services or devices many times before. At the simplest level, machine learning uses algorithms trained on data sets to create machine learning models that allow computer systems to perform tasks like making song recommendations, identifying the fastest way to travel to a destination, or translating text from one language to another. Some of the most common examples of AI in use today include: ChatGPT : Uses large language models (LLMs) to generate text in response to questions or comments posed to it. Google Translate: Uses deep learning algorithms to translate text from one language to another. Netflix: Uses machine learning algorithms to create personalized recommendation engines for users based on their previous viewing history. Tesla: Uses computer vision to power self-driving features on their cars. Read more: Deep Learning vs. Machine Learning: Beginner’s Guide The increasing accessibility of generative AI tools has made it an in-demand skill for many tech roles . If you're interested in learning to work with AI for your career, you might consider a free, beginner-friendly online program like Google's Introduction to Generative AI . AI in the workforce Artificial intelligence is prevalent across many industries. Automating tasks that don't require human intervention saves money and time, and can reduce the risk of human error. Here are a couple of ways AI could be employed in different industries: Finance industry. Fraud detection is a notable use case for AI in the finance industry. AI's capability to analyze large amounts of data enables it to detect anomalies or patterns that signal fraudulent behavior. Health care industry. AI-powered robotics could support surgeries close to highly delicate organs or tissue to mitigate blood loss or risk of infection. Subscribe to our weekly newsletter Career Chat . It's a low-commitment way to stay current with industry trends and skills you can use to guide your career path. What is artificial general intelligence (AGI)? Artificial general intelligence (AGI) refers to a theoretical state in which computer systems will be able to achieve or exceed human intelligence. In other words, AGI is “true” artificial intelligence, as depicted in countless science fiction novels, television shows, movies, and comics. As for the precise meaning of “AI” itself, researchers don’t quite agree on how we would recognize “true” artificial general intelligence when it appears. However, the most famous approach to identifying whether a machine is intelligent or not is known as the Turing Test or Imitation Game, an experiment that was first outlined by influential mathematician, computer scientist, and cryptanalyst Alan Turing in a 1950 paper on computer intelligence. There, Turing described a three-player game in which a human “interrogator” is asked to communicate via text with another human and a machine and judge who composed each response. If the interrogator cannot reliably identify the human, then Turing says the machine can be said to be intelligent [ 1 ]. To complicate matters, researchers and philosophers also can’t quite agree whether we’re beginning to achieve AGI, if it’s still far off, or just totally impossible. For example, while a recent paper from Microsoft Research and OpenAI argues that Chat GPT-4 is an early form of AGI, many other researchers are skeptical of these claims and argue that they were just made for publicity [ 2 , 3 ]. Regardless of how far we are from achieving AGI, you can assume that when someone uses the term artificial general intelligence, they’re referring to the kind of sentient computer programs and machines that are commonly found in popular science fiction. Read more: Artificial General Intelligence vs. AI Strong AI vs. Weak AI When researching artificial intelligence, you might have come across the terms “strong” and “weak” AI. Though these terms might seem confusing, you likely already have a sense of what they mean. Strong AI is essentially AI that is capable of human-level, general intelligence. In other words, it’s just another way to say “artificial general intelligence.” Weak AI , meanwhile, refers to the narrow use of widely available AI technology, like machine learning or deep learning, to perform very specific tasks, such as playing chess, recommending songs, or steering cars. Also known as Artificial Narrow Intelligence (ANI), weak AI is essentially the kind of AI we use daily. Read more: Machine Learning vs. AI: Differences, Uses, and Benefits The 4 Types of AI As researchers attempt to build more advanced forms of artificial intelligence, they must also begin to formulate more nuanced understandings of what intelligence or even consciousness precisely mean. In their attempt to clarify these concepts, researchers have outlined four types of artificial intelligence . Here’s a summary of each AI type, according to Professor Arend Hintze of the University of Michigan [ 4 ]: 1. Reactive machines Reactive machines are the most basic type of artificial intelligence. Machines built in this way don’t possess any knowledge of previous events but instead only “react” to what is before them in a given moment. As a result, they can only perform certain advanced tasks within a very narrow scope, such as playing chess, and are incapable of performing tasks outside of their limited context. 2. Limited memory machines Machines with limited memory possess a limited understanding of past events. They can interact more with the world around them than reactive machines can. For example, self-driving cars use a form of limited memory to make turns, observe approaching vehicles, and adjust their speed. However, machines with only limited memory cannot form a complete understanding of the world because their recall of past events is limited and only used in a narrow band of time. 3. Theory of mind machines Machines that possess a “theory of mind” represent an early form of artificial general intelligence. In addition to being able to create representations of the world, machines of this type would also have an understanding of other entities that exist within the world. As of this moment, this reality has still not materialized. 4. Self-aware machines Machines with self-awareness are the theoretically most advanced type of AI and would possess an understanding of the world, others, and itself. This is what most people mean when they talk about achieving AGI. Currently, this is a far-off reality. What is generative artificial intelligence? Generative AI is a kind of artificial intelligence capable of producing original content, such as written text or images, in response to user inputs or "prompts." Generative models are also known as large language models (LLMs) because they're essentially complex, deep learning models trained on vast amounts of data that can be interacted with using normal human language rather than technical jargon. Generative AI is becoming increasingly common in everyday life, powering tools such as ChatGPT, Google Gemini, and Microsoft Copilot. While other kinds of machine learning models are well suited for performing narrow, repetitive tasks, generative AI is capable of responding to user inputs with unique outputs that allow it to respond dynamically in real-time. This makes it particularly useful for powering interactive programs like virtual assistants, chatbots , and recommendation systems. That said, while generative AI may produce responses that make it seem like self-aware AI, the reality is that its responses are the result of statistical analysis rather than sentience. Read more: Generative AI Examples and How the Technology Works AI benefits and dangers AI has a range of applications with the potential to transform how we work and live. While many of these transformations are exciting, like self-driving cars, virtual assistants, or wearable devices in the healthcare industry, they also pose many challenges. It’s a complicated picture that often summons competing images: a utopia for some, a dystopia for others. The reality is likely to be much more complex. Here are a few of the possible benefits and dangers AI may pose: Potential Benefits Potential Dangers Greater accuracy for certain repeatable tasks, such as assembling vehicles or computers. Job loss due to increased automation. Decreased operational costs due to greater efficiency of machines. Potential for bias or discrimination as a result of the data set on which the AI is trained. Increased personalization within digital services and products. Possible cybersecurity concerns. Improved decision-making in certain situations. Lack of transparency over how decisions are arrived at, resulting in less than optimal solutions. Ability to quickly generate new content, such as text or images. Potential to create misinformation, as well as inadvertently violate laws and regulations. These are just some of the ways that AI provides benefits and dangers to society. When using new technologies like AI, it’s best to keep a clear mind about what it is and isn’t. With great power comes great responsibility, after all. Read more: AI Ethics: What It Is and Why It Matters Build AI skills on Coursera Artificial Intelligence is quickly changing the world we live in. If you’re interested in learning more about AI and how you can use it at work or in your own life, consider taking one of these courses or specializations on Coursera today: For a quick overview of AI, take DeepLearning.AI's AI For Everyone course. There, you'll learn what AI can realistically do and not do, how to spot opportunities to apply AI to problems in your own organization, and what it feels like to build machine learning and data science projects. Top build job-ready AI skills to enhance your career, enroll in the IBM AI Foundations for Everyone Specialization . Learn foundational AI concepts, explore AI tools and services, and engage with AI environments through hands-on projects. To learn how AI can address complex real-world problems, explore DeepLearning.AI’s AI For Good Specialization . Here, you’ll build skills combining human and machine intelligence for positive real-world impact using AI in a beginner-friendly, three-course program. Article sources 1 . UMBC. “ Computing Machinery and Intelligence by A. M. Turing , https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf.” Accessed December 19, 2024. 2 . ArXiv. “ Sparks of Artificial General Intelligence: Early experiments with GPT-4 , https://arxiv.org/abs/2303.12712.” Accessed December 19, 2024. 3 . Wired. “ What’s AGI, and Why Are AI Experts Skeptical? , https://www.wired.com/story/what-is-artificial-general-intelligence-agi-explained/.” Accessed December 19, 2024. 4 . GovTech. “ Understanding the Four Types of Artificial Intelligence , https://www.govtech.com/computing/understanding-the-four-types-of-artificial-intelligence.html.” Accessed December 19, 2024. View all sources Updated on May 23, 2025 Written by: C Coursera Staff Editorial Team Coursera’s editorial team is comprised of highly experienced professional editors, writers, and fact... This content has been made available for informational purposes only. Learners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals. Coursera Footer Technical Skills ChatGPT Coding Computer Science Cybersecurity DevOps Ethical Hacking Generative AI Java Programming Python Web Development Analytical Skills Artificial Intelligence Big Data Business Analysis Data Analytics Data Science Financial Modeling Machine Learning Microsoft Excel Microsoft Power BI SQL Business Skills Accounting Digital Marketing E-commerce Finance Google Graphic Design IBM Marketing Project Management Social Media Marketing Career Resources Essential IT Certifications High-Income Skills to Learn How to Get a PMP Certification How to Learn Artificial Intelligence Popular Cybersecurity Certifications Popular Data Analytics Certifications What Does a Data Analyst Do? Career Development Resources Career Aptitude Test Share your Coursera Learning Story Coursera About What We Offer Leadership Careers Catalog Coursera Plus Professional Certificates MasterTrack® Certificates Degrees For Enterprise For Government For Campus Become a Partner Social Impact Free Courses ECTS Credit Recommendations Community Learners Partners Beta Testers Blog The Coursera Podcast Tech Blog More Press Investors Terms Privacy Help Accessibility Contact Articles Directory Affiliates Modern Slavery Statement Manage Cookie Preferences Learn Anywhere © 2025 Coursera Inc. All rights reserved.
====================================================================================================
What is Artificial Intelligence? - NASA Explore Search News & Events News & Events News Releases Recently Published Video Series on NASA+ Podcasts & Audio Blogs Newsletters Social Media Media Resources Events Upcoming Launches & Landings Virtual Guest Program Multimedia Multimedia NASA+ Images NASA Live NASA Apps Podcasts Image of the Day e-Books Interactives STEM Multimedia NASA Brand & Usage Guidelines NASA+ Search Suggested Searches Climate Change Artemis Expedition 64 Mars perseverance SpaceX Crew-2 International Space Station View All Topics A-Z Home Missions Humans in Space Earth The Solar System The Universe Science Aeronautics Technology Learning Resources About NASA Español News & Events Multimedia NASA+ Featured 6 min read NASA Mars Orbiter Learns New Moves After Nearly 20 Years in Space article 2 days ago 4 min read NASA, Australia Team Up for Artemis II Lunar Laser Communications Test article 2 days ago 6 min read What’s Up: June 2025 Skywatching Tips from NASA article 4 weeks ago Back Missions Search All NASA Missions A to Z List of Missions Upcoming Launches and Landings Spaceships and Rockets Communicating with Missions Artemis James Webb Space Telescope Hubble Space Telescope International Space Station OSIRIS-Rex Humans in Space Why Go to Space Astronauts Commercial Space Destinations Spaceships and Rockets Living in Space Earth Explore Earth Science Climate Change Earth, Our Planet Earth Science in Action Earth Multimedia Earth Data Earth Science Researchers The Solar System The Sun Mercury Venus Earth The Moon Mars Jupiter Saturn Uranus Neptune Pluto & Dwarf Planets Asteroids, Comets & Meteors The Kuiper Belt The Oort Cloud Skywatching The Universe Exoplanets The Search for Life in the Universe Stars Galaxies Black Holes The Big Bang Dark Energy Dark Matter Science Earth Science Planetary Science Astrophysics & Space Science The Sun & Heliophysics Biological & Physical Sciences Lunar Science Citizen Science Astromaterials Aeronautics Research Human Space Travel Research Aeronautics Science in the Air NASA Aircraft Flight Innovation Supersonic Flight Air Traffic Solutions Green Aviation Tech Drones & You Technology Technology Transfer & Spinoffs Space Travel Technology Technology Living in Space Manufacturing and Materials Robotics Science Instruments Computing Learning Resources For Kids and Students For Educators For Colleges and Universities For Professionals Science for Everyone Requests for Exhibits, Artifacts, or Speakers STEM Engagement at NASA About NASA NASA's Impacts Centers and Facilities Directorates Organizations People of NASA Careers Internships Our History Doing Business with NASA Get Involved Contact NASA en Español Ciencia Aeronáutica Ciencias Terrestres Sistema Solar Universo News & Events News Releases Recently Published Video Series on NASA+ Podcasts & Audio Blogs Newsletters Social Media Media Resources Events Upcoming Launches & Landings Virtual Guest Program Multimedia NASA+ Images NASA Live NASA Apps Podcasts Image of the Day e-Books Interactives STEM Multimedia NASA Brand & Usage Guidelines Featured 2 min read Curiosity Blog, Sols 4580-4581: Something in the Air… article 2 days ago 6 min read By Air and by Sea: Validating NASA’s PACE Ocean Color Instrument article 2 days ago 2 min read Hubble Captures an Active Galactic Center article 1 day ago Highlights 2 min read NASA Announces Winners of 2025 Human Lander Challenge article 19 hours ago 4 min read NASA, Australia Team Up for Artemis II Lunar Laser Communications Test article 2 days ago 1 min read Testing NASA-Developed Heat Shield Made by U.S. Company article 4 days ago Highlights 6 min read By Air and by Sea: Validating NASA’s PACE Ocean Color Instrument article 2 days ago 4 min read NASA-Assisted Scientists Get Bird’s-Eye View of Population Status article 3 days ago 4 min read NASA Tech to Use Moonlight to Enhance Measurements from Space article 1 week ago Highlights 6 min read NASA Mars Orbiter Learns New Moves After Nearly 20 Years in Space article 2 days ago 6 min read NASA’s Perseverance Rover Scours Mars for Science article 3 days ago 5 min read NASA’s Curiosity Mars Rover Starts Unpacking Boxwork Formations article 5 days ago Featured 2 min read NASA Citizen Scientists Find New Eclipsing Binary Stars article 2 days ago 5 min read NASA’s Webb Digs into Structural Origins of Disk Galaxies article 2 days ago 5 min read Likely Saturn-Mass Planet Imaged by NASA Webb Is Lightest Ever Seen article 3 days ago Highlights 2 min read New Visualization Portal article 2 days ago 6 min read By Air and by Sea: Validating NASA’s PACE Ocean Color Instrument article 2 days ago 2 min read NASA Citizen Scientists Find New Eclipsing Binary Stars article 2 days ago Highlights 3 min read NASA Air Taxi Passenger Comfort Studies Move Forward article 1 week ago 2 min read NASA Aircraft to Make Low-Altitude Flights in Mid-Atlantic, California article 1 week ago 4 min read NASA Tech to Measure Heat, Strain in Hypersonic Flight article 1 week ago Highlights 4 min read NASA-Assisted Scientists Get Bird’s-Eye View of Population Status article 3 days ago 1 min read Testing NASA-Developed Heat Shield Made by U.S. Company article 4 days ago 1 min read Heliophysics – Research and Development of Initiatives of Advanced New Technologies (RADIANT) Program article 5 days ago Featured 5 min read Career Spotlight: Mathematician (Ages 14-18) article 1 month ago Featured 2 min read NASA Citizen Scientists Find New Eclipsing Binary Stars article 2 days ago 5 min read NASA’s Webb Digs into Structural Origins of Disk Galaxies article 2 days ago 4 min read NASA, Australia Team Up for Artemis II Lunar Laser Communications Test article 2 days ago Highlights 5 min read Las carreras en la NASA despegan con las pasantías article 2 months ago 4 min read El X-59 de la NASA completa las pruebas electromagnéticas article 4 months ago 1 min read Mejores imágenes de Ciencia en la estación espacial 2024 article 4 months ago Artificial Intelligence Artificial Intelligence What is AI? AI Ethics AI Inventory What is Artificial Intelligence? Defining Artificial Intelligence Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc. There is no single, simple definition of artificial intelligence because AI tools are capable of a wide range of tasks and outputs, but NASA follows the definition of AI found within EO 13960 , which references Section 238(g) of the National Defense Authorization Act of 2019. Any artificial system that performs tasks under varying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets. An artificial system developed in computer software, physical hardware, or other context that solves tasks requiring human-like perception, cognition, planning, learning, communication, or physical action. An artificial system designed to think or act like a human, including cognitive architectures and neural networks. A set of techniques, including machine learning that is designed to approximate a cognitive task. An artificial system designed to act rationally, including an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communicating, decision-making, and acting. How Artificial Intelligence, Machine Learning, and Deep Learning Fit Together Artificial Intelligence and Machine Learning (ML): AI tools used at NASA sometimes use machine learning, which uses data and algorithms to train computers to make classifications, generate predictions, or uncover similarities or trends across large datasets. Some common methods used at NASA include: Decision Support Complex processes require tools to consider imperfect or unknown situations. This method of artificial intelligence considers multiple outcomes and probabilities to inform decisions. Deep learning A subset of machine learning that involves neural networks with many layers. It distinguishes itself from other forms of neural networks primarily through its capability to learn features automatically from data. Natural language processing A subset of machine learning that trains computers to understand, interpret, and manipulate human language. Neural networks A method to train computers to process data in a way that’s inspired by the human brain, using a layered, interconnected neuron-inspired structure. National Aeronautics and Space Administration NASA explores the unknown in air and space, innovates for the benefit of humanity, and inspires the world through discovery. About NASA's Mission Join Us Home News & Events Multimedia NASA+ Missions Humans in Space Earth The Solar System The Universe Science Aeronautics Technology Learning Resources About NASA NASA en Español Follow NASA More NASA Social Accounts NASA Newsletters Sitemap For Media Privacy Policy FOIA No FEAR Act Office of the IG Budget & Annual Reports Agency Financial Reports Contact NASA Accessibility Page Last Updated: May 13, 2024 Page Editor: Kelley May Responsible NASA Official: Abigail Bowman Was this page helpful? Was this page helpful? Yes No ×
====================================================================================================
What Is Artificial Intelligence (AI)? | IBM What is artificial intelligence (AI)? 9 August 2024 Link copied Authors Cole Stryker Editorial Lead, AI Models Eda Kavlakoglu Program Manager What is AI? Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy. Applications and devices equipped with AI can see and identify objects. They can understand and respond to human language. They can learn from new information and experience. They can make detailed recommendations to users and experts. They can act independently, replacing the need for human intelligence or intervention (a classic example being a self-driving car). But in 2024, most AI researchers, practitioners and most AI-related headlines are focused on breakthroughs in generative AI (gen AI), a technology that can create original text, images, video and other content. To fully understand generative AI, it’s important to first understand the technologies on which generative AI tools are built: machine learning (ML) and deep learning . Industry newsletter The latest tech news, backed by expert insights Stay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter. See the IBM Privacy Statement . Thank you! You are subscribed. Your subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here . Refer to our IBM Privacy Statement for more information. Machine learning A simple way to think about AI is as a series of nested or derivative concepts that have emerged over more than 70 years: Directly underneath AI, we have machine learning, which involves creating models by training an algorithm to make predictions or decisions based on data. It encompasses a broad range of techniques that enable computers to learn from and make inferences based on data without being explicitly programmed for specific tasks. There are many types of machine learning techniques or algorithms, including linear regression , logistic regression , decision trees , random forest , support vector machines (SVMs) , k-nearest neighbor (KNN), clustering and more. Each of these approaches is suited to different kinds of problems and data. But one of the most popular types of machine learning algorithm is called a neural network (or artificial neural network). Neural networks are modeled after the human brain's structure and function. A neural network consists of interconnected layers of nodes (analogous to neurons) that work together to process and analyze complex data. Neural networks are well suited to tasks that involve identifying complex patterns and relationships in large amounts of data. The simplest form of machine learning is called supervised learning , which involves the use of labeled data sets to train algorithms to classify data or predict outcomes accurately. In supervised learning, humans pair each training example with an output label. The goal is for the model to learn the mapping between inputs and outputs in the training data, so it can predict the labels of new, unseen data. Deep learning Deep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, that more closely simulate the complex decision-making power of the human brain. Deep neural networks include an input layer, at least three but usually hundreds of hidden layers, and an output layer, unlike neural networks used in classic machine learning models, which usually have only one or two hidden layers. These multiple layers enable unsupervised learning : they can automate the extraction of features from large, unlabeled and unstructured data sets, and make their own predictions about what the data represents. Because deep learning doesn’t require human intervention, it enables machine learning at a tremendous scale. It is well suited to natural language processing (NLP) , computer vision , and other tasks that involve the fast, accurate identification complex patterns and relationships in large amounts of data. Some form of deep learning powers most of the artificial intelligence (AI) applications in our lives today. Deep learning also enables: Semi-supervised learning , which combines supervised and unsupervised learning by using both labeled and unlabeled data to train AI models for classification and regression tasks. Self-supervised learning , which generates implicit labels from unstructured data, rather than relying on labeled data sets for supervisory signals. Reinforcement learning , which learns by trial-and-error and reward functions rather than by extracting information from hidden patterns. Transfer learning , in which knowledge gained through one task or data set is used to improve model performance on another related task or different data set. Generative AI Generative AI, sometimes called "gen AI" , refers to deep learning models that can create complex original content such as long-form text, high-quality images, realistic video or audio and more in response to a user’s prompt or request. At a high level, generative models encode a simplified representation of their training data, and then draw from that representation to create new work that’s similar, but not identical, to the original data. Generative models have been used for years in statistics to analyze numerical data. But over the last decade, they evolved to analyze and generate more complex data types. This evolution coincided with the emergence of three sophisticated deep learning model types: Variational autoencoders or VAEs, which were introduced in 2013, and enabled models that could generate multiple variations of content in response to a prompt or instruction. Diffusion models, first seen in 2014, which add "noise" to images until they are unrecognizable, and then remove the noise to generate original images in response to prompts. Transformers (also called transformer models), which are trained on sequenced data to generate extended sequences of content (such as words in sentences, shapes in an image, frames of a video or commands in software code). Transformers are at the core of most of today’s headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard and Midjourney. Mixture of Experts | 27 June, episode 61 Decoding AI: Weekly News Roundup Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights. Watch the latest podcast episodes How generative AI works In general, generative AI operates in three phases: Training, to create a foundation model. Tuning, to adapt the model to a specific application. Generation, evaluation and more tuning, to improve accuracy. Training Generative AI begins with a "foundation model"; a deep learning model that serves as the basis for multiple different types of generative AI applications. The most common foundation models today are large language models (LLMs) , created for text generation applications. But there are also foundation models for image, video, sound or music generation, and multimodal foundation models that support several kinds of content. To create a foundation model, practitioners train a deep learning algorithm on huge volumes of relevant raw, unstructured, unlabeled data, such as terabytes or petabytes of data text or images or video from the internet. The training yields a neural network of billions of parameters encoded representations of the entities, patterns and relationships in the data that can generate content autonomously in response to prompts. This is the foundation model. This training process is compute-intensive, time-consuming and expensive. It requires thousands of clustered graphics processing units (GPUs) and weeks of processing, all of which typically costs millions of dollars. Open source foundation model projects, such as Meta's Llama-2, enable gen AI developers to avoid this step and its costs. Tuning Next, the model must be tuned to a specific content generation task. This can be done in various ways, including: Fine-tuning, which involves feeding the model application-specific labeled data, questions or prompts the application is likely to receive, and corresponding correct answers in the wanted format. Reinforcement learning with human feedback (RLHF), in which human users evaluate the accuracy or relevance of model outputs so that the model can improve itself. This can be as simple as having people type or talk back corrections to a chatbot or virtual assistant. Generation, evaluation and more tuning Developers and users regularly assess the outputs of their generative AI apps, and further tune the model even as often as once a week for greater accuracy or relevance. In contrast, the foundation model itself is updated much less frequently, perhaps every year or 18 months. Another option for improving a gen AI app's performance is retrieval augmented generation (RAG), a technique for extending the foundation model to use relevant sources outside of the training data to refine the parameters for greater accuracy or relevance. AI agents and agentic AI An AI agent is an autonomous AI program, it can perform tasks and accomplish goals on behalf of a user or another system without human intervention, by designing its own workflow and using available tools (other applications or services). Agentic AI is a system of multiple AI agents, the efforts of which are coordinated, or orchestrated, to accomplish a more complex task or a greater goal than any single agent in the system could accomplish. Unlike chatbots and other AI models which operate within predefined constraints and require human intervention, AI agents and agentic AI exhibit autonomy, goal-driven behavior and adaptability to changing circumstances. The terms “agent” and “agentic” refer to these models’ agency , or their capacity to act independently and purposefully. One way to think of agents is as a natural next step after generative AI. Gen AI models focus on creating content based on learned patterns; agents use that content to interact with each other and other tools to make decisions, solve problems and complete tasks. For example, a gen AI app might be able to tell you the best time to climb Mt. Everest given your work schedule, but an agent can tell you this, and then use an online travel service to book you the best flight and reserve a room in the most convenient hotel in Nepal. Explore our 2025 guide to AI agents Benefits of AI AI offers numerous benefits across various industries and applications. Some of the most commonly cited benefits include: Automation of repetitive tasks. More and faster insight from data. Enhanced decision-making. Fewer human errors. 24x7 availability. Reduced physical risks. Automation of repetitive tasks AI can automate routine, repetitive and often tedious tasks including digital tasks such as data collection, entering and preprocessing, and physical tasks such as warehouse stock-picking and manufacturing processes. This automation frees to work on higher value, more creative work. Enhanced decision-making Whether used for decision support or for fully automated decision-making, AI enables faster, more accurate predictions and reliable, data-driven decisions . Combined with automation, AI enables businesses to act on opportunities and respond to crises as they emerge, in real time and without human intervention. Fewer human errors AI can reduce human errors in various ways, from guiding people through the proper steps of a process, to flagging potential errors before they occur, and fully automating processes without human intervention. This is especially important in industries such as healthcare where, for example, AI-guided surgical robotics enable consistent precision. Machine learning algorithms can continually improve their accuracy and further reduce errors as they're exposed to more data and "learn" from experience. Round-the-clock availability and consistency AI is always on, available around the clock, and delivers consistent performance every time. Tools such as AI chatbots or virtual assistants can lighten staffing demands for customer service or support. In other applications such as materials processing or production lines, AI can help maintain consistent work quality and output levels when used to complete repetitive or tedious tasks. Reduced physical risk By automating dangerous work such as animal control, handling explosives, performing tasks in deep ocean water, high altitudes or in outer space, AI can eliminate the need to put human workers at risk of injury or worse. While they have yet to be perfected, self-driving cars and other vehicles offer the potential to reduce the risk of injury to passengers. AI use cases The real-world applications of AI are many. Here is just a small sampling of use cases across various industries to illustrate its potential: Customer experience, service and support Companies can implement AI-powered chatbots and virtual assistants to handle customer inquiries, support tickets and more. These tools use natural language processing (NLP) and generative AI capabilities to understand and respond to customer questions about order status, product details and return policies. Chatbots and virtual assistants enable always-on support, provide faster answers to frequently asked questions (FAQs), free human agents to focus on higher-level tasks, and give customers faster, more consistent service. Fraud detection Machine learning and deep learning algorithms can analyze transaction patterns and flag anomalies, such as unusual spending or login locations, that indicate fraudulent transactions. This enables organizations to respond more quickly to potential fraud and limit its impact, giving themselves and customers greater peace of mind. Personalized marketing Retailers, banks and other customer-facing companies can use AI to create personalized customer experiences and marketing campaigns that delight customers, improve sales and prevent churn. Based on data from customer purchase history and behaviors, deep learning algorithms can recommend products and services customers are likely to want, and even generate personalized copy and special offers for individual customers in real time. Human resources and recruitment AI-driven recruitment platforms can streamline hiring by screening resumes, matching candidates with job descriptions, and even conducting preliminary interviews using video analysis. These and other tools can dramatically reduce the mountain of administrative paperwork associated with fielding a large volume of candidates. It can also reduce response times and time-to-hire, improving the experience for candidates whether they get the job or not. Application development and modernization Generative AI code generation tools and automation tools can streamline repetitive coding tasks associated with application development, and accelerate the migration and modernization (reformatting and replatorming) of legacy applications at scale. These tools can speed up tasks, help ensure code consistency and reduce errors. Predictive maintenance Machine learning models can analyze data from sensors, Internet of Things (IoT) devices and operational technology (OT) to forecast when maintenance will be required and predict equipment failures before they occur. AI-powered preventive maintenance helps prevent downtime and enables you to stay ahead of supply chain issues before they affect the bottom line. AI challenges and risks Organizations are scrambling to take advantage of the latest AI technologies and capitalize on AI's many benefits. This rapid adoption is necessary, but adopting and maintaining AI workflows comes with challenges and risks. Data risks AI systems rely on data sets that might be vulnerable to data poisoning, data tampering, data bias or cyberattacks that can lead to data breaches. Organizations can mitigate these risks by protecting data integrity and implementing security and availability throughout the entire AI lifecycle, from development to training and deployment and postdeployment. Model risks Threat actors can target AI models for theft, reverse engineering or unauthorized manipulation. Attackers might compromise a model’s integrity by tampering with its architecture, weights or parameters; the core components that determine a model’s behavior, accuracy and performance. Operational risks Like all technologies, models are susceptible to operational risks such as model drift, bias and breakdowns in the governance structure. Left unaddressed, these risks can lead to system failures and cybersecurity vulnerabilities that threat actors can use. Ethics and legal risks If organizations don’t prioritize safety and ethics when developing and deploying AI systems, they risk committing privacy violations and producing biased outcomes. For example, biased training data used for hiring decisions might reinforce gender or racial stereotypes and create AI models that favor certain demographic groups over others. AI ethics and governance AI ethics is a multidisciplinary field that studies how to optimize AI's beneficial impact while reducing risks and adverse outcomes. Principles of AI ethics are applied through a system of AI governance consisted of guardrails that help ensure that AI tools and systems remain safe and ethical. AI governance encompasses oversight mechanisms that address risks. An ethical approach to AI governance requires the involvement of a wide range of stakeholders, including developers, users, policymakers and ethicists, helping to ensure that AI-related systems are developed and used to align with society's values. Here are common values associated with AI ethics and responsible AI : Explainability and interpretability As AI becomes more advanced, humans are challenged to comprehend and retrace how the algorithm came to a result. Explainable AI is a set of processes and methods that enables human users to interpret, comprehend and trust the results and output created by algorithms. Fairness and inclusion Although machine learning, by its very nature, is a form of statistical discrimination, the discrimination becomes objectionable when it places privileged groups at systematic advantage and certain unprivileged groups at systematic disadvantage, potentially causing varied harms. To encourage fairness, practitioners can try to minimize algorithmic bias across data collection and model design, and to build more diverse and inclusive teams. Robustness and security Robust AI effectively handles exceptional conditions, such as abnormalities in input or malicious attacks, without causing unintentional harm. It is also built to withstand intentional and unintentional interference by protecting against exposed vulnerabilities. Accountability and transparency Organizations should implement clear responsibilities and governance structures for the development, deployment and outcomes of AI systems. In addition, users should be able to see how an AI service works, evaluate its functionality, and comprehend its strengths and limitations. Increased transparency provides information for AI consumers to better understand how the AI model or service was created. Privacy and compliance Many regulatory frameworks, including GDPR, mandate that organizations abide by certain privacy principles when processing personal information. It is crucial to be able to protect AI models that might contain personal information, control what data goes into the model in the first place, and to build adaptable systems that can adjust to changes in regulation and attitudes around AI ethics. Weak AI vs. Strong AI In order to contextualize the use of AI at various levels of complexity and sophistication, researchers have defined several types of AI that refer to its level of sophistication: Weak AI : Also known as “narrow AI,” defines AI systems designed to perform a specific task or a set of tasks. Examples might include “smart” voice assistant apps, such as Amazon’s Alexa, Apple’s Siri, a social media chatbot or the autonomous vehicles promised by Tesla. Strong AI : Also known as “artificial general intelligence” (AGI) or “general AI,” possess the ability to understand, learn and apply knowledge across a wide range of tasks at a level equal to or surpassing human intelligence . This level of AI is currently theoretical and no known AI systems approach this level of sophistication. Researchers argue that if AGI is even possible, it requires major increases in computing power. Despite recent advances in AI development, self-aware AI systems of science fiction remain firmly in that realm. History of AI The idea of "a machine that thinks" dates back to ancient Greece. But since the advent of electronic computing (and relative to some of the topics discussed in this article) important events and milestones in the evolution of AI include the following: 1950 Alan Turing publishes Computing Machinery and Intelligence . In this paper, Turing famous for breaking the German ENIGMA code during WWII and often referred to as the "father of computer science" asks the following question: "Can machines think?" From there, he offers a test, now famously known as the "Turing Test," where a human interrogator would try to distinguish between a computer and human text response. While this test has undergone much scrutiny since it was published, it remains an important part of the history of AI, and an ongoing concept within philosophy as it uses ideas around linguistics. 1956 John McCarthy coins the term "artificial intelligence" at the first-ever AI conference at Dartmouth College. (McCarthy went on to invent the Lisp language.) Later that year, Allen Newell, J.C. Shaw and Herbert Simon create the Logic Theorist, the first-ever running AI computer program. 1967 Frank Rosenblatt builds the Mark 1 Perceptron, the first computer based on a neural network that "learned" through trial and error. Just a year later, Marvin Minsky and Seymour Papert publish a book titled Perceptrons, which becomes both the landmark work on neural networks and, at least for a while, an argument against future neural network research initiatives. 1980 Neural networks, which use a backpropagation algorithm to train itself, became widely used in AI applications. 1995 Stuart Russell and Peter Norvig publish Artificial Intelligence: A Modern Approach , which becomes one of the leading textbooks in the study of AI. In it, they delve into four potential goals or definitions of AI, which differentiates computer systems based on rationality and thinking versus acting. 1997 IBM's Deep Blue beats then world chess champion Garry Kasparov, in a chess match (and rematch). 2004 John McCarthy writes a paper, What Is Artificial Intelligence? , and proposes an often-cited definition of AI. By this time, the era of big data and cloud computing is underway, enabling organizations to manage ever-larger data estates, which will one day be used to train AI models. 2011 IBM Watson® beats champions Ken Jennings and Brad Rutter at Jeopardy! Also, around this time, data science begins to emerge as a popular discipline. 2015 Baidu's Minwa supercomputer uses a special deep neural network called a convolutional neural network to identify and categorize images with a higher rate of accuracy than the average human. 2016 DeepMind's AlphaGo program, powered by a deep neural network, beats Lee Sodol, the world champion Go player, in a five-game match. The victory is significant given the huge number of possible moves as the game progresses (over 14.5 trillion after just four moves). Later, Google purchased DeepMind for a reported USD 400 million. 2022 A rise in large language models or LLMs, such as OpenAI’s ChatGPT, creates an enormous change in performance of AI and its potential to drive enterprise value. With these new generative AI practices, deep-learning models can be pretrained on large amounts of data. 2024 The latest AI trends point to a continuing AI renaissance. Multimodal models that can take multiple types of data as input are providing richer, more robust experiences. These models bring together computer vision image recognition and NLP speech recognition capabilities. Smaller models are also making strides in an age of diminishing returns with massive models with large parameter counts. Ebook How to choose the right foundation model Learn how to choose the right approach in preparing datasets and employing foundation models. Read the ebook Resources Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report Report From AI projects to profits: How agentic AI can sustain financial returns Learn how organizations are shifting from launching AI in disparate pilots to using it to drive transformation at the core. Read the report Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Webinar Driving client innovation with agentic AI: Insights from the IBM and Microsoft Hackathon Join us for an insightful webinar where leaders and participants from the recent IBM Consulting and Microsoft hackathon share their experiences and insights on creating prototypes and MVPs. Watch the webinar AI models Explore IBM Granite IBM® Granite® is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report AI in Action 2024 We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Related solutions IBM watsonx.ai Train, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data. Discover watsonx.ai Artificial intelligence solutions Put AI to work in your business with IBM’s industry-leading AI expertise and portfolio of solutions at your side. Explore AI solutions AI consulting and services Reinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value. Explore AI services Take the next step Get one-stop access to capabilities that span the AI development lifecycle. Produce powerful AI solutions with user-friendly interfaces, workflows and access to industry-standard APIs and SDKs. Explore watsonx.ai Book a live demo
====================================================================================================
ISO - What is artificial intelligence (AI)? Skip to main content Applications OBP English español français русский Menu Standards Sectors Health IT & related technologies Management & services Security, safety & risk Transport Energy Diversity & inclusion Environmental sustainability Food & agriculture Materials Building & construction Engineering About ISO Insights & news Insights All insights Healthcare Artificial intelligence Climate change Transport Cybersecurity Quality management Renewable energy Occupational health and safety News Expert talk Standards world Media kit Taking part Store Search Cart What is artificial intelligence (AI)? In the not-so-distant past, the idea of machines that could think, learn and make decisions was confined to the realm of science fiction. Today, artificial intelligence (AI) has transcended those fictional boundaries, embedding itself into the fabric of our daily lives. But what is artificial intelligence? At its core, AI refers to computer systems capable of performing tasks that typically require human intelligence, such as reasoning, learning, perception and language understanding. These systems analyse vast datasets, recognize patterns and make decisions with unprecedented speed and accuracy . From Amazon’s Alexa+ anticipating your needs to AI-driven drug development accelerating medical breakthroughs, AI’s applications are vast and varied. But AI isn’t just about chatbots – it’s a transformative force reshaping entire industries. From its core principles to cutting-edge applications, join us as we dive deep into the technology that is redefining the future. What is AI? Decoding the AI meaning The definition of artificial intelligence goes beyond simple automation – it’s the ability of machines to think, learn and adapt. No longer confined to routine tasks, AI now tackles complex challenges once exclusive to human intelligence . It understands language, detects patterns, makes decisions, and even predicts future outcomes with uncanny accuracy. So what can AI do? Today’s AI is more powerful than ever. It sees, listens and responds. It learns from experience, refines its skills and integrates seamlessly into our daily lives. From personalized recommendations to fully autonomous systems, AI is transforming the way we innovate, compete and grow in real-time. Self-driving cars? That’s just the beginning. AI has crossed a new threshold in the past year. The real game-changer is generative AI – machines that don’t just process data, they create . They write code, compose music, generate lifelike images and videos, and even produce entire articles indistinguishable from human work. At the heart of this revolution are machine learning and deep learning , the driving forces accelerating AI’s evolution. These technologies are rewriting the rules of innovation, transforming how we interact with technology, and unlocking a future we’re only beginning to imagine. Sign up for email updates Stay updated on artificial intelligence and related standards! Subscribe Almost done! You are only one step away from joining the ISO subscriber list. Please confirm your subscription by clicking on the email we've just sent to you. You will not be registered until you confirm your subscription. If you can't find the email, kindly check your spam folder and/or the promotions tab (if you use Gmail). How your data will be used Please see ISO privacy notice . This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. What are the benefits of AI? AI technology is redefining how we live and work, driving smarter automation, deeper insights and more strategic decision-making. Here’s a look at the key benefits of AI. Automating processes AI takes efficiency to the next level by automating complex workflows and reducing human workload. In cybersecurity, AI-powered systems hunt down threats before they strike. In smart factories, robots with AI-driven vision spot defects, optimize production and keep operations seamless. And companies that use AI in business? They can scale faster, work smarter and do more with less. Zero human error Unlike humans, AI never slips up or gets distracted. It follows strict AI algorithms, ensuring pinpoint accuracy in finance, healthcare and manufacturing. From detecting fraud in banking to perfectly calibrated robotic surgeries, AI enhances reliability across industries. No more repetitive tasks Why waste time on mind-numbing work? AI in business handles document validation, call transcriptions and customer queries – freeing up human talent for creative problem-solving. In hazardous environments, AI-powered robots take over risky jobs, keeping workers safe. Faster, smarter decisions AI processes vast amounts of data at lightning speed, uncovering patterns and insights far beyond human capabilities. It powers real-time financial fraud detection, medical diagnostics and predictive analytics, enabling professionals to stay ahead of the curve. In a world where speed and accuracy are everything, the benefits of AI are game-changing – faster decisions, sharper insights, and the confidence to act before it’s too late. 24/7 reliability Forget downtime – AI works around the clock without breaks, fatigue or errors. From cybersecurity monitoring to healthcare diagnostics and customer support, AI technology ensures uninterrupted performance, keeping businesses and services running smoothly around the clock. Accelerating breakthroughs AI is reshaping research and development, driving discoveries in medicine, climate science and engineering. It speeds up drug discovery, deciphers genetic data for personalized medicine and optimizes renewable energy models. With AI, progress happens faster and smarter. How does AI work? At its core, AI processes vast amounts of data, uncovering patterns and making predictions with remarkable precision. It achieves this by leveraging large datasets and intelligent AI algorithms – structured sets of rules that allow software to learn from patterns in the data. The driving force behind this capability? Neural networks : complex systems of interconnected nodes that pass information through multiple layers to find connections and extract meaning from data. To truly understand how AI works, we must unpack the following concepts: Learning : At the heart of AI lies machine learning , enabling systems to analyse data, recognize patterns and make decisions without explicit programming. Taking this further, deep learning uses advanced neural networks to process millions of data points, allowing AI software to understand more complex patterns and continually improve its performance. Reasoning : AI doesn’t just recognize trends – it can think and infer. By mimicking human reasoning, AI evaluates commands, context and available data to develop strategies, form hypotheses and make informed decisions in real time. Problem solving : AI approaches problem solving through data manipulation, running simulations, testing different possibilities and refining its strategy. Through intelligent AI algorithms, it explores various possible paths to find the most optimal solution to complex problems. Language processing : AI uses natural language processing – or NLP – to analyse human language data in a way that computers can understand. What is NLP? It refers to the ability of machines to understand, interpret and generate human language, using text analysis, sentiment analysis and machine translation. Perception : Through computer vision , AI-powered systems process data from cameras and sensors to identify objects, detect faces and recognize images with precision. From facial recognition to self-driving cars, perception-driven AI is revolutionizing the way machines interact with the world. Strong AI vs weak AI AI spans a wide spectrum of capabilities, but essentially, it falls into two broad categories: weak AI and strong AI. Weak AI, often referred to as artificial narrow intelligence (ANI) or narrow AI , refers to systems designed to excel at specific tasks within well-defined parameters. These systems operate within a limited scope and lack the capacity for general intelligence. Think of them as highly specialized tools – efficient, precise, but confined to their programmed functions. But don’t let the name fool you! Weak AI is anything but weak – it powers countless artificial intelligence applications we interact with daily. Examples of narrow AI are all around us. From Siri and Alexa’s instant responses to self-driving cars, ANI is the impetus behind today’s most advanced AI innovations. Here are some real-world examples of AI applications powered by narrow AI: Smart assistants : Among the best-known examples of weak AI, digital assistants use natural language processing to handle tasks such as setting reminders, answering questions and controlling smart home devices. Chatbots : Ever chatted with customer support on an e-commerce site? Chances are you were speaking with an ANI-powered chatbot. These AI-driven systems answer routine enquiries, leaving humans free to perform higher-level tasks. Recommendation engines : Whether it’s Netflix curating your next must-watch series or Amazon predicting your next purchase, ANI analyses user habits to provide personalized recommendations based on viewing, buying or browsing patterns. Navigation apps : How do you get from A to B without getting lost? Apps like Google Maps rely on ANI algorithms to process real-time traffic data, optimize routes and guide users to their destinations efficiently. Email spam filters : Do you wonder why most spam emails never reach your inbox? ANI-powered filters scan messages, detect suspicious content and redirect unwanted emails to the spam folder. Autocorrect features : Whether you’re texting on an iPhone or composing an email, AI software refines your writing by correcting typos and suggesting words based on your typing patterns, ensuring smoother, more efficient communication. Each of these applications showcases ANI’s ability to tackle specific tasks by leveraging large datasets and specialized algorithms. So, the next time you’re impressed by AI’s capabilities, remember – it’s weak AI driving these remarkable innovations, transforming our world in ways we once thought impossible. Strong AI Also known as artificial general intelligence (AGI) Designed to adapt, learn and apply knowledge across various domains Weak AI Also known as artificial narrow intelligence (ANI) or narrow AI Designed to excel at specific tasks within well-defined parameters In contrast to narrow AI, the concept of strong AI – also known as general AI – aims to develop systems capable of handling a broad range of tasks with human-like proficiency. Unlike their task-specific ANI counterparts, strong AI systems aspire to possess a form of general intelligence that enables them to learn, adapt and apply knowledge across multiple domains. The ultimate goal? To create artificial entities with cognitive abilities that mirror those of humans, capable of engaging in intellectual tasks spanning diverse fields. For now, strong AI remains purely speculative, with no practical examples in real life. However, that hasn’t stopped AI researchers from pushing the boundaries of AI’s potential development. Research in artificial general intelligence (AGI) is exploring how AI could evolve beyond its specialized functions into autonomous systems capable of independent reasoning. In theory, AGI could take on any human job, whether it’s cleaning, coding or scientific research. While we’re not there yet, the potential impact of AGI spans multiple industries, including: Language : Writing essays, poems and engaging in conversations. Healthcare : Medical imaging, drug research and surgery. Transportation : Fully automated cars, trains and planes. Arts and entertainment : Creating music, visual art and films. Domestic robots : Cooking, cleaning and childcare. Manufacturing : Supply chain management, stocktaking and consumer services. Engineering : Programming, building and architecture. Security : Detecting fraud, preventing security breaches and improving public safety. While researchers and developers continue to push the limits of AGI, achieving true general intelligence, on a par with human cognition, remains a formidable challenge and a distant goal. That said, with rapid advancements in AI technology and machine learning, the real question is no longer if AGI will emerge, but when . What are the four types of AI? Artificial intelligence spans a wide range of capabilities, each designed for specific functions and objectives. Understanding the four types of AI provides insight into the ever-evolving landscape of machine intelligence. Reactive machines : These AI systems operate strictly within predefined rules but lack the ability to learn from new data or experiences. A prime example is chatbots, which generate responses based on programmed algorithms , rather than adapting to conversations. While they excel at specific tasks, they cannot evolve beyond their initial programming. Limited memory : Unlike reactive machines, AI systems with limited memory can learn from historical data, enabling them to make informed decisions based on past experiences . These types of AI are seen in self-driving cars, which use sensors and machine learning algorithms to analyse traffic patterns and navigate safely through dynamic environments. Similarly, natural language processing applications leverage historical data to refine language comprehension and interpretation over time. Theory of mind : Still theoretical, this type of AI would be capable of understanding human emotions, intentions and social cues. A machine with a theory of mind could then use that information to anticipate human actions and engage in intuitive, empathetic interactions. If realized, this AI could revolutionize human-computer and social robotics, creating systems that genuinely understand us. Self-aware AI : The most futuristic (and controversial) concept, self-aware AI refers to machines with human-like consciousness – aware of their own existence and capable of perceiving emotions in others. While captivating in science-fiction classics like Blade Runner , this level of AI remains purely hypothetical, sparking both fascination and debate about the future of artificial intelligence. These four types of AI highlight the vast spectrum of intelligence within artificial systems. As AI technology advances, exploring the capabilities and limitations of each type will deepen our understanding of machine intelligence and its impact on society. Machine learning vs deep learning Central to these advancements are machine learning and deep learning, two subfields of AI that drive many of today’s innovations. While closely related, each has its own distinct approach to learning and problem solving. Machine learning relies on different learning methods to train AI systems. The three primary types are: Supervised learning : The algorithm is trained on a labelled dataset, where each input has a known output. By learning from these labelled examples, the model can make accurate predictions on new, unseen data. Unsupervised learning : Unlike supervised learning, this method works without predefined labels or outputs. Instead, the algorithm learns to identify hidden structures or groupings within the data, making it essential for tasks like clustering or anomaly detection. Reinforcement learning : In this approach, an AI agent interacts with an environment and learns through trial and error. It receives rewards for desirable actions or penalties for mistakes, gradually improving its decision-making over time. This technique is widely used in robotics, gaming and autonomous systems. A subset of machine learning, deep learning focuses on training artificial neural networks with multiple layers, inspired by the human brain’s structure and function. These networks consist of interconnected nodes (neurons) that process and transmit signals, enabling AI to learn complex patterns. Unlike traditional machine learning models, deep learning algorithms automatically extract features from raw data, refining their understanding through layers of abstraction. This makes them exceptionally powerful in image and speech recognition, natural language processing and other advanced AI applications. Yet their high complexity comes at a cost – deep learning requires massive datasets, extensive training and significant computational power to achieve optimal performance. Examples of AI technology While many people associate AI with smart assistants like Siri and Alexa, new AI technology is emerging fast, making daily tasks more efficient and transforming industries in unexpected ways. Here are some key applications: Healthcare : AI can process and analyse vast amounts of patient data, enabling accurate diagnoses, predictive analytics and personalized treatment recommendations for better health outcomes. It also plays a crucial role in drug discovery and medical imaging, helping doctors detect diseases earlier and more effectively. Business and manufacturing : AI-driven automation enhances efficiency across industries, from fraud detection and risk assessment to market trend analysis. In manufacturing, AI-powered robots streamline production while predictive maintenance helps prevent equipment failures before they happen. In retail, AI enables personalized shopping experiences, smart inventory management, chatbots for customer support and data-driven advertising strategies to increase sales. Education : AI-powered intelligent tutoring systems adapt to students’ learning styles, providing personalized feedback and guidance. AI also automates grading, content creation and virtual-reality simulations, making education more interactive and efficient. Transport : AI keeps traffic moving, prevents breakdowns and streamlines logistics in shipping and supply chains. From fleet tracking to automated scheduling, it ensures faster, smarter and more efficient operations. Agriculture : AI-driven drones and sensors monitor soil health, detect crop diseases and optimize irrigation. Smart systems also recommend efficient pesticide use and resource management, helping farmers maximize crop yields with minimal waste. Entertainment : AI curates personalized recommendations, matching you with the perfect movie, song or book based on your preferences. Virtual and augmented reality push immersion to new levels, while AI-driven CGI and special effects bring movies and games to life with stunning realism. The growth and impact of generative AI The rise of large-scale language models like Chat GPT is just the beginning. Welcome to the era of generative AI – a groundbreaking frontier in artificial intelligence that goes beyond analysing data to creating entirely new content. Unlike traditional AI systems, which excel at classification and prediction, generative models push boundaries by mimicking human creativity and imagination . They generate text, images, music, and even entire virtual worlds, blurring the line between machine output and human innovation. But generative AI isn’t flawless. While its capabilities are revolutionary, challenges remain. Deepfakes, misinformation, biases, copyright issues and job displacement are all real concerns. These generative models also demand immense computational power, driving up costs and environmental impact while posing security and quality control risks. Despite these hurdles, examples of artificial intelligence in this space continue to expand, proving its extraordinary potential . Researchers are actively tackling these challenges through improved detection systems, refined training data, enhanced security measures and optimized computational efficiency. A balanced approach, supported by guidelines and stronger regulation, will also be key to ensuring generative AI serves as a force for progress, not disruption. AI governance and regulations As AI becomes deeply embedded in industries worldwide, ensuring the quality and reliability of AI software is more critical than ever. Yet, despite its rapid growth, AI still operates in a largely unregulated space, posing risks that demand urgent attention. This is where International Standards come in. Standards, such as those developed by ISO/IEC JTC 1/SC 42 on artificial intelligence, play a pivotal role in addressing the responsible development and use of AI technologies . They provide decision makers and policymakers with a structured framework to create consistent, auditable and transparent AI systems, closing regulatory gaps. For businesses, aligning with these standards isn’t just about compliance – it’s a strategic advantage. From risk management to responsible AI governance, standardized AI practices enhance credibility, build trust with stakeholders, and ensure that the benefits of artificial intelligence outweigh the risks. ISO/IEC 42001:2023 AI management systems ISO/IEC 23894:2023 AI — Guidance on risk management ISO/IEC 23053:2022 Framework for AI systems using machine learning History of artificial intelligence: who invented AI? AI has progressed in leaps and bounds, transforming many aspects of our world. But to truly appreciate its current capabilities, it’s important to understand its origins and evolution . So who created AI? To find out, let’s take a journey through the fascinating history of artificial intelligence. Today’s AI loosely stems from the 19 th -century invention of Charles Babbage’s “difference engine” – the world’s first successful automatic calculator . British code-breaker Alan Turing, who was a key figure in the Allies’ intelligence arsenal during WWII, amongst other feats, can also be seen as a father figure of today’s iterations of AI. In 1950, he proposed the Turing Test, designed to assess a machine’s ability to exhibit intelligent behaviour indistinguishable from that of a human. From that point onward, advancements in AI technology began to accelerate exponentially, spearheaded by such influential figures as John McCarthy, Marvin Minsky, Herbert Simon, Geoffrey Hinton, Yoshua Bengio, Yann LeCun, and many others. But it wasn’t all smooth sailing. While AI flourished in the early years, with computers’ capability to store more information , it soon hit a roadblock: computers simply couldn’t store enough information or process it fast enough. It wasn’t until the 1980s that AI experienced a renaissance, sparked by an expansion of the algorithm toolkit and an increase in funding. To cut a long story short, here are some key events and milestones in the history of artificial intelligence: 1950 : Alan Turing publishes the paper “Computing Machinery and Intelligence”, in which he proposes the Turing Test as a way of assessing whether or not a computer counts as intelligent. 1956 : A small group of scientists gather for the Dartmouth Summer Research Project on Artificial Intelligence, which is regarded as the birth of this field of research. 1966-1974 : This is conventionally known as the “First AI Winter”, a period marked by reduced funding and progress in AI research due to failure to live up to early hype and expectations. 1997 : Deep Blue, an IBM chess computer, defeats world champion Garry Kasparov in a highly publicized chess match, demonstrating the fabulous potential of AI systems. In the same year, speech recognition software, developed by Dragon Systems, was implemented on Windows. 2011 : In a televised Jeopardy! contest, IBM’s Watson Deep QA computer defeats two of the quiz shows’ all-time champions, showcasing the ability of AI systems to understand natural language. 2012 : The “deep learning” approach, inspired by the human brain, revolutionizes many AI applications, ushering in the current AI boom. 2016 : Developed by a Google subsidiary, the computer program AlphaGo captures the world’s attention when it defeats legendary Go player Lee Sedol. The ancient board game “Go” is one of the most complex ever created. 2017 to date : Rapid advancements in computer vision, natural language processing, robotics and autonomous systems are driven by progress in deep learning and increased computational power. 2023 : The rise of large language models, such as GPT-3 and its successors, demonstrates the potential of AI systems to generate human-like text, answer questions and assist with a wide range of tasks. 2024 : New breakthroughs in multimodal AI allow systems to process and integrate various types of data (text, images, audio and video) for more comprehensive and intelligent solutions. AI-powered digital assistants are now capable of engaging in natural, contextual conversations as well as assisting with a wide variety of tasks. How will AI change our world? The exponential growth of computing power and the Internet has propelled machine learning from concept to reality. Today, AI algorithms don’t just follow instructions, they learn from vast datasets, improving with each iteration. At its most advanced, this has led to deep learning, where computers refine their “intelligence” through experience, much like the human brain. And the impact? AI is everywhere – powering how we work, communicate and engage with technology. From medical breakthroughs to climate solutions, its impact will be profound and far-reaching. But with innovation comes responsibility. As AI becomes more powerful and pervasive, we must ensure it is developed and used responsibly. For this to be achieved, it is crucial to stay informed and be proactive in shaping its development – to build a future that is both beneficial and empowering for all. Table of contents Enable Javascript to view table Media contact The Content Team ISO, Geneva, Switzerland +41 22 749 01 11 team-content@iso.org Media contact The Content Team ISO, Geneva, Switzerland +41 22 749 01 11 team-content@iso.org Explore Artificial intelligence: What it is, how it works and why it matters For those unfamiliar with computer science, it can be overwhelming to try and grasp the many facets of artificial intelligence and their implications. Here, we break down what artificial intelligence is, how it works, the difference between machine learning, deep learning, natural language processing … Insights & news Insights All insights What is artificial intelligence (AI)? Sitemap Standards Benefits Popular standards Conformity assessment SDGs Sectors Health IT & related technologies Management & services Security, safety & risk Transport Energy Environmental sustainability Materials About ISO What we do Structure Members Events Strategy Insights & news Insights All insights Healthcare Artificial intelligence Climate change Transport News Expert talk Standards world Media kit Taking part Who develops standards Deliverables Get involved Collaborating to accelerate effective climate action Resources Drafting standards Store Store Publications and products ISO name and logo Privacy Notice Copyright Cookie policy Media kit Jobs Help and support Making lives easier , safer and better . Sign up for email updates © All Rights Reserved All ISO publications and materials are protected by copyright and are subject to the user’s acceptance of ISO’s conditions of copyright. Any use, including reproduction requires our written permission. All copyright requests should be addressed to copyright@iso.org . With the exception of the content available through the ISO Open data page and subject to the terms contained therein, no ISO content may be used for any machine learning and/or artificial intelligence and/or similar technologies, including but not limited to accessing or using it to (i) train data for large language or similar models, or (ii) prompt or otherwise enable artificial intelligence or similar tools to generate responses. We are committed to ensuring that our website is accessible to everyone. If you have any questions or suggestions regarding the accessibility of this site, please contact us . Add to cart
====================================================================================================
What Is Artificial Intelligence (AI)? | Google Cloud Page Contents Topics What is Artificial Intelligence? What is Artificial Intelligence (AI)? Artificial intelligence (AI) is a set of technologies that enable computers to perform a variety of advanced functions, including the ability to see , understand and translate spoken and written language , analyze data , make recommendations, and more. AI is the backbone of innovation in modern computing, unlocking value for individuals and businesses. For example, optical character recognition (OCR ) uses AI to extract text and data from images and documents, turns unstructured content into business-ready structured data, and unlocks valuable insights. Ready to get started? New customers get $300 in free credits to spend on Google Cloud. Get started for free Stay informed 22:54 Introduction to generative AI Artificial intelligence defined Artificial intelligence is a field of science concerned with building computers and machines that can reason, learn, and act in such a way that would normally require human intelligence or that involves data whose scale exceeds what humans can analyze. AI is a broad field that encompasses many different disciplines, including computer science, data analytics and statistics, hardware and software engineering, linguistics, neuroscience, and even philosophy and psychology. On an operational level for business use, AI is a set of technologies that are based primarily on machine learning and deep learning, used for data analytics, predictions and forecasting, object categorization, natural language processing, recommendations, intelligent data retrieval, and more. How does AI work? While the specifics vary across different AI techniques, the core principle revolves around data. AI systems learn and improve through exposure to vast amounts of data, identifying patterns and relationships that humans may miss. This learning process often involves algorithms, which are sets of rules or instructions that guide the AI's analysis and decision-making. In machine learning, a popular subset of AI, algorithms are trained on labeled or unlabeled data to make predictions or categorize information. Deep learning , a further specialization, utilizes artificial neural networks with multiple layers to process information, mimicking the structure and function of the human brain. Through continuous learning and adaptation, AI systems become increasingly adept at performing specific tasks, from recognizing images to translating languages and beyond. Want to learn how to get started with AI? Take the free beginner's introduction to generative AI . Types of artificial intelligence Artificial intelligence can be organized in several ways, depending on stages of development or actions being performed. For instance, four stages of AI development are commonly recognized. Reactive machines: Limited AI that only reacts to different kinds of stimuli based on preprogrammed rules. Does not use memory and thus cannot learn with new data. IBM’s Deep Blue that beat chess champion Garry Kasparov in 1997 was an example of a reactive machine. Limited memory: Most modern AI is considered to be limited memory. It can use memory to improve over time by being trained with new data, typically through an artificial neural network or other training model. Deep learning, a subset of machine learning, is considered limited memory artificial intelligence. Theory of mind: Theory of mind AI does not currently exist, but research is ongoing into its possibilities. It describes AI that can emulate the human mind and has decision-making capabilities equal to that of a human, including recognizing and remembering emotions and reacting in social situations as a human would. Self aware: A step above theory of mind AI, self-aware AI describes a mythical machine that is aware of its own existence and has the intellectual and emotional capabilities of a human. Like theory of mind AI, self-aware AI does not currently exist. A more useful way of broadly categorizing types of artificial intelligence is by what the machine can do. All of what we currently call artificial intelligence is considered artificial “narrow” intelligence, in that it can perform only narrow sets of actions based on its programming and training. For instance, an AI algorithm that is used for object classification won’t be able to perform natural language processing. Google Search is a form of narrow AI, as is predictive analytics, or virtual assistants. Artificial general intelligence (AGI) would be the ability for a machine to “sense, think, and act” just like a human. AGI does not currently exist. The next level would be artificial superintelligence (ASI), in which the machine would be able to function in all ways superior to a human. Artificial intelligence training models When businesses talk about AI, they often talk about “training data.” But what does that mean? Remember that limited-memory artificial intelligence is AI that improves over time by being trained with new data. Machine learning is a subset of artificial intelligence that uses algorithms to train data to obtain results. In broad strokes, three kinds of learnings models are often used in machine learning: Supervised learning is a machine learning model that maps a specific input to an output using labeled training data (structured data). In simple terms, to train the algorithm to recognize pictures of cats, feed it pictures labeled as cats. Unsupervised learning is a machine learning model that learns patterns based on unlabeled data (unstructured data). Unlike supervised learning, the end result is not known ahead of time. Rather, the algorithm learns from the data, categorizing it into groups based on attributes. For instance, unsupervised learning is good at pattern matching and descriptive modeling. In addition to supervised and unsupervised learning, a mixed approach called semi-supervised learning is often employed, where only some of the data is labeled. In semi-supervised learning, an end result is known, but the algorithm must figure out how to organize and structure the data to achieve the desired results. Reinforcement learning is a machine learning model that can be broadly described as “learn by doing.” An “agent” learns to perform a defined task by trial and error (a feedback loop) until its performance is within a desirable range. The agent receives positive reinforcement when it performs the task well and negative reinforcement when it performs poorly. An example of reinforcement learning would be teaching a robotic hand to pick up a ball. Common types of artificial neural networks A common type of training model in AI is an artificial neural network, a model loosely based on the human brain. A neural network is a system of artificial neurons—sometimes called perceptrons—that are computational nodes used to classify and analyze data. The data is fed into the first layer of a neural network, with each perceptron making a decision, then passing that information onto multiple nodes in the next layer. Training models with more than three layers are referred to as “deep neural networks” or “deep learning.” Some modern neural networks have hundreds or thousands of layers. The output of the final perceptrons accomplish the task set to the neural network, such as classify an object or find patterns in data. Some of the most common types of artificial neural networks you may encounter include: Feedforward neural networks (FF) are one of the oldest forms of neural networks, with data flowing one way through layers of artificial neurons until the output is achieved. In modern days, most feedforward neural networks are considered “deep feedforward” with several layers (and more than one “hidden” layer). Feedforward neural networks are typically paired with an error-correction algorithm called “backpropagation” that, in simple terms, starts with the result of the neural network and works back through to the beginning, finding errors to improve the accuracy of the neural network. Many simple but powerful neural networks are deep feedforward. Recurrent neural networks (RNN) differ from feedforward neural networks in that they typically use time series data or data that involves sequences. Unlike feedforward neural networks, which use weights in each node of the network, recurrent neural networks have “memory” of what happened in the previous layer as contingent to the output of the current layer. For instance, when performing natural language processing, RNNs can “keep in mind” other words used in a sentence. RNNs are often used for speech recognition, translation, and to caption images. Long/short term memory (LSTM) is an advanced form of RNN that can use memory to “remember” what happened in previous layers. The difference between RNNs and LSTM is that LSTM can remember what happened several layers ago, through the use of “memory cells.” LSTM is often used in speech recognition and making predictions. Convolutional neural networks (CNN) include some of the most common neural networks in modern artificial intelligence. Most often used in image recognition, CNNs use several distinct layers (a convolutional layer, then a pooling layer) that filter different parts of an image before putting it back together (in the fully connected layer). The earlier convolutional layers may look for simple features of an image, such as colors and edges, before looking for more complex features in additional layers. Generative adversarial networks (GAN) involve two neural networks competing against each other in a game that ultimately improves the accuracy of the output. One network (the generator) creates examples that the other network (the discriminator) attempts to prove true or false. GANs have been used to create realistic images and even make art. Benefits of AI Automation AI can automate workflows and processes or work independently and autonomously from a human team. For example, AI can help automate aspects of cybersecurity by continuously monitoring and analyzing network traffic. Similarly, a smart factory may have dozens of different kinds of AI in use, such as robots using computer vision to navigate the factory floor or to inspect products for defects, create digital twins, or use real-time analytics to measure efficiency and output. Reduce human error AI can eliminate manual errors in data processing, analytics, assembly in manufacturing, and other tasks through automation and algorithms that follow the same processes every single time. Eliminate repetitive tasks AI can be used to perform repetitive tasks, freeing human capital to work on higher impact problems. AI can be used to automate processes, like verifying documents, transcribing phone calls, or answering simple customer questions like “what time do you close?” Robots are often used to perform “dull, dirty, or dangerous” tasks in the place of a human. Fast and accurate AI can process more information more quickly than a human, finding patterns and discovering relationships in data that a human may miss. Infinite availability AI is not limited by time of day, the need for breaks, or other human encumbrances. When running in the cloud, AI and machine learning can be “always on,” continuously working on its assigned tasks. Accelerated research and development The ability to analyze vast amounts of data quickly can lead to accelerated breakthroughs in research and development. For instance, AI has been used in predictive modeling of potential new pharmaceutical treatments, or to quantify the human genome. Solve your business challenges with Google Cloud New customers get $300 in free credits to spend on Google Cloud. Get started Sign up for Google Cloud newsletters with product updates, event information, special offers, and more. Stay informed Applications and use cases for artificial intelligence Speech recognition Automatically convert spoken speech into written text. Image recognition Identify and categorize various aspects of an image. Translation Translate written or spoken words from one language into another. Predictive modeling Mine data to forecast specific outcomes with high degrees of granularity. Data analytics Find patterns and relationships in data for business intelligence. Cybersecurity Autonomously scan networks for cyber attacks and threats. Related products and services Google offers a number of sophisticated artificial intelligence products, solutions, and applications on a trusted cloud platform that enables businesses to easily build and implement AI algorithms and models. By using products like Vertex AI , CCAI , DocAI , or AI APIs , organizations can make sense of all the data they’re producing, collecting, or otherwise analyzing, no matter what format it’s in, to make actionable business decisions. Explore all AI products and solutions Innovative AI and machine learning products, solutions, and services powered by Google’s research and technology. Vertex AI Build, deploy, and scale ML models faster, with pretrained and custom tooling within a unified artificial intelligence platform. Vertex AI Studio Tool for rapidly prototyping and testing generative AI models. Document AI Automate data capture at scale to reduce document processing costs. AlloyDB AI Build a wide range of generative AI applications using familiar PostgreSQL and run models in Vertex AI. Solution Contact Center AI Deliver exceptional customer service and increase operational efficiency using artificial intelligence. Enable your virtual agent to converse naturally with customers and expertly assist human agents on complex cases. Solution Dialogflow CX Create conversational experiences across devices and platforms. Take the next step Start building on Google Cloud with $300 in free credits and 20+ always free products. Get started for free Need help getting started? Contact sales Work with a trusted partner Find a partner Want to hear from us? Join the monthly newsletter menu Overview Solutions Products Pricing Resources Docs Support Contact Us  search_spark send_spark Docs Support Console Sign in Start free Start free Contact Us close Accelerate your digital transformation Whether your business is early in its journey or well on its way to digital transformation, Google Cloud can help solve your toughest challenges. Learn more Key benefits Why Google Cloud Top reasons businesses choose us. AI and ML Get enterprise-ready AI. Multicloud Run your apps wherever you need them. Global infrastructure Build on the same infrastructure as Google. Data Cloud Make smarter decisions with unified data. Modern Infrastructure Cloud Next generation of cloud infrastructure. Security Protect your users, data, and apps. Productivity and collaboration Connect your teams with AI-powered apps. Reports and insights Executive insights Curated C-suite perspectives. Analyst reports Read what industry analysts say about us. Whitepapers Browse and download popular whitepapers. Customer stories Explore case studies and videos. close Industry Solutions Application Modernization Artificial Intelligence APIs and Applications Data Analytics Databases Infrastructure Modernization Productivity and Collaboration Security Startups and SMB See all solutions Industry Solutions Reduce cost, increase operational agility, and capture new market opportunities. Retail Analytics and collaboration tools for the retail value chain. Consumer Packaged Goods Solutions for CPG digital transformation and brand growth. Financial Services Computing, data management, and analytics tools for financial services. Healthcare and Life Sciences Advance research at scale and empower healthcare innovation. Media and Entertainment Solutions for content production and distribution operations. Telecommunications Hybrid and multi-cloud services to deploy and monetize 5G. Games AI-driven solutions to build and scale games faster. Manufacturing Migration and AI tools to optimize the manufacturing value chain. Supply Chain and Logistics Enable sustainable, efficient, and resilient data-driven operations across supply chain and logistics operations. Government Data storage, AI, and analytics solutions for government agencies. Education Teaching tools to provide more engaging learning experiences. Not seeing what you're looking for? See all industry solutions Application Modernization Assess, plan, implement, and measure software practices and capabilities to modernize and simplify your organization’s business application portfolios. CAMP Program that uses DORA to improve your software delivery capabilities. Modernize Traditional Applications Analyze, categorize, and get started with cloud migration on traditional workloads. Migrate from PaaS: Cloud Foundry, Openshift Tools for moving your existing containers into Google's managed container services. Migrate from Mainframe Automated tools and prescriptive guidance for moving your mainframe apps to the cloud. Modernize Software Delivery Software supply chain best practices - innerloop productivity, CI/CD and S3C. DevOps Best Practices Processes and resources for implementing DevOps in your org. SRE Principles Tools and resources for adopting SRE in your org. Day 2 Operations for GKE Tools and guidance for effective GKE management and monitoring. FinOps and Optimization of GKE Best practices for running reliable, performant, and cost effective applications on GKE. Run Applications at the Edge Guidance for localized and low latency apps on Google’s hardware agnostic edge solution. Architect for Multicloud Manage workloads across multiple clouds with a consistent platform. Go Serverless Fully managed environment for developing, deploying and scaling apps. Artificial Intelligence Add intelligence and efficiency to your business with AI and machine learning. Customer Engagement Suite with Google AI End-to-end application that combines our most advanced conversational AI. Document AI Document processing and data capture automated at scale. Vertex AI Search for retail Google-quality search and product recommendations for retailers. Gemini for Google Cloud AI assistants for application development, coding, and more. Generative AI on Google Cloud Transform content creation and discovery, research, customer service, and developer efficiency with the power of generative AI. APIs and Applications Speed up the pace of innovation without coding, using APIs, apps, and automation. New Business Channels Using APIs Attract and empower an ecosystem of developers and partners. Unlocking Legacy Applications Using APIs Cloud services for extending and modernizing legacy apps. Open Banking APIx Simplify and accelerate secure delivery of open banking compliant APIs. Data Analytics Generate instant insights from data at any scale with a serverless, fully managed analytics platform that significantly simplifies analytics. Data Migration Migrate and modernize with an AI-ready data platform. Data Lake Modernization Services for building and modernizing your data lake. Stream Analytics Insights from ingesting, processing, and analyzing event streams. Marketing Analytics Solutions for collecting, analyzing, and activating customer data. Datasets Data from Google, public, and commercial providers to enrich your analytics and AI initiatives. Business Intelligence Solutions for modernizing your BI stack and creating rich data experiences. AI for Data Analytics Write SQL, build predictive models, and visualize data with AI for data analytics. Databases Migrate and manage enterprise data with security, reliability, high availability, and fully managed data services. Database Migration Guides and tools to simplify your database migration life cycle. Database Modernization Upgrades to modernize your operational database infrastructure. Databases for Games Build global, live games with Google Cloud databases. Google Cloud Databases Database services to migrate, manage, and modernize data. Migrate Oracle workloads to Google Cloud Rehost, replatform, rewrite your Oracle workloads. Open Source Databases Fully managed open source databases with enterprise-grade support. SQL Server on Google Cloud Options for running SQL Server virtual machines on Google Cloud. Gemini for Databases Supercharge database development and management with AI. Infrastructure Modernization Migrate quickly with solutions for SAP, VMware, Windows, Oracle, and other workloads. Application Migration Discovery and analysis tools for moving to the cloud. SAP on Google Cloud Certifications for running SAP applications and SAP HANA. High Performance Computing Compute, storage, and networking options to support any workload. Windows on Google Cloud Tools and partners for running Windows workloads. Data Center Migration Migration solutions for VMs, apps, databases, and more. Active Assist Automatic cloud resource optimization and increased security. Virtual Desktops Remote work solutions for desktops and applications (VDI & DaaS). Rapid Migration and Modernization Program End-to-end migration program to simplify your path to the cloud. Backup and Disaster Recovery Ensure your business continuity needs are met. Red Hat on Google Cloud Google and Red Hat provide an enterprise-grade platform for traditional on-prem and custom applications. Cross-Cloud Network Simplify hybrid and multicloud networking, and secure your workloads, data, and users. Observability Monitor, troubleshoot, and improve app performance with end-to-end visibility. Productivity and Collaboration Change the way teams work with solutions designed for humans and built for impact. Google Workspace Collaboration and productivity tools for enterprises. Google Workspace Essentials Secure video meetings and modern collaboration for teams. Cloud Identity Unified platform for IT admins to manage user devices and apps. Chrome Enterprise ChromeOS, Chrome Browser, and Chrome devices built for business. Security Detect, investigate, and respond to online threats to help protect your business. Security Analytics and Operations Solution for analyzing petabytes of security telemetry. Web App and API Protection Threat and fraud protection for your web applications and APIs. Security and Resilience Framework Solutions for each phase of the security and resilience life cycle. Risk and compliance as code (RCaC) Solution to modernize your governance, risk, and compliance function with automation. Software Supply Chain Security Solution for improving end-to-end software supply chain security. Security Foundation Recommended products to help achieve a strong security posture. Google Cloud Cybershield™ Strengthen nationwide cyber defense. Startups and SMB Accelerate startup and SMB growth with tailored solutions and programs. Startup Program Get financial, business, and technical support to take your startup to the next level. Small and Medium Business Explore solutions for web hosting, app development, AI, and analytics. Software as a Service Build better SaaS products, scale efficiently, and grow your business. close Featured Products AI and Machine Learning Business Intelligence Compute Containers Data Analytics Databases Developer Tools Distributed Cloud Hybrid and Multicloud Industry Specific Integration Services Management Tools Maps and Geospatial Media Services Migration Mixed Reality Networking Operations Productivity and Collaboration Security and Identity Serverless Storage Web3 See all products (100+) Featured Products Compute Engine Virtual machines running in Google’s data center. Cloud Storage Object storage that’s secure, durable, and scalable. BigQuery Data warehouse for business agility and insights. Cloud Run Fully managed environment for running containerized apps. Google Kubernetes Engine Managed environment for running containerized apps. Vertex AI Unified platform for ML models and generative AI. Looker Platform for BI, data applications, and embedded analytics. Apigee API Management Manage the full life cycle of APIs anywhere with visibility and control. Cloud SQL Relational database services for MySQL, PostgreSQL and SQL Server. Gemini Google Cloud products powered by Gemini. Cloud CDN Content delivery network for delivering web and video. Not seeing what you're looking for? See all products (100+) AI and Machine Learning Vertex AI Platform Unified platform for ML models and generative AI. Vertex AI Studio Build, tune, and deploy foundation models on Vertex AI. Vertex AI Agent Builder Build and deploy gen AI experiences. Conversational Agents Build conversational AI with both deterministic and gen AI functionality. Vertex AI Search Build Google-quality search for your enterprise apps and experiences. Speech-to-Text Speech recognition and transcription across 125 languages. Text-to-Speech Speech synthesis in 220+ voices and 40+ languages. Translation AI Language detection, translation, and glossary support. Document AI Document processing and data capture automated at scale. Vision AI Custom and pre-trained models to detect emotion, text, and more. Contact Center as a Service Omnichannel contact center solution that is native to the cloud. Not seeing what you're looking for? See all AI and machine learning products Business Intelligence Looker Platform for BI, data applications, and embedded analytics. Looker Studio Interactive data suite for dashboarding, reporting, and analytics. Compute Compute Engine Virtual machines running in Google’s data center. App Engine Serverless application platform for apps and back ends. Cloud GPUs GPUs for ML, scientific computing, and 3D visualization. Migrate to Virtual Machines Server and virtual machine migration to Compute Engine. Spot VMs Compute instances for batch jobs and fault-tolerant workloads. Batch Fully managed service for scheduling batch jobs. Sole-Tenant Nodes Dedicated hardware for compliance, licensing, and management. Bare Metal Infrastructure to run specialized workloads on Google Cloud. Recommender Usage recommendations for Google Cloud products and services. VMware Engine Fully managed, native VMware Cloud Foundation software stack. Cloud Run Fully managed environment for running containerized apps. Not seeing what you're looking for? See all compute products Containers Google Kubernetes Engine Managed environment for running containerized apps. Cloud Run Fully managed environment for running containerized apps. Cloud Build Solution for running build steps in a Docker container. Artifact Registry Package manager for build artifacts and dependencies. Cloud Code IDE support to write, run, and debug Kubernetes applications. Cloud Deploy Fully managed continuous delivery to GKE and Cloud Run. Migrate to Containers Components for migrating VMs into system containers on GKE. Deep Learning Containers Containers with data science frameworks, libraries, and tools. Knative Components to create Kubernetes-native cloud-based software. Data Analytics BigQuery Data warehouse for business agility and insights. Looker Platform for BI, data applications, and embedded analytics. Dataflow Streaming analytics for stream and batch processing. Pub/Sub Messaging service for event ingestion and delivery. Dataproc Service for running Apache Spark and Apache Hadoop clusters. Cloud Data Fusion Data integration for building and managing data pipelines. Cloud Composer Workflow orchestration service built on Apache Airflow. BigLake Storage engine to query multi-format and multimodal data. Dataplex Intelligent data fabric for unifying data management across silos. Dataform Build, version control, and deploy SQL workflows in BigQuery. Analytics Hub Service for securely and efficiently exchanging data analytics assets. Not seeing what you're looking for? See all data analytics products Databases AlloyDB for PostgreSQL Fully managed, PostgreSQL-compatible database for enterprise workloads. Cloud SQL Fully managed database for MySQL, PostgreSQL, and SQL Server. Firestore Cloud-native document database for building rich mobile, web, and IoT apps. Spanner Cloud-native relational database with unlimited scale and 99.999% availability. Bigtable Cloud-native wide-column database for large-scale, low-latency workloads. Datastream Serverless change data capture and replication service. Database Migration Service Serverless, minimal downtime migrations to Cloud SQL. Bare Metal Solution Fully managed infrastructure for your Oracle workloads. Memorystore Fully managed Redis and Memcached for sub-millisecond data access. Developer Tools Artifact Registry Universal package manager for build artifacts and dependencies. Cloud Code IDE support to write, run, and debug Kubernetes applications. Cloud Build Continuous integration and continuous delivery platform. Cloud Deploy Fully managed continuous delivery to GKE and Cloud Run. Cloud Deployment Manager Service for creating and managing Google Cloud resources. Cloud SDK Command-line tools and libraries for Google Cloud. Cloud Scheduler Cron job scheduler for task automation and management. Cloud Source Repositories Private Git repository to store, manage, and track code. Infrastructure Manager Automate infrastructure management with Terraform. Cloud Workstations Managed and secure development environments in the cloud. Gemini Code Assist AI-powered assistant available across Google Cloud and your IDE. Not seeing what you're looking for? See all developer tools Distributed Cloud Google Distributed Cloud Connected Distributed cloud services for edge workloads. Google Distributed Cloud Air-gapped Distributed cloud for air-gapped workloads. Hybrid and Multicloud Google Kubernetes Engine Managed environment for running containerized apps. Apigee API Management API management, development, and security platform. Migrate to Containers Tool to move workloads and existing applications to GKE. Cloud Build Service for executing builds on Google Cloud infrastructure. Observability Monitoring, logging, and application performance suite. Cloud Service Mesh Fully managed service mesh based on Envoy and Istio. Google Distributed Cloud Fully managed solutions for the edge and data centers. Industry Specific Anti Money Laundering AI Detect suspicious, potential money laundering activity with AI. Cloud Healthcare API Solution for bridging existing care systems and apps on Google Cloud. Device Connect for Fitbit Gain a 360-degree patient view with connected Fitbit data on Google Cloud. Telecom Network Automation Ready to use cloud-native automation for telecom networks. Telecom Data Fabric Telecom data management and analytics with an automated approach. Telecom Subscriber Insights Ingests data to improve subscriber acquisition and retention. Spectrum Access System (SAS) Controls fundamental access to the Citizens Broadband Radio Service (CBRS). Integration Services Application Integration Connect to 3rd party apps and enable data consistency without code. Workflows Workflow orchestration for serverless products and API services. Apigee API Management Manage the full life cycle of APIs anywhere with visibility and control. Cloud Tasks Task management service for asynchronous task execution. Cloud Scheduler Cron job scheduler for task automation and management. Dataproc Service for running Apache Spark and Apache Hadoop clusters. Cloud Data Fusion Data integration for building and managing data pipelines. Cloud Composer Workflow orchestration service built on Apache Airflow. Pub/Sub Messaging service for event ingestion and delivery. Eventarc Build an event-driven architecture that can connect any service. Management Tools Cloud Shell Interactive shell environment with a built-in command line. Cloud console Web-based interface for managing and monitoring cloud apps. Cloud Endpoints Deployment and development management for APIs on Google Cloud. Cloud IAM Permissions management system for Google Cloud resources. Cloud APIs Programmatic interfaces for Google Cloud services. Service Catalog Service catalog for admins managing internal enterprise solutions. Cost Management Tools for monitoring, controlling, and optimizing your costs. Observability Monitoring, logging, and application performance suite. Carbon Footprint Dashboard to view and export Google Cloud carbon emissions reports. Config Connector Kubernetes add-on for managing Google Cloud resources. Active Assist Tools for easily managing performance, security, and cost. Not seeing what you're looking for? See all management tools Maps and Geospatial Earth Engine Geospatial platform for Earth observation data and analysis. Google Maps Platform Create immersive location experiences and improve business operations. Media Services Cloud CDN Content delivery network for serving web and video content. Live Stream API Service to convert live video and package for streaming. OpenCue Open source render manager for visual effects and animation. Transcoder API Convert video files and package them for optimized delivery. Video Stitcher API Service for dynamic or server side ad insertion. Migration Migration Center Unified platform for migrating and modernizing with Google Cloud. Application Migration App migration to the cloud for low-cost refresh cycles. Migrate to Virtual Machines Components for migrating VMs and physical servers to Compute Engine. Cloud Foundation Toolkit Reference templates for Deployment Manager and Terraform. Database Migration Service Serverless, minimal downtime migrations to Cloud SQL. Migrate to Containers Components for migrating VMs into system containers on GKE. BigQuery Data Transfer Service Data import service for scheduling and moving data into BigQuery. Rapid Migration and Modernization Program End-to-end migration program to simplify your path to the cloud. Transfer Appliance Storage server for moving large volumes of data to Google Cloud. Storage Transfer Service Data transfers from online and on-premises sources to Cloud Storage. VMware Engine Migrate and run your VMware workloads natively on Google Cloud. Mixed Reality Immersive Stream for XR Hosts, renders, and streams 3D and XR experiences. Networking Cloud Armor Security policies and defense against web and DDoS attacks. Cloud CDN and Media CDN Content delivery network for serving web and video content. Cloud DNS Domain name system for reliable and low-latency name lookups. Cloud Load Balancing Service for distributing traffic across applications and regions. Cloud NAT NAT service for giving private instances internet access. Cloud Connectivity Connectivity options for VPN, peering, and enterprise needs. Network Connectivity Center Connectivity management to help simplify and scale networks. Network Intelligence Center Network monitoring, verification, and optimization platform. Network Service Tiers Cloud network options based on performance, availability, and cost. Virtual Private Cloud Single VPC for an entire organization, isolated within projects. Private Service Connect Secure connection between your VPC and services. Not seeing what you're looking for? See all networking products Operations Cloud Logging Google Cloud audit, platform, and application logs management. Cloud Monitoring Infrastructure and application health with rich metrics. Error Reporting Application error identification and analysis. Managed Service for Prometheus Fully-managed Prometheus on Google Cloud. Cloud Trace Tracing system collecting latency data from applications. Cloud Profiler CPU and heap profiler for analyzing application performance. Cloud Quotas Manage quotas for all Google Cloud services. Productivity and Collaboration AppSheet No-code development platform to build and extend applications. AppSheet Automation Build automations and applications on a unified platform. Google Workspace Collaboration and productivity tools for individuals and organizations. Google Workspace Essentials Secure video meetings and modern collaboration for teams. Gemini for Workspace Embeds generative AI across Google Workspace apps. Cloud Identity Unified platform for IT admins to manage user devices and apps. Chrome Enterprise ChromeOS, Chrome browser, and Chrome devices built for business. Security and Identity Cloud IAM Permissions management system for Google Cloud resources. Sensitive Data Protection Discover, classify, and protect your valuable data assets. Mandiant Managed Defense Find and eliminate threats with confidence 24x7. Google Threat Intelligence Know who’s targeting you. Security Command Center Platform for defending against threats to your Google Cloud assets. Cloud Key Management Manage encryption keys on Google Cloud. Mandiant Incident Response Minimize the impact of a breach. Chrome Enterprise Premium Get secure enterprise browsing with extensive endpoint visibility. Assured Workloads Compliance and security controls for sensitive workloads. Google Security Operations Detect, investigate, and respond to cyber threats. Mandiant Consulting Get expert guidance before, during, and after an incident. Not seeing what you're looking for? See all security and identity products Serverless Cloud Run Fully managed environment for running containerized apps. Cloud Functions Platform for creating functions that respond to cloud events. App Engine Serverless application platform for apps and back ends. Workflows Workflow orchestration for serverless products and API services. API Gateway Develop, deploy, secure, and manage APIs with a fully managed gateway. Storage Cloud Storage Object storage that’s secure, durable, and scalable. Block Storage High-performance storage for AI, analytics, databases, and enterprise applications. Filestore File storage that is highly scalable and secure. Persistent Disk Block storage for virtual machine instances running on Google Cloud. Cloud Storage for Firebase Object storage for storing and serving user-generated content. Local SSD Block storage that is locally attached for high-performance needs. Storage Transfer Service Data transfers from online and on-premises sources to Cloud Storage. Parallelstore High performance, managed parallel file service. Google Cloud NetApp Volumes File storage service for NFS, SMB, and multi-protocol environments. Backup and DR Service Service for centralized, application-consistent data protection. Web3 Blockchain Node Engine Fully managed node hosting for developing on the blockchain. Blockchain RPC Enterprise-grade RPC for building on the blockchain. close Save money with our transparent approach to pricing Google Cloud's pay-as-you-go pricing offers automatic savings based on monthly usage and discounted rates for prepaid resources. Contact us today to get a quote. Request a quote Pricing overview and tools Google Cloud pricing Pay only for what you use with no lock-in. Pricing calculator Calculate your cloud savings. Google Cloud free tier Explore products with free monthly usage. Cost optimization framework Get best practices to optimize workload costs. Cost management tools Tools to monitor and control your costs. Product-specific Pricing Compute Engine Cloud SQL Google Kubernetes Engine Cloud Storage BigQuery See full price list with 100+ products close Learn & build Google Cloud Free Program $300 in free credits and 20+ free products. Solution Generator Get AI generated solution recommendations. Quickstarts Get tutorials and walkthroughs. Blog Read our latest product news and stories. Learning Hub Grow your career with role-based training. Google Cloud certification Prepare and register for certifications. Cloud computing basics Learn more about cloud computing basics. Cloud Architecture Center Get reference architectures and best practices. Connect Innovators Join Google Cloud's developer program. Developer Center Stay in the know and stay connected. Events and webinars Browse upcoming and on demand events. Google Cloud Community Ask questions, find answers, and connect. Consulting and Partners Google Cloud Consulting Work with our experts on cloud projects. Google Cloud Marketplace Deploy ready-to-go solutions in a few clicks. Google Cloud partners Explore benefits of working with a partner. Become a partner Join the Partner Advantage program. close Overview arrow_forward Solutions arrow_forward Products arrow_forward Pricing arrow_forward Resources arrow_forward Docs Support Console Accelerate your digital transformation Learn more Key benefits Why Google Cloud AI and ML Multicloud Global infrastructure Data Cloud Modern Infrastructure Cloud Security Productivity and collaboration Reports and insights Executive insights Analyst reports Whitepapers Customer stories Industry Solutions Retail Consumer Packaged Goods Financial Services Healthcare and Life Sciences Media and Entertainment Telecommunications Games Manufacturing Supply Chain and Logistics Government Education See all industry solutions See all solutions Application Modernization CAMP Modernize Traditional Applications Migrate from PaaS: Cloud Foundry, Openshift Migrate from Mainframe Modernize Software Delivery DevOps Best Practices SRE Principles Day 2 Operations for GKE FinOps and Optimization of GKE Run Applications at the Edge Architect for Multicloud Go Serverless Artificial Intelligence Customer Engagement Suite with Google AI Document AI Vertex AI Search for retail Gemini for Google Cloud Generative AI on Google Cloud APIs and Applications New Business Channels Using APIs Unlocking Legacy Applications Using APIs Open Banking APIx Data Analytics Data Migration Data Lake Modernization Stream Analytics Marketing Analytics Datasets Business Intelligence AI for Data Analytics Databases Database Migration Database Modernization Databases for Games Google Cloud Databases Migrate Oracle workloads to Google Cloud Open Source Databases SQL Server on Google Cloud Gemini for Databases Infrastructure Modernization Application Migration SAP on Google Cloud High Performance Computing Windows on Google Cloud Data Center Migration Active Assist Virtual Desktops Rapid Migration and Modernization Program Backup and Disaster Recovery Red Hat on Google Cloud Cross-Cloud Network Observability Productivity and Collaboration Google Workspace Google Workspace Essentials Cloud Identity Chrome Enterprise Security Security Analytics and Operations Web App and API Protection Security and Resilience Framework Risk and compliance as code (RCaC) Software Supply Chain Security Security Foundation Google Cloud Cybershield™ Startups and SMB Startup Program Small and Medium Business Software as a Service Featured Products Compute Engine Cloud Storage BigQuery Cloud Run Google Kubernetes Engine Vertex AI Looker Apigee API Management Cloud SQL Gemini Cloud CDN See all products (100+) AI and Machine Learning Vertex AI Platform Vertex AI Studio Vertex AI Agent Builder Conversational Agents Vertex AI Search Speech-to-Text Text-to-Speech Translation AI Document AI Vision AI Contact Center as a Service See all AI and machine learning products Business Intelligence Looker Looker Studio Compute Compute Engine App Engine Cloud GPUs Migrate to Virtual Machines Spot VMs Batch Sole-Tenant Nodes Bare Metal Recommender VMware Engine Cloud Run See all compute products Containers Google Kubernetes Engine Cloud Run Cloud Build Artifact Registry Cloud Code Cloud Deploy Migrate to Containers Deep Learning Containers Knative Data Analytics BigQuery Looker Dataflow Pub/Sub Dataproc Cloud Data Fusion Cloud Composer BigLake Dataplex Dataform Analytics Hub See all data analytics products Databases AlloyDB for PostgreSQL Cloud SQL Firestore Spanner Bigtable Datastream Database Migration Service Bare Metal Solution Memorystore Developer Tools Artifact Registry Cloud Code Cloud Build Cloud Deploy Cloud Deployment Manager Cloud SDK Cloud Scheduler Cloud Source Repositories Infrastructure Manager Cloud Workstations Gemini Code Assist See all developer tools Distributed Cloud Google Distributed Cloud Connected Google Distributed Cloud Air-gapped Hybrid and Multicloud Google Kubernetes Engine Apigee API Management Migrate to Containers Cloud Build Observability Cloud Service Mesh Google Distributed Cloud Industry Specific Anti Money Laundering AI Cloud Healthcare API Device Connect for Fitbit Telecom Network Automation Telecom Data Fabric Telecom Subscriber Insights Spectrum Access System (SAS) Integration Services Application Integration Workflows Apigee API Management Cloud Tasks Cloud Scheduler Dataproc Cloud Data Fusion Cloud Composer Pub/Sub Eventarc Management Tools Cloud Shell Cloud console Cloud Endpoints Cloud IAM Cloud APIs Service Catalog Cost Management Observability Carbon Footprint Config Connector Active Assist See all management tools Maps and Geospatial Earth Engine Google Maps Platform Media Services Cloud CDN Live Stream API OpenCue Transcoder API Video Stitcher API Migration Migration Center Application Migration Migrate to Virtual Machines Cloud Foundation Toolkit Database Migration Service Migrate to Containers BigQuery Data Transfer Service Rapid Migration and Modernization Program Transfer Appliance Storage Transfer Service VMware Engine Mixed Reality Immersive Stream for XR Networking Cloud Armor Cloud CDN and Media CDN Cloud DNS Cloud Load Balancing Cloud NAT Cloud Connectivity Network Connectivity Center Network Intelligence Center Network Service Tiers Virtual Private Cloud Private Service Connect See all networking products Operations Cloud Logging Cloud Monitoring Error Reporting Managed Service for Prometheus Cloud Trace Cloud Profiler Cloud Quotas Productivity and Collaboration AppSheet AppSheet Automation Google Workspace Google Workspace Essentials Gemini for Workspace Cloud Identity Chrome Enterprise Security and Identity Cloud IAM Sensitive Data Protection Mandiant Managed Defense Google Threat Intelligence Security Command Center Cloud Key Management Mandiant Incident Response Chrome Enterprise Premium Assured Workloads Google Security Operations Mandiant Consulting See all security and identity products Serverless Cloud Run Cloud Functions App Engine Workflows API Gateway Storage Cloud Storage Block Storage Filestore Persistent Disk Cloud Storage for Firebase Local SSD Storage Transfer Service Parallelstore Google Cloud NetApp Volumes Backup and DR Service Web3 Blockchain Node Engine Blockchain RPC Save money with our transparent approach to pricing Request a quote Pricing overview and tools Google Cloud pricing Pricing calculator Google Cloud free tier Cost optimization framework Cost management tools Product-specific Pricing Compute Engine Cloud SQL Google Kubernetes Engine Cloud Storage BigQuery See full price list with 100+ products Learn & build Google Cloud Free Program Solution Generator Quickstarts Blog Learning Hub Google Cloud certification Cloud computing basics Cloud Architecture Center Connect Innovators Developer Center Events and webinars Google Cloud Community Consulting and Partners Google Cloud Consulting Google Cloud Marketplace Google Cloud partners Become a partner
====================================================================================================
What is Artificial Intelligence? Understanding AI and Its Impact on Our Future Skip to content Science News Today Biology Physics Chemistry Astronomy Health and Medicine Psychology Earth Sciences Archaeology Technology Editorial Guidelines Technology What is Artificial Intelligence? Understanding AI and Its Impact on Our Future Muhammad Tuhin March 26, 2025 June 22, 2025 Artificial Intelligence (AI) is a transformative field that has reshaped the way we think about machines, automation, and the future of technology. With advancements in computational power, data processing, and algorithms, AI has moved from a distant theoretical concept to a powerful force that is integrated into countless industries and aspects of daily life. But what exactly is AI? At its core, Artificial Intelligence refers to the simulation of human intelligence in machines, allowing them to perform tasks that would typically require human cognitive processes such as learning, problem-solving, understanding natural language, and even creative thinking. The Origins and Evolution of Artificial Intelligence To understand AI in its current form, it’s important to consider its origins. The roots of AI trace back to the ancient idea of creating machines that can replicate human abilities. However, the formalization of AI as a field of study began in the mid-20th century. Alan Turing, one of the pioneers of computer science, played a critical role in laying the foundation for modern AI with his development of the Turing Test in 1950. The test was designed to measure a machine’s ability to exhibit intelligent behavior indistinguishable from that of a human. In 1956, a significant milestone in AI history occurred with the Dartmouth Conference, where the term “Artificial Intelligence” was coined. The event brought together leading scientists, such as John McCarthy, Marvin Minsky, and Allen Newell, who shared the belief that machines could be designed to simulate aspects of human cognition. This conference set the stage for decades of research and development in AI. Over the next few decades, AI research saw varying levels of success, often characterized by periods of optimism followed by “AI winters”—times when funding and interest in AI research waned due to unmet expectations. However, the resurgence of AI came in the late 1990s and early 2000s, thanks to significant advancements in machine learning algorithms, data availability, and computational power. Today, AI is thriving in areas such as natural language processing, computer vision, autonomous vehicles, robotics, and beyond. The Components of Artificial Intelligence AI is a broad and multifaceted field that encompasses several key components, each contributing to the development of intelligent systems. These components are the building blocks that enable machines to exhibit behaviors that are considered intelligent. Machine Learning (ML) Machine Learning is arguably the most important subfield of AI. It focuses on the development of algorithms that allow machines to learn from data, improving their performance over time without being explicitly programmed. Unlike traditional programming, where a developer writes a set of rules for the machine to follow, machine learning allows systems to find patterns in data and use them to make predictions or decisions. There are several types of machine learning, including supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning. In supervised learning, the machine is trained on labeled data, meaning the correct output is already known, and the system learns to predict these outputs. Unsupervised learning, on the other hand, deals with unlabeled data, where the machine must find patterns and structures within the data on its own. Reinforcement learning is a particularly exciting area of machine learning that focuses on teaching machines through trial and error. By receiving feedback in the form of rewards or penalties, the machine learns to take actions that maximize its reward, similar to how humans learn from experiences. Natural Language Processing (NLP) Natural Language Processing (NLP) is the branch of AI that enables machines to understand, interpret, and generate human language. Language is inherently complex and ambiguous, which makes NLP one of the most challenging areas of AI. NLP systems are designed to process and analyze vast amounts of textual data, enabling machines to perform tasks such as language translation, sentiment analysis, and even chatbots that can carry on a conversation with humans. The rise of powerful language models like OpenAI’s GPT (Generative Pretrained Transformer) and Google’s BERT has drastically improved NLP’s capabilities. These models are capable of understanding context, generating human-like text, and even answering questions with impressive accuracy. Computer Vision Computer vision is the field of AI that allows machines to interpret and understand visual information from the world, such as images and videos. It involves the use of algorithms to analyze and process visual data, enabling systems to recognize objects, detect faces, interpret gestures, and even understand the context of a scene. Computer vision has a wide range of applications, from facial recognition technology used in smartphones to medical imaging systems that help doctors diagnose diseases. Autonomous vehicles also rely heavily on computer vision to understand their environment and make decisions on the road. Robotics Robotics is an interdisciplinary field that combines AI with physical machines. Robots are often equipped with sensors, actuators, and processors that allow them to interact with their environment, perform tasks autonomously, and even adapt to changing conditions. Robotics powered by AI has made significant strides in industries like manufacturing, healthcare, and logistics. AI-powered robots can perform repetitive tasks with precision, improve productivity, and even assist in delicate surgeries. The future of robotics holds even more potential, with robots becoming more intelligent, adaptive, and capable of performing increasingly complex tasks in a variety of fields. The Role of Big Data and Computing Power in AI A critical factor driving the progress of AI has been the availability of vast amounts of data and the increase in computing power. Machine learning, especially deep learning, requires enormous datasets to identify patterns and learn complex representations. These datasets, often referred to as “big data,” contain information collected from a variety of sources, such as social media, sensors, transactions, and more. As AI systems become more sophisticated, the need for powerful computing infrastructure grows. Modern AI models require significant computational resources, and breakthroughs in hardware, such as Graphics Processing Units (GPUs) and specialized AI chips, have played a key role in enabling deep learning algorithms to process vast amounts of data quickly and efficiently. Cloud computing has also contributed to AI’s growth, as it provides scalable storage and processing power that can be accessed remotely. This means that companies and researchers no longer need to invest in expensive hardware infrastructure; instead, they can take advantage of cloud-based services to run AI models and process data at scale. Types of Artificial Intelligence AI can be categorized in various ways, with two of the most common classifications being based on capability and functionality. Based on Capability Narrow AI (Weak AI): Narrow AI refers to AI systems that are designed and trained to perform specific tasks. These systems operate within a narrow range of functions, such as voice assistants (e.g., Siri, Alexa), recommendation algorithms, or image recognition software. While they can perform their designated tasks with impressive accuracy, they are limited to those specific tasks and cannot generalize beyond them. General AI (Strong AI): General AI is the hypothetical form of AI that would possess the ability to understand, learn, and apply intelligence across a wide range of tasks, much like a human. It would have the capacity to reason, problem-solve, and adapt to different environments without needing to be specifically trained for each new task. General AI is still a distant goal and remains largely a subject of research and philosophical debate. Superintelligent AI: This represents a level of intelligence that surpasses human capabilities in every aspect, including creativity, problem-solving, and emotional intelligence. While superintelligent AI is often depicted in science fiction, it poses significant ethical and existential challenges. Many experts believe that it’s crucial to develop safety protocols and guidelines to prevent any potential negative consequences from superintelligent AI. Based on Functionality Reactive Machines: These are the most basic type of AI. They can only respond to specific stimuli or inputs with pre-programmed responses, and they do not retain memory of past interactions. A classic example is IBM’s Deep Blue, which famously defeated world chess champion Garry Kasparov. Deep Blue’s strategy was based solely on evaluating possible moves in the game, without learning or remembering previous games. Limited Memory AI: These systems can retain and utilize past experiences to inform decisions. Self-driving cars are an example of limited memory AI, as they use data from past trips, sensor readings, and road conditions to navigate new environments. Theory of Mind AI: This type of AI is still theoretical and refers to machines that could understand and simulate human emotions, beliefs, intentions, and mental states. The goal is for AI to have the ability to understand human thoughts and emotions in a way that enables more intuitive interaction with people. Self-Aware AI: The highest level of AI, self-aware systems would have a sense of consciousness and an understanding of their existence. While this remains speculative and far from realization, self-aware AI raises important ethical questions about autonomy and rights. The Applications of AI AI has found its way into numerous sectors and industries, making it an indispensable tool in modern society. Its applications are wide-ranging and continually evolving. Healthcare AI’s role in healthcare is revolutionizing diagnosis, treatment planning, and patient care. AI-powered diagnostic tools can analyze medical images to detect conditions such as cancer or neurological disorders with remarkable accuracy. Machine learning algorithms are also used to predict patient outcomes, recommend personalized treatment plans, and even assist in drug discovery. Robotic surgery systems, such as those used in minimally invasive procedures, are powered by AI, enabling surgeons to perform complex tasks with greater precision. AI is also improving administrative tasks in healthcare, such as scheduling and patient record management, leading to more efficient healthcare delivery. Finance In the finance industry, AI is being used for fraud detection, algorithmic trading, risk management, and customer service. Machine learning models analyze transaction data to detect fraudulent activities, while AI-powered chatbots assist customers with inquiries and transactions. AI also plays a role in predicting market trends, helping investors make more informed decisions. Transportation Self-driving cars and autonomous vehicles are perhaps the most talked-about applications of AI in transportation. AI enables vehicles to navigate roads, recognize objects, and make decisions in real-time, without human intervention. Beyond individual cars, AI is also being applied to optimize traffic flow and improve public transportation systems. Entertainment AI is transforming the entertainment industry by personalizing recommendations for viewers and listeners. Streaming platforms like Netflix and Spotify use AI algorithms to suggest content based on user preferences and viewing history. In gaming, AI is used to create more intelligent and adaptive non-player characters (NPCs), providing a more immersive experience. Education In education, AI is being used to create personalized learning experiences for students. AI-driven tools can assess individual learning styles and progress, offering tailored lessons and feedback. Virtual tutors powered by AI are also helping students with subjects ranging from math to language learning. The Ethical Implications of AI With the rise of AI, many ethical questions and concerns have emerged. These concerns range from the potential loss of jobs due to automation to the risk of AI being used for malicious purposes, such as surveillance or warfare. One of the primary challenges of AI development is ensuring that it is aligned with human values and ethical principles. Transparency, fairness, and accountability are crucial considerations in AI design. There is a growing need for regulations and frameworks that ensure AI systems are developed and deployed responsibly, without reinforcing biases or creating unintended harm. The Future of Artificial Intelligence As AI continues to evolve, its impact on society will only deepen. The future of AI is filled with possibilities, including the development of General AI, advancements in human-AI collaboration, and innovations in fields like healthcare, energy, and space exploration. AI has the potential to solve some of humanity’s greatest challenges, from curing diseases to tackling climate change. However, its development must be guided by careful consideration of its ethical implications, ensuring that AI benefits all of humanity and does not inadvertently harm individuals or communities. In conclusion, Artificial Intelligence is a rapidly advancing field that holds immense potential to revolutionize every aspect of human life. From its humble beginnings to its current applications across industries, AI is shaping the future in profound ways. As we continue to unlock its capabilities, it is essential that we approach its development with responsibility and foresight, ensuring that AI serves as a tool for the betterment of society and the world. Love this? Share it and help us spark curiosity about science! Post navigation Edge Computing: Processing Data at the Speed of Life The Future of AI: Will Machines Surpass Human Intelligence? Search Search Lasted Posts Ancient Human Fossils Discovered Beneath the Java Sea The Dark Side of Perfectionism What Your Mind Does When You Daydream How the Brain Learns to Be Resilient Why We Feel Empty — Even When Life Looks Full The Psychology of Hope: Why It Matters More Than You Think How the Brain Processes Grief Over Time Why We Fear Vulnerability — But Crave Connection The Neuroscience of Confidence (and How to Build It) How Social Media Is Rewiring Our Minds Legal About Us Contact Us Disclaimer Editorial Guidelines Privacy Policy Terms and Conditions Copyright © 2025 Science News Today . Proudly powered by WordPress | Theme: Apace by ThemezHut . We use cookies to ensure that we give you the best experience on our website. If you continue to use this site we will assume that you are happy with it. Ok
====================================================================================================
What is Artificial Intelligence? A Comprehensive Guide for Beginners - Caltech Skip to content Home Bootcamps Menu Home Bootcamps Home Bootcamps Menu Home Bootcamps AI ML Caltech Bootcamp / Blog / / What is Artificial Intelligence? A Comprehensive Guide for Beginners Written by Karin Kelley | Updated on November 27, 2023 AI is a game-changing technology that is becoming more pervasive in our daily and professional lives. But what is Artificial Intelligence, and what does AI mean? At a high level, just imagine a world where computers aren’t just machines that follow manual instructions but have brains of their own. We’re talking about creating smart systems like humans that can “think,” learn, reason, and make informed decisions. In this article, we will dive deep into the world of AI, explaining what it is, what types are available today and on the horizon, share artificial intelligence examples, and how you can get online AI training to join this exciting field. Let’s get started. What is Artificial Intelligence? A High-Level View Artificial intelligence, often called AI, refers to developing computer systems that can perform tasks that usually require human intelligence. It’s like allowing machines to think, learn, and make decisions independently. AI technology enables computers to analyze vast amounts of data, recognize patterns, and solve complex problems without explicit programming. It involves the creation of intelligent machines that can perceive the world around them, understand natural language, and adapt to changing circumstances. While AI may still feel like science fiction to some, it’s all around us, shaping how we interact with technology and transforming industries such as healthcare, finance, and entertainment. Also Read: Is AI Engineering a Viable Career? What is Artificial Intelligence, and What Are the Main Types of AI AI comes in different flavors, each with unique capabilities and characteristics. In this section, we’ll explore the top types of AI that have been developed over the years. From reactive machines to systems that possess a theory of mind, let’s delve into the exciting world of AI and its diverse applications. Here are the main types of AI you should know about: Reactive Machines: These AI systems are all about the present moment. They analyze the current situation and respond based solely on the available data. They don’t have memory or the ability to learn from past experiences. Reactive machines excel in tasks like playing chess or providing weather forecasts, where immediate analysis is crucial. Theory of Mind: This type of AI takes a step beyond reactive machines and attempts to understand human emotions, beliefs, and intentions. It aims to develop systems that can perceive and interpret the mental states of individuals. While still a work in progress, the theory of mind AI holds promise for applications in fields like psychology and human-computer interaction. Limited Memory: As the name suggests, these AI systems have a limited memory capacity, allowing them to retain and recall information from recent experiences. Based on past data, limited memory AI can learn and improve its performance over time. This type of AI is commonly used in chatbots, recommendation systems, and customer service applications. Self-Awareness: Imagine an AI system that understands its environment and has a sense of self. Self-aware AI is a cutting-edge concept that involves developing machines with consciousness and introspection. While still highly speculative and the subject of ongoing research, self-aware AI could have profound implications in fields like robotics and cognitive science. As you can see, the world of AI is rich and varied, encompassing different types of systems with varying levels of capabilities. Each type brings its own unique set of strengths and limitations depending on the use case. What Is Artificial Intelligence? Exploring Industry Applications of AI AI has infiltrated nearly every industry, revolutionizing how things are done and pushing boundaries like never before. From healthcare to finance, let’s explore how Artificial Intelligence is making waves in various sectors, creating opportunities and transforming processes along the way. Here are some remarkable examples of AI in action across different industries: Healthcare: AI is empowering healthcare professionals with advanced tools for diagnosis, treatment, and patient care. It enables faster and more accurate medical image analysis, assists in drug discovery, and even helps predict diseases and epidemics based on vast amounts of data. AI-powered virtual assistants can also provide personalized healthcare recommendations and monitor patients remotely, improving accessibility and patient outcomes. Autonomous Vehicles: The rise of autonomous vehicles is fueled by AI. Self-driving cars use AI algorithms and sensor technology to perceive and navigate the road, making transportation safer and more efficient. AI helps vehicles detect and respond to pedestrians, other vehicles and changing traffic conditions, ultimately reducing accidents and enhancing the overall driving experience. Retail: AI is transforming the retail landscape by optimizing inventory management, enhancing customer experiences, and personalizing recommendations. Chatbots and virtual assistants use natural language processing (NLP) and machine learning to assist customers, answer questions, and guide them through the shopping process. AI-powered algorithms analyze vast amounts of customer data to provide tailored recommendations, improving customer satisfaction and driving sales. Education: AI is revolutionizing the way we learn and teach. Intelligent tutoring systems leverage AI to provide personalized learning experiences, adapting to individual student needs and tracking progress. AI can also automate administrative tasks, freeing up time for educators to focus on instruction. Additionally, AI-powered language processing tools facilitate language learning, speech recognition, and translation, making education more accessible and inclusive. Finance: In the financial industry, AI is used for fraud detection, algorithmic trading, risk assessment, and customer service. Machine learning algorithms can analyze vast amounts of financial data in real-time, detecting anomalies and patterns that may indicate fraudulent activity. AI-powered trading systems leverage data analysis and predictive models to make faster and more informed investment decisions. Manufacturing: AI streamlines manufacturing processes, improves efficiency, and enables predictive maintenance. AI-powered robots and automation systems can perform repetitive tasks precisely, reducing human error and increasing productivity. Machine learning algorithms analyze sensor data to predict equipment failures and optimize maintenance schedules, minimizing downtime and maximizing operational efficiency. These examples only scratch the surface of how AI is transforming industries across the board. As AI evolves and becomes more sophisticated, we can expect even greater advancements and new possibilities for the future, and skilled AI and machine learning professionals are required to drive these initiatives. Also Read: What is Machine Learning? A Comprehensive Guide for Beginners Taking a Deeper Dive: Machine Learning vs. Deep Learning When exploring the world of AI, you’ll often come across terms like deep learning (DL) and machine learning (ML). While these two concepts are related, they have distinct differences. So, let’s shed some light on the nuances between deep learning and machine learning and how they work together to power the advancements we see in Artificial Intelligence. Machine Learning First up, let’s talk about machine learning. It’s a subset of AI that focuses on enabling computers to learn from data and make predictions or take actions without being explicitly programmed. Machine learning algorithms learn patterns and relationships in the data through training, allowing them to make informed decisions or generate insights. It encompasses techniques like supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error). Deep Learning Now, let’s dive into deep learning. Deep learning is a specialized branch of machine learning that mimics the structure and function of the human brain. It involves training deep neural networks with multiple layers to recognize and understand complex patterns in data. These neural networks are built using interconnected nodes or “artificial neurons,” which process and propagate information through the network. Deep learning has gained significant attention and success in speech and image recognition, computer vision, and NLP. Machine Learning vs. Deep Learning, or ML and DL? So, what sets deep learning and machine learning apart? While machine learning focuses on developing algorithms that can learn and make predictions from data, deep learning takes it a step further by using deep neural networks with multiple layers of artificial neurons. Deep learning excels in handling large and complex data sets, extracting intricate features, and achieving state-of-the-art performance in tasks that require high levels of abstraction and representation learning. Although deep learning and machine learning differ in their approach, they are complementary. Deep learning is a subset of machine learning, utilizing its principles and techniques to build more sophisticated models. Deep learning can benefit from machine learning’s ability to preprocess and structure data, while machine learning can benefit from deep learning’s capacity to extract intricate features automatically. Together, they form a powerful combination that drives the advancements and breakthroughs we see in AI today. In summary, machine learning focuses on algorithms that learn from data to make decisions or predictions, while deep learning utilizes deep neural networks to recognize complex patterns and achieve high levels of abstraction. These two branches of AI work hand in hand, with machine learning providing the foundation and preprocessing for deep learning models to extract meaningful insights from vast amounts of data. Real-World Artificial Intelligence Examples in Action In today’s tech-driven world, major companies like Google, Amazon, Microsoft, IBM, and Apple are at the forefront of AI innovation. Harnessing the power of Artificial Intelligence (AI), these industry giants have implemented groundbreaking applications that shape how we live, work, and interact with technology. Let’s explore one real-world example of how these companies leverage AI to drive their products and services: Google: Google employs AI in various ways, but one prominent example is its Google Assistant. Powered by machine learning and natural language processing, Google Assistant offers a conversational interface to interact with users and provide personalized assistance across devices, from smartphones to smart speakers. Amazon: Amazon has made significant strides with AI through its popular voice-activated assistant, Alexa. Alexa utilizes natural language understanding and machine learning algorithms to perform tasks, answer questions, and control smart home devices. It continuously learns and improves its capabilities, making it an integral part of Amazon’s ecosystem. Microsoft: Microsoft’s flagship AI application is Cortana, its virtual assistant. By leveraging machine learning and natural language processing, Cortana helps users with various tasks, such as managing schedules, providing reminders, and conducting searches. It seamlessly integrates with Microsoft’s suite of products and services. IBM: IBM’s Watson is a prime example of AI in action. Watson utilizes deep learning, natural language processing, and machine learning to analyze vast amounts of data and extract insights. It has been employed in industries like healthcare, finance, and customer service, revolutionizing how professionals make decisions and providing intelligent solutions. Apple: Apple has incorporated AI into its products, notably with Siri. Siri, Apple’s voice-activated assistant, employs natural language processing and machine learning to assist users with tasks, answer questions, and interact with various apps and services. Siri has become a familiar voice on Apple devices, enhancing the user experience. In summary, these tech giants have harnessed the power of AI to develop innovative applications that cater to different aspects of our lives. AI is at the heart of their offerings, from voice assistants and virtual agents to data analysis and personalized recommendations. Through the intelligent integration of AI technologies, these companies have shaped the landscape of modern technology and continue to push the boundaries of what is possible. Also Read: AI ML Engineer Salary – What You Can Expect Ready to Join the AI Revolution? Now that you have a decent answer to the question “What is Artificial Intelligence?” and know that AI is no longer just a concept from science fiction but a powerful force driving innovation across industries, what does this mean for professionals? The demand for AI practitioners is increasing as companies recognize the need for skilled individuals to harness the potential of this transformative technology. If you’re passionate about AI and want to be at the forefront of this exciting field, consider getting certified through an online AI course . Equip yourself with the knowledge and skills needed to shape the future of AI and seize the opportunities that await. Also Read: The Future of AI: A Comprehensive Guide Artificial Intelligence & Machine Learning Bootcamp Duration: 6 months Learning Format: Online Bootcamp View This Program Leave a Comment Cancel Reply Your email address will not be published. Required fields are marked * Type here.. Name* Email* Website Save my name, email, and website in this browser for the next time I comment. Recommended Articles Is AI Engineering a Viable Career? Here’s What You Need to Know in 2025 February 16, 2025 AI touches nearly every aspect of our digital lives today, and AI engineers are driving this new reality. In this blog, we will share a definitive AI engineer job description for professionals interested in pursuing a career in this growing field. What is Feature Engineering for Machine Learning? February 13, 2025 This article explores feature engineering, including its definition, its need in machine learning, the processes, steps, techniques, tools, and examples. What is Deep Learning? Models, Applications, and Examples February 13, 2025 This article discusses deep learning, including defining the term, explaining how it works, identifying types of deep learning, stating the pros and cons, and more. Machine Learning Engineer Salary: Expected Trends in 2025 January 23, 2025 ML engineers are in super high demand globally. Here, we break down what machine learning engineer salaries certified professionals can command if you gain the required skills. How to Become a Robotics Engineer in 2025? A Comprehensive Guide December 2, 2024 Do you want to learn how to become a robotics engineer? Learn how to get into robotics engineering and what it takes to excel in this exciting field with our comprehensive guide. Today’s Top 10 AI Technologies: Here’s Everything You Should Know November 25, 2024 AI is now part of daily lives. This article explores the top AI technologies, including a brief definition of AI; its history, pros and cons, and a bit more about how it works for aspiring professionals in the field. Artificial Intelligence & Machine Learning Bootcamp Duration 6 months Learning Format Online Bootcamp Program Benefits 9+ top tools covered, 25+ hands-on projects Masterclasses by distinguished Caltech instructors In collaboration with IBM Global AI and ML experts lead training View This Program Call us on : 1800-212-7688 Live Chat California Institute of Technology Facebook-f Linkedin-in Privacy Policy | Contact Us | Sitemap Top Caltech Programs Caltech AI & Machine Learning Bootcamp Caltech Data Science Bootcamp Caltech Cloud Computing Bootcamp Caltech DevOps Bootcamp Caltech UI UX Bootcamp Menu Caltech AI & Machine Learning Bootcamp Caltech Data Science Bootcamp Caltech Cloud Computing Bootcamp Caltech DevOps Bootcamp Caltech UI UX Bootcamp Powered by
====================================================================================================
What is Artificial Intelligence(AI)? - GeeksforGeeks Skip to content Courses DSA to Development GATE 2026 Prep Get 3 IBM Certifications For Working Professionals Interview 101: DSA & System Design Data Science Training Program JAVA Backend Development (Live) Data Analytics Training DevOps Engineering (LIVE) Data Structures & Algorithms in Python For Students Placement Preparation with DSA Data Science (Live) Data Structure & Algorithm-Self Paced (C++/JAVA) Master Competitive Programming Full Stack Development with React & Node JS (Live) Full Stack Development Data Science & ML Program All Courses Tutorials Python Java Data Structures & Algorithms ML & Data Science Interview Corner Programming Languages Web Development GATE CS Subjects DevOps And Linux School Learning Practice Practice Coding Problems GfG 160: Free DSA Practice Problem of the Day ETS TOEFL: Scholarship Contest All Contests and Events Jobs Become a Mentor Apply Now! Post Jobs Job-A-Thon: Hiring Challenge Notifications Mark all as read All View All Notifications Mark all as read All Unread Read You're all caught up!! Data Science IBM Certification Data Science Data Science Projects Data Analysis Data Visualization Machine Learning ML Projects Deep Learning NLP Computer Vision Artificial Intelligence Sign In ▲ Open In App Explore GfG Courses Share Your Experiences Artificial Intelligence Tutorial | AI Tutorial What is Artificial Intelligence(AI)? History of AI Types of AI Types of Artificial Intelligence (AI) Types of AI Based on Capabilities: An In-Depth Exploration Types of AI Based on Functionalities Agents in AI Problem Solving in AI Search Algorithms in AI Uninformed Search Algorithms in AI Informed Search Algorithms in Artificial Intelligence Local Search Algorithm in Artificial Intelligence Adversarial Search Algorithms in Artificial Intelligence (AI) Constraint Satisfaction Problems (CSP) in Artificial Intelligence Knowledge, Reasoning and Planning in AI How do knowledge representation and reasoning techniques support intelligent systems? First-Order Logic in Artificial Intelligence Types of Reasoning in Artificial Intelligence What is the Role of Planning in Artificial Intelligence? Representing Knowledge in an Uncertain Domain in AI Learning in AI Supervised Machine Learning What is Unsupervised Learning? Semi-Supervised Learning in ML Reinforcement Learning Self-Supervised Learning (SSL) Introduction to Deep Learning Natural Language Processing (NLP) - Overview Computer Vision Tutorial Artificial Intelligence in Robotics Generative AI Generative Adversarial Network (GAN) Variational AutoEncoders What are Diffusion Models? Transformers in Machine Learning DSA to Development Course What is Artificial Intelligence(AI)? Last Updated : 22 Apr, 2025 Comments Improve Suggest changes Like Article Like Report Artificial Intelligence (AI) refers to the technology that allows machines and computers to replicate human intelligence. It enables systems to perform tasks that require human-like decision-making, such as learning from data, identifying patterns, making informed choices and solving complex problems. AI improves continuously by utilizing methods like machine learning and deep learning. In real-world applications, AI is used in healthcare for diagnosing diseases, finance for fraud detection, e-commerce for personalized recommendations and transportation for self-driving cars. It also powers virtual assistants like Siri and Alexa, chatbots for customer support and manufacturing robots that automate production processes. Artificial Intelligence (AI) operates on a core set of concepts and technologies that enable machines to perform tasks that typically require human intelligence. Here are some foundational concepts: Machine Learning (ML) Machine Learning is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed to perform a task, a machine learning model uses algorithms to identify patterns within data and improve its performance over time without human intervention. Generative AI Generative AI refers to a type of artificial intelligence designed to create new content, whether it's text, images, music, or even video. Unlike traditional AI, which typically focuses on analyzing and classifying data, generative AI goes a step further by using patterns it has learned from large datasets to generate new, original outputs. Essentially, it "creates" rather than just "recognizes." How Generative AI Works Generative AI works through complex algorithms and deep learning models, often using techniques like neural networks. These networks are trained on vast amounts of data, allowing the AI to understand the underlying structure and patterns within the data. Here’s a breakdown of how it works: Training on Large Datasets Generative AI models are trained on massive datasets, which could include anything from text (like books or articles) to images or even music. During the training process, the AI learns the relationships and patterns in the data, enabling it to generate new content based on what it has learned. Neural Networks and Deep Learning At the heart of generative AI is deep learning, a subset of machine learning that mimics how our brain processes information. These deep neural networks consist of multiple layers, which process the input data in stages to detect patterns and learn the complexities of the data. Creating New Content Once trained, generative AI can create new content by predicting what comes next based on the patterns it has learned. For instance, when generating text, it might predict the next word or phrase based on previous input. In image generation, it could produce entirely new images by blending elements it has learned from its training data. Feedback Loop and Refinement Generative AI often works in a feedback loop, where it refines its creations through multiple iterations. The more data the AI is exposed to, the better it becomes at creating content that is relevant, coherent, and realistic. Natural Language Processing (NLP) Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and interact with human language in a way that feels natural. Essentially, NLP allows machines to read, interpret and respond to text or speech the way humans do. It's the technology behind things like chatbots, voice assistants (such as Alexa or Siri) and even autocorrect on your phone. NLP involves a combination of linguistics (the study of language) and computer science to process and analyze human language. Expert Systems Expert Systems are a type of artificial intelligence designed to replicate the decision-making ability of a human expert in a specific field. They use a combination of stored knowledge and logical reasoning to make decisions, solve problems or provide recommendations. An expert system works by following a set of predefined "if-then" rules, which are based on the knowledge of experts in the field. How Does AI Work? AI works by simulating human intelligence in machines through algorithms, data and models that enable them to perform tasks that would typically require human intervention. Here's a simplified breakdown: Data Collection : AI systems rely on vast amounts of data. This data can come from various sources, like images, texts or sensor readings. For example, if we're building an AI that recognizes cats in images, we'd need a large dataset of labeled images of cats. Processing and Learning : Machine learning (ML), a subset of AI, uses algorithms to analyze the data. The system learns patterns from the data by training a model. For instance, an AI system might learn the features of a cat, like its shape, ears and whiskers, by being exposed to thousands of labeled images of cats and non-cats. Model Training : The AI model undergoes training using the data. In this process, the model adjusts its parameters based on the input data and the desired output. The more data and training time, the more accurate the model becomes. Decision Making : After training, the AI can make decisions or predictions based on new, unseen data. For example, it might predict whether an image contains a cat, based on the patterns it learned from previous training data. Feedback and Improvement : In many AI systems, particularly in reinforcement learning, feedback is used to improve performance over time. The system's actions are continuously evaluated and adjustments are made to improve future performance. To read about how AI work in detail, refer to article: How Does AI Work? Types of AI (Artificial Intelligence) AI can be classified into two main categories based on its capabilities and functionalities. Based on Capabilities: Narrow AI (Weak AI) : This type of AI is designed to perform a specific task or a narrow set of tasks, such as voice assistants or recommendation systems. It excels in one area but lacks general intelligence. General AI (Strong AI) : General AI is a theoretical concept where AI can perform any intellectual task that a human can do. It demonstrates human-like reasoning and understanding across multiple domains, making it capable of tackling a wide variety of tasks. Superintelligent AI : Superintelligent AI is a hypothetical form of AI that would surpass human intelligence in all areas. It would be capable of performing tasks more efficiently and effectively than humans. Based on Functionalities: Reactive Machines : Reactive machines are AI systems that respond to specific tasks or situations but do not store memories or improve over time. They are programmed to react in a fixed way without learning from past experiences. Limited Memory : Limited memory AI can store and learn from past experiences to make better decisions in the future. Self-driving cars are an example, as they use historical data to navigate and adapt to changing environments. Theory of Mind : The theory of mind is a theoretical type of AI that would be able to understand emotions, beliefs, intentions and other mental states. This would allow the AI to interact with humans in a more natural and empathetic manner. Self-Aware AI : Self-aware AI is a hypothetical form of AI that possesses consciousness and self-awareness. It would have an understanding of its own existence and could make decisions based on that awareness. To read about Types of AI in detail, refer to article: Types of AI . AI Models AI models are computer programs that learn to perform tasks by recognizing patterns in data, similar to how our brains learn from experience. They are trained on large datasets and then use what they’ve learned to make decisions, whether it’s identifying faces in a photo, translating languages or generating text. There are different kinds of AI models based on how they learn: 1. Supervised Learning Models In Supervised learning , the AI is provided with a set of examples where both the input and the desired output are known. For example, to teach an AI to recognize handwritten numbers, we would show it many images of handwritten digits, each labeled with the correct number (0-9). Over time, the model adjusts its internal settings (called weights) to minimize the difference between its predictions and the correct labels given by the "teacher." This method works well when you have large amounts of high-quality, labeled data and is commonly used for tasks like image classification, speech recognition and spam detection. 2. Unsupervised Learning Models In Unsupervised Learning models, the AI is given input data without labels or explicit instructions on what to look for. Its task is to find hidden patterns, clusters, or structures on its own. For instance, if you give an unsupervised model a collection of news articles, it might automatically group them into categories like sports, politics, or entertainment, without anyone telling it those categories. This type of learning is helpful for uncovering new insights in data, reducing dimensions for visualization, and spotting unusual patterns, such as fraud or other anomalies. 3. Reinforcement Learning Models Reinforcement learning works differently from the other two methods. In this case, there isn’t a teacher providing the “correct” answer. Instead, the AI learns through a system of rewards and penalties. For example , in a video game, an agent might start by making random movements and gradually learn which actions lead to winning by receiving points or rewards. Over time, the model develops a strategy (or policy) to maximize its rewards. This type of learning is used in fields like robotics, game-playing (such as AlphaGo), and even automated trading systems. B enefits of AI The widespread use of Artificial Intelligence (AI) has brought numerous advantages across various sectors and aspects of our daily lives. Here are some of the primary benefits of AI: Efficiency and Automation : AI can automate repetitive tasks, reducing human error and saving time. This leads to increased productivity and allows humans to focus on more complex tasks. Improved Decision Making : AI can analyze vast amounts of data quickly and provide insights, helping businesses and organizations make better, data-driven decisions. Personalization : AI can be used to offer personalized experiences in areas like retail, entertainment and online services, improving user satisfaction. For example , recommendation systems on platforms like Netflix or Amazon suggest products or content based on individual preferences. 24/7 Availability : Unlike humans, AI systems can operate around the clock without breaks. This is particularly useful in customer support, monitoring and other services that require constant attention. Data Analysis and Pattern Recognition : AI excels at processing large datasets and recognizing patterns that may be difficult for humans to identify. This is especially beneficial in fields like healthcare, finance and marketing. Artificial Intelligence Use Cases Artificial Intelligence has many practical applications across various industries and domains, including: Retail : AI enhances personalized shopping experiences, manages inventory, forecasts demand and powers chatbots for customer service. Platforms like Amazon and Netflix use recommendation systems to suggest products or content based on user behavior. Manufacturing : AI is utilized in predictive maintenance, quality control, process optimization and supply chain management. It helps identify machine faults before they happen and optimizes production lines for efficiency. Customer Service : AI-driven chatbots and virtual assistants are widely used for providing round-the-clock customer support. These systems handle routine inquiries, troubleshoot common problems and escalate more complex issues to human agents. Marketing and Advertising : AI helps segment audiences, predict customer behavior, optimize ad targeting and improve content personalization. It ensures businesses deliver the right message to the right audience at the optimal time. Agriculture : AI is applied to monitor crop health, optimize irrigation and predict harvest times. AI-powered drones and sensors analyze field data to detect issues like pest infestations or nutrient deficiencies, supporting precision farming. Human Resources : AI streamlines recruitment by screening resumes, matching candidates and scheduling interviews. It can also assess employee performance and predict retention risks, aiding HR departments in making data-driven decisions. To read about Applications of AI in detail, refer to our article: Application of Artificial Intelligence . Comment More info Advertise with us Next Article History of AI P Palak Jain Improve Article Tags : Computer Subject Artificial Intelligence AI-ML-DS Like 631k+ interested Geeks DSA to Development: A Complete Guide Explore 470k+ interested Geeks Complete Machine Learning & Data Science Program Explore Corporate & Communications Address: A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) Registered Address: K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305 Advertise with us Company About Us Legal Privacy Policy Careers In Media Contact Us Corporate Solution Campus Training Program Explore Job-A-Thon Offline Classroom Program DSA in JAVA/C++ Master System Design Master CP Videos Tutorials Python Java C++ PHP GoLang SQL R Language Android DSA Data Structures Algorithms DSA for Beginners Basic DSA Problems DSA Roadmap DSA Interview Questions Competitive Programming Data Science & ML Data Science With Python Machine Learning ML Maths Data Visualisation Pandas NumPy NLP Deep Learning Web Technologies HTML CSS JavaScript TypeScript ReactJS NextJS NodeJs Bootstrap Tailwind CSS Python Tutorial Python Examples Django Tutorial Python Projects Python Tkinter Web Scraping OpenCV Tutorial Python Interview Question Computer Science GATE CS Notes Operating Systems Computer Network Database Management System Software Engineering Digital Logic Design Engineering Maths DevOps Git AWS Docker Kubernetes Azure GCP DevOps Roadmap System Design High Level Design Low Level Design UML Diagrams Interview Guide Design Patterns OOAD System Design Bootcamp Interview Questions School Subjects Mathematics Physics Chemistry Biology Social Science English Grammar Databases SQL MYSQL PostgreSQL PL/SQL MongoDB Preparation Corner Company-Wise Recruitment Process Aptitude Preparation Puzzles Company-Wise Preparation More Tutorials Software Development Software Testing Product Management Project Management Linux Excel All Cheat Sheets Courses IBM Certification Courses DSA and Placements Web Development Data Science Programming Languages DevOps & Cloud Programming Languages C Programming with Data Structures C++ Programming Course Java Programming Course Python Full Course Clouds/ Devops DevOps Engineering AWS Solutions Architect Certification Salesforce Certified Administrator Course GATE 2026 GATE CS Rank Booster GATE DA Rank Booster GATE CS & IT Course - 2026 GATE DA Course 2026 GATE Rank Predictor @GeeksforGeeks, Sanchhaya Education Private Limited , All rights reserved We use cookies to ensure you have the best browsing experience on our website. By using our site, you acknowledge that you have read and understood our Cookie Policy & Privacy Policy Got It ! Improvement Suggest changes Suggest Changes Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal. Create Improvement Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all. Suggest Changes min 4 words, max Words Limit:1000 Thank You! Your suggestions are valuable to us. What kind of Experience do you want to share? Interview Experiences Admission Experiences Career Journeys Work Experiences Campus Experiences Competitive Exam Experiences
====================================================================================================
What Is Artificial Intelligence? Definition and History of AI - Caltech Science Exchange skip to main content Topics Open Topics submenu Artificial Intelligence COVID-19 and Viruses Earthquakes Greater Los Angeles Fires Neuroscience Quantum Science and Technology Sustainability Voting and Elections Biotechnology (Coming Soon) Scientific Practice (Coming Soon) Connect Open Connect submenu After the Fires Podcast Ask a Question Caltech Conversations Open Caltech Conversations submenu Conversations on Sustainability Conversations on COVID-19 Conversations on the Quantum World Conversations on Artificial Intelligence Conversations After the Fires Resources for Students & Educators About Search Search Menu Close Topics Open Topics submenu Connect Open Connect submenu About Topics Back Artificial Intelligence COVID-19 and Viruses Earthquakes Greater Los Angeles Fires Neuroscience Quantum Science and Technology Sustainability Voting and Elections Biotechnology (Coming Soon) Scientific Practice (Coming Soon) Connect Back After the Fires Podcast Ask a Question Caltech Conversations Conversations on Sustainability Conversations on COVID-19 Conversations on the Quantum World Conversations on Artificial Intelligence Conversations After the Fires Resources for Students & Educators Search Search Caltech Science Exchange / Topics / Artificial Intelligence / What Is AI? What Is AI? Share this This article was reviewed by a member of Caltech's Faculty . Artificial intelligence is transforming scientific research as well as everyday life, from communications to transportation to health care and more. Explore what defines artificial intelligence, how it has evolved, and what we might expect from it in the future. The field of artificial intelligence arose from the idea that machines might be able to think like humans do. It required an analysis of how our brains process information and use it to perform new tasks and adapt to novel situations. Continuing exploration of these concepts has fueled technological innovation and led to the development of AI applications that use data to identify patterns, carry out predictions, and make decisions. Often these applications are more efficient and precise than humans are—sometimes replacing people to perform repetitive or tedious tasks and calculations. Today, rapid advances in the field have opened new avenues for research and discovery but also raise ethical and safety questions. Dive Deeper The Art of Predicting Tastes in Art Image Lightbox New Caltech Center Sheds Light on the Future of Generative AI, Innovation, and Regulation Image Lightbox A Test of Artificial Intelligence Image Lightbox California Institute of Technology 1200 East California Boulevard Pasadena, California 91125 Content Use Policy | Digital Accessibility | Privacy Notice | Site Content Copyright © 2025
====================================================================================================
What is AI, and how do programmes like ChatGPT and DeepSeek work? Skip to content British Broadcasting Corporation Home News Sport Business Innovation Culture Arts Travel Earth Audio Video Live Home News Israel-Gaza War War in Ukraine US & Canada UK UK Politics England N. Ireland N. Ireland Politics Scotland Scotland Politics Wales Wales Politics Africa Asia China India Australia Europe Latin America Middle East In Pictures BBC InDepth BBC Verify Sport Business Executive Lounge Technology of Business Future of Business Innovation Technology Science & Health Artificial Intelligence AI v the Mind Culture Film & TV Music Art & Design Style Books Entertainment News Arts Arts in Motion Travel Destinations Africa Antarctica Asia Australia and Pacific Caribbean & Bermuda Central America Europe Middle East North America South America World’s Table Culture & Experiences Adventures The SpeciaList Earth Natural Wonders Weather & Science Climate Solutions Sustainable Business Green Living Audio Podcasts Radio Audio FAQs Video Live Live News Live Sport Home News Sport Business Innovation Culture Arts Travel Earth Audio Video Live Weather Newsletters What is AI, and how do programmes like ChatGPT and DeepSeek work? 18 February 2025 Share Save Share Save Getty Images Artificial intelligence (AI) has increasingly become part of everyday life over the past decade. It is used for everything from personalising social media feeds to powering medical breakthroughs. But as big tech firms and governments vie to be at the forefront of AI's development, critics have expressed caution over its potential misuse, ethical complexities and environmental impact. What is AI and what is it used for? AI allows computers to learn and solve problems in ways that can seem human. Computers cannot think, empathise or reason. However, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge. AI programmes can process large amounts of data, identify patterns and follow detailed instructions about what to do with that information. Watch: What is artificial intelligence? This could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items. The technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars. AI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music. Scientists are also using AI as a way to help spot cancers, speed up diagnoses and identify new medicines. Computer vision, a form of AI that enables computers to detect objects or people in images, is being used by radiographers to help them review X-ray results. A simple guide to help you understand AI Five things you really need to know about AI What are generative AI programs like ChatGPT, DeepSeek and Midjourney? Generative AI is used to create new content which can feel like it has been made by a human. It does this by learning from vast quantities of existing data such as online text and images. ChatGPT and Chinese rival DeepSeek's chatbot are two widely-used generative AI tools. Midjourney can create images from simple text prompts. So-called chatbots such as Google's Gemini or Meta AI can hold text conversations with users. Getty Images Elon Musk's generative AI chatbot Grok can generate images for users who pay for X (formerly Twitter). Generative AI can also be used to make high-quality videos and music. Songs mimicking the style or sound of famous musicians have gone viral , sometimes leaving fans confused about their authenticity. Why is AI controversial? While acknowledging AI's potential, some experts are worried about the implications of its rapid growth. The International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs , and worsen financial inequality. Prof Geoffrey Hinton, a computer scientist regarded as one of the "godfathers" of AI development, has expressed concern that powerful AI systems could even make humans extinct - a fear dismissed by his fellow "AI godfather", Yann LeCun . Critics also highlight the tech's potential to reproduce biased information, or discriminate against some social groups . This is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect biases such as sexism or racism. Facebook apology as AI labels black men 'primates' Twitter finds racial bias in image-cropping AI And while AI programmes are growing more adept, they are still prone to errors. Generative AI systems are known for their ability to "hallucinate" and assert falsehoods as fact. Apple halted a new AI feature in January after it incorrectly summarised news app notifications . The BBC complained about the feature after Apple's AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself. Google has also faced criticism over inaccurate answers produced by its AI search overviews . This has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code. There are worries about students using AI technology to "cheat" on assignments , or employees "smuggling" it into work . Writers, musicians and artists have also pushed back against the technology, accusing AI developers of using their work to train systems without consent or compensation. Getty Images Billie Eilish was among 200 artists who called for an end to "predatory" use of AI in music in an open letter. Thousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a "major, unjust threat" to their livelihoods. Billie Eilish and Nicki Minaj want stop to 'predatory' music AI AI-written book shows why the tech 'terrifies' creatives How does AI impact the environment? It is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands . Creating the powerful computer chips needed to run AI programmes also takes lots of power and water. Demand for generative AI services has meant an increase in the number of data centres. These huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool. Some large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling. However, some experts and activists fear that AI will worsen water supply problems. The BBC was told in February that government plans to make the UK a "world leader" in AI could put already stretched supplies of drinking water under strain . In September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought. Electricity grids creak as AI demands soar What rules are in place for AI? Some governments have already introduced rules governing how AI operates. The EU's Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether . Generative AI developers in China are required to safeguard citizens' data, and promote transparency and accuracy of information. But they are also bound by the country's strict censorship laws . In the UK, Prime Minister Sir Keir Starmer has said the government "will test and understand AI before we regulate it". Both the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models. In 2024 the two countries signed an agreement to collaborate on developing "robust" AI testing methods. However, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology . Several countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material. Man who made 'depraved' child images with AI jailed Inside the deepfake porn crisis engulfing Korean schools Artificial intelligence Related MrBeast removes YouTube AI tool after backlash 1 day ago Newsbeat Ravenscraig site could become AI data centre in £3bn plan 1 day ago Glasgow & West Scotland AI technology used in crackdown on littering 2 days ago Hull & East Yorkshire British Broadcasting Corporation Home News Sport Business Innovation Culture Arts Travel Earth Audio Video Live Weather BBC Shop BritBox BBC in other languages Follow BBC on: Terms of Use About the BBC Privacy Policy Cookies Accessibility Help Contact the BBC Advertise with us Do not share or sell my info BBC.com Help & FAQs Copyright 2025 BBC. All rights reserved. The BBC is not responsible for the content of external sites. Read about our approach to external linking.
====================================================================================================
Enable JavaScript and cookies to continue
====================================================================================================
What is AI? Everything to know about artificial intelligence | ZDNET X Trending Miss out on Nintendo Switch 2 preorders? Here's how to buy one Nintendo Switch 2 revealed: Specs, pricing, release date (out now), and more official details The $700 Android phone that made me forget about my Pixel 9 Pro Best small business web hosting services of 2025 Memorial Day headphone sales 2025 Best Linux VPNs of 2025 Best online video editors of 2025 Best CRM software of 2025 Best small business CRM software of 2025 Best free website builders of 2025 Best website builders of 2025 Best free web hosting services of 2025 Best malware removal software of 2025 Best remote access software of 2025 Best password managers for families in 2025 Best password managers for businesses of 2025 Best business VoIP providers of 2025 Best data removal services: Delete yourself from the internet Best email hosting service Best VPS hosting service How to clear the cache on your Windows 11 PC Finally, a Windows 11 tablet I'd recommend to both business and professional users NEO QLED vs OLED: Which TV tech is right for you? ZDNET Recommends Tech Gaming Headphones Laptops Mobile Accessories Networking PCs Printers Smartphones Smart Watches Speakers Streaming Devices Streaming Services Tablets TVs Wearables Kitchen & Household Office Furniture Office Hardware & Appliances Smart Home Smart Lighting Yard & Outdoors Innovation Artificial Intelligence AR + VR Cloud Digital Transformation Energy Robotics Sustainability Transportation Work Life Accelerate your tech game Paid Content How the New Space Race Will Drive Innovation How the metaverse will change the future of work and society Managing the Multicloud The Future of the Internet The New Rules of Work The Tech Trends to Watch in 2023 Business See all Business Amazon Apple Developer E-Commerce Edge Computing Enterprise Software Executive Google Microsoft Professional Development Social Media SMB Windows How AI is transforming organizations everywhere The intersection of generative AI and engineering Software development: Emerging trends and changing roles Security See all Security Cyber Threats Password Manager Ransomware VPN Cybersecurity: Let's get tactical Securing the Cloud Advice Deals How-to Product Comparisons Product Spotlights Reviews Buying Guides See all Buying Guides Best Samsung phones Best Android phones Best smart rings Best blood pressure watches Best headphones for sleeping Best robot vacuum mops Best web hosting services Best travel VPNs Best VPNs Best AI image generators Best AI chatbots Best 75-inch TVs Best smartphones Best iPhones Best MagSafe battery packs Best digital notebooks Best TV antennas Best TVs Best laptops Best tablets Best smartwatches Best headphones Best live TV streaming services tomorrow belongs to those who embrace it today ZDNET France ZDNET Germany ZDNET Korea ZDNET Japan Go See all Topics Finance Education Health Special Features ZDNET In Depth ZDNET Recommends Newsletters Videos Editorial Guidelines Trending Miss out on Nintendo Switch 2 preorders? Here's how to buy one Nintendo Switch 2 revealed: Specs, pricing, release date (out now), and more official details The $700 Android phone that made me forget about my Pixel 9 Pro Best small business web hosting services of 2025 Memorial Day headphone sales 2025 Best Linux VPNs of 2025 Best online video editors of 2025 Best CRM software of 2025 Best small business CRM software of 2025 Best free website builders of 2025 Best website builders of 2025 Best free web hosting services of 2025 Best malware removal software of 2025 Best remote access software of 2025 Best password managers for families in 2025 Best password managers for businesses of 2025 Best business VoIP providers of 2025 Best data removal services: Delete yourself from the internet Best email hosting service Best VPS hosting service How to clear the cache on your Windows 11 PC Finally, a Windows 11 tablet I'd recommend to both business and professional users NEO QLED vs OLED: Which TV tech is right for you? ZDNET Recommends Tech Gaming Headphones Laptops Mobile Accessories Networking PCs Printers Smartphones Smart Watches Speakers Streaming Devices Streaming Services Tablets TVs Wearables Kitchen & Household Office Furniture Office Hardware & Appliances Smart Home Smart Lighting Yard & Outdoors Innovation Artificial Intelligence AR + VR Cloud Digital Transformation Energy Robotics Sustainability Transportation Work Life Accelerate your tech game Paid Content How the New Space Race Will Drive Innovation How the metaverse will change the future of work and society Managing the Multicloud The Future of the Internet The New Rules of Work The Tech Trends to Watch in 2023 Business See all Business Amazon Apple Developer E-Commerce Edge Computing Enterprise Software Executive Google Microsoft Professional Development Social Media SMB Windows How AI is transforming organizations everywhere The intersection of generative AI and engineering Software development: Emerging trends and changing roles Security See all Security Cyber Threats Password Manager Ransomware VPN Cybersecurity: Let's get tactical Securing the Cloud Advice Deals How-to Product Comparisons Product Spotlights Reviews Buying Guides See all Buying Guides Best Samsung phones Best Android phones Best smart rings Best blood pressure watches Best headphones for sleeping Best robot vacuum mops Best web hosting services Best travel VPNs Best VPNs Best AI image generators Best AI chatbots Best 75-inch TVs Best smartphones Best iPhones Best MagSafe battery packs Best digital notebooks Best TV antennas Best TVs Best laptops Best tablets Best smartwatches Best headphones Best live TV streaming services More See all Topics Finance Education Health Special Features ZDNET In Depth ZDNET Recommends Newsletters Videos Editorial Guidelines Innovation Part of a ZDNET Special Feature: Managing AI and ML in the Enterprise Why you can trust ZDNET : ZDNET independently tests and researches products to bring you our best recommendations and advice. When you buy through our links, we may earn a commission. Our process 'ZDNET Recommends': What exactly does it mean? ZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we’re assessing. When you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers. ZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form . Close Home Innovation Artificial Intelligence What is AI? Everything to know about artificial intelligence We cover everything that makes up the technology, from machine learning and LLMs to general AI and neural networks, and how to use it. Written by Radhika Rajkumar, Editor June 5, 2024 at 11:29 a.m. PT Weiquan Lin/Getty Images What is artificial intelligence? Artificial intelligence (AI) is a concept that refers to a machine's ability to perform a task that would've previously required human intelligence. It's been around since the 1950s , and its definition has been modified over decades of research and technological advancements. Today, AI powers self-driving cars , laptops , chatbots like ChatGPT , and image generators . So what is it, and how does it work? The phrase AI comes from the idea that if intelligence is inherent to organic life, its existence elsewhere makes it artificial. Computer scientist Alan Turing was one of the first to explore the idea that machines could use information and logic to make decisions as people do. He coined the Turing test, which compares machine ability to human ability to see if people can detect it as artificial ( convincing deepfakes are an example of AI passing the Turing test). Basic computing systems function because programmers code them to do specific tasks. AI, on the other hand, is only possible when computers can store information, including past commands, similar to how the human brain learns by storing skills and memories. This ability makes AI systems capable of adapting and performing new skills for tasks they weren't explicitly programmed to do. Also: ChatGPT vs. Microsoft Copilot vs. Gemini: Which is the best AI chatbot? Some experts define intelligence as the ability to adapt, solve problems, plan, improvise in new situations, and learn new things. Though these systems aren't a replacement for human intelligence or social interaction, today's AI systems demonstrate some traits found in human intelligence, including learning, problem-solving, pattern-finding, perception, and even a limited spectrum of creativity and social awareness. Also: The best AI image generators to try right now Of course, an important component of human intelligence is something that AI hasn't been able to replicate yet: context. For example, Google AI lacks real-world logic and can't discern human subtleties like sarcasm and humor, as evidenced by the technology advising you to add glue to pizza sauce to help the cheese stick or use gasoline to make spaghetti spicy . These examples are lower stakes, but an AI system taking action without semantic understanding can have major consequences in the wrong situation. Show more How can I use AI? Andriy Onufriyenko/Getty Images AI has a slew of possible applications, many of which are now widely available in everyday life. At the consumer level, this potential includes the newly revamped Google Search , wearables , and even vacuums . The smart speakers on your mantle with Alexa or Google voice assistant built-in are also great examples of AI. Popular AI chatbots like ChatGPT , Microsoft's Copilot , and Claude can be used for conversational questions or tasks, like breaking down concepts, drafting emails or project outlines, and even writing creative stories. But because AI models cannot tell fact from fiction, these chatbots tend to hallucinate or make things up -- where applicable, always verify the statements a chatbot makes with independent research, especially if you're unsure about the quality of its citations. Also: How does ChatGPT work? A major function of AI in consumer products is personalization, whether for targeted ads or biometric security. This is why your phone can distinguish your face from someone else's when you're unlocking it with Face ID, for example -- it's learned what yours looks like by referencing billions of other people's faces and matching specific data points. On a bigger scale, marketing and content teams can use AI to streamline production , while developers write and execute code with it. AI can also exponentially increase the speed and efficiency of medical research . Show more What is machine learning (ML)? Bing Image Creator/ZDNET Machine learning (ML) refers to the process of training a set of algorithms on large amounts of data to recognize patterns, which helps make predictions and decisions. This pattern-seeking enables systems to automate tasks they haven't been explicitly programmed to do, which is the biggest differentiator of AI from other computer science topics. This capability is what many refer to as AI, but ML is a subset of AI. When data is structured, or organized, a system can more easily detect an anomaly -- for example, when a transaction on your credit card is from a part of the world it's not used to seeing in your activity. Also: What is machine learning? Everything you need to know Examples of ML include search engines, image and speech recognition, and fraud detection. Similar to Face ID, when users upload photos to Facebook, the social network's image recognition can analyze the images, recognize faces, and make recommendations to tag the friends it's identified. With time, practice, and more image data, the system hones this skill and becomes more accurate. Show more How does machine learning work? Machine learning is generally split into two main categories: supervised and unsupervised learning. Supervised learning This common technique for teaching AI systems uses annotated data or data labeled and categorized by humans. ML systems are then fed this data to learn patterns. Suppose you wanted to train an ML model to recognize and differentiate images of circles and squares. In that case, you'd gather a large dataset of images of circles (like photos of planets, wheels, and other circular objects) and squares (tables, whiteboards, etc.), complete with labels for what each shape is. The algorithm would then learn from this labeled collection of images to distinguish the shapes and their characteristics: in this case, circles don't have corners, and squares have four equal-length sides. The system can then see a new image and determine the shapes. Unsupervised learning By contrast, unsupervised learning lets algorithms try to identify patterns in unlabeled data by looking for similarities that it can use to categorize the data. The algorithms aren't programmed in advance to pick out specific types of data; they simply look for data with similarities that they can group -- for example, segmenting customers based on shopping behavior to target them with personalized marketing campaigns. Also: Machine learning is going real-time: Here's why and how Reinforcement learning In reinforcement learning, the system is trained to maximize a reward based on input data, going through a trial-and-error process until it arrives at the best possible outcome. Imagine training a system to play a video game. The system can receive a positive reward if it gets a higher score and a negative reward for a low score. The system learns to analyze the game and make moves, learning solely from the rewards it receives. It can eventually play by itself and learn to achieve a high score without human intervention. Reinforcement learning is also used in research, where it can help teach autonomous robots the optimal way to behave in real-world environments. Robots learning to navigate new environments they haven't ingested data on -- like maneuvering around surprise obstacles -- is an example of more advanced ML that can be considered AI. Show more What are the different types of AI? Artificial intelligence can be divided into three subcategories: narrow AI, general AI, and super AI. Show more What is narrow AI? June Wan/ZDNET Artificial narrow intelligence (ANI) refers to intelligent systems designed or trained to carry out specific tasks or solve particular problems without being explicitly designed. This type of AI is crucial to voice assistants like Siri, Alexa, and Google Assistant. ANI is sometimes called weak AI, as it doesn't possess general intelligence. But that doesn't mean it isn't powerful in its own right. In addition to voice assistants, image-recognition systems, technologies that respond to simple customer service requests, and tools that flag inappropriate content online are examples of ANI. ChatGPT is also an example of ANI, as it is programmed to perform a specific task: generate text responses to prompts it's given. Also: Microsoft Copilot Pro vs. OpenAI's ChatGPT Plus Show more What is general AI? Yuichiro Chino/Getty Images Artificial general intelligence (AGI), or strong AI, is still a hypothetical concept as it involves a machine understanding and autonomously performing vastly different tasks based on accumulated experience. This type of intelligence is more on the level of human intellect, as AGI systems would be able to reason and think more like people do. Also: AI's true goal may no longer be intelligence Like a human, AGI could potentially understand any intellectual task, think abstractly, learn from its experiences, and use that knowledge to solve new problems. Essentially, we're talking about a system or machine capable of common sense, which is currently unachievable with any available AI. Developing a system with consciousness is still, presumably, a fair way in the distance, but it is the ultimate goal of AI research. OpenAI hints that its forthcoming GPT-5 will get us closer to AGI. Show more What is super AI? Yuichiro Chino/Moment via Getty Images Artificial superintelligence (ASI) would be a machine intelligence that surpasses all forms of human intelligence and outperforms humans in every function. A system like this wouldn't just rock humankind to its core -- it could also destroy it. If that sounds like something straight out of a science fiction novel, it's because it kind of is. Also: Mechanics of the future: Meet the specialists assembling AI An intelligent system that can learn and continuously improve itself is still a hypothetical concept. However, if applied effectively and ethically, the system could lead to extraordinary progress and achievements in medicine, technology, and more. Show more What are some recent examples of AI? Some of the most impressive advancements in AI are the development and release of GPT 3.5 and, most recently, GPT-4o , in addition to lifelike AI avatars and deepfakes . But there have been many other revolutionary achievements in AI -- too many to include here. Here are some of the most notable. ChatGPT (and the GPTs) ChatGPT is an AI chatbot capable of generating and translating natural language and answering questions. Though it's arguably the most popular AI tool, thanks to its widespread accessibility, OpenAI made significant waves in artificial intelligence by creating GPTs 1, 2, and 3 before releasing ChatGPT. Also: 6 ways ChatGPT can make your everyday life easier GPT stands for Generative Pre-trained Transformer, and GPT-3 was the largest language model at its 2020 launch, with 175 billion parameters. Then came GPT-3.5, which powers the free tier of ChatGPT. The largest version, GPT-4, accessible through the free version of ChatGPT, ChatGPT Plus, and Microsoft Copilot, has one trillion parameters. Self-driving cars Though the safety of self-driving cars is a top concern for potential users, the technology continues to advance and improve with breakthroughs in AI. These vehicles use ML algorithms to combine data from sensors and cameras to perceive their surroundings and determine the best course of action. Also: An autonomous car that wakes up and greets you could be in your future The autopilot feature in Tesla's electric vehicles is probably what most people think of when considering self-driving cars. But Waymo, from Google's parent company Alphabet, also makes autonomous rides -- as a driverless taxi, for example, or to deliver Uber Eats -- in San Francisco, CA, and Phoenix, AZ. Cruise is another robotaxi service, and auto companies like Audi, GM, and Ford are also presumably working on self-driving vehicle technology. Robotics The achievements of Boston Dynamics stand out in the area of AI and robotics. Though we're still a long way from creating Terminator-level AI technology, watching Boston Dyanmics' hydraulic, humanoid robots use AI to navigate and respond to different terrains is impressive. DeepMind Google subsidiary DeepMind is an AI pioneer focusing on AGI. Though not there yet, the company made headlines in 2016 for creating AlphaGo, an AI system that beat the world's best (human) professional Go player. Since then, DeepMind has created AlphaFold , a system that can predict the complex 3D shapes of proteins. It has also developed programs to diagnose eye diseases as effectively as top doctors. Also: What is generative AI and why is it so popular? Here's everything you need to know Show more What are large language models? A predominant example of AI is large language models (LLMs). These models use unsupervised machine learning and are trained on massive amounts of text to learn how human language works. Tech companies often scrape these texts from the internet for free to keep costs down -- they include articles, books, content from websites and forums, and more . In the training process, LLMs process billions of words and phrases to learn patterns and relationships between them, enabling the models to generate human-like answers to prompts. But again, keep in mind that these models are replicating common grammatical patterns and word pairings, albeit at a sophisticated level -- they aren't thinking like we do, in the sense that they cannot understand fact, logic, or common sense. Also: AI will unleash the next level of human potential. Here's how OpenAI's recently released GPT-4o tops the Chatbot Arena leaderboard as of now. The company's GPT-4 Turbo is considered one of the most advanced LLMs, while GPT-4 is the largest LLM at supposedly 1.78 trillion parameters. ChatGPT runs on both GPT-3.5 and GPT-4. Gemini is powered by an LLM of the same name developed by Google, and while its number of parameters hasn't been confirmed, it's estimated to be as many as 175 trillion. Show more Chatbot Arena Update! 1. Multilingual Arena -- four new languages (German, Spanish, Russian, Japanese). GPT-4o is #1 in English, German, and Spanish. Gemini-1.5-Pro is #1 in Japanese, Chinese, and French. Claude-3 Opus is #1 in Russian. The competition is tight, and we need… pic.twitter.com/RlNqh0XmMM — lmsys.org (@lmsysorg) June 3, 2024 What are neural networks? picture alliance/Contributor/Getty Images The success of machine learning relies on neural networks. These are mathematical models whose structure and functioning are loosely based on the connections between neurons in the human brain, mimicking how they signal to one another. Imagine a group of robots that are working together to solve a puzzle. Each is programmed to recognize a different shape or color in the puzzle pieces. A neural network is like a group of robots combining their abilities to solve the puzzle together. Neural networks can tweak internal parameters to change what they output. Each is fed databases to learn what it should put out when presented with certain data during training. Also: Six skills you need to become an AI prompt engineer These networks comprise interconnected layers of algorithms that feed data into each other. Neural networks can be trained to perform specific tasks by modifying the importance attributed to data as it passes between layers. During the training of these neural networks, the weights attached to data as it passes between layers will continue to be varied until the output from the neural network is very close to what is desired. At that point, the network will have 'learned' how to carry out a particular task. The desired output could be anything from correctly labeling fruit in an image to predicting when an elevator might fail based on its sensor data. Show more What is deep learning? Deep learning is part of the ML family and involves training artificial neural networks with three or more layers to perform different tasks. These neural networks are expanded into sprawling networks with a large number of deep layers that are trained using massive amounts of data. Deep learning models tend to have more than three layers at least and can have hundreds of layers at most. Deep learning can use supervised or unsupervised learning or both in training processes. Also: What is deep learning? Everything you need to know Because deep learning technology can learn to recognize complex patterns in data using AI, it is often used in natural language processing (NLP), speech recognition, and image recognition. Show more What is conversational AI? Conversational AI refers to systems programmed to have conversations with a user and are trained to listen (input) and respond (output) in a conversational manner. Conversational AI uses NLP to understand and respond naturally. Also: Why conversational AI is now ready for prime time Some examples of conversational AI are chatbots like Gemini, smart speakers with a voice assistant like Amazon Alexa, or virtual assistants on your smartphone like Siri. Show more What AI services are available to use? Consumers and businesses alike have a wealth of AI services available to expedite tasks and add convenience to day-to-day life -- you probably have something in your home that uses AI in some capacity. Here are some common examples of AI available to the public, both free and for a cost: Voice assistants: Amazon Alexa on the Echo device on your shelf, Apple's Siri on your iPhone, and Google Assistant on a Pixel device all use natural language processing to understand and respond to your questions or commands. Chatbots: AI chatbots like ChatGPT, Copilot , and Perplexity are another form of virtual assistant that can interact with people and, in some cases, hold human-like conversations, even mimicking empathy and concern. Language translation: Services like Google Translate, Microsoft Translator, Amazon Translate, and ChatGPT use machine learning to translate text. Productivity: Microsoft Copilot for Microsoft 365 is a great example of an LLM used as an AI productivity tool embedded within Word, PowerPoint, Outlook, Excel, Teams, and more to automate tasks. For example, simply entering 'Email the team about the latest status on the project' will trigger Copilot to automatically gather information from emails and documents to generate a text with your request. Image and video recognition: Different programs use AI to find information about the content in images and videos, such as faces, text, and objects. Clarifai, which employs machine learning to organize unstructured data from sources, and Amazon Rekognition , an AWS service that lets users upload images to receive information, are two examples of this. Software development: Many developers have been using ChatGPT to write and debug code for over a year, but many other AI tools are available to make a programmer's job easier. One example is the AI pair programmer GitHub Copilot by OpenAI Codex, a generative language model that can write code faster with less effort by autocompleting comments and code instantly. Building a business: Many companies are creating AI tools specifically for businesses, like OpenAI's GPT-4 API , or Amazon Bedrock , a suite of cloud-based AI tools for developers. Also: The best free AI courses (and whether AI 'micro-degrees' and certificates are worth it) Show more What company is leading the AI race? With generative AI taking off, several companies are working competitively in the space -- both legacy tech firms and startups. While each is developing too quickly for there to be a static leader, here are some of the major players. OpenAI Unsurprisingly, OpenAI has made a huge impact in AI after making its powerful generative AI tools available for free, including ChatGPT and Dall-E 3 , an AI image generator. Also: Have 10 hours? IBM will train you in AI fundamentals - for free Anthropic Anthropic created Claude , a powerful group of LLMs, and is considered a primary competitor of OpenAI. The company focuses on safety and ethical concerns in its AI research. Alphabet Google's parent company, Alphabet, has its hands in several different AI systems through companies including DeepMind, Waymo, and Google. Also: Ready to upskill? Look to the edge (where it's not all about AI) Google had a rough start in the AI chatbot race with an underperforming tool called Google Bard, originally powered by LaMDA. The company then switched the LLM behind Bard twice -- the first time for PaLM 2, and then for Gemini, the LLM currently powering it. With the last change, Google also renamed the bot Bard for Gemini. Also: What is Gemini? Everything you should know about Google's new AI model DeepMind continues to pursue AGI . It's developed machine-learning models for Document AI, optimized the viewer experience on Youtube, made AlphaFold available for researchers worldwide, and more. Though you may not hear of Alphabet's AI endeavors in the news every day, its work in deep learning and AI in general has the potential to change the future for human beings. Microsoft Aside from creating Microsoft Copilot, the company provides a suite of AI tools for developers on Azure , such as platforms for developing machine learning, data analytics, conversational AI, and customizable APIs that achieve human parity in computer vision, speech, and language. Also: Microsoft CEO Nadella: 'Expect us to incorporate AI in every layer of the stack' Microsoft has also invested heavily in OpenAI's development. The tech giant uses GPT-4 in Copilot, formerly known as Bing chat , and in an advanced version of Dall-E 3 to generate images through Microsoft Designer . Apple Apple has also entered the space most recently with its AI-upgraded line of iPads and potential new announcements to come at WWDC. Other companies Other firms are making strides in artificial intelligence, including Baidu , Alibaba , Cruise , Lenovo , Tesla , and more. Show more How will AI change the world? At the rate and scale it's being applied, AI will impact how we work, shop, and consume media, and our privacy, our health, and more. As with most historical shifts, the benefits, downsides, and potential harms are mixed. Every advancement in technology has changed the nature of work. By automating certain tasks, AI is transforming the day-to-day work lives of people across industries, and creating new roles (and rendering some obsolete ). In creative fields, for example, generative AI reduces the cost, time, and human input to make marketing and video content . Also: 12 reasons AI taking on more work doesn't mean it replaces you AI is increasingly playing a role in our healthcare systems and medical research. The technology could help make care more scalable and accessible. Doctors and radiologists could make cancer diagnoses using fewer resources, spot genetic sequences related to diseases, and identify molecules that could lead to more effective medications, potentially saving countless lives. Also: How AI hallucinations could help create life-saving antibiotics The tech is also creating new questions about how we keep all kinds of data -- even our thoughts -- private. AI has made facial recognition and surveillance commonplace, causing many experts to advocate banning it altogether. At the same time that AI is heightening privacy and security concerns, the technology is also enabling companies to make strides in cybersecurity software. As models -- and the companies that build them -- get more powerful, users call for more transparency around how they're created, and at what cost. The practice of companies scraping images and text from the internet to train their models has prompted a still-unfolding legal conversation around licensing creative material. Neural networks can be used to realistically replicate someone's voice or likeness without their consent, making deepfakes and misinformation a present concern, especially for upcoming elections . Because AI makes automation so easy on a large scale, researchers and tech employees share concerns about its role in weapons manufacturing and warfare. Also: The ethics of generative AI: How we can harness this powerful technology Show more Will an AI steal your job? The possibility of artificially intelligent systems replacing a considerable chunk of modern labor is a credible near-future possibility. While commonplace AI won't replace all jobs, what seems certain is that AI will change the nature of work, with the only question being how rapidly and profoundly automation will alter the workplace. Also: These are the jobs most likely to be taken over by AI However, artificial intelligence can't run independently. While many jobs with routine, repetitive data work might be automated, workers in other jobs can use tools like generative AI to become more productive and efficient. There is a broad range of opinions among AI experts about how quickly artificially intelligent systems will surpass human capabilities. Also: Can AI be a team player in collaborative software development? Show more Artificial Intelligence The best AI for coding in 2025 (including two new top picks - and what not to use) I tested 10 AI content detectors - and these 5 correctly identified AI text every time The best AI image generators are getting scary good at things they used to be terrible at Looking for an AI-powered website builder? Here's your best option in 2025 Use AI at work? You might be ruining your reputation, a new study finds The best AI for coding in 2025 (including two new top picks - and what not to use) I tested 10 AI content detectors - and these 5 correctly identified AI text every time The best AI image generators are getting scary good at things they used to be terrible at Looking for an AI-powered website builder? Here's your best option in 2025 Use AI at work? You might be ruining your reputation, a new study finds Editorial standards Show Comments Log In to Comment Community Guidelines Related AI usage is stalling out at work from lack of education and support You've heard about AI killing jobs, but here are 15 news ones AI could create AI agents win over professionals - but only to do their grunt work, Stanford study finds ZDNET we equip you to harness the power of disruptive innovation, at work and at home. Topics Galleries Videos Do Not Sell or Share My Personal Information about ZDNET Meet The Team Sitemap Reprint Policy Join | Log In Newsletters Licensing Accessibility © 2025 ZDNET, A Ziff Davis company. All rights reserved. Privacy Policy | | Cookie Settings | Advertise | Terms of Use
====================================================================================================
Artificial intelligence | NIST Skip to main content An official website of the United States government Here’s how you know Here’s how you know Official websites use .gov A .gov website belongs to an official government organization in the United States. Secure .gov websites use HTTPS A lock ( Lock A locked padlock ) or https:// means you’ve safely connected to the .gov website. Share sensitive information only on official, secure websites. https://www.nist.gov/artificial-intelligence Search NIST Menu Close Publications What We Do All Topics Advanced communications Artificial intelligence Bioscience Buildings and construction Chemistry Cybersecurity Electronics Energy Environment Fire Forensic science Health Information technology Infrastructure Manufacturing Materials Mathematics and statistics Metrology Nanotechnology Neutron research Performance excellence Physics Public safety Quantum information science Resilience Standards Transportation Labs & Major Programs Assoc Director of Laboratory Programs Laboratories Communications Technology Laboratory Engineering Laboratory Information Technology Laboratory Material Measurement Laboratory Physical Measurement Laboratory User Facilities NIST Center for Neutron Research CNST NanoFab Research Test Beds Research Projects Tools & Instruments Major Programs Baldrige Performance Excellence Program CHIPS for America Initiative Manufacturing Extension Partnership (MEP) Office of Advanced Manufacturing Special Programs Office Technology Partnerships Office Services & Resources Measurements and Standards Calibration Services Laboratory Accreditation (NVLAP) Quality System Standard Reference Materials (SRMs) Standard Reference Instruments (SRIs) Standards.gov Time Services Office of Weights and Measures Software Data Chemistry WebBook National Vulnerability Database Physical Reference Data Standard Reference Data (SRD) Storefront License & Patents Computer Security Resource Center (CSRC) NIST Research Library News & Events News Events Blogs Feature Stories Awards Video Gallery Image Gallery Media Contacts About NIST About Us Leadership Organization Structure Budget & Planning Contact Us Visit Careers Student programs Work with NIST History NIST Digital Archives NIST Museum NIST and the Nobel Educational Resources Information Technology Artificial intelligence Congressional Mandates & Executive Orders AI Risk Management Framework AI Innovation Lab (NAIIL) Center for AI Standards and Innovation AI Resource Center AI Research Expand or Collapse Bias Explainability Security Zero Drafts Pilot Project AI Standards AI Consortium Technical Contributions to AI Governance AI Engagement Related Links Sign Up to Get NIST News GovDelivery Artificial intelligence Topics AI Test, Evaluation, Validation and Verification (TEVV) Applied AI AI Research Hardware for AI Machine learning Trustworthy and Responsible AI NIST promotes innovation and cultivates trust in the design, development, use and governance of artificial intelligence (AI) technologies and systems in ways that enhance economic security, competitiveness, and quality of life. NIST advances a risk-based approach to maximize the benefits of AI while minimizing its potential negative consequences. NIST efforts focus on fundamental research to improve AI measurement science, standards, and related tools — including benchmarks and evaluations. NIST has a nonregulatory measurement science mission that encourages engagement with industry and others who voluntarily adopt its guidance. NIST recently launched its AI Standards “Zero Drafts” Pilot Project to accelerate AI innovation by developing AI standards more quickly while encouraging openness and collaboration. Input is encouraged. What NIST Does Conducts fundamental research, emphasizing measurements and risk management: NIST’s AI portfolio includes fundamental research to build the scientific foundation for AI measurements, evaluations, standards, and guidelines — including software, hardware, human interaction and teaming, and all relevant intersections and interfaces. Enables effective use of AI across government agencies: NIST develops guidelines, tools, and benchmarks that support responsible use of AI. This includes operationalizing the AI Risk Management Framework (AI RMF) and advancing use-inspired AI that bolsters innovations across NIST's research portfolio. Lays the foundation for risk-based AI governance that enables innovation: NIST's AI work is anchored in the AI RMF , a guide to managing AI-associated risks to individuals, organizations and society. A suite of guidelines is hosted by the NIST AI Resource Center . Creates reliable, interoperable, and widely accepted methods to measure and evaluate AI: NIST develops tests for and runs AI-related evaluations , like those carried out by NIST GenAI . Promotes development of voluntary AI technical standards: NIST leads and participates in the development of technical standards , including international standards, that promote innovation and public trust in systems that use AI. In addition, NIST serves as the federal government's AI standards coordinator. Contributes to national and international discussions on AI governance: NIST lends its scientific and technical expertise as a neutral convener of organizations with disparate views about AI matters, and participates actively in national and global discussions about AI. Why NIST? Experience: 120+ years of experience in research, development and standards. That includes widely recognized work advancing measurements, tools, standards and test beds that underlie trustworthy AI technologies. Expertise: NIST draws upon a highly specialized workforce across many scientific and technical domains. Collaborative approach: NIST works closely with organizations across the U.S. and globally through proactive engagements from start to finish. Partnerships are key. NIST’s work is driven by Congressional mandates, Presidential Executive Orders and federal policies, and the input and needs expressed by U.S. industry, the global research community, other federal agencies, and the broader AI community — as well as by NIST’s experience and its own capabilities. The agency's efforts are carried out across the NIST laboratories and programs, working closely with the broader AI community. View artificial intelligence publications News and Updates NIST Finalizes Guidelines for Evaluating ‘Differential Privacy’ Guarantees to De-Identify Data Read more NIST Researcher Describes Data Considerations for Industrial Artificial Intelligence Read more NIST Hosts Second Stakeholder Workshop on Digital Twins Read more View All News and Updates Featured Videos Bias in AI Psychology of Interpretable and Explainable AI View All Videos Blog Posts Robots and AI Are Working Together to Bring You Better Medicines, Shampoo and More Read more From Trash to Cash: How AI and Machine Learning Can Help Make Recycling Less Expensive for Local Governments Read more From Diamonds in Your Computer to Safer Medications, NIST Researchers Look at What’s Next for 2024 and Beyond Read more View All Blog Posts View upcoming artificial intelligence events Was this page helpful? HEADQUARTERS 100 Bureau Drive Gaithersburg, MD 20899 301-975-2000 Webmaster | Contact Us | Our Other Offices X.com Facebook LinkedIn Instagram YouTube Giphy RSS Feed Mailing List How are we doing? Feedback Site Privacy Accessibility Privacy Program Copyrights Vulnerability Disclosure No Fear Act Policy FOIA Environmental Policy Scientific Integrity Information Quality Standards Commerce.gov Science.gov USA.gov Vote.gov
====================================================================================================
What is AI (Artificial Intelligence)? Definition, Types, Examples & Use Cases Enterprise AI Search the TechTarget Network Login Register Explore the Network TechTarget Network Business Analytics CIO Data Management ERP Enterprise AI AI Business Strategies AI Careers AI Infrastructure AI Platforms AI Technologies More Topics Applications of AI ML Platforms Other Content News Features Tips Webinars 2024 IT Salary Survey Results Sponsored Sites More Answers Conference Guides Definitions Opinions Podcasts Quizzes Tech Accelerators Tutorials Videos Follow: Home AI technologies Tech Accelerator What is enterprise AI? A complete guide for businesses Prev Next 15 AI risks businesses must confront and how to address them AI use cases in banking create opportunities, improve systems Download this guide 1 X Free Download A guide to artificial intelligence in the enterprise This wide-ranging guide to artificial intelligence in the enterprise provides the building blocks for becoming successful business consumers of AI technologies. It starts with introductory explanations of AI's history, how AI works and the main types of AI. The importance and impact of AI is covered next, followed by information on AI's key benefits and risks, current and potential AI use cases, building a successful AI strategy, steps for implementing AI tools in the enterprise and technological breakthroughs that are driving the field forward. Throughout the guide, we include hyperlinks to TechTarget articles that provide more detail and insights on the topics discussed. Definition What is AI (Artificial Intelligence)? Definition, Types, Examples & Use Cases Share this item with your network: By Lev Craig, Site Editor Nicole Laskowski, Senior News Director Linda Tucci, Industry Editor -- CIO/IT Strategy Published: Oct 01, 2024 What is AI? Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. It includes learning, reasoning, and self-correction. Examples of AI applications include expert systems , natural language processing ( NLP ), speech recognition , machine vision , and generative tools like ChatGPT and Perplexity. As the hype around AI has accelerated, vendors have scrambled to promote how their products and services incorporate it. Often, what they refer to as "AI" is a well-established technology such as machine learning . AI requires specialized hardware and software for writing and training machine learning algorithms. No single programming language is used exclusively in AI, but Python, R, Java, C++ and Julia are all popular languages among AI developers. How does AI work? In general, AI systems work by ingesting large amounts of labeled training data, analyzing that data for correlations and patterns, and using these patterns to make predictions about future states. This article is part of What is enterprise AI? A complete guide for businesses Which also includes: How can AI drive revenue? Here are 10 approaches 8 jobs that AI can't replace and why 8 AI and machine learning trends to watch in 2025 For example, an AI chatbot that is fed examples of text can learn to generate lifelike exchanges with people, and an image recognition tool can learn to identify and describe objects in images by reviewing millions of examples. Generative AI techniques, which have advanced rapidly over the past few years, can create realistic text, images, music and other media. Programming AI systems focuses on cognitive skills such as the following: Learning. This aspect of AI programming involves acquiring data and creating rules, known as algorithms , to transform it into actionable information. These algorithms provide computing devices with step-by-step instructions for completing specific tasks. Reasoning. This aspect involves choosing the right algorithm to reach a desired outcome. Self-correction. This aspect involves algorithms continuously learning and tuning themselves to provide the most accurate results possible. Creativity. This aspect uses neural networks , rule-based systems , statistical methods and other AI techniques to generate new images, text, music, ideas and so on. Differences among AI, machine learning and deep learning The terms AI, machine learning and deep learning are often used interchangeably, especially in companies' marketing materials, but they have distinct meanings. In short, AI describes the broad concept of machines simulating human intelligence, while machine learning and deep learning are specific techniques within this field. The term AI, coined in the 1950s, encompasses an evolving and wide range of technologies that aim to simulate human intelligence, including machine learning and deep learning. Machine learning enables software to autonomously learn patterns and predict outcomes by using historical data as input. This approach became more effective with the availability of large training data sets. Deep learning, a subset of machine learning, aims to mimic the brain's structure using layered neural networks. It underpins many major breakthroughs and recent advances in AI, including autonomous vehicles and ChatGPT. Why is AI important? AI is important for its potential to change how we live, work and play. It has been effectively used in business to automate tasks traditionally done by humans, including customer service, lead generation, fraud detection and quality control. In a number of areas, AI can perform tasks more efficiently and accurately than humans. It is especially useful for repetitive, detail-oriented tasks such as analyzing large numbers of legal documents to ensure relevant fields are properly filled in. AI's ability to process massive data sets gives enterprises insights into their operations they might not otherwise have noticed. The rapidly expanding array of generative AI tools is also becoming important in fields ranging from education to marketing to product design. Advances in AI techniques have not only helped fuel an explosion in efficiency, but also opened the door to entirely new business opportunities for some larger enterprises. Prior to the current wave of AI, for example, it would have been hard to imagine using computer software to connect riders to taxis on demand, yet Uber has become a Fortune 500 company by doing just that. AI has become central to many of today's largest and most successful companies, including Alphabet, Apple, Microsoft and Meta, which use AI to improve their operations and outpace competitors. At Alphabet subsidiary Google, for example, AI is central to its eponymous search engine, and self-driving car company Waymo began as an Alphabet division. The Google Brain research lab also invented the transformer architecture that underpins recent NLP breakthroughs such as OpenAI's ChatGPT . What are the advantages and disadvantages of artificial intelligence? AI technologies, particularly deep learning models such as artificial neural networks, can process large amounts of data much faster and make predictions more accurately than humans can. While the huge volume of data created on a daily basis would bury a human researcher, AI applications using machine learning can take that data and quickly turn it into actionable information. A primary disadvantage of AI is that it is expensive to process the large amounts of data AI requires. As AI techniques are incorporated into more products and services, organizations must also be attuned to AI's potential to create biased and discriminatory systems, intentionally or inadvertently. Advantages of AI The following are some advantages of AI: Excellence in detail-oriented jobs. AI is a good fit for tasks that involve identifying subtle patterns and relationships in data that might be overlooked by humans. For example, in oncology, AI systems have demonstrated high accuracy in detecting early-stage cancers, such as breast cancer and melanoma , by highlighting areas of concern for further evaluation by healthcare professionals. Efficiency in data-heavy tasks. AI systems and automation tools dramatically reduce the time required for data processing. This is particularly useful in sectors like finance, insurance and healthcare that involve a great deal of routine data entry and analysis, as well as data-driven decision-making. For example, in banking and finance , predictive AI models can process vast volumes of data to forecast market trends and analyze investment risk. Time savings and productivity gains. AI and robotics can not only automate operations but also improve safety and efficiency. In manufacturing, for example, AI-powered robots are increasingly used to perform hazardous or repetitive tasks as part of warehouse automation , thus reducing the risk to human workers and increasing overall productivity. Consistency in results. Today's analytics tools use AI and machine learning to process extensive amounts of data in a uniform way, while retaining the ability to adapt to new information through continuous learning. For example, AI applications have delivered consistent and reliable outcomes in legal document review and language translation. Customization and personalization. AI systems can enhance user experience by personalizing interactions and content delivery on digital platforms. On e-commerce platforms, for example, AI models analyze user behavior to recommend products suited to an individual's preferences, increasing customer satisfaction and engagement. Round-the-clock availability. AI programs do not need to sleep or take breaks. For example, AI-powered virtual assistants can provide uninterrupted, 24/7 customer service even under high interaction volumes, improving response times and reducing costs. Scalability. AI systems can scale to handle growing amounts of work and data. This makes AI well suited for scenarios where data volumes and workloads can grow exponentially, such as internet search and business analytics . Accelerated research and development. AI can speed up the pace of R&D in fields such as pharmaceuticals and materials science. By rapidly simulating and analyzing many possible scenarios, AI models can help researchers discover new drugs , materials or compounds more quickly than traditional methods. Sustainability and conservation . AI and machine learning are increasingly used to monitor environmental changes, predict future weather events and manage conservation efforts . Machine learning models can process satellite imagery and sensor data to track wildfire risk , pollution levels and endangered species populations, for example. Process optimization. AI is used to streamline and automate complex processes across various industries. For example, AI models can identify inefficiencies and predict bottlenecks in manufacturing workflows, while in the energy sector, they can forecast electricity demand and allocate supply in real time. Disadvantages of AI The following are some disadvantages of AI: High costs. Developing AI can be very expensive. Building an AI model requires a substantial upfront investment in infrastructure , computational resources and software to train the model and store its training data. After initial training, there are further ongoing costs associated with model inference and retraining. As a result, costs can rack up quickly, particularly for advanced, complex systems like generative AI applications; OpenAI CEO Sam Altman has stated that training the company's GPT-4 model cost over $100 million. Technical complexity. Developing, operating and troubleshooting AI systems -- especially in real-world production environments -- requires a great deal of technical know-how. In many cases, this knowledge differs from that needed to build non-AI software . For example, building and deploying a machine learning application involves a complex, multistage and highly technical process, from data preparation to algorithm selection to parameter tuning and model testing. Talent gap. Compounding the problem of technical complexity, there is a significant shortage of professionals trained in AI and machine learning compared with the growing need for such skills. This gap between AI talent supply and demand means that, even though interest in AI applications is growing, many organizations cannot find enough qualified workers to staff their AI initiatives. Algorithmic bias. AI and machine learning algorithms reflect the biases present in their training data -- and when AI systems are deployed at scale, the biases scale, too. In some cases, AI systems may even amplify subtle biases in their training data by encoding them into reinforceable and pseudo-objective patterns. In one well-known example, Amazon developed an AI-driven recruitment tool to automate the hiring process that inadvertently favored male candidates, reflecting larger-scale gender imbalances in the tech industry. Difficulty with generalization. AI models often excel at the specific tasks for which they were trained but struggle when asked to address novel scenarios. This lack of flexibility can limit AI's usefulness, as new tasks might require the development of an entirely new model. An NLP model trained on English-language text, for example, might perform poorly on text in other languages without extensive additional training. While work is underway to improve models' generalization ability -- known as domain adaptation or transfer learning -- this remains an open research problem. Job displacement. AI can lead to job loss if organizations replace human workers with machines -- a growing area of concern as the capabilities of AI models become more sophisticated and companies increasingly look to automate workflows using AI. For example, some copywriters have reported being replaced by large language models ( LLMs ) such as ChatGPT. While widespread AI adoption may also create new job categories, these may not overlap with the jobs eliminated, raising concerns about economic inequality and reskilling. Security vulnerabilities. AI systems are susceptible to a wide range of cyberthreats, including data poisoning and adversarial machine learning . Hackers can extract sensitive training data from an AI model, for example, or trick AI systems into producing incorrect and harmful output. This is particularly concerning in security-sensitive sectors such as financial services and government. Environmental impact. The data centers and network infrastructures that underpin the operations of AI models consume large amounts of energy and water. Consequently, training and running AI models has a significant impact on the climate . AI's carbon footprint is especially concerning for large generative models, which require a great deal of computing resources for training and ongoing use. Legal issues. AI raises complex questions around privacy and legal liability, particularly amid an evolving AI regulation landscape that differs across regions. Using AI to analyze and make decisions based on personal data has serious privacy implications, for example, and it remains unclear how courts will view the authorship of material generated by LLMs trained on copyrighted works. Strong AI vs. weak AI AI can generally be categorized into two types: narrow (or weak ) AI and general (or strong) AI. Narrow AI. This form of AI refers to models trained to perform specific tasks. Narrow AI operates within the context of the tasks it is programmed to perform, without the ability to generalize broadly or learn beyond its initial programming. Examples of narrow AI include virtual assistants, such as Apple Siri and Amazon Alexa, and recommendation engines , such as those found on streaming platforms like Spotify and Netflix. General AI. This type of AI, which does not currently exist, is more often referred to as artificial general intelligence ( AGI ). If created, AGI would be capable of performing any intellectual task that a human being can. To do so, AGI would need the ability to apply reasoning across a wide range of domains to understand complex problems it was not specifically programmed to solve. This, in turn, would require something known in AI as fuzzy logic : an approach that allows for gray areas and gradations of uncertainty, rather than binary, black-and-white outcomes. Importantly, the question of whether AGI can be created -- and the consequences of doing so -- remains hotly debated among AI experts. Even today's most advanced AI technologies, such as ChatGPT and other highly capable LLMs, do not demonstrate cognitive abilities on par with humans and cannot generalize across diverse situations. ChatGPT, for example, is designed for natural language generation, and it is not capable of going beyond its original programming to perform tasks such as complex mathematical reasoning. 4 types of AI AI can be categorized into four types , beginning with the task-specific intelligent systems in wide use today and progressing to sentient systems, which do not yet exist. The categories are as follows: Type 1: Reactive machines. These AI systems have no memory and are task specific. An example is Deep Blue, the IBM chess program that beat Russian chess grandmaster Garry Kasparov in the 1990s. Deep Blue was able to identify pieces on a chessboard and make predictions, but because it had no memory, it could not use past experiences to inform future ones. Type 2: Limited memory. These AI systems have memory, so they can use past experiences to inform future decisions. Some of the decision-making functions in self-driving cars are designed this way. Type 3: Theory of mind. Theory of mind is a psychology term. When applied to AI, it refers to a system capable of understanding emotions. This type of AI can infer human intentions and predict behavior, a necessary skill for AI systems to become integral members of historically human teams. Type 4: Self-awareness. In this category, AI systems have a sense of self, which gives them consciousness. Machines with self-awareness understand their own current state. This type of AI does not yet exist. Understanding the key differences between artificial and human intelligence is crucial to effective and responsible AI use. What are examples of AI technology, and how is it used today? AI technologies can enhance existing tools' functionalities and automate various tasks and processes, affecting numerous aspects of everyday life. The following are a few prominent examples. Automation AI enhances automation technologies by expanding the range, complexity and number of tasks that can be automated. An example is robotic process automation ( RPA ), which automates repetitive, rules-based data processing tasks traditionally performed by humans. Because AI helps RPA bots adapt to new data and dynamically respond to process changes, integrating AI and machine learning capabilities enables RPA to manage more complex workflows. Machine learning Machine learning is the science of teaching computers to learn from data and make decisions without being explicitly programmed to do so. Deep learning, a subset of machine learning, uses sophisticated neural networks to perform what is essentially an advanced form of predictive analytics. Machine learning algorithms can be broadly classified into three categories: supervised learning , unsupervised learning and reinforcement learning . Supervised learning trains models on labeled data sets, enabling them to accurately recognize patterns, predict outcomes or classify new data. Unsupervised learning trains models to sort through unlabeled data sets to find underlying relationships or clusters. Reinforcement learning takes a different approach, in which models learn to make decisions by acting as agents and receiving feedback on their actions. There is also semi-supervised learning , which combines aspects of supervised and unsupervised approaches. This technique uses a small amount of labeled data and a larger amount of unlabeled data, thereby improving learning accuracy while reducing the need for labeled data, which can be time and labor intensive to procure. Computer vision Computer vision is a field of AI that focuses on teaching machines how to interpret the visual world. By analyzing visual information such as camera images and videos using deep learning models, computer vision systems can learn to identify and classify objects and make decisions based on those analyses. The primary aim of computer vision is to replicate or improve on the human visual system using AI algorithms. Computer vision is used in a wide range of applications, from signature identification to medical image analysis to autonomous vehicles. Machine vision, a term often conflated with computer vision, refers specifically to the use of computer vision to analyze camera and video data in industrial automation contexts, such as production processes in manufacturing. Natural language processing NLP refers to the processing of human language by computer programs. NLP algorithms can interpret and interact with human language, performing tasks such as translation, speech recognition and sentiment analysis . One of the oldest and best-known examples of NLP is spam detection, which looks at the subject line and text of an email and decides whether it is junk. More advanced applications of NLP include LLMs such as ChatGPT and Anthropic's Claude . Robotics Robotics is a field of engineering that focuses on the design, manufacturing and operation of robots: automated machines that replicate and replace human actions, particularly those that are difficult, dangerous or tedious for humans to perform. Examples of robotics applications include manufacturing, where robots perform repetitive or hazardous assembly-line tasks, and exploratory missions in distant, difficult-to-access areas such as outer space and the deep sea. The integration of AI and machine learning significantly expands robots' capabilities by enabling them to make better-informed autonomous decisions and adapt to new situations and data. For example, robots with machine vision capabilities can learn to sort objects on a factory line by shape and color. Autonomous vehicles Autonomous vehicles, more colloquially known as self-driving cars, can sense and navigate their surrounding environment with minimal or no human input. These vehicles rely on a combination of technologies, including radar, GPS, and a range of AI and machine learning algorithms, such as image recognition . These algorithms learn from real-world driving, traffic and map data to make informed decisions about when to brake, turn and accelerate; how to stay in a given lane; and how to avoid unexpected obstructions, including pedestrians. Although the technology has advanced considerably in recent years, the ultimate goal of an autonomous vehicle that can fully replace a human driver has yet to be achieved. Generative AI The term generative AI refers to machine learning systems that can generate new data from text prompts -- most commonly text and images, but also audio, video, software code, and even genetic sequences and protein structures. Through training on massive data sets, these algorithms gradually learn the patterns of the types of media they will be asked to generate, enabling them later to create new content that resembles that training data. Generative AI saw a rapid growth in popularity following the introduction of widely available text and image generators in 2022, such as ChatGPT, Dall-E and Midjourney, and is increasingly applied in business settings. While many generative AI tools' capabilities are impressive, they also raise concerns around issues such as copyright, fair use and security that remain a matter of open debate in the tech sector. What are the applications of AI? AI has entered a wide variety of industry sectors and research areas. The following are several of the most notable examples. AI in healthcare AI is applied to a range of tasks in the healthcare domain, with the overarching goals of improving patient outcomes and reducing systemic costs. One major application is the use of machine learning models trained on large medical data sets to assist healthcare professionals in making better and faster diagnoses. For example, AI-powered software can analyze CT scans and alert neurologists to suspected strokes . On the patient side, online virtual health assistants and chatbots can provide general medical information, schedule appointments, explain billing processes and complete other administrative tasks. Predictive modeling AI algorithms can also be used to combat the spread of pandemics such as COVID-19 . AI in business AI is increasingly integrated into various business functions and industries, aiming to improve efficiency, customer experience, strategic planning and decision-making. For example, machine learning models power many of today's data analytics and customer relationship management ( CRM ) platforms, helping companies understand how to best serve customers through personalizing offerings and delivering better-tailored marketing. Virtual assistants and chatbots are also deployed on corporate websites and in mobile applications to provide round-the-clock customer service and answer common questions. In addition, more and more companies are exploring the capabilities of generative AI tools such as ChatGPT for automating tasks such as document drafting and summarization, product design and ideation, and computer programming. AI in education AI has a number of potential applications in education technology. It can automate aspects of grading processes, giving educators more time for other tasks. AI tools can also assess students' performance and adapt to their individual needs, facilitating more personalized learning experiences that enable students to work at their own pace. AI tutors could also provide additional support to students, ensuring they stay on track. The technology could also change where and how students learn, perhaps altering the traditional role of educators. As the capabilities of LLMs such as ChatGPT and Google Gemini grow, such tools could help educators craft teaching materials and engage students in new ways. However, the advent of these tools also forces educators to reconsider homework and testing practices and revise plagiarism policies, especially given that AI detection and AI watermarking tools are currently unreliable. AI in finance and banking Banks and other financial organizations use AI to improve their decision-making for tasks such as granting loans, setting credit limits and identifying investment opportunities. In addition, algorithmic trading powered by advanced AI and machine learning has transformed financial markets, executing trades at speeds and efficiencies far surpassing what human traders could do manually. AI and machine learning have also entered the realm of consumer finance. For example, banks use AI chatbots to inform customers about services and offerings and to handle transactions and questions that don't require human intervention. Similarly, Intuit offers generative AI features within its TurboTax e-filing product that provide users with personalized advice based on data such as the user's tax profile and the tax code for their location. AI in law AI is changing the legal sector by automating labor-intensive tasks such as document review and discovery response, which can be tedious and time consuming for attorneys and paralegals. Law firms today use AI and machine learning for a variety of tasks, including analytics and predictive AI to analyze data and case law, computer vision to classify and extract information from documents, and NLP to interpret and respond to discovery requests. In addition to improving efficiency and productivity, this integration of AI frees up human legal professionals to spend more time with clients and focus on more creative, strategic work that AI is less well suited to handle. With the rise of generative AI in law , firms are also exploring using LLMs to draft common documents, such as boilerplate contracts. AI in entertainment and media The entertainment and media business uses AI techniques in targeted advertising, content recommendations, distribution and fraud detection. The technology enables companies to personalize audience members' experiences and optimize delivery of content. Generative AI is also a hot topic in the area of content creation. Advertising professionals are already using these tools to create marketing collateral and edit advertising images. However, their use is more controversial in areas such as film and TV scriptwriting and visual effects, where they offer increased efficiency but also threaten the livelihoods and intellectual property of humans in creative roles . AI in journalism In journalism, AI can streamline workflows by automating routine tasks, such as data entry and proofreading. Investigative journalists and data journalists also use AI to find and research stories by sifting through large data sets using machine learning models, thereby uncovering trends and hidden connections that would be time consuming to identify manually. For example, five finalists for the 2024 Pulitzer Prizes for journalism disclosed using AI in their reporting to perform tasks such as analyzing massive volumes of police records. While the use of traditional AI tools is increasingly common, the use of generative AI to write journalistic content is open to question, as it raises concerns around reliability, accuracy and ethics. AI in software development and IT AI is used to automate many processes in software development, DevOps and IT . For example, AIOps tools enable predictive maintenance of IT environments by analyzing system data to forecast potential issues before they occur, and AI-powered monitoring tools can help flag potential anomalies in real time based on historical system data. Generative AI tools such as GitHub Copilot and Tabnine are also increasingly used to produce application code based on natural-language prompts. While these tools have shown early promise and interest among developers , they are unlikely to fully replace software engineers. Instead, they serve as useful productivity aids, automating repetitive tasks and boilerplate code writing. AI in security AI and machine learning are prominent buzzwords in security vendor marketing, so buyers should take a cautious approach. Still, AI is indeed a useful technology in multiple aspects of cybersecurity , including anomaly detection, reducing false positives and conducting behavioral threat analytics. For example, organizations use machine learning in security information and event management ( SIEM ) software to detect suspicious activity and potential threats. By analyzing vast amounts of data and recognizing patterns that resemble known malicious code, AI tools can alert security teams to new and emerging attacks, often much sooner than human employees and previous technologies could. AI in manufacturing Manufacturing has been at the forefront of incorporating robots into workflows, with recent advancements focusing on collaborative robots, or cobots . Unlike traditional industrial robots, which were programmed to perform single tasks and operated separately from human workers, cobots are smaller, more versatile and designed to work alongside humans. These multitasking robots can take on responsibility for more tasks in warehouses, on factory floors and in other workspaces, including assembly, packaging and quality control. In particular, using robots to perform or assist with repetitive and physically demanding tasks can improve safety and efficiency for human workers. AI in transportation In addition to AI's fundamental role in operating autonomous vehicles, AI technologies are used in automotive transportation to manage traffic, reduce congestion and enhance road safety. In air travel, AI can predict flight delays by analyzing data points such as weather and air traffic conditions. In overseas shipping, AI can enhance safety and efficiency by optimizing routes and automatically monitoring vessel conditions. In supply chains, AI is replacing traditional methods of demand forecasting and improving the accuracy of predictions about potential disruptions and bottlenecks. The COVID-19 pandemic highlighted the importance of these capabilities, as many companies were caught off guard by the effects of a global pandemic on the supply and demand of goods. Augmented intelligence vs. artificial intelligence The term artificial intelligence is closely linked to popular culture, which could create unrealistic expectations among the general public about AI's impact on work and daily life. A proposed alternative term, augmented intelligence , distinguishes machine systems that support humans from the fully autonomous systems found in science fiction -- think HAL 9000 from 2001: A Space Odyssey or Skynet from the Terminator movies. The two terms can be defined as follows: Augmented intelligence. With its more neutral connotation, the term augmented intelligence suggests that most AI implementations are designed to enhance human capabilities, rather than replace them. These narrow AI systems primarily improve products and services by performing specific tasks. Examples include automatically surfacing important data in business intelligence reports or highlighting key information in legal filings. The rapid adoption of tools like ChatGPT and Gemini across various industries indicates a growing willingness to use AI to support human decision-making. Artificial intelligence. In this framework, the term AI would be reserved for advanced general AI in order to better manage the public's expectations and clarify the distinction between current use cases and the aspiration of achieving AGI. The concept of AGI is closely associated with the concept of the technological singularity -- a future wherein an artificial superintelligence far surpasses human cognitive abilities, potentially reshaping our reality in ways beyond our comprehension. The singularity has long been a staple of science fiction, but some AI developers today are actively pursuing the creation of AGI. Ethical use of artificial intelligence While AI tools present a range of new functionalities for businesses , their use raises significant ethical questions. For better or worse, AI systems reinforce what they have already learned, meaning that these algorithms are highly dependent on the data they are trained on. Because a human being selects that training data, the potential for bias is inherent and must be monitored closely. Generative AI adds another layer of ethical complexity . These tools can produce highly realistic and convincing text, images and audio -- a useful capability for many legitimate applications, but also a potential vector of misinformation and harmful content such as deepfakes . Consequently, anyone looking to use machine learning in real-world production systems needs to factor ethics into their AI training processes and strive to avoid unwanted bias. This is especially important for AI algorithms that lack transparency, such as complex neural networks used in deep learning. Responsible AI refers to the development and implementation of safe, compliant and socially beneficial AI systems. It is driven by concerns about algorithmic bias, lack of transparency and unintended consequences. The concept is rooted in longstanding ideas from AI ethics, but gained prominence as generative AI tools became widely available -- and, consequently, their risks became more concerning. Integrating responsible AI principles into business strategies helps organizations mitigate risk and foster public trust. Explainability , or the ability to understand how an AI system makes decisions, is a growing area of interest in AI research. Lack of explainability presents a potential stumbling block to using AI in industries with strict regulatory compliance requirements. For example, fair lending laws require U.S. financial institutions to explain their credit-issuing decisions to loan and credit card applicants. When AI programs make such decisions, however, the subtle correlations among thousands of variables can create a black-box problem, where the system's decision-making process is opaque. In summary, AI's ethical challenges include the following: Bias due to improperly trained algorithms and human prejudices or oversights. Misuse of generative AI to produce deepfakes, phishing scams and other harmful content. Legal concerns , including AI libel and copyright issues. Job displacement due to increasing use of AI to automate workplace tasks. Data privacy concerns , particularly in fields such as banking, healthcare and legal that deal with sensitive personal data. These components make up responsible AI use. AI governance and regulations Despite potential risks, there are currently few regulations governing the use of AI tools, and many existing laws apply to AI indirectly rather than explicitly. For example, as previously mentioned, U.S. fair lending regulations such as the Equal Credit Opportunity Act require financial institutions to explain credit decisions to potential customers. This limits the extent to which lenders can use deep learning algorithms, which by their nature are opaque and lack explainability. The European Union has been proactive in addressing AI governance. The EU's General Data Protection Regulation ( GDPR ) already imposes strict limits on how enterprises can use consumer data, affecting the training and functionality of many consumer-facing AI applications. In addition, the EU AI Act , which aims to establish a comprehensive regulatory framework for AI development and deployment, went into effect in August 2024. The Act imposes varying levels of regulation on AI systems based on their riskiness, with areas such as biometrics and critical infrastructure receiving greater scrutiny. While the U.S. is making progress, the country still lacks dedicated federal legislation akin to the EU's AI Act. Policymakers have yet to issue comprehensive AI legislation , and existing federal-level regulations focus on specific use cases and risk management, complemented by state initiatives. That said, the EU's more stringent regulations could end up setting de facto standards for multinational companies based in the U.S., similar to how GDPR shaped the global data privacy landscape. With regard to specific U.S. AI policy developments, the White House Office of Science and Technology Policy published a "Blueprint for an AI Bill of Rights" in October 2022, providing guidance for businesses on how to implement ethical AI systems. The U.S. Chamber of Commerce also called for AI regulations in a report released in March 2023, emphasizing the need for a balanced approach that fosters competition while addressing risks. More recently, in October 2023, President Biden issued an executive order on the topic of secure and responsible AI development. Among other things, the order directed federal agencies to take certain actions to assess and manage AI risk and developers of powerful AI systems to report safety test results. The outcome of the upcoming U.S. presidential election is also likely to affect future AI regulation, as candidates Kamala Harris and Donald Trump have espoused differing approaches to tech regulation. Crafting laws to regulate AI will not be easy, partly because AI comprises a variety of technologies used for different purposes, and partly because regulations can stifle AI progress and development, sparking industry backlash. The rapid evolution of AI technologies is another obstacle to forming meaningful regulations, as is AI's lack of transparency, which makes it difficult to understand how algorithms arrive at their results. Moreover, technology breakthroughs and novel applications such as ChatGPT and Dall-E can quickly render existing laws obsolete. And, of course, laws and other regulations are unlikely to deter malicious actors from using AI for harmful purposes . These are commonly described as the four main types of AI. What is the history of AI? The concept of inanimate objects endowed with intelligence has been around since ancient times. The Greek god Hephaestus was depicted in myths as forging robot-like servants out of gold, while engineers in ancient Egypt built statues of gods that could move, animated by hidden mechanisms operated by priests. Throughout the centuries, thinkers from the Greek philosopher Aristotle to the 13th-century Spanish theologian Ramon Llull to mathematician René Descartes and statistician Thomas Bayes used the tools and logic of their times to describe human thought processes as symbols. Their work laid the foundation for AI concepts such as general knowledge representation and logical reasoning. The late 19th and early 20th centuries brought forth foundational work that would give rise to the modern computer. In 1836, Cambridge University mathematician Charles Babbage and Augusta Ada King, Countess of Lovelace, invented the first design for a programmable machine, known as the Analytical Engine. Babbage outlined the design for the first mechanical computer, while Lovelace -- often considered the first computer programmer -- foresaw the machine's capability to go beyond simple calculations to perform any operation that could be described algorithmically. As the 20th century progressed, key developments in computing shaped the field that would become AI . In the 1930s, British mathematician and World War II codebreaker Alan Turing introduced the concept of a universal machine that could simulate any other machine. His theories were crucial to the development of digital computers and, eventually, AI. 1940s Princeton mathematician John Von Neumann conceived the architecture for the stored-program computer -- the idea that a computer's program and the data it processes can be kept in the computer's memory. Warren McCulloch and Walter Pitts proposed a mathematical model of artificial neurons, laying the foundation for neural networks and other future AI developments. 1950s With the advent of modern computers, scientists began to test their ideas about machine intelligence. In 1950, Turing devised a method for determining whether a computer has intelligence, which he called the imitation game but has become more commonly known as the Turing test . This test evaluates a computer's ability to convince interrogators that its responses to their questions were made by a human being. The modern field of AI is widely cited as beginning in 1956 during a summer conference at Dartmouth College. Sponsored by the Defense Advanced Research Projects Agency, the conference was attended by 10 luminaries in the field, including AI pioneers Marvin Minsky, Oliver Selfridge and John McCarthy , who is credited with coining the term "artificial intelligence." Also in attendance were Allen Newell, a computer scientist, and Herbert A. Simon, an economist, political scientist and cognitive psychologist. The two presented their groundbreaking Logic Theorist, a computer program capable of proving certain mathematical theorems and often referred to as the first AI program. A year later, in 1957, Newell and Simon created the General Problem Solver algorithm that, despite failing to solve more complex problems, laid the foundations for developing more sophisticated cognitive architectures. 1960s In the wake of the Dartmouth College conference, leaders in the fledgling field of AI predicted that human-created intelligence equivalent to the human brain was around the corner, attracting major government and industry support. Indeed, nearly 20 years of well-funded basic research generated significant advances in AI. McCarthy developed Lisp , a language originally designed for AI programming that is still used today. In the mid-1960s, MIT professor Joseph Weizenbaum developed Eliza, an early NLP program that laid the foundation for today's chatbots. 1970s In the 1970s, achieving AGI proved elusive, not imminent, due to limitations in computer processing and memory as well as the complexity of the problem. As a result, government and corporate support for AI research waned, leading to a fallow period lasting from 1974 to 1980 known as the first AI winter . During this time, the nascent field of AI saw a significant decline in funding and interest. 1980s In the 1980s, research on deep learning techniques and industry adoption of Edward Feigenbaum's expert systems sparked a new wave of AI enthusiasm. Expert systems, which use rule-based programs to mimic human experts' decision-making, were applied to tasks such as financial analysis and clinical diagnosis. However, because these systems remained costly and limited in their capabilities, AI's resurgence was short-lived, followed by another collapse of government funding and industry support. This period of reduced interest and investment, known as the second AI winter, lasted until the mid-1990s. 1990s Increases in computational power and an explosion of data sparked an AI renaissance in the mid- to late 1990s, setting the stage for the remarkable advances in AI we see today. The combination of big data and increased computational power propelled breakthroughs in NLP, computer vision, robotics, machine learning and deep learning. A notable milestone occurred in 1997, when Deep Blue defeated Kasparov, becoming the first computer program to beat a world chess champion. 2000s Further advances in machine learning, deep learning, NLP, speech recognition and computer vision gave rise to products and services that have shaped the way we live today. Major developments include the 2000 launch of Google's search engine and the 2001 launch of Amazon's recommendation engine. Also in the 2000s, Netflix developed its movie recommendation system, Facebook introduced its facial recognition system and Microsoft launched its speech recognition system for transcribing audio. IBM launched its Watson question-answering system, and Google started its self-driving car initiative, Waymo. 2010s The decade between 2010 and 2020 saw a steady stream of AI developments. These include the launch of Apple's Siri and Amazon's Alexa voice assistants; IBM Watson's victories on Jeopardy ; the development of self-driving features for cars; and the implementation of AI-based systems that detect cancers with a high degree of accuracy. The first generative adversarial network was developed, and Google launched TensorFlow, an open source machine learning framework that is widely used in AI development. A key milestone occurred in 2012 with the groundbreaking AlexNet, a convolutional neural network that significantly advanced the field of image recognition and popularized the use of GPUs for AI model training. In 2016, Google DeepMind's AlphaGo model defeated world Go champion Lee Sedol, showcasing AI's ability to master complex strategic games. The previous year saw the founding of research lab OpenAI , which would make important strides in the second half of that decade in reinforcement learning and NLP. 2020s The current decade has so far been dominated by the advent of generative AI, which can produce new content based on a user's prompt. These prompts often take the form of text, but they can also be images, videos, design blueprints, music or any other input that the AI system can process. Output content can range from essays to problem-solving explanations to realistic images based on pictures of a person. In 2020, OpenAI released the third iteration of its GPT language model, but the technology did not reach widespread awareness until 2022. That year, the generative AI wave began with the launch of image generators Dall-E 2 and Midjourney in April and July, respectively. The excitement and hype reached full force with the general release of ChatGPT that November. OpenAI's competitors quickly responded to ChatGPT's release by launching rival LLM chatbots, such as Anthropic's Claude and Google's Gemini. Audio and video generators such as ElevenLabs and Runway followed in 2023 and 2024. Generative AI technology is still in its early stages, as evidenced by its ongoing tendency to hallucinate and the continuing search for practical, cost-effective applications. But regardless, these developments have brought AI into the public conversation in a new way, leading to both excitement and trepidation. AI tools and services: Evolution and ecosystems AI tools and services are evolving at a rapid rate. Current innovations can be traced back to the 2012 AlexNet neural network, which ushered in a new era of high-performance AI built on GPUs and large data sets. The key advancement was the discovery that neural networks could be trained on massive amounts of data across multiple GPU cores in parallel, making the training process more scalable. In the 21st century, a symbiotic relationship has developed between algorithmic advancements at organizations like Google, Microsoft and OpenAI, on the one hand, and the hardware innovations pioneered by infrastructure providers like Nvidia, on the other. These developments have made it possible to run ever-larger AI models on more connected GPUs, driving game-changing improvements in performance and scalability. Collaboration among these AI luminaries was crucial to the success of ChatGPT, not to mention dozens of other breakout AI services. Here are some examples of the innovations that are driving the evolution of AI tools and services. Transformers Google led the way in finding a more efficient process for provisioning AI training across large clusters of commodity PCs with GPUs. This, in turn, paved the way for the discovery of transformers, which automate many aspects of training AI on unlabeled data. With the 2017 paper "Attention Is All You Need," Google researchers introduced a novel architecture that uses self-attention mechanisms to improve model performance on a wide range of NLP tasks, such as translation, text generation and summarization. This transformer architecture was essential to developing contemporary LLMs, including ChatGPT. Hardware optimization Hardware is equally important to algorithmic architecture in developing effective, efficient and scalable AI. GPUs, originally designed for graphics rendering, have become essential for processing massive data sets. Tensor processing units and neural processing units , designed specifically for deep learning, have sped up the training of complex AI models. Vendors like Nvidia have optimized the microcode for running across multiple GPU cores in parallel for the most popular algorithms. Chipmakers are also working with major cloud providers to make this capability more accessible as AI as a service (AIaaS) through IaaS, SaaS and PaaS models. Generative pre-trained transformers and fine-tuning The AI stack has evolved rapidly over the last few years. Previously, enterprises had to train their AI models from scratch. Now, vendors such as OpenAI, Nvidia, Microsoft and Google provide generative pre-trained transformers (GPTs) that can be fine-tuned for specific tasks with dramatically reduced costs, expertise and time. AI cloud services and AutoML One of the biggest roadblocks preventing enterprises from effectively using AI is the complexity of data engineering and data science tasks required to weave AI capabilities into new or existing applications. All leading cloud providers are rolling out branded AIaaS offerings to streamline data prep, model development and application deployment. Top examples include Amazon AI , Google AI , Microsoft Azure AI and Azure ML, IBM Watson and Oracle Cloud 's AI features. Similarly, the major cloud providers and other vendors offer automated machine learning ( AutoML ) platforms to automate many steps of ML and AI development. AutoML tools democratize AI capabilities and improve efficiency in AI deployments. Cutting-edge AI models as a service Leading AI model developers also offer cutting-edge AI models on top of these cloud services. OpenAI has multiple LLMs optimized for chat, NLP, multimodality and code generation that are provisioned through Azure. Nvidia has pursued a more cloud-agnostic approach by selling AI infrastructure and foundational models optimized for text, images and medical data across all cloud providers. Many smaller players also offer models customized for various industries and use cases. George Lawton also contributed to this article. Continue Reading About What is AI (Artificial Intelligence)? Definition, Types, Examples & Use Cases Top AI and machine learning trends How businesses can measure AI success with KPIs Steps to achieve AI implementation in your business What is trustworthy AI and why is it important? The future of AI: What to expect in the next 5 years Related Terms What is a qubit (quantum bit)? A qubit, short for quantum bit, is the basic unit of information in quantum computing and the counterpart to the bit, or binary ... See complete definition What is Apple Intelligence? Apple Intelligence is the platform name for a suite of generative AI capabilities that Apple is integrating across its products, ... See complete definition What is prediction error? A prediction error is the failure of a model of a system to accurately forecast outcomes. See complete definition Dig Deeper on AI technologies AI medical terminology: 10 key terms to understand By: Jill McKeon Generative AI vs. machine learning: Key differences and use cases By: Stephen Bigelow The different types of AI explained By: Alexander Gillis What is artificial intelligence as a service (AIaaS)? By: Alexander Gillis Sponsored News Transform Claims Management: Enhancing Accuracy, Compliance and Efficiency –Zelis Healthcare Harness AI at the Edge to Enhance Business Success –HPE & Intel See More Vendor Resources Human-like AI quest drives general AI development efforts –TechTarget ComputerWeekly.com How to become an artificial intelligence engineer, step by step –TechTarget ComputerWeekly.com Latest TechTarget resources Business Analytics CIO Data Management ERP Business Analytics ThoughtSpot evolving as BI becomes driven by AI Recent releases, including the Agentic Analytics Platform and Agentic Semantic Layer, demonstrate that the vendor continues to be... Latest Databricks tools use AI to simplify AI development Fueled by user feedback, the vendor's newest features include a framework that automates building agents and a no-code interface ... 7 top cloud-based analytics tools for enterprise use Cloud-based analytics tools offer flexible deployment, advanced visualization and integration capabilities to help organizations ... Search CIO In an FTC antitrust win, Meta could face divestitures The FTC argues that Meta acquired Instagram and WhatsApp to eliminate competition in social media networks. If the FTC wins its ... Google settlement may affect DOJ antitrust remedies Google faces numerous antitrust challenges and has agreed to spend $500 million revamping its regulatory compliance structure in ... Trump wants to axe rules affecting business competition As the FTC and DOJ work to assess what rules to cut, lawmakers disagree on how deregulation will affect U.S. markets. Search Data Management Confluent platform update targets performance, simplicity The vendor's latest release replaces its coordinating technology to make its tools easier to use and updates its Control Center ... New Actian features target data discoverability, reliability Automatically embedded data governance, data product registration on a data marketplace platform and a natural language interface... Why Apache Iceberg is essential for modern data lakehouses Organizations adopt Apache Iceberg to build open data lakehouses that support high-performance analytics, multi-cloud strategies ... Search ERP 9 generative AI use cases in supply chain Generative AI's demand forecasting and inventory optimization abilities, among others, can help companies meet their goals. Learn... 12 steps you need to carry out post-ERP implementation Learn the essential steps your project team must take to ensure ERP implementation is successful after the go-live. 12 ERP KPIs for post-implementation success Learn the metrics that help IT teams assess whether an ERP system has helped to streamline processes and improve overall business... About Us Editorial Ethics Policy Meet The Editors Contact Us Advertisers Partner with Us Media Kit Corporate Site Contributors Reprints Answers Definitions E-Products Events Features Guides Opinions Photo Stories Quizzes Tips Tutorials Videos ©2025 TechTarget , Inc. d/b/a Informa TechTarget. All Rights Reserved. Privacy Policy Cookie Preferences Cookie Preferences Do Not Sell or Share My Personal Information Close
====================================================================================================
Artificial intelligence - Machine Learning, Robotics, Algorithms | Britannica Search Britannica Click here to search Search Britannica Click here to search SUBSCRIBE SUBSCRIBE Login https://premium.britannica.com/premium-membership/?utm_source=premium&utm_medium=nav-login-box&utm_campaign=evergreen SUBSCRIBE Home History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Games & Quizzes Videos On This Day One Good Fact Dictionary New Articles History & Society Lifestyles & Social Issues Philosophy & Religion Politics, Law & Government World History Science & Tech Health & Medicine Science Technology Biographies Browse Biographies Animals & Nature Birds, Reptiles & Other Vertebrates Bugs, Mollusks & Other Invertebrates Environment Fossils & Geologic Time Mammals Plants Geography & Travel Geography & Travel Arts & Culture Entertainment & Pop Culture Literature Sports & Recreation Visual Arts Image Galleries Podcasts Summaries Top Questions Britannica Kids Ask the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Videos artificial intelligence Table of Contents Introduction & Top Questions What is intelligence? Learning Reasoning Problem solving Perception Language Methods and goals in AI Symbolic vs. connectionist approaches Artificial general intelligence (AGI), applied AI, and cognitive simulation AI technology Machine learning Large language models and natural language processing Autonomous vehicles Virtual assistants Risks Is artificial general intelligence (AGI) possible? Want to learn more? References & Edit History Quick Facts & Related Topics Images & Videos For Students artificial intelligence summary Quizzes Computers and Technology Quiz Related Questions What is artificial intelligence? Technology Computers Methods and goals in AI in artificial intelligence Simplify &nbspThis&nbsp Article Ask the Chatbot Print print Print Please select which sections you would like to print: Table Of Contents Cite verified Cite While every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions. Select Citation Style MLA APA Chicago Manual of Style Copy Citation Share Share Share to social media Facebook X URL https://www.britannica.com/technology/artificial-intelligence Feedback External Websites Feedback Corrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login). Feedback Type Select a type (Required) Factual Correction Spelling/Grammar Correction Link Correction Additional Information Other Your Feedback Submit Feedback Thank you for your feedback Our editors will review what you’ve submitted and determine whether to revise the article. External Websites National Center for Biotechnology Information - PubMed Central - The rise of artificial intelligence in healthcare applications Lifewire - What is artificial intelligence? Frontiers - Frontiers in Robotics and AI - A Review of Future and Ethical Perspectives of Robotics and AI Academia - Locomotive Optimization Using Artificial Intelligence Approach Computer History Museum - AI and Robotics Internet Encyclopedia of Philosophy - Artificial Intelligence IOPscience - Journal of Physics: Conference Series - Application of Artificial Intelligence in Integrated Circuits (PDF) Harvard University - Science in the News - The History of Artificial Intelligence Academia - History of Artificial Intelligence National Center for Biotechnology Information - PubMed Central - What is new in computer vision and artificial intelligence in medical image analysis applications Journal of Emerging Technologies and Innovative Research - A Study on the Robotics and Artificial Intelligence Britannica Websites Articles from Britannica Encyclopedias for elementary and high school students. artificial intelligence - Children's Encyclopedia (Ages 8-11) artificial intelligence (AI) - Student Encyclopedia (Ages 11 and up) Simplify &nbspThis&nbsp Article Ask the Chatbot a Question Also known as: AI Written by B.J. Copeland Professor of Philosophy and Director of the Turing Archive for the History of Computing, University of Canterbury, Christchurch, New Zealand. Author of Artificial Intelligence and others. B.J. Copeland Fact-checked by The Editors of Encyclopaedia Britannica Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree. They write new content and verify and edit content received from contributors. The Editors of Encyclopaedia Britannica Last Updated: Jun 25, 2025 • Article History Table of Contents Table of Contents Simplify &nbspThis&nbsp Article Ask the Chatbot a Question Key People: Geoffrey Hinton John M. Jumper Marvin Minsky Edward Albert Feigenbaum Allen Newell (Show more) Related Topics: history of artificial intelligence (AI) Logic Theorist General Problem Solver frame generative AI (Show more) On the Web: Frontiers - Frontiers in Robotics and AI - A Review of Future and Ethical Perspectives of Robotics and AI (June 04, 2025) (Show more) See all related content News • How ChatGPT and other AI tools are changing the teaching profession • June 25, 2025, 9:22 PM ET (AP) ... (Show more) Judge dismisses authors' copyright lawsuit against Meta over AI training • June 25, 2025, 8:55 PM ET (AP) Bipartisan bill seeks to ban Chinese AI from federal agencies, as U.S. vows to win the AI race • June 25, 2025, 12:47 PM ET (AP) Anthropic wins ruling on AI training in copyright lawsuit but must face trial on pirated books • June 24, 2025, 4:40 PM ET (AP) Music streaming service Deezer adds AI song tags in fight against fraud • June 20, 2025, 9:39 AM ET (AP) Show less Symbolic vs. connectionist approaches AI research follows two distinct, and to some extent competing, methods, the symbolic (or “top-down”) approach, and the connectionist (or “bottom-up”) approach. The top-down approach seeks to replicate intelligence by analyzing cognition independent of the biological structure of the brain , in terms of the processing of symbols—whence the symbolic label. The bottom-up approach , on the other hand, involves creating artificial neural networks in imitation of the brain’s structure—whence the connectionist label. To illustrate the difference between these approaches, consider the task of building a system, equipped with an optical scanner , that recognizes the letters of the alphabet. A bottom-up approach typically involves training an artificial neural network by presenting letters to it one by one, gradually improving performance by “tuning” the network. (Tuning adjusts the responsiveness of different neural pathways to different stimuli.) In contrast, a top-down approach typically involves writing a computer program that compares each letter with geometric descriptions. Simply put, neural activities are the basis of the bottom-up approach, while symbolic descriptions are the basis of the top-down approach. In The Fundamentals of Learning (1932), Edward Thorndike , a psychologist at Columbia University , New York City , first suggested that human learning consists of some unknown property of connections between neurons in the brain. In The Organization of Behavior (1949), Donald Hebb, a psychologist at McGill University , Montreal, suggested that learning specifically involves strengthening certain patterns of neural activity by increasing the probability (weight) of induced neuron firing between the associated connections. In 1957 two vigorous advocates of symbolic AI—Allen Newell, a researcher at the RAND Corporation , Santa Monica , California, and Herbert Simon , a psychologist and computer scientist at Carnegie Mellon University , Pittsburgh—summed up the top-down approach in what they called the physical symbol system hypothesis. This hypothesis states that processing structures of symbols is sufficient, in principle, to produce artificial intelligence in a digital computer and that, moreover, human intelligence is the result of the same type of symbolic manipulations. During the 1950s and ’60s the top-down and bottom-up approaches were pursued simultaneously, and both achieved noteworthy, if limited, results. During the 1970s, however, bottom-up AI was neglected, and it was not until the 1980s that this approach again became prominent. Nowadays both approaches are followed, and both are acknowledged as facing difficulties. Symbolic techniques work in simplified realms but typically break down when confronted with the real world; meanwhile, bottom-up researchers have been unable to replicate the nervous systems of even the simplest living things. Caenorhabditis elegans , a much-studied worm, has approximately 300 neurons whose pattern of interconnections is perfectly known. Yet connectionist models have failed to mimic even this worm. Evidently, the neurons of connectionist theory are gross oversimplifications of the real thing. Britannica Quiz Computers and Technology Quiz Artificial general intelligence (AGI), applied AI, and cognitive simulation Employing the methods outlined above, AI research attempts to reach one of three goals: artificial general intelligence (AGI), applied AI, or cognitive simulation. AGI (also called strong AI ) aims to build machines that think. The ultimate ambition of AGI is to produce a machine whose overall intellectual ability is indistinguishable from that of a human being’s . To date, progress has been uneven. Despite advances in large-language models, it is debatable whether AGI can emerge from even more powerful models or if a completely different approach is needed. Indeed, some researchers working in AI’s other two branches view AGI as not worth pursuing. Applied AI, also known as advanced information processing , aims to produce commercially viable “smart” systems—for example, “expert” medical diagnosis systems and stock-trading systems. Applied AI has enjoyed considerable success. In cognitive simulation, computers are used to test theories about how the human mind works—for example, theories about how people recognize faces or recall memories. Cognitive simulation is already a powerful tool in both neuroscience and cognitive psychology . AI technology In the early 21st century faster processing power and larger datasets (“ big data ”) brought artificial intelligence out of computer science departments and into the wider world. Moore’s law , the observation that computing power doubled roughly every 18 months, continued to hold true. The stock responses of the early chatbot Eliza fit comfortably within 50 kilobytes; the language model at the heart of ChatGPT was trained on 45 terabytes of text. Machine learning The ability of neural networks to take on added layers and thus work on more-complex problems increased in 2006 with the invention of the “greedy layer-wise pretraining” technique, in which it was found that it was easier to train each layer of a neural network individually than to train the whole network from input to output. This improvement in neural network training led to a type of machine learning called “ deep learning,” in which neural networks have four or more layers, including the initial input and the final output. Moreover, such networks are able to learn unsupervised—that is, to discover features in data without initial prompting. Among the achievements of deep learning have been advances in image classification in which specialized neural networks called convolution neural networks (CNNs) are trained on features found in a set of images of many different types of objects. The CNN is then able to take an input image, compare it with features in images in its training set, and classify the image as being of, for example, a cat or an apple. One such network, PReLU-net by Kaiming He and collaborators at Microsoft Research, has classified images even better than a human did. Garry Kasparov and Deep Blue World chess champion Garry Kasparov playing against Deep Blue, the chess-playing computer built by IBM. In 1996 Kasparov won the first match 4−2, but in 1997 he lost to Deep Blue 3 ½−2 ½. (more) The achievement of Deep Blue in beating world chess champion Garry Kasparov was surpassed by DeepMind’s AlphaGo, which mastered go , a much more complicated game than chess. AlphaGo’s neural networks learned to play go from human players and by playing itself. It defeated top go player Lee Sedol 4–1 in 2016. AlphaGo was in turn surpassed by AlphaGo Zero, which, starting from only the rules of go, was eventually able to defeat AlphaGo 100–0. A more general neural network, Alpha Zero, was able to use the same techniques to quickly master chess and shogi . Machine learning has found applications in many fields beyond gaming and image classification. The pharmaceutical company Pfizer used the technique to quickly search millions of possible compounds in developing the COVID-19 treatment Paxlovid. Google uses machine learning to filter out spam from the inbox of Gmail users. Banks and credit card companies use historical data to train models to detect fraudulent transactions. TikTok account featuring a deepfake of Keanu Reeves The “Unreal Keanu Reeves” TikTok account posts include relationship humor and dances. (more) Deepfakes are AI-generated media produced using two different deep-learning algorithms : one that creates the best possible replica of a real image or video and another that detects whether the replica is fake and, if it is, reports on the differences between it and the original. The first algorithm produces a synthetic image and receives feedback on it from the second algorithm ; it then adjusts it to make it appear more real. The process is repeated until the second algorithm does not detect any false imagery. Deepfake media portray images that do not exist in reality or events that have never occurred. Widely circulated deepfakes include an image of Pope Francis in a puffer jacket, an image of former U.S. president Donald Trump in a scuffle with police officers, and a video of Facebook CEO Mark Zuckerberg giving a speech about his company’s nefarious power. Such events did not occur in real life. Large language models and natural language processing Natural language processing (NLP) involves analyzing how computers can process and parse language similarly to the way humans do. To do this, NLP models must use computational linguistics , statistics , machine learning, and deep-learning models. Early NLP models were hand-coded and rule-based but did not account for exceptions and nuances in language. Statistical NLP was the next step, using probability to assign the likelihood of certain meanings to different parts of text. Modern NLP systems use deep-learning models and techniques that help them to “learn” as they process information. Conversation with ChatGPT Screenshot of a ChatGPT conversation created by Encyclopædia Britannica editor Erik Gregersen. The conversation prompt was to write a 250-word encyclopaedia article about ChatGPT. (more) Prominent examples of modern NLP are language models that use AI and statistics to predict the final form of a sentence on the basis of existing portions. In large language model (LLM), the word large refers to the parameters , or variables and weights, used by the model to influence the prediction outcome. Although there is no definition for how many parameters are needed, LLM training datasets range in size from 110 million parameters (Google’s BERT base model) to 340 billion parameters (Google’s PaLM 2 model). Large also refers to the sheer amount of data used to train an LLM, which can be multiple petabytes in size and contain trillions of tokens, which are the basic units of text or code, usually a few characters long, that are processed by the model. One popular language model was GPT-3, released by OpenAI in June 2020. One of the first LLMs, GPT-3 could solve high-school-level math problems as well as create computer programs. GPT-3 was the foundation of ChatGPT software , released in November 2022. ChatGPT almost immediately disturbed academics, journalists, and others because of concern that it was impossible to distinguish human writing from ChatGPT-generated writing. A flurry of LLMs and chatbots based on them followed in ChatGPT’s wake. Microsoft added the chatbot Copilot in 2023 to its Windows 11 operating system, its Bing search engine , and its Edge browser. That same year, Google released a chatbot, Bard (later Gemini), and in 2024, the company announced that “AI Overviews” of subjects would appear at the top of search results. One issue with LLMs is “hallucinations”: rather than communicating to a user that it does not know something, the model responds with probable but inaccurate text based on the user’s prompts. This issue may be partially attributed to using LLMs as search engines rather than in their intended role as text generators. One method to combat hallucinations is known as prompt engineering , whereby engineers design prompts that aim to extract the optimal output from the model. For example, one such prompt style is chain-of-thought, in which the initial prompt contains both an example question and a carefully worked out answer to show the LLM how to proceed. Other examples of machines using NLP are voice-operated GPS systems, customer service chatbots, and language translation programs. In addition, businesses use NLP to enhance understanding of and service to consumers by auto-completing search queries and monitoring social media . Programs such as OpenAI’s DALL-E, Stable Diffusion , and Midjourney use NLP to create images based on textual prompts, which can be as simple as “a red block on top of a green block” or as complex as “a cube with the texture of a porcupine.” The programs are trained on large datasets with millions or billions of text-image pairs—that is, images with textual descriptions. NLP presents certain issues, especially as machine-learning algorithms and the like often express biases implicit in the content on which they are trained. For example, when asked to describe a doctor, language models may be more likely to respond with “He is a doctor” than “She is a doctor,” demonstrating inherent gender bias. Bias in NLP can have real-world consequences. For instance, in 2015 Amazon’s NLP program for résumé screening to aid in the selection of job candidates was found to discriminate against women, as women were underrepresented in the original training set collected from employees. Autonomous vehicles Machine learning and AI are foundational elements of autonomous vehicle systems. Vehicles are trained on complex data (e.g., the movement of other vehicles, road signs) with machine learning, which helps to improve the algorithms they operate under. AI enables vehicles’ systems to make decisions without needing specific instructions for each potential situation. In order to make autonomous vehicles safe and effective, artificial simulations are created to test their capabilities. To create such simulations, black-box testing is used, in contrast to white-box validation. White-box testing, in which the internal structure of the system being tested is known to the tester, can prove the absence of failure. Black-box methods are much more complicated and involve taking a more adversarial approach. In such methods, the internal design of the system is unknown to the tester, who instead targets the external design and structure. These methods attempt to find weaknesses in the system to ensure that it meets high safety standards. As of 2024, fully autonomous vehicles are not available for consumer purchase. Certain obstacles have proved challenging to overcome. For example, maps of almost four million miles of public roads in the United States would be needed for an autonomous vehicle to operate effectively, which presents a daunting task for manufacturers. Additionally, the most popular cars with a “self-driving” feature, those of Tesla , have raised safety concerns, as such vehicles have even headed toward oncoming traffic and metal posts. AI has not progressed to the point where cars can engage in complex interactions with other drivers or with cyclists or pedestrians. Such “common sense” is necessary to prevent accidents and create a safe environment . In October 2015 Google’s self-driving car, Waymo (which the company had been working on since 2009) completed its first fully driverless trip with one passenger. The technology had been tested on one billion miles within simulations, and two million miles on real roads. Waymo, which boasts a fleet of fully electric-powered vehicles, operates in San Francisco and Phoenix, where users can call for a ride, much as with Uber or Lyft. The steering wheel, gas pedal, and brake pedal operate without human guidance, differentiating the technology from Tesla’s autonomous driving feature. Though the technology’s valuation peaked at $175 billion in November 2019, it had sunk to just $30 billion by 2020. Waymo is being investigated by the U.S. National Highway Traffic Safety Administration (NHTSA) after more than 20 different reports of traffic violations. In certain cases, the vehicles drove on the wrong side of the road and in one instance, hit a cyclist. Virtual assistants Virtual assistants (VAs) serve a variety of functions, including helping users schedule tasks, making and receiving calls, and guiding users on the road. These devices require large amounts of data and learn from user input to become more effective at predicting user needs and behavior. The most popular VAs on the market are Amazon Alexa , Google Assistant, and Apple ’s Siri. Virtual assistants differ from chatbots and conversational agents in that they are more personalized, adapting to an individual user’s behavior and learning from it to improve over time. Human-machine communication began in the 1960s with Eliza. PARRY, designed by the psychiatrist Kenneth Colby, followed in the early 1970s and was designed to mimic a conversation with a person with paranoid schizophrenia . Simon, designed by IBM in 1994, was one of the first devices that could technically be called a “smartphone,” and was marketed as a personal digital assistant (PDA). Simon was the first device to feature a touchscreen, and it had email and fax capability as well. Although Simon was not technically a VA, its development was essential in creating future assistants. In February 2010 Siri, the first modern VA, was introduced for iOS, Apple’s mobile operating system , with the iPhone 4S. Siri was the first VA able to be downloaded to a smartphone . Voice assistants parse human speech by breaking it down into distinct sounds known as phonemes , using an automatic speech recognition (ASR) system. After breaking down the speech, the VA analyzes and “remembers” the tone and other aspects of the voice to recognize the user. Over time, VAs have become more sophisticated through machine learning, as they have access to many millions of words and phrases. In addition, they often use the Internet to find answers to user questions—for example, when a user asks for a weather forecast. Risks AI poses certain risks in terms of ethical and socioeconomic consequences. As more tasks become automated, especially in such industries as marketing and health care, many workers are poised to lose their jobs. Although AI may create some new jobs, these may require more technical skills than the jobs AI has replaced. Moreover, AI has certain biases that are difficult to overcome without proper training. For example, U.S. police departments have begun using predictive policing algorithms to indicate where crimes are most likely to occur. However, such systems are based partly on arrest rates, which are already disproportionately high in Black communities . This may lead to over-policing in such areas, which further affects these algorithms. As humans are inherently biased , algorithms are bound to reflect human biases. Privacy is another aspect of AI that concerns experts. As AI often involves collecting and processing large amounts of data, there is the risk that this data will be accessed by the wrong people or organizations. With generative AI, it is even possible to manipulate images and create fake profiles. AI can also be used to survey populations and track individuals in public spaces. Experts have implored policymakers to develop practices and policies that maximize the benefits of AI while minimizing the potential risks. In January 2024 singer Taylor Swift was the target of sexually explicit non-consensual deepfakes that were widely circulated on social media. Many individuals had already faced this type of online abuse (made possible by AI), but Swift’s status brought the issue to the forefront of public policy. Google data center Aerial view of a Google data center complex in Eemshaven, Netherlands. (more) LLMs are located at data centers that require large amounts of electricity. In 2020 Microsoft pledged that it would be carbon neutral by 2030. In 2024 it announced that in the previous fiscal year its carbon emissions had increased by almost 30 percent, mostly from the building materials and hardware required in building more data centers. A ChatGPT query requires about 10 times more electricity than a Google Search. Goldman Sachs has estimated that data centers will use about 8 percent of U.S. electricity in 2030. As of 2024 there are few laws regulating AI . Existing laws such as the European Union ’s General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) do govern AI models but only insofar as they use personal information. The most wide-reaching regulation is the EU’s AI Act , which passed in March 2024. Under the AI Act, models that perform social scoring of citizens’ behavior and characteristics and that attempt to manipulate users’ behavior are banned. AI models that deal with “high-risk” subjects, such as law enforcement and infrastructure , must be registered in an EU database. AI has also led to issues concerning copyright law and policy. In 2023 the U.S. government Copyright Office began an initiative to investigate the issue of AI using copyrighted works to generate content. That year almost 15 new cases of copyright-related suits were filed against companies involved in creating generative AI programs. One prominent company, Stability AI, came under fire for using unlicensed images to generate new content. Getty Images, which filed the suit, added its own AI feature to its platform, partially in response to the host of services that offer “stolen imagery.” There are also questions of whether work created by AI is worthy of a copyright label. Currently, AI-made content cannot be copyrighted, but there are arguments for and against copyrighting it. Although many AI companies claim that their content does not require human labor, in many cases, such “groundbreaking” technology is reliant on exploited workers from developing countries. For example, a Time magazine investigation found that OpenAI had used Kenyan workers (who had been paid less than $2 an hour) to sort through text snippets in order to help remove toxic and sexually explicit language from ChatGPT. The project was canceled in February 2022 because of how traumatic the task was for workers. Although Amazon had marketed its Amazon Go cashier-less stores as being fully automated (e.g., its AI could detect the items in a customer’s basket), it was revealed that the “Just Walk Out” technology was actually powered by outsourced labor from India, where more than a thousand workers operated as “remote cashiers,” leading to the joke that, in this case, AI stood for Actually Indians.
====================================================================================================
Artificial Intelligence (AI): What It Is, How It Works, Types, and Uses Skip to content News Markets Companies Earnings CD Rates Mortgage Rates Economy Government Crypto Live Markets News Personal Finance View All Investing Stocks Cryptocurrency Bonds ETFs Options and Derivatives Commodities Trading Automated Investing Brokers Fundamental Analysis Markets View All Simulator Login / Portfolio Trade Research My Games Leaderboard Banking Savings Accounts Certificates of Deposit (CDs) Money Market Accounts Checking Accounts View All Personal Finance Budgeting and Saving Personal Loans Insurance Mortgages Credit and Debt Student Loans Taxes Credit Cards Financial Literacy Retirement View All Economy Government and Policy Monetary Policy Fiscal Policy Economics View All Reviews Best Online Brokers Best Crypto Exchanges Best Savings Rates Best CD Rates Best Life Insurance Best Mortgage Rates Best Robo-Advisors Best Personal Loans Best Debt Relief Companies View All Trade Search Search Please fill out this field. Search Search Please fill out this field. News News Markets Companies Earnings CD Rates Mortgage Rates Economy Government Crypto Live Markets News Personal Finance View All Investing Investing Stocks Cryptocurrency Bonds ETFs Options and Derivatives Commodities Trading Automated Investing Brokers Fundamental Analysis Markets View All Simulator Simulator Login / Portfolio Trade Research My Games Leaderboard Banking Banking Savings Accounts Certificates of Deposit (CDs) Money Market Accounts Checking Accounts View All Personal Finance Personal Finance Budgeting and Saving Personal Loans Insurance Mortgages Credit and Debt Student Loans Taxes Credit Cards Financial Literacy Retirement View All Economy Economy Government and Policy Monetary Policy Fiscal Policy Economics View All Reviews Reviews Best Online Brokers Best Crypto Exchanges Best Savings Rates Best CD Rates Best Life Insurance Best Mortgage Rates Best Robo-Advisors Best Personal Loans Best Debt Relief Companies View All Follow Us Table of Contents Expand Table of Contents What Is Artificial Intelligence (AI)? How It Works Types Uses FAQs The Bottom Line Artificial Intelligence (AI): What It Is, How It Works, Types, and Uses By The Investopedia Team Full Bio Investopedia contributors come from a range of backgrounds, and over 25 years there have been thousands of expert writers and editors who have contributed. Learn about our editorial policies Updated April 10, 2025 Reviewed by Gordon Scott Reviewed by Gordon Scott Full Bio Gordon Scott has been an active investor and technical analyst or 20+ years. He is a Chartered Market Technician (CMT). Learn about our Financial Review Board Daniel Fishel / Investopedia Close What Is Artificial Intelligence (AI)? Artificial intelligence (AI) technology allows computers and machines to simulate human intelligence and problem-solving tasks. The ideal characteristic of artificial intelligence is its ability to rationalize and take action to achieve a specific goal. AI research began in the 1950s and was used in the 1960s by the U.S. Department of Defense when it trained computers to mimic human reasoning. A subset of artificial intelligence is machine learning (ML) , a concept that computer programs can automatically learn from and adapt to new data without human assistance. Key Takeaways Artificial intelligence (AI) technology allows computers and machines to simulate human intelligence and problem-solving capabilities. Algorithms are part of the structure of AI, where simple algorithms are used in simple applications, while more complex ones help frame strong artificial intelligence. AI technology is apparent in computers that play chess, self-driving cars, and banking systems to detect fraudulent activity. Client-Financial Advisor Discussion Guide Should I Invest in Artificial Intelligence? Download Guide Download Guide How Artificial Intelligence (AI) Works Artificial intelligence commonly brought to mind the implementation of robots . As technology evolved, previous benchmarks that define artificial intelligence became outdated. Technologies that enable artificial intelligence include: Computer vision enables computers to identify objects and people in pictures and photos. Natural language processing (NLP) allows computers to understand human language. Graphical processing units are computer chips that help computers form graphics and images through mathematical calculations. The Internet of Things is the network of physical devices, vehicles, and other objects embedded with sensors, software, and network connectivity, that collect and share data. Application programming allows two or more computer programs or components to communicate with each other. Fast Fact Algorithms often play a part in the structure of artificial intelligence, where simple algorithms are used in simple applications, while more complex ones help frame strong artificial intelligence. Types of Artificial Intelligence Narrow AI : Also known as weak AI , this system is designed to carry out one particular job. Weak AI systems include video games and personal assistants like Amazon’s Alexa and Apple’s Siri. Users ask the assistant a question, which it answers for you. General AI : This type includes strong artificial intelligence systems that carry on the tasks considered to be human-like. They tend to be more complex and complicated and can be found in applications like self-driving cars or hospital operating rooms. Important Super AI is a strictly theoretical type of AI and has not yet been realized. Super AI would think, reason, learn, and possess cognitive abilities that surpass those of human beings. Using Artificial Intelligence Artificial intelligence can be applied to many sectors and industries , including credit scoring, law enforcement , and the healthcare industry. In a medical setting, it can be useful for suggesting drug dosages, identifying treatments, and aiding in surgical procedures in the operating room. Other examples of machines with artificial intelligence include computers that play chess and self-driving cars . AI has applications in the financial industry , where it detects and flags fraudulent banking activity. Applications for AI can help streamline and make trading easier . In 2022, AI entered the mainstream with applications of the Generative Pre-Trained Transformer (GPT). The most popular applications are OpenAI’s DALL-E text-to-image tool and ChatGPT . According to a 2024 survey by Deloitte, 79% of respondents who are leaders in the AI industry expect generative AI to transform their organizations by 2027. What Is Reactive AI? Reactive AI is a type of narrow AI that uses algorithms to optimize outputs based on a set of inputs. Chess-playing AIs, for example, are reactive systems that optimize the best strategy to win the game. Reactive AI tends to be fairly static, unable to learn or adapt to novel situations. What Are the Concerns Surrounding the Use of AI? Many are concerned with how artificial intelligence may affect human employment . With many industries looking to automate certain jobs with intelligent machinery, there is a concern that employees would be pushed out of the workforce. Self-driving cars may remove the need for taxis and car-share programs, while manufacturers may easily replace human labor with machines, making people’s skills obsolete. How Is AI Used in Healthcare? In healthcare settings, AI is used to assist in diagnostics. AI can identify small anomalies in scans to better triangulate diagnoses from a patient’s symptoms and vitals. AI can classify patients, maintain and track medical records, and deal with health insurance claims. The Bottom Line Artificial intelligence (AI) is an evolving technology that tries to simulate human intelligence using machines. AI encompasses various subfields, including machine learning (ML) and deep learning, which allow systems to learn and adapt in novel ways from training data. It has vast applications across multiple industries , such as healthcare, finance, and transportation. While AI offers significant advancements , it also raises ethical, privacy, and employment concerns. Article Sources Investopedia requires writers to use primary sources to support their work. These include white papers, government data, original reporting, and interviews with industry experts. We also reference original research from other reputable publishers where appropriate. You can learn more about the standards we follow in producing accurate, unbiased content in our editorial policy. SAS. “ Artificial Intelligence .” OpenAI. “ DALL·E: Creating Images From Text .” OpenAI. “ Introducing ChatGPT .” Deloitte. “ The State of Generative AI in the Enterprise: Q1 Report, January 2024 .” Page 7. Compare Accounts Advertiser Disclosure × The offers that appear in this table are from partnerships from which Investopedia receives compensation. This compensation may impact how and where listings appear. Investopedia does not include all offers available in the marketplace. Read more Investing Alternative Investments Partner Links Take the Next Step to Invest Advertiser Disclosure × The offers that appear in this table are from partnerships from which Investopedia receives compensation. This compensation may impact how and where listings appear. Investopedia does not include all offers available in the marketplace. Related Articles Best Real Estate Crowdfunding Sites for July 2025 A Beginner's Guide to Real Estate Investing Best Online Gold Dealers for July 2025 What Is Property? Definition, Types, Valuation, and Taxation RealtyMogul Review What Is the Structure of a Private Equity Fund? The Most Important Factors for Real Estate Investing Real Estate: Definition, Types, How to Invest in It How to Find Your Return on Investment (ROI) in Real Estate Silver Certificate Dollar Bills: What They're Worth Today What Is a Sheriff's Sale? When It's Used, Process, and Proceeds What Is ChatGPT, and How Does It Make Money? 5 Types of REITs and How to Invest in Them An Introduction to Structured Products What Raw Materials Do Auto Manufacturers Use? Venture Capitalists: Who Are They and What Do They Do? About Us Terms of Service Dictionary Editorial Policy Advertise News Privacy Policy Contact Us Careers # A B C D E F G H I J K L M N O P Q R S T U V W X Y Z Investopedia is part of the Dotdash Meredith publishing family.
====================================================================================================
What is artificial intelligence? | Britannica Search Britannica Click here to search Search Britannica Click here to search SUBSCRIBE SUBSCRIBE Login https://premium.britannica.com/premium-membership/?utm_source=premium&utm_medium=nav-login-box&utm_campaign=evergreen SUBSCRIBE Home History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Games & Quizzes Videos On This Day One Good Fact Dictionary New Articles History & Society Lifestyles & Social Issues Philosophy & Religion Politics, Law & Government World History Science & Tech Health & Medicine Science Technology Biographies Browse Biographies Animals & Nature Birds, Reptiles & Other Vertebrates Bugs, Mollusks & Other Invertebrates Environment Fossils & Geologic Time Mammals Plants Geography & Travel Geography & Travel Arts & Culture Entertainment & Pop Culture Literature Sports & Recreation Visual Arts Image Galleries Podcasts Summaries Top Questions Britannica Kids Ask the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Videos Home Technology Computers What is artificial intelligence? More Actions Cite verified Cite While every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions. Select Citation Style MLA APA Chicago Manual of Style Copy Citation Share Share Share to social media Facebook X URL https://www.britannica.com/question/What-is-artificial-intelligence Feedback Corrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login). Feedback Type Select a type (Required) Factual Correction Spelling/Grammar Correction Link Correction Additional Information Other Your Feedback Submit Feedback Thank you for your feedback Our editors will review what you’ve submitted and determine whether to revise the article. External Websites Written and fact-checked by The Editors of Encyclopaedia Britannica Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree. They write new content and verify and edit content received from contributors. The Editors of Encyclopaedia Britannica Artificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the intellectual processes characteristic of humans , such as the ability to reason. Although there are as yet no AIs that match full human flexibility over wider domains or in tasks requiring much everyday knowledge, some AIs perform specific tasks as well as humans. Learn more. History at your fingertips – Sign up here to see what happened On This Day, every day in your inbox! Enter your email Subscribe By signing up for this email, you are agreeing to news, offers, and information from Encyclopaedia Britannica. Click here to view our Privacy Notice . Easy unsubscribe links are provided in every email. Thank you for subscribing! Be on the lookout for your Britannica newsletter to get trusted stories delivered right to your inbox. Stay Connected Facebook X YouTube Instagram About Us & Legal Info Contact Us Privacy Policy Terms of Use Equal Opportunity ©2025 Encyclopædia Britannica, Inc.
====================================================================================================
Artificial intelligence - Machine Learning, Robotics, Algorithms | Britannica Search Britannica Click here to search Search Britannica Click here to search SUBSCRIBE SUBSCRIBE Login https://premium.britannica.com/premium-membership/?utm_source=premium&utm_medium=nav-login-box&utm_campaign=evergreen SUBSCRIBE Home History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Games & Quizzes Videos On This Day One Good Fact Dictionary New Articles History & Society Lifestyles & Social Issues Philosophy & Religion Politics, Law & Government World History Science & Tech Health & Medicine Science Technology Biographies Browse Biographies Animals & Nature Birds, Reptiles & Other Vertebrates Bugs, Mollusks & Other Invertebrates Environment Fossils & Geologic Time Mammals Plants Geography & Travel Geography & Travel Arts & Culture Entertainment & Pop Culture Literature Sports & Recreation Visual Arts Image Galleries Podcasts Summaries Top Questions Britannica Kids Ask the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Videos artificial intelligence Table of Contents Introduction & Top Questions What is intelligence? Learning Reasoning Problem solving Perception Language Methods and goals in AI Symbolic vs. connectionist approaches Artificial general intelligence (AGI), applied AI, and cognitive simulation AI technology Machine learning Large language models and natural language processing Autonomous vehicles Virtual assistants Risks Is artificial general intelligence (AGI) possible? Want to learn more? References & Edit History Quick Facts & Related Topics Images & Videos For Students artificial intelligence summary Quizzes Computers and Technology Quiz Related Questions What is artificial intelligence? Technology Computers Is artificial general intelligence (AGI) possible? in artificial intelligence Simplify &nbspThis&nbsp Article Ask the Chatbot Print print Print Please select which sections you would like to print: Table Of Contents Cite verified Cite While every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions. Select Citation Style MLA APA Chicago Manual of Style Copy Citation Share Share Share to social media Facebook X URL https://www.britannica.com/technology/artificial-intelligence Feedback External Websites Feedback Corrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login). Feedback Type Select a type (Required) Factual Correction Spelling/Grammar Correction Link Correction Additional Information Other Your Feedback Submit Feedback Thank you for your feedback Our editors will review what you’ve submitted and determine whether to revise the article. External Websites National Center for Biotechnology Information - PubMed Central - The rise of artificial intelligence in healthcare applications Lifewire - What is artificial intelligence? Frontiers - Frontiers in Robotics and AI - A Review of Future and Ethical Perspectives of Robotics and AI Academia - Locomotive Optimization Using Artificial Intelligence Approach Computer History Museum - AI and Robotics Internet Encyclopedia of Philosophy - Artificial Intelligence IOPscience - Journal of Physics: Conference Series - Application of Artificial Intelligence in Integrated Circuits (PDF) Harvard University - Science in the News - The History of Artificial Intelligence Academia - History of Artificial Intelligence National Center for Biotechnology Information - PubMed Central - What is new in computer vision and artificial intelligence in medical image analysis applications Journal of Emerging Technologies and Innovative Research - A Study on the Robotics and Artificial Intelligence Britannica Websites Articles from Britannica Encyclopedias for elementary and high school students. artificial intelligence - Children's Encyclopedia (Ages 8-11) artificial intelligence (AI) - Student Encyclopedia (Ages 11 and up) Simplify &nbspThis&nbsp Article Ask the Chatbot a Question Also known as: AI Written by B.J. Copeland Professor of Philosophy and Director of the Turing Archive for the History of Computing, University of Canterbury, Christchurch, New Zealand. Author of Artificial Intelligence and others. B.J. Copeland Fact-checked by The Editors of Encyclopaedia Britannica Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree. They write new content and verify and edit content received from contributors. The Editors of Encyclopaedia Britannica Last Updated: Jun 25, 2025 • Article History Table of Contents Table of Contents Simplify &nbspThis&nbsp Article Ask the Chatbot a Question Key People: Geoffrey Hinton John M. Jumper Marvin Minsky Edward Albert Feigenbaum Allen Newell (Show more) Related Topics: history of artificial intelligence (AI) Logic Theorist General Problem Solver frame generative AI (Show more) On the Web: Frontiers - Frontiers in Robotics and AI - A Review of Future and Ethical Perspectives of Robotics and AI (June 04, 2025) (Show more) See all related content News • How ChatGPT and other AI tools are changing the teaching profession • June 25, 2025, 9:22 PM ET (AP) ... (Show more) Judge dismisses authors' copyright lawsuit against Meta over AI training • June 25, 2025, 8:55 PM ET (AP) Bipartisan bill seeks to ban Chinese AI from federal agencies, as U.S. vows to win the AI race • June 25, 2025, 12:47 PM ET (AP) Anthropic wins ruling on AI training in copyright lawsuit but must face trial on pirated books • June 24, 2025, 4:40 PM ET (AP) Music streaming service Deezer adds AI song tags in fight against fraud • June 20, 2025, 9:39 AM ET (AP) Show less What do you think? Is Artificial Intelligence Good for Society? Explore the ProCon debate Artificial general intelligence (AGI), or strong AI—that is, artificial intelligence that aims to duplicate human intellectual abilities—remains controversial and out of reach. The difficulty of scaling up AI’s modest achievements cannot be overstated. However, this lack of progress may simply be testimony to the difficulty of AGI, not to its impossibility. Let us turn to the very idea of AGI. Can a computer possibly think? The theoretical linguist Noam Chomsky suggests that debating this question is pointless, for it is an essentially arbitrary decision whether to extend common usage of the word think to include machines. There is, Chomsky claims, no factual question as to whether any such decision is right or wrong—just as there is no question as to whether our decision to say that airplanes fly is right, or our decision not to say that ships swim is wrong. However, this seems to oversimplify matters. The important question is, Could it ever be appropriate to say that computers think and, if so, what conditions must a computer satisfy in order to be so described? Some authors offer the Turing test as a definition of intelligence. However, the mathematician and logician Alan Turing himself pointed out that a computer that ought to be described as intelligent might nevertheless fail his test if it were incapable of successfully imitating a human being . For example, ChatGPT often invokes its status as a large language model and thus would be unlikely to pass the Turing test. If an intelligent entity can fail the test, then the test cannot function as a definition of intelligence. It is even questionable whether passing the test would actually show that a computer is intelligent, as the information theorist Claude Shannon and the AI pioneer John McCarthy pointed out in 1956. Shannon and McCarthy argued that, in principle, it is possible to design a machine containing a complete set of canned responses to all the questions that an interrogator could possibly ask during the fixed time span of the test. Like PARRY, this machine would produce answers to the interviewer’s questions by looking up appropriate responses in a giant table. This objection seems to show that, in principle, a system with no intelligence at all could pass the Turing test. In fact, AI has no real definition of intelligence to offer, not even in the subhuman case. Rats are intelligent, but what exactly must an artificial intelligence achieve before researchers can claim that it has reached rats’ level of success? In the absence of a reasonably precise criterion for when an artificial system counts as intelligent, there is no objective way of telling whether an AI research program has succeeded or failed. One result of AI’s failure to produce a satisfactory criterion of intelligence is that, whenever researchers achieve one of AI’s goals—for example, a program that can hold a conversation like GPT or beat the world chess champion like Deep Blue—critics are able to say, “ That’s not intelligence!” Marvin Minsky ’s response to the problem of defining intelligence is to maintain—like Turing before him—that intelligence is simply our name for any problem-solving mental process that we do not yet understand. Minsky likens intelligence to the concept of “unexplored regions of Africa”: it disappears as soon as we discover it. Want to learn more? • Find out why AI messes up hands and fingers. More From Britannica chess: Chess and artificial intelligence • How much do you know about computers and technology? • What are the major events in 21st-century technology? B.J. Copeland
====================================================================================================
What Is Artificial Intelligence (AI)? | Google Cloud Page Contents Topics What is Artificial Intelligence? What is Artificial Intelligence (AI)? Artificial intelligence (AI) is a set of technologies that enable computers to perform a variety of advanced functions, including the ability to see , understand and translate spoken and written language , analyze data , make recommendations, and more. AI is the backbone of innovation in modern computing, unlocking value for individuals and businesses. For example, optical character recognition (OCR ) uses AI to extract text and data from images and documents, turns unstructured content into business-ready structured data, and unlocks valuable insights. Ready to get started? New customers get $300 in free credits to spend on Google Cloud. Get started for free Stay informed 22:54 Introduction to generative AI Artificial intelligence defined Artificial intelligence is a field of science concerned with building computers and machines that can reason, learn, and act in such a way that would normally require human intelligence or that involves data whose scale exceeds what humans can analyze. AI is a broad field that encompasses many different disciplines, including computer science, data analytics and statistics, hardware and software engineering, linguistics, neuroscience, and even philosophy and psychology. On an operational level for business use, AI is a set of technologies that are based primarily on machine learning and deep learning, used for data analytics, predictions and forecasting, object categorization, natural language processing, recommendations, intelligent data retrieval, and more. How does AI work? While the specifics vary across different AI techniques, the core principle revolves around data. AI systems learn and improve through exposure to vast amounts of data, identifying patterns and relationships that humans may miss. This learning process often involves algorithms, which are sets of rules or instructions that guide the AI's analysis and decision-making. In machine learning, a popular subset of AI, algorithms are trained on labeled or unlabeled data to make predictions or categorize information. Deep learning , a further specialization, utilizes artificial neural networks with multiple layers to process information, mimicking the structure and function of the human brain. Through continuous learning and adaptation, AI systems become increasingly adept at performing specific tasks, from recognizing images to translating languages and beyond. Want to learn how to get started with AI? Take the free beginner's introduction to generative AI . Types of artificial intelligence Artificial intelligence can be organized in several ways, depending on stages of development or actions being performed. For instance, four stages of AI development are commonly recognized. Reactive machines: Limited AI that only reacts to different kinds of stimuli based on preprogrammed rules. Does not use memory and thus cannot learn with new data. IBM’s Deep Blue that beat chess champion Garry Kasparov in 1997 was an example of a reactive machine. Limited memory: Most modern AI is considered to be limited memory. It can use memory to improve over time by being trained with new data, typically through an artificial neural network or other training model. Deep learning, a subset of machine learning, is considered limited memory artificial intelligence. Theory of mind: Theory of mind AI does not currently exist, but research is ongoing into its possibilities. It describes AI that can emulate the human mind and has decision-making capabilities equal to that of a human, including recognizing and remembering emotions and reacting in social situations as a human would. Self aware: A step above theory of mind AI, self-aware AI describes a mythical machine that is aware of its own existence and has the intellectual and emotional capabilities of a human. Like theory of mind AI, self-aware AI does not currently exist. A more useful way of broadly categorizing types of artificial intelligence is by what the machine can do. All of what we currently call artificial intelligence is considered artificial “narrow” intelligence, in that it can perform only narrow sets of actions based on its programming and training. For instance, an AI algorithm that is used for object classification won’t be able to perform natural language processing. Google Search is a form of narrow AI, as is predictive analytics, or virtual assistants. Artificial general intelligence (AGI) would be the ability for a machine to “sense, think, and act” just like a human. AGI does not currently exist. The next level would be artificial superintelligence (ASI), in which the machine would be able to function in all ways superior to a human. Artificial intelligence training models When businesses talk about AI, they often talk about “training data.” But what does that mean? Remember that limited-memory artificial intelligence is AI that improves over time by being trained with new data. Machine learning is a subset of artificial intelligence that uses algorithms to train data to obtain results. In broad strokes, three kinds of learnings models are often used in machine learning: Supervised learning is a machine learning model that maps a specific input to an output using labeled training data (structured data). In simple terms, to train the algorithm to recognize pictures of cats, feed it pictures labeled as cats. Unsupervised learning is a machine learning model that learns patterns based on unlabeled data (unstructured data). Unlike supervised learning, the end result is not known ahead of time. Rather, the algorithm learns from the data, categorizing it into groups based on attributes. For instance, unsupervised learning is good at pattern matching and descriptive modeling. In addition to supervised and unsupervised learning, a mixed approach called semi-supervised learning is often employed, where only some of the data is labeled. In semi-supervised learning, an end result is known, but the algorithm must figure out how to organize and structure the data to achieve the desired results. Reinforcement learning is a machine learning model that can be broadly described as “learn by doing.” An “agent” learns to perform a defined task by trial and error (a feedback loop) until its performance is within a desirable range. The agent receives positive reinforcement when it performs the task well and negative reinforcement when it performs poorly. An example of reinforcement learning would be teaching a robotic hand to pick up a ball. Common types of artificial neural networks A common type of training model in AI is an artificial neural network, a model loosely based on the human brain. A neural network is a system of artificial neurons—sometimes called perceptrons—that are computational nodes used to classify and analyze data. The data is fed into the first layer of a neural network, with each perceptron making a decision, then passing that information onto multiple nodes in the next layer. Training models with more than three layers are referred to as “deep neural networks” or “deep learning.” Some modern neural networks have hundreds or thousands of layers. The output of the final perceptrons accomplish the task set to the neural network, such as classify an object or find patterns in data. Some of the most common types of artificial neural networks you may encounter include: Feedforward neural networks (FF) are one of the oldest forms of neural networks, with data flowing one way through layers of artificial neurons until the output is achieved. In modern days, most feedforward neural networks are considered “deep feedforward” with several layers (and more than one “hidden” layer). Feedforward neural networks are typically paired with an error-correction algorithm called “backpropagation” that, in simple terms, starts with the result of the neural network and works back through to the beginning, finding errors to improve the accuracy of the neural network. Many simple but powerful neural networks are deep feedforward. Recurrent neural networks (RNN) differ from feedforward neural networks in that they typically use time series data or data that involves sequences. Unlike feedforward neural networks, which use weights in each node of the network, recurrent neural networks have “memory” of what happened in the previous layer as contingent to the output of the current layer. For instance, when performing natural language processing, RNNs can “keep in mind” other words used in a sentence. RNNs are often used for speech recognition, translation, and to caption images. Long/short term memory (LSTM) is an advanced form of RNN that can use memory to “remember” what happened in previous layers. The difference between RNNs and LSTM is that LSTM can remember what happened several layers ago, through the use of “memory cells.” LSTM is often used in speech recognition and making predictions. Convolutional neural networks (CNN) include some of the most common neural networks in modern artificial intelligence. Most often used in image recognition, CNNs use several distinct layers (a convolutional layer, then a pooling layer) that filter different parts of an image before putting it back together (in the fully connected layer). The earlier convolutional layers may look for simple features of an image, such as colors and edges, before looking for more complex features in additional layers. Generative adversarial networks (GAN) involve two neural networks competing against each other in a game that ultimately improves the accuracy of the output. One network (the generator) creates examples that the other network (the discriminator) attempts to prove true or false. GANs have been used to create realistic images and even make art. Benefits of AI Automation AI can automate workflows and processes or work independently and autonomously from a human team. For example, AI can help automate aspects of cybersecurity by continuously monitoring and analyzing network traffic. Similarly, a smart factory may have dozens of different kinds of AI in use, such as robots using computer vision to navigate the factory floor or to inspect products for defects, create digital twins, or use real-time analytics to measure efficiency and output. Reduce human error AI can eliminate manual errors in data processing, analytics, assembly in manufacturing, and other tasks through automation and algorithms that follow the same processes every single time. Eliminate repetitive tasks AI can be used to perform repetitive tasks, freeing human capital to work on higher impact problems. AI can be used to automate processes, like verifying documents, transcribing phone calls, or answering simple customer questions like “what time do you close?” Robots are often used to perform “dull, dirty, or dangerous” tasks in the place of a human. Fast and accurate AI can process more information more quickly than a human, finding patterns and discovering relationships in data that a human may miss. Infinite availability AI is not limited by time of day, the need for breaks, or other human encumbrances. When running in the cloud, AI and machine learning can be “always on,” continuously working on its assigned tasks. Accelerated research and development The ability to analyze vast amounts of data quickly can lead to accelerated breakthroughs in research and development. For instance, AI has been used in predictive modeling of potential new pharmaceutical treatments, or to quantify the human genome. Solve your business challenges with Google Cloud New customers get $300 in free credits to spend on Google Cloud. Get started Sign up for Google Cloud newsletters with product updates, event information, special offers, and more. Stay informed Applications and use cases for artificial intelligence Speech recognition Automatically convert spoken speech into written text. Image recognition Identify and categorize various aspects of an image. Translation Translate written or spoken words from one language into another. Predictive modeling Mine data to forecast specific outcomes with high degrees of granularity. Data analytics Find patterns and relationships in data for business intelligence. Cybersecurity Autonomously scan networks for cyber attacks and threats. Related products and services Google offers a number of sophisticated artificial intelligence products, solutions, and applications on a trusted cloud platform that enables businesses to easily build and implement AI algorithms and models. By using products like Vertex AI , CCAI , DocAI , or AI APIs , organizations can make sense of all the data they’re producing, collecting, or otherwise analyzing, no matter what format it’s in, to make actionable business decisions. Explore all AI products and solutions Innovative AI and machine learning products, solutions, and services powered by Google’s research and technology. Vertex AI Build, deploy, and scale ML models faster, with pretrained and custom tooling within a unified artificial intelligence platform. Vertex AI Studio Tool for rapidly prototyping and testing generative AI models. Document AI Automate data capture at scale to reduce document processing costs. AlloyDB AI Build a wide range of generative AI applications using familiar PostgreSQL and run models in Vertex AI. Solution Contact Center AI Deliver exceptional customer service and increase operational efficiency using artificial intelligence. Enable your virtual agent to converse naturally with customers and expertly assist human agents on complex cases. Solution Dialogflow CX Create conversational experiences across devices and platforms. Take the next step Start building on Google Cloud with $300 in free credits and 20+ always free products. Get started for free Need help getting started? Contact sales Work with a trusted partner Find a partner Want to hear from us? Join the monthly newsletter menu Overview Solutions Products Pricing Resources Docs Support Contact Us  search_spark send_spark Docs Support Console Sign in Start free Start free Contact Us close Accelerate your digital transformation Whether your business is early in its journey or well on its way to digital transformation, Google Cloud can help solve your toughest challenges. Learn more Key benefits Why Google Cloud Top reasons businesses choose us. AI and ML Get enterprise-ready AI. Multicloud Run your apps wherever you need them. Global infrastructure Build on the same infrastructure as Google. Data Cloud Make smarter decisions with unified data. Modern Infrastructure Cloud Next generation of cloud infrastructure. Security Protect your users, data, and apps. Productivity and collaboration Connect your teams with AI-powered apps. Reports and insights Executive insights Curated C-suite perspectives. Analyst reports Read what industry analysts say about us. Whitepapers Browse and download popular whitepapers. Customer stories Explore case studies and videos. close Industry Solutions Application Modernization Artificial Intelligence APIs and Applications Data Analytics Databases Infrastructure Modernization Productivity and Collaboration Security Startups and SMB See all solutions Industry Solutions Reduce cost, increase operational agility, and capture new market opportunities. Retail Analytics and collaboration tools for the retail value chain. Consumer Packaged Goods Solutions for CPG digital transformation and brand growth. Financial Services Computing, data management, and analytics tools for financial services. Healthcare and Life Sciences Advance research at scale and empower healthcare innovation. Media and Entertainment Solutions for content production and distribution operations. Telecommunications Hybrid and multi-cloud services to deploy and monetize 5G. Games AI-driven solutions to build and scale games faster. Manufacturing Migration and AI tools to optimize the manufacturing value chain. Supply Chain and Logistics Enable sustainable, efficient, and resilient data-driven operations across supply chain and logistics operations. Government Data storage, AI, and analytics solutions for government agencies. Education Teaching tools to provide more engaging learning experiences. Not seeing what you're looking for? See all industry solutions Application Modernization Assess, plan, implement, and measure software practices and capabilities to modernize and simplify your organization’s business application portfolios. CAMP Program that uses DORA to improve your software delivery capabilities. Modernize Traditional Applications Analyze, categorize, and get started with cloud migration on traditional workloads. Migrate from PaaS: Cloud Foundry, Openshift Tools for moving your existing containers into Google's managed container services. Migrate from Mainframe Automated tools and prescriptive guidance for moving your mainframe apps to the cloud. Modernize Software Delivery Software supply chain best practices - innerloop productivity, CI/CD and S3C. DevOps Best Practices Processes and resources for implementing DevOps in your org. SRE Principles Tools and resources for adopting SRE in your org. Day 2 Operations for GKE Tools and guidance for effective GKE management and monitoring. FinOps and Optimization of GKE Best practices for running reliable, performant, and cost effective applications on GKE. Run Applications at the Edge Guidance for localized and low latency apps on Google’s hardware agnostic edge solution. Architect for Multicloud Manage workloads across multiple clouds with a consistent platform. Go Serverless Fully managed environment for developing, deploying and scaling apps. Artificial Intelligence Add intelligence and efficiency to your business with AI and machine learning. Customer Engagement Suite with Google AI End-to-end application that combines our most advanced conversational AI. Document AI Document processing and data capture automated at scale. Vertex AI Search for retail Google-quality search and product recommendations for retailers. Gemini for Google Cloud AI assistants for application development, coding, and more. Generative AI on Google Cloud Transform content creation and discovery, research, customer service, and developer efficiency with the power of generative AI. APIs and Applications Speed up the pace of innovation without coding, using APIs, apps, and automation. New Business Channels Using APIs Attract and empower an ecosystem of developers and partners. Unlocking Legacy Applications Using APIs Cloud services for extending and modernizing legacy apps. Open Banking APIx Simplify and accelerate secure delivery of open banking compliant APIs. Data Analytics Generate instant insights from data at any scale with a serverless, fully managed analytics platform that significantly simplifies analytics. Data Migration Migrate and modernize with an AI-ready data platform. Data Lake Modernization Services for building and modernizing your data lake. Stream Analytics Insights from ingesting, processing, and analyzing event streams. Marketing Analytics Solutions for collecting, analyzing, and activating customer data. Datasets Data from Google, public, and commercial providers to enrich your analytics and AI initiatives. Business Intelligence Solutions for modernizing your BI stack and creating rich data experiences. AI for Data Analytics Write SQL, build predictive models, and visualize data with AI for data analytics. Databases Migrate and manage enterprise data with security, reliability, high availability, and fully managed data services. Database Migration Guides and tools to simplify your database migration life cycle. Database Modernization Upgrades to modernize your operational database infrastructure. Databases for Games Build global, live games with Google Cloud databases. Google Cloud Databases Database services to migrate, manage, and modernize data. Migrate Oracle workloads to Google Cloud Rehost, replatform, rewrite your Oracle workloads. Open Source Databases Fully managed open source databases with enterprise-grade support. SQL Server on Google Cloud Options for running SQL Server virtual machines on Google Cloud. Gemini for Databases Supercharge database development and management with AI. Infrastructure Modernization Migrate quickly with solutions for SAP, VMware, Windows, Oracle, and other workloads. Application Migration Discovery and analysis tools for moving to the cloud. SAP on Google Cloud Certifications for running SAP applications and SAP HANA. High Performance Computing Compute, storage, and networking options to support any workload. Windows on Google Cloud Tools and partners for running Windows workloads. Data Center Migration Migration solutions for VMs, apps, databases, and more. Active Assist Automatic cloud resource optimization and increased security. Virtual Desktops Remote work solutions for desktops and applications (VDI & DaaS). Rapid Migration and Modernization Program End-to-end migration program to simplify your path to the cloud. Backup and Disaster Recovery Ensure your business continuity needs are met. Red Hat on Google Cloud Google and Red Hat provide an enterprise-grade platform for traditional on-prem and custom applications. Cross-Cloud Network Simplify hybrid and multicloud networking, and secure your workloads, data, and users. Observability Monitor, troubleshoot, and improve app performance with end-to-end visibility. Productivity and Collaboration Change the way teams work with solutions designed for humans and built for impact. Google Workspace Collaboration and productivity tools for enterprises. Google Workspace Essentials Secure video meetings and modern collaboration for teams. Cloud Identity Unified platform for IT admins to manage user devices and apps. Chrome Enterprise ChromeOS, Chrome Browser, and Chrome devices built for business. Security Detect, investigate, and respond to online threats to help protect your business. Security Analytics and Operations Solution for analyzing petabytes of security telemetry. Web App and API Protection Threat and fraud protection for your web applications and APIs. Security and Resilience Framework Solutions for each phase of the security and resilience life cycle. Risk and compliance as code (RCaC) Solution to modernize your governance, risk, and compliance function with automation. Software Supply Chain Security Solution for improving end-to-end software supply chain security. Security Foundation Recommended products to help achieve a strong security posture. Google Cloud Cybershield™ Strengthen nationwide cyber defense. Startups and SMB Accelerate startup and SMB growth with tailored solutions and programs. Startup Program Get financial, business, and technical support to take your startup to the next level. Small and Medium Business Explore solutions for web hosting, app development, AI, and analytics. Software as a Service Build better SaaS products, scale efficiently, and grow your business. close Featured Products AI and Machine Learning Business Intelligence Compute Containers Data Analytics Databases Developer Tools Distributed Cloud Hybrid and Multicloud Industry Specific Integration Services Management Tools Maps and Geospatial Media Services Migration Mixed Reality Networking Operations Productivity and Collaboration Security and Identity Serverless Storage Web3 See all products (100+) Featured Products Compute Engine Virtual machines running in Google’s data center. Cloud Storage Object storage that’s secure, durable, and scalable. BigQuery Data warehouse for business agility and insights. Cloud Run Fully managed environment for running containerized apps. Google Kubernetes Engine Managed environment for running containerized apps. Vertex AI Unified platform for ML models and generative AI. Looker Platform for BI, data applications, and embedded analytics. Apigee API Management Manage the full life cycle of APIs anywhere with visibility and control. Cloud SQL Relational database services for MySQL, PostgreSQL and SQL Server. Gemini Google Cloud products powered by Gemini. Cloud CDN Content delivery network for delivering web and video. Not seeing what you're looking for? See all products (100+) AI and Machine Learning Vertex AI Platform Unified platform for ML models and generative AI. Vertex AI Studio Build, tune, and deploy foundation models on Vertex AI. Vertex AI Agent Builder Build and deploy gen AI experiences. Conversational Agents Build conversational AI with both deterministic and gen AI functionality. Vertex AI Search Build Google-quality search for your enterprise apps and experiences. Speech-to-Text Speech recognition and transcription across 125 languages. Text-to-Speech Speech synthesis in 220+ voices and 40+ languages. Translation AI Language detection, translation, and glossary support. Document AI Document processing and data capture automated at scale. Vision AI Custom and pre-trained models to detect emotion, text, and more. Contact Center as a Service Omnichannel contact center solution that is native to the cloud. Not seeing what you're looking for? See all AI and machine learning products Business Intelligence Looker Platform for BI, data applications, and embedded analytics. Looker Studio Interactive data suite for dashboarding, reporting, and analytics. Compute Compute Engine Virtual machines running in Google’s data center. App Engine Serverless application platform for apps and back ends. Cloud GPUs GPUs for ML, scientific computing, and 3D visualization. Migrate to Virtual Machines Server and virtual machine migration to Compute Engine. Spot VMs Compute instances for batch jobs and fault-tolerant workloads. Batch Fully managed service for scheduling batch jobs. Sole-Tenant Nodes Dedicated hardware for compliance, licensing, and management. Bare Metal Infrastructure to run specialized workloads on Google Cloud. Recommender Usage recommendations for Google Cloud products and services. VMware Engine Fully managed, native VMware Cloud Foundation software stack. Cloud Run Fully managed environment for running containerized apps. Not seeing what you're looking for? See all compute products Containers Google Kubernetes Engine Managed environment for running containerized apps. Cloud Run Fully managed environment for running containerized apps. Cloud Build Solution for running build steps in a Docker container. Artifact Registry Package manager for build artifacts and dependencies. Cloud Code IDE support to write, run, and debug Kubernetes applications. Cloud Deploy Fully managed continuous delivery to GKE and Cloud Run. Migrate to Containers Components for migrating VMs into system containers on GKE. Deep Learning Containers Containers with data science frameworks, libraries, and tools. Knative Components to create Kubernetes-native cloud-based software. Data Analytics BigQuery Data warehouse for business agility and insights. Looker Platform for BI, data applications, and embedded analytics. Dataflow Streaming analytics for stream and batch processing. Pub/Sub Messaging service for event ingestion and delivery. Dataproc Service for running Apache Spark and Apache Hadoop clusters. Cloud Data Fusion Data integration for building and managing data pipelines. Cloud Composer Workflow orchestration service built on Apache Airflow. BigLake Storage engine to query multi-format and multimodal data. Dataplex Intelligent data fabric for unifying data management across silos. Dataform Build, version control, and deploy SQL workflows in BigQuery. Analytics Hub Service for securely and efficiently exchanging data analytics assets. Not seeing what you're looking for? See all data analytics products Databases AlloyDB for PostgreSQL Fully managed, PostgreSQL-compatible database for enterprise workloads. Cloud SQL Fully managed database for MySQL, PostgreSQL, and SQL Server. Firestore Cloud-native document database for building rich mobile, web, and IoT apps. Spanner Cloud-native relational database with unlimited scale and 99.999% availability. Bigtable Cloud-native wide-column database for large-scale, low-latency workloads. Datastream Serverless change data capture and replication service. Database Migration Service Serverless, minimal downtime migrations to Cloud SQL. Bare Metal Solution Fully managed infrastructure for your Oracle workloads. Memorystore Fully managed Redis and Memcached for sub-millisecond data access. Developer Tools Artifact Registry Universal package manager for build artifacts and dependencies. Cloud Code IDE support to write, run, and debug Kubernetes applications. Cloud Build Continuous integration and continuous delivery platform. Cloud Deploy Fully managed continuous delivery to GKE and Cloud Run. Cloud Deployment Manager Service for creating and managing Google Cloud resources. Cloud SDK Command-line tools and libraries for Google Cloud. Cloud Scheduler Cron job scheduler for task automation and management. Cloud Source Repositories Private Git repository to store, manage, and track code. Infrastructure Manager Automate infrastructure management with Terraform. Cloud Workstations Managed and secure development environments in the cloud. Gemini Code Assist AI-powered assistant available across Google Cloud and your IDE. Not seeing what you're looking for? See all developer tools Distributed Cloud Google Distributed Cloud Connected Distributed cloud services for edge workloads. Google Distributed Cloud Air-gapped Distributed cloud for air-gapped workloads. Hybrid and Multicloud Google Kubernetes Engine Managed environment for running containerized apps. Apigee API Management API management, development, and security platform. Migrate to Containers Tool to move workloads and existing applications to GKE. Cloud Build Service for executing builds on Google Cloud infrastructure. Observability Monitoring, logging, and application performance suite. Cloud Service Mesh Fully managed service mesh based on Envoy and Istio. Google Distributed Cloud Fully managed solutions for the edge and data centers. Industry Specific Anti Money Laundering AI Detect suspicious, potential money laundering activity with AI. Cloud Healthcare API Solution for bridging existing care systems and apps on Google Cloud. Device Connect for Fitbit Gain a 360-degree patient view with connected Fitbit data on Google Cloud. Telecom Network Automation Ready to use cloud-native automation for telecom networks. Telecom Data Fabric Telecom data management and analytics with an automated approach. Telecom Subscriber Insights Ingests data to improve subscriber acquisition and retention. Spectrum Access System (SAS) Controls fundamental access to the Citizens Broadband Radio Service (CBRS). Integration Services Application Integration Connect to 3rd party apps and enable data consistency without code. Workflows Workflow orchestration for serverless products and API services. Apigee API Management Manage the full life cycle of APIs anywhere with visibility and control. Cloud Tasks Task management service for asynchronous task execution. Cloud Scheduler Cron job scheduler for task automation and management. Dataproc Service for running Apache Spark and Apache Hadoop clusters. Cloud Data Fusion Data integration for building and managing data pipelines. Cloud Composer Workflow orchestration service built on Apache Airflow. Pub/Sub Messaging service for event ingestion and delivery. Eventarc Build an event-driven architecture that can connect any service. Management Tools Cloud Shell Interactive shell environment with a built-in command line. Cloud console Web-based interface for managing and monitoring cloud apps. Cloud Endpoints Deployment and development management for APIs on Google Cloud. Cloud IAM Permissions management system for Google Cloud resources. Cloud APIs Programmatic interfaces for Google Cloud services. Service Catalog Service catalog for admins managing internal enterprise solutions. Cost Management Tools for monitoring, controlling, and optimizing your costs. Observability Monitoring, logging, and application performance suite. Carbon Footprint Dashboard to view and export Google Cloud carbon emissions reports. Config Connector Kubernetes add-on for managing Google Cloud resources. Active Assist Tools for easily managing performance, security, and cost. Not seeing what you're looking for? See all management tools Maps and Geospatial Earth Engine Geospatial platform for Earth observation data and analysis. Google Maps Platform Create immersive location experiences and improve business operations. Media Services Cloud CDN Content delivery network for serving web and video content. Live Stream API Service to convert live video and package for streaming. OpenCue Open source render manager for visual effects and animation. Transcoder API Convert video files and package them for optimized delivery. Video Stitcher API Service for dynamic or server side ad insertion. Migration Migration Center Unified platform for migrating and modernizing with Google Cloud. Application Migration App migration to the cloud for low-cost refresh cycles. Migrate to Virtual Machines Components for migrating VMs and physical servers to Compute Engine. Cloud Foundation Toolkit Reference templates for Deployment Manager and Terraform. Database Migration Service Serverless, minimal downtime migrations to Cloud SQL. Migrate to Containers Components for migrating VMs into system containers on GKE. BigQuery Data Transfer Service Data import service for scheduling and moving data into BigQuery. Rapid Migration and Modernization Program End-to-end migration program to simplify your path to the cloud. Transfer Appliance Storage server for moving large volumes of data to Google Cloud. Storage Transfer Service Data transfers from online and on-premises sources to Cloud Storage. VMware Engine Migrate and run your VMware workloads natively on Google Cloud. Mixed Reality Immersive Stream for XR Hosts, renders, and streams 3D and XR experiences. Networking Cloud Armor Security policies and defense against web and DDoS attacks. Cloud CDN and Media CDN Content delivery network for serving web and video content. Cloud DNS Domain name system for reliable and low-latency name lookups. Cloud Load Balancing Service for distributing traffic across applications and regions. Cloud NAT NAT service for giving private instances internet access. Cloud Connectivity Connectivity options for VPN, peering, and enterprise needs. Network Connectivity Center Connectivity management to help simplify and scale networks. Network Intelligence Center Network monitoring, verification, and optimization platform. Network Service Tiers Cloud network options based on performance, availability, and cost. Virtual Private Cloud Single VPC for an entire organization, isolated within projects. Private Service Connect Secure connection between your VPC and services. Not seeing what you're looking for? See all networking products Operations Cloud Logging Google Cloud audit, platform, and application logs management. Cloud Monitoring Infrastructure and application health with rich metrics. Error Reporting Application error identification and analysis. Managed Service for Prometheus Fully-managed Prometheus on Google Cloud. Cloud Trace Tracing system collecting latency data from applications. Cloud Profiler CPU and heap profiler for analyzing application performance. Cloud Quotas Manage quotas for all Google Cloud services. Productivity and Collaboration AppSheet No-code development platform to build and extend applications. AppSheet Automation Build automations and applications on a unified platform. Google Workspace Collaboration and productivity tools for individuals and organizations. Google Workspace Essentials Secure video meetings and modern collaboration for teams. Gemini for Workspace Embeds generative AI across Google Workspace apps. Cloud Identity Unified platform for IT admins to manage user devices and apps. Chrome Enterprise ChromeOS, Chrome browser, and Chrome devices built for business. Security and Identity Cloud IAM Permissions management system for Google Cloud resources. Sensitive Data Protection Discover, classify, and protect your valuable data assets. Mandiant Managed Defense Find and eliminate threats with confidence 24x7. Google Threat Intelligence Know who’s targeting you. Security Command Center Platform for defending against threats to your Google Cloud assets. Cloud Key Management Manage encryption keys on Google Cloud. Mandiant Incident Response Minimize the impact of a breach. Chrome Enterprise Premium Get secure enterprise browsing with extensive endpoint visibility. Assured Workloads Compliance and security controls for sensitive workloads. Google Security Operations Detect, investigate, and respond to cyber threats. Mandiant Consulting Get expert guidance before, during, and after an incident. Not seeing what you're looking for? See all security and identity products Serverless Cloud Run Fully managed environment for running containerized apps. Cloud Functions Platform for creating functions that respond to cloud events. App Engine Serverless application platform for apps and back ends. Workflows Workflow orchestration for serverless products and API services. API Gateway Develop, deploy, secure, and manage APIs with a fully managed gateway. Storage Cloud Storage Object storage that’s secure, durable, and scalable. Block Storage High-performance storage for AI, analytics, databases, and enterprise applications. Filestore File storage that is highly scalable and secure. Persistent Disk Block storage for virtual machine instances running on Google Cloud. Cloud Storage for Firebase Object storage for storing and serving user-generated content. Local SSD Block storage that is locally attached for high-performance needs. Storage Transfer Service Data transfers from online and on-premises sources to Cloud Storage. Parallelstore High performance, managed parallel file service. Google Cloud NetApp Volumes File storage service for NFS, SMB, and multi-protocol environments. Backup and DR Service Service for centralized, application-consistent data protection. Web3 Blockchain Node Engine Fully managed node hosting for developing on the blockchain. Blockchain RPC Enterprise-grade RPC for building on the blockchain. close Save money with our transparent approach to pricing Google Cloud's pay-as-you-go pricing offers automatic savings based on monthly usage and discounted rates for prepaid resources. Contact us today to get a quote. Request a quote Pricing overview and tools Google Cloud pricing Pay only for what you use with no lock-in. Pricing calculator Calculate your cloud savings. Google Cloud free tier Explore products with free monthly usage. Cost optimization framework Get best practices to optimize workload costs. Cost management tools Tools to monitor and control your costs. Product-specific Pricing Compute Engine Cloud SQL Google Kubernetes Engine Cloud Storage BigQuery See full price list with 100+ products close Learn & build Google Cloud Free Program $300 in free credits and 20+ free products. Solution Generator Get AI generated solution recommendations. Quickstarts Get tutorials and walkthroughs. Blog Read our latest product news and stories. Learning Hub Grow your career with role-based training. Google Cloud certification Prepare and register for certifications. Cloud computing basics Learn more about cloud computing basics. Cloud Architecture Center Get reference architectures and best practices. Connect Innovators Join Google Cloud's developer program. Developer Center Stay in the know and stay connected. Events and webinars Browse upcoming and on demand events. Google Cloud Community Ask questions, find answers, and connect. Consulting and Partners Google Cloud Consulting Work with our experts on cloud projects. Google Cloud Marketplace Deploy ready-to-go solutions in a few clicks. Google Cloud partners Explore benefits of working with a partner. Become a partner Join the Partner Advantage program. close Overview arrow_forward Solutions arrow_forward Products arrow_forward Pricing arrow_forward Resources arrow_forward Docs Support Console Accelerate your digital transformation Learn more Key benefits Why Google Cloud AI and ML Multicloud Global infrastructure Data Cloud Modern Infrastructure Cloud Security Productivity and collaboration Reports and insights Executive insights Analyst reports Whitepapers Customer stories Industry Solutions Retail Consumer Packaged Goods Financial Services Healthcare and Life Sciences Media and Entertainment Telecommunications Games Manufacturing Supply Chain and Logistics Government Education See all industry solutions See all solutions Application Modernization CAMP Modernize Traditional Applications Migrate from PaaS: Cloud Foundry, Openshift Migrate from Mainframe Modernize Software Delivery DevOps Best Practices SRE Principles Day 2 Operations for GKE FinOps and Optimization of GKE Run Applications at the Edge Architect for Multicloud Go Serverless Artificial Intelligence Customer Engagement Suite with Google AI Document AI Vertex AI Search for retail Gemini for Google Cloud Generative AI on Google Cloud APIs and Applications New Business Channels Using APIs Unlocking Legacy Applications Using APIs Open Banking APIx Data Analytics Data Migration Data Lake Modernization Stream Analytics Marketing Analytics Datasets Business Intelligence AI for Data Analytics Databases Database Migration Database Modernization Databases for Games Google Cloud Databases Migrate Oracle workloads to Google Cloud Open Source Databases SQL Server on Google Cloud Gemini for Databases Infrastructure Modernization Application Migration SAP on Google Cloud High Performance Computing Windows on Google Cloud Data Center Migration Active Assist Virtual Desktops Rapid Migration and Modernization Program Backup and Disaster Recovery Red Hat on Google Cloud Cross-Cloud Network Observability Productivity and Collaboration Google Workspace Google Workspace Essentials Cloud Identity Chrome Enterprise Security Security Analytics and Operations Web App and API Protection Security and Resilience Framework Risk and compliance as code (RCaC) Software Supply Chain Security Security Foundation Google Cloud Cybershield™ Startups and SMB Startup Program Small and Medium Business Software as a Service Featured Products Compute Engine Cloud Storage BigQuery Cloud Run Google Kubernetes Engine Vertex AI Looker Apigee API Management Cloud SQL Gemini Cloud CDN See all products (100+) AI and Machine Learning Vertex AI Platform Vertex AI Studio Vertex AI Agent Builder Conversational Agents Vertex AI Search Speech-to-Text Text-to-Speech Translation AI Document AI Vision AI Contact Center as a Service See all AI and machine learning products Business Intelligence Looker Looker Studio Compute Compute Engine App Engine Cloud GPUs Migrate to Virtual Machines Spot VMs Batch Sole-Tenant Nodes Bare Metal Recommender VMware Engine Cloud Run See all compute products Containers Google Kubernetes Engine Cloud Run Cloud Build Artifact Registry Cloud Code Cloud Deploy Migrate to Containers Deep Learning Containers Knative Data Analytics BigQuery Looker Dataflow Pub/Sub Dataproc Cloud Data Fusion Cloud Composer BigLake Dataplex Dataform Analytics Hub See all data analytics products Databases AlloyDB for PostgreSQL Cloud SQL Firestore Spanner Bigtable Datastream Database Migration Service Bare Metal Solution Memorystore Developer Tools Artifact Registry Cloud Code Cloud Build Cloud Deploy Cloud Deployment Manager Cloud SDK Cloud Scheduler Cloud Source Repositories Infrastructure Manager Cloud Workstations Gemini Code Assist See all developer tools Distributed Cloud Google Distributed Cloud Connected Google Distributed Cloud Air-gapped Hybrid and Multicloud Google Kubernetes Engine Apigee API Management Migrate to Containers Cloud Build Observability Cloud Service Mesh Google Distributed Cloud Industry Specific Anti Money Laundering AI Cloud Healthcare API Device Connect for Fitbit Telecom Network Automation Telecom Data Fabric Telecom Subscriber Insights Spectrum Access System (SAS) Integration Services Application Integration Workflows Apigee API Management Cloud Tasks Cloud Scheduler Dataproc Cloud Data Fusion Cloud Composer Pub/Sub Eventarc Management Tools Cloud Shell Cloud console Cloud Endpoints Cloud IAM Cloud APIs Service Catalog Cost Management Observability Carbon Footprint Config Connector Active Assist See all management tools Maps and Geospatial Earth Engine Google Maps Platform Media Services Cloud CDN Live Stream API OpenCue Transcoder API Video Stitcher API Migration Migration Center Application Migration Migrate to Virtual Machines Cloud Foundation Toolkit Database Migration Service Migrate to Containers BigQuery Data Transfer Service Rapid Migration and Modernization Program Transfer Appliance Storage Transfer Service VMware Engine Mixed Reality Immersive Stream for XR Networking Cloud Armor Cloud CDN and Media CDN Cloud DNS Cloud Load Balancing Cloud NAT Cloud Connectivity Network Connectivity Center Network Intelligence Center Network Service Tiers Virtual Private Cloud Private Service Connect See all networking products Operations Cloud Logging Cloud Monitoring Error Reporting Managed Service for Prometheus Cloud Trace Cloud Profiler Cloud Quotas Productivity and Collaboration AppSheet AppSheet Automation Google Workspace Google Workspace Essentials Gemini for Workspace Cloud Identity Chrome Enterprise Security and Identity Cloud IAM Sensitive Data Protection Mandiant Managed Defense Google Threat Intelligence Security Command Center Cloud Key Management Mandiant Incident Response Chrome Enterprise Premium Assured Workloads Google Security Operations Mandiant Consulting See all security and identity products Serverless Cloud Run Cloud Functions App Engine Workflows API Gateway Storage Cloud Storage Block Storage Filestore Persistent Disk Cloud Storage for Firebase Local SSD Storage Transfer Service Parallelstore Google Cloud NetApp Volumes Backup and DR Service Web3 Blockchain Node Engine Blockchain RPC Save money with our transparent approach to pricing Request a quote Pricing overview and tools Google Cloud pricing Pricing calculator Google Cloud free tier Cost optimization framework Cost management tools Product-specific Pricing Compute Engine Cloud SQL Google Kubernetes Engine Cloud Storage BigQuery See full price list with 100+ products Learn & build Google Cloud Free Program Solution Generator Quickstarts Blog Learning Hub Google Cloud certification Cloud computing basics Cloud Architecture Center Connect Innovators Developer Center Events and webinars Google Cloud Community Consulting and Partners Google Cloud Consulting Google Cloud Marketplace Google Cloud partners Become a partner
====================================================================================================
BOND May 2025 Trends – Artiﬁcial Intelligence Trends – Artificial Intelligence (AI) May 30, 2025 Mary Meeker / Jay Simons / Daegwon Chae / Alexander Krey 2 Context We set out to compile foundational trends related to AI. A starting collection of several disparate datapoints turned into this beast. As soon as we updated one chart, we often had to update another – a data game of whack-a-mole… a pattern that shows no sign of stopping…and will grow more complex as competition among tech incumbents, emerging attackers and sovereigns accelerates. Vint Cerf, one of the ‘Founders of the Internet,’ said in 1999, ‘…they say a year in the Internet business is like a dog year – equivalent to seven years in a regular person's life.’ At the time, the pace of change catalyzed by the internet was unprecedented. Consider now that AI user and usage trending is ramping materially faster…and the machines can outpace us. The pace and scope of change related to the artificial intelligence technology evolution is indeed unprecedented, as supported by the data. This document is filled with user, usage and revenue charts that go up-and-to-the-right… often supported by spending charts that also go up-and-to-the right. Creators / bettors / consumers are taking advantage of global internet rails that are accessible to 5.5B citizens via connected devices; ever-growing digital datasets that have been in the making for over three decades; breakthrough large language models (LLMs) that – in effect – found freedom with the November 2022 launch of OpenAI’s ChatGPT with its extremely easy-to-use / speedy user interface. In addition, relatively new AI company founders have been especially aggressive about innovation / product releases / investments / acquisitions / cash burn and capital raises. At the same time, more traditional tech companies (often with founder involvement) have increasingly directed more of their hefty free cash flows toward AI in efforts to drive growth and fend off attackers. And global competition – especially related to China and USA tech developments – is acute. The outline for our document is on the next page, followed by eleven charts that help illustrate observations that follow. We hope this compilation adds to the discussion of the breadth of change at play – technical / financial / social / physical / geopolitical. No doubt, people (and machines) will improve on the points as we all aim to adapt to this evolving journey as knowledge – and its distribution – get leveled up rapidly in new ways. Special thanks to Grant Watson and Keeyan Sanjasaz and BOND colleagues who helped steer ideas and bring this report to life. And, to the many friends and technology builders who helped, directly or via your work, and are driving technology forward. • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 3 1 2 3 4 5 6 7 8 9-51 52-128 129-152 153-247 248-298 299-307 308-322 # 323-336 Outline Weekly Active Users, MM 4 Charts Paint Thousands of Words… Seem Like Change Happening Faster Than Ever? Yes, It Is AI User + Usage + CapEx Growth = Unprecedented Developers in Leading Chipmaker’s Ecosystem 1 2.1 Source: Leading Chipmaker Details on Page 38 AI User + Usage + CapEx Growth = Unprecedented 2.2 Internet vs. Leading USA-Based LLM: Total Current Users Outside North America Note: LLM data is for monthly active mobile app users. App not available in select countries, including China and Russia, as of 5/25. Source: United Nations / International Telecommunications Union (3/25), Sensor Tower (5/25) 0 Years In Share of Total Current Users, % Details on Page 56 AI User + Usage + CapEx Growth = Unprecedented Leading USA-Based LLM Users 2 Source: Company disclosures Details on Page 55 6MM 2005 2025 Number of Developers, MM 0% 50% 100% Internet LLM 33 Years In 90% @ Year 3 90% @ Year 23 10/22 4/25 800MM Big Six* USA Technology Company CapEx *Apple, NVIDIA, Microsoft, Alphabet, Amazon (AWS only), & Meta Platforms Source: Capital IQ (3/25), Morgan Stanley 2014 2024 CapEx, $B +63% $212B Details on Page 97 5 …Charts Paint Thousands of Words… AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise 5 Leading USA LLMs vs. China LLM Desktop User Share Note: Data is non-deduped. Share is relative, measured across six leading global LLMs. Source: YipitData (5/25) Desktop User Share, % 2/24 2/25 4/25 75% 60% 10% 21% 15% 0% Details on Page 293 USA – LLM #1 China USA – LLM #2 AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 3 Cost of Key Technologies Relative to Launch Year % of Original Price By Year (Indexed to Year 0) Note: Per-token inference costs shown. Source: Richard Hirsh; John McCallum; OpenAI Details on Page 138 0 Years 72 Years Electric Power Computer Memory AI Inference AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise 5.1 China vs. USA vs. Rest of World Industrial Robots Installed Note: Data as of 2023. Source: International Federation of Robotics Industrial Robots Installed Details on Page 289 AI Usage + Cost + Loss Growth = Unprecedented 4 Leading USA-Based AI LLM Revenue vs. Compute Expense Note: Figures are estimates. Source: The Information, public estimates 2022 2024 Revenue (Blue) & Compute Expense (Red) +$3.7B -$5B Details on Page 173 2023 China Rest of World (excl. China & USA) USA 2014 2023 6 …Charts Paint Thousands of Words AI & Physical World Ramps = Fast + Data-Driven 6 A Ride Share vs. Autonomous Taxi Provider, San Francisco Operating Zone Market Share Source: YipitData (4/25) Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before 7 Leading USA-Based LLM App Users by Region Note: Region definitions per World Bank definitions. China not included in East Asia figures. Data for standalone app only. Source: Sensor Tower (5/25) 5/23 4/25 Mobile App Monthly Active Users, MM Details on Page 315 AI & Work Evolution = Real + Rapid 8 USA IT Jobs – AI vs. Non-AI Details on Page 302 +448% -9% 1/18 4/25 Source: University of Maryland’s UMD-LinkUp AIMaps (in collaboration with Outrigger Group) (5/25) Change in USA IT Job Postings, Indexed to 1/18 (AI = Blue, Non-AI = Green) Details on Page 332 27% 19% 8/23 4/25 % of San Francisco Gross Bookings 34% 0% East Asia & Pacific Sub-Saharan Africa South Asia North America Middle East & North Africa Latin America & Caribbean Europe & Central Asia Ride Share Autonomous Taxi Non-AI IT Jobs AI IT Jobs 7 Overview… To say the world is changing at unprecedented rates is an understatement. Rapid and transformative technology innovation / adoption represent key underpinnings of these changes. As does leadership evolution for the global powers. Google’s founding mission (1998) was to ‘organize the world’s information and make it universally accessible and useful.’ Alibaba’s founding mission (1999) was to ‘make it easy to do business anywhere.’ Facebook’s founding mission (2004) was ‘to give people the power to share and make the world more open and connected.’ Fast forward to today with the world’s organized, connected and accessible information being supercharged by artificial intelligence, accelerating computing power, and semi-borderless capital…all driving massive change. Sport provides a good analogy for AI’s constant improvements. As athletes continue to wow us and break records, their talent is increasingly enhanced by better data / inputs / training. The same is true for businesses, where computers are ingesting massive datasets to get smarter and more competitive. Breakthroughs in large models, cost-per-token declines, open-source proliferation and chip performance improvements are making new tech advances increasingly more powerful, accessible, and economically viable. OpenAI’s ChatGPT – based on user / usage / monetization metrics – is history’s biggest ‘overnight’ success (nine years post-founding). AI usage is surging among consumers, developers, enterprises and governments. And unlike the Internet 1.0 revolution – where technology started in the USA and steadily diffused globally – ChatGPT hit the world stage all at once, growing in most global regions simultaneously. Meanwhile, platform incumbents and emerging challengers are racing to build and deploy the next layers of AI infrastructure: agentic interfaces, enterprise copilots, real-world autonomous systems, and sovereign models. Rapid advances in artificial intelligence, compute infrastructure, and global connectivity are fundamentally reshaping how work gets done, how capital is deployed, and how leadership is defined – across both companies and countries. At the same time, we have leadership evolution among the global powers, each of whom is challenging the other’s competitive and comparative advantage. We see the world’s most powerful countries revved up by varying degrees of economic / societal / territorial aspiration… 8 …Overview …Increasingly, two hefty forces – technological and geopolitical – are intertwining. Andrew Bosworth (Meta Platforms CTO), on a recent ‘Possible’ podcast described the current state of AI as our space race and the people we’re discussing, especially China, are highly capable… there’s very few secrets. And there’s just progress. And you want to make sure that you’re never behind. The reality is AI leadership could beget geopolitical leadership – and not vice-versa. This state of affairs brings tremendous uncertainty…yet it leads us back to one of our favorite quotes – Statistically speaking, the world doesn’t end that often, from former T. Rowe Price Chairman and CEO Brian Rogers. As investors, we always assume everything can go wrong, but the exciting part is the consideration of what can go right. Time and time again, the case for optimism is one of the best bets one can make. The magic of watching AI do your work for you feels like the early days of email and web search – technologies that fundamentally changed our world. The better / faster / cheaper impacts of AI seem just as magical, but even quicker. No doubt, these are also dangerous and uncertain times. But a long-term case for optimism for artificial intelligence is based on the idea that intense competition and innovation… increasingly-accessible compute…rapidly-rising global adoption of AI-infused technology…and thoughtful and calculated leadership can foster sufficient trepidation and respect, that in turn, could lead to Mutually Assured Deterrence. For some, the evolution of AI will create a race to the bottom; for others, it will create a race to the top. The speculative and frenetic forces of capitalism and creative destruction are tectonic. It’s undeniable that it’s ‘game on,’ especially with the USA and China and the tech powerhouses charging ahead. In this document, we share data / research / benchmarks from third parties that use methodologies they deem to be effective – we are thankful for the hard work so many are doing to illustrate trending during this uniquely dynamic time. Our goal is to add to the discussion. • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 9 1 2 3 4 5 6 7 8 Outline 10 Technology Compounding = Numbers Behind The Momentum 11 Technology Compounding Over Thousand-Plus Years = Better + Faster + Cheaper → More… Note: Chart expressed in trillions of real GDP as measured by 2011 ‘GK$’ on a logarithmic scale. GK$ (Gross Knowledge Dollars) is an informal term used to estimate the potential business value of a specific insight, idea, or proprietary knowledge. It reflects how much that knowledge could be worth if applied effectively, even if it hasn’t yet generated revenue. Source: Microsoft, ‘Governing AI: A Blueprint for the Future,’ Microsoft Report (5/23); Data via Maddison Project & Our World in Data Technology Compounding = Numbers Behind The Momentum Global GDP – Last 1,000+ Years, per Maddison Project 1100 1000 1300 1200 1400 1500 1600 1700 1800 1900 2000 Printing Press Steam Engines Telegraph Electrification Mass Steel Production Mass Production & Assembly Lines Internal Combustion Engine Flight Synthetic Fertilizer Transistors PCs Internet Smartphones Cloud 12 …Technology Compounding Over Fifty-Plus Years = Better + Faster + Cheaper → More Note: PC units as of 2000. Desktop internet users as of 2005, installed base as of 2010. Mobile internet units are the installed based of smartphones & tablets in 2020. Cloud & data center capex includes Google, Amazon, Microsoft, Meta, Alibaba, Apple, IBM, Oracle, Tencent, & Baidu for ten years ending 2022. ‘Tens of billions of units’ refers to the potential device & user base that could end up using AI technology; this includes smartphones, IOT devices, robotics, etc. Source: Weiss et al. ‘AI Index: Mapping the $4 Trillion Enterprise Impact’ via Morgan Stanley (10/23) Enabling Infrastructure CPUs Big Data / Cloud GPUs Computing Cycles Over Time – 1960s-2020s, per Morgan Stanley Note: Axis is logarithmic; i.e., there are expected to be tens of thousands more AI Era devices than Mainframe devices 1960 1970 1980 1990 2000 2010 2020 2030 1 100 10,000 1,000,000 Mainframe Minicomputer PC Desktop Internet Mobile Internet AI Era ~1MM+ Units ~10MM+ Units ~300MM+ Units ~1B+ Units / Users ~4B+ Units Tens of Billions of Units MM Units in Log Scale Technology Compounding = Numbers Behind The Momentum 13 AI Technology Compounding = Numbers Behind The Momentum 14 260% Annual Growth Over Fifteen Years of… Data to Train AI Models Led To… Note: Only “notable” language models shown (per Epoch AI, includes state of the art improvement on a recognized benchmark, >1K citations, historically relevant, with significant use). Source: Epoch AI (5/25) Training Dataset Size (Number of Words) for Key AI Models – 1950-2025, per Epoch AI Training Dataset Size – Number of Words +260% / Year AI Technology Compounding = Numbers Behind The Momentum 15 …360% Annual Growth Over Fifteen Years of… Compute to Train AI Models Led To… *A FLOP (floating point operation) is a basic unit of computation used to measure processing power, representing a single arithmetic calculation involving decimal numbers. In AI, total FLOPs are often used to estimate the computational cost of training or running a model. Note: Only language models shown (per Epoch AI, includes state of the art improvement on a recognized benchmark, >1K citations, historically relevant, with significant use). Source: Epoch AI (5/25) Training Compute – FLOP* Grok 3 +360% / Year AI Technology Compounding = Numbers Behind The Momentum Training Compute (FLOP) for Key AI Models – 1950-2025, per Epoch AI 16 …200% Annual Growth Over Nine Years of… Compute Gains from Better Algorithms Led To… Note: Estimates how much progress comes from bigger models versus smarter algorithms, based on how much computing power you'd need to reach top performance without any improvements. Source: Epoch AI (3/24) Impact of Improved Algorithms on AI Model Performance – 2014-2023, per Epoch AI Effective Compute (Relative to 2014) +200% / Year AI Technology Compounding = Numbers Behind The Momentum 17 …150% Annual Growth Over Six Years of… Performance Gains from Better AI Supercomputers Led To… Source: Epoch AI (4/25) AI Technology Compounding = Numbers Behind The Momentum Performance, 16-bit FLOP/s +150% / Year Enabled by 1.6x annual growth in chips per cluster and 1.6x annual growth in performance per chip Performance of Leading AI Supercomputers (FLOP/s) – 2019-2025, per Epoch AI 18 …167% Annual Growth Over Four Years in… Number of Powerful AI Models *As of 4/25, ‘Large-Scale AI Models’ are generally defined as those with a training compute of 1023 FLOPs or greater, per Epoch AI. Source: Epoch AI (5/25) Number of New Large-Scale AI Models (Larger than 1023 FLOP*) – 2017-2024, per Epoch AI Number of New Models Released Each Year AI Technology Compounding = Numbers Behind The Momentum 0 50 100 2017 2018 2019 2020 2021 2022 2023 2024 Includes models from • xAI • Anthropic • Meta • NVIDIA • Mistral • Arc Institute • & Others… +167% / Year Both models from DeepMind (AlphaGo Zero & Master) Publication Date 19 ChatGPT AI User + Subscriber + Revenue Growth Ramps = Hard to Match, Ever Note: 4/25 user count estimate from OpenAI CEO Sam Altman’s 4/11/25 TED Talk disclosure. Revenue figures are estimates based off OpenAI disclosures. Source: OpenAI disclosures (as of 4/25), The Information (4/25) (link, link, link & link) ChatGPT User + Subscriber + Revenue Growth – 10/22-4/25, per OpenAI & The Information AI Technology Compounding = Numbers Behind The Momentum ChatGPT Weekly Active Users, MM 0 400 800 10/22 8/23 6/24 4/25 Users (MM) 0 10 20 10/22 8/23 6/24 4/25 Subscribers (MM) Subscribers , MM Revenue ($B) Revenue, $B $0 $2 $4 2022 2023 2024 Time to 365B Annual Searches = ChatGPT 5.5x Faster vs. Google Note: Dashed-line bars are for years where Google did not disclose annual search volumes. Source: Google public disclosures, OpenAI (12/24). ChatGPT figures are estimates per company disclosures of ~1B daily queries Annual Searches by Year (B) Since Public Launches of Google & ChatGPT – 1998-2025, per Google & OpenAI 20 AI Technology Compounding = Numbers Behind The Momentum Annual Searches, B ChatGPT Hit 365B Annual Searches in 2 Years (2024) vs. Google’s 11 Years (2009) 0 2,500 5,000 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Google Search ChatGPT Years Since Public Launch (Google = 9/98, ChatGPT = 11/22) 21 In 1998, tapping emerging Internet access, Google set out to ‘organize the world’s information and make it universally accessible and useful.’ Nearly three decades later – after some of the fastest change humankind has seen – a lot of information is indeed digitized / accessible / useful. The AI-driven evolution of how we access and move information is happening much faster… …AI is a compounder – on internet infrastructure, which allows for wicked-fast adoption of easy-to-use broad-interest services. AI Technology Compounding = Numbers Behind The Momentum 22 Knowledge Distribution Evolution = Over ~Six Centuries 23 Knowledge Distribution – 1440-1992 = Static + Physical Delivery… Source: Wikimedia Commons Knowledge Distribution Evolution = Over ~Six Centuries Printing Press – Invented 1440 24 …Knowledge Distribution – 1993-2021 = Active + Digital Delivery… *The internet is widely agreed to have been ‘publicly released’ in 1993 with release of the World Wide Web (WWW) into the public domain, which allowed users to create websites; however, Tim Berners-Lee invented the World Wide Web in 1989, per CERN. Source: Google, USA Department of Defense, CERN Internet – Public Release 1993* Knowledge Distribution Evolution = Over ~Six Centuries 25 …Knowledge Distribution – 2022+ = Active + Digital + Generative Delivery *We define the public launch of ChatGPT in November 2022 as the public release of Generative AI which we see as AI’s ‘iPhone Moment.’ ChatGPT saw the fastest user ramp ever for a standalone product (5 days to secure 1MM users). Generative AI = AI that can create content – text, images, audio, or code – based on learned patterns. Source: OpenAI Generative AI – Public Launch of ChatGPT 2022* Knowledge Distribution Evolution = Over ~Six Centuries 26 Knowledge is a process of piling up facts; wisdom lies in their simplification. Martin H. Fischer, German-born American Physician / Teacher / Author (1879-1962) Knowledge Distribution Evolution = Over ~Six Centuries 27 AI = Many Years Before Lift-Off 28 AI Milestone Timeline – 1950-2022, per Stanford University… 1: AI ‘Winter’ was a term used by Nils J. Nilsson, the Kumagai Professor of Engineering in computer science at Stanford University, to describe the period during which AI continued to make conceptual progress but could boast no significant practical successes. This subsequently led to a drop in AI interest and funding. Includes data from sources beyond Stanford. Source: Stanford University & Stanford Law School sources, iRobot, TechCrunch, BBC, OpenAI. Data aggregated by BOND. 10/50: Alan Turing creates his Turing Test to measure computer intelligence, positing that computers could think like humans 6/56: Stanford computer scientist John McCarthy convenes the Dartmouth Conference on ‘Artificial Intelligence,’ a term he coined 1/62: Arthur Samuel, an IBM computer scientist, creates a self-learning program that proves capable of defeating a top USA checkers champion AI ‘Winter1’ (1967-1996) 1/66: Stanford researchers deploy Shakey, the first general- purpose mobile robot that can reason about its own actions 5/97: Deep Blue, IBM’s chess- playing computer, defeats Garry Kasparov, the world chess champion at the time 9/02: Roomba, the first mass- produced autonomous robotic vacuum cleaner that can navigate homes, is launched 10/05: A Stanford team build a driverless car named Stanley; it completes a 132-mile course, winning the DARPA Grand Challenge 4/10: Apple acquires Siri voice assistant & integrates it into iPhone 4S model one year later 6/14: Eugene Goostman, a chatbot, passes the Turing Test, with 1/3 of judges believing that Eugene is human 6/18: OpenAI releases GPT-1, the first of their large language models 6/20: OpenAI releases GPT- 3, an AI tool for automated conversations; Microsoft exclusively licenses the model 11/22: OpenAI releases ChatGPT to the public AI = Many Years Before Lift-Off 29 …AI Milestone Timeline – 2023-2025, per Stanford University *Multimodal = AI that can understand and process multiple data types (e.g., text, images, audio) together. **Open-source = AI models and tools made publicly available for use, modification, and redistribution. 1) 4/25 estimate from OpenAI CEO Sam Altman’s 4/11/25 TED Talk disclosure. Source: Aggregated by BOND from OpenAI, Microsoft, Google, Anthropic, Meta, Apple, Alibaba, Deepseek, UK Government, US Department of Homeland Security. China data may be subject to informational limitations due to government restrictions. 3/23: Microsoft Integrates Copilot into its 365 product suite 3/23: Anthropic releases Claude, its AI assistant focused on safety & inter- pretability 3/24: USA Department of Homeland Security unveils its AI Roadmap Strategy 5/24: OpenAI releases GPT-4o, which has full multimodality across audio, visual, & text inputs 7/24: Apple releases Apple Intelligence, an AI system integrated into its devices, for developers 12/24: OpenAI announces o3, its highest-ever performing model 1/25: Alibaba unveils Qwen2.5-Max, which surpasses the performance of other leading models (GPT- 4o, Claude 3.5) on some reasoning tests 3/23: OpenAI releases GPT-4, a multimodal* model capable of processing both text & images 3/23: Google releases Bard, its ChatGPT competitor 11/23: 28 countries, including USA, EU members & China, sign Bletchley Declaration on AI Safety 4/24: Meta Platforms releases its open- source** Llama 3 model with 70B parameters 5/24: Google introduces AI overviews to augment its search functions 9/24: Alibaba releases 100 open-source Qwen 2.5 models, with performance in line with Western competitors 1/25: DeepSeek releases its R1 & R1- Zero open- source reasoning models 2/25: OpenAI releases GPT-4.5, Anthropic releases Claude 3.7 Sonnet, & xAI releases Grok 3 4/25: ChatGPT reaches 800MM weekly users1 AI = Many Years Before Lift-Off 30 AI = Circa Q2:25 31 Top Ten Things AI Can Do Today, per ChatGPT AI = Circa Q2:25 Source: ChatGPT (5/15/25) 32 AI = Circa 2030? 33 Top Ten Things AI Will Likely Do in Five Years, per ChatGPT AI = Circa 2030? Source: ChatGPT (5/15/25) 34 AI = Circa 2035? 35 Top Ten Things AI Will Likely Do in Ten Years, per ChatGPT Source: ChatGPT (5/15/25) AI = Circa 2035? 36 AI Development Trending = Unprecedented 37 Machine-Learning Model* Trending = In 2015... Industry Surpassed Academia as Data + Compute + Financial Needs Rose *Machine Learning = A subset of AI where machines learn from patterns in data without being explicitly programmed. Note: Academia includes models developed by one or more institutions, including government agencies. Industry-academia collaboration excludes government partnerships and only captures partnerships between academic institutions and industry. Industry excludes models developed in partnership with any entity other than another company. Epoch AI, an AI Index data provider, uses the term ‘notable machine learning models’ to designate particularly influential models within the AI/machine learning ecosystem. Epoch maintains a database of 900 AI models released since the 1950s, selecting entries based on criteria such as state-of-the-art advancements, historical significance, or high citation rates. Since Epoch manually curates the data, some models considered notable by some may not be included. A count of zero academic models does not mean that no notable models were produced by academic institutions in 2023, but rather that Epoch AI has not identified any as notable. Additionally, academic publications often take longer to gain recognition, as highly cited papers introducing significant architectures may take years to achieve prominence. China data may be subject to informational limitations due to government restrictions. Source: Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) 2003-2014: Academia Era 2015-today: Industry Era Global Notable Machine Learning Models by Sector – 2003-2024, per Stanford HAI Annual New Notable Machine-Learning Models AI Development Trending = Unprecedented 38 AI Developer Growth (NVIDIA Ecosystem as Proxy) = +6x to 6MM Developers Over Seven Years Number of Developers, MM 0 3 6 2005 2007 2009 2011 2013 2015 2017 2019 2021 2023 2025 Note: We assume negligible developers in NVIDIA’s ecosystem in 2005 per this text from an 8/20 blog post titled ‘2 Million Registered Developers, Countless Breakthroughs’: ‘It took 13 years to reach 1 million registered developers, and less than two more to reach 2 million.’ Source: NVIDIA blog posts, press releases, & company overviews +6x AI Development Trending = Unprecedented Global Developers in NVIDIA Ecosystem (MM) – 2005-2025, Per NVIDIA 39 AI Developer Growth (Google Ecosystem as Proxy) = +5x to 7MM Developers Y/Y Developers Building with Gemini, MM AI Development Trending = Unprecedented Note: Per Google in 5/25, ‘Over 7 million developers are building with Gemini, five times more than this time last year.’ Source: Google, ‘Google I/O 2025: From research to reality’ (5/25) 1.4MM 7.0MM 0 5 10 1/24 1/25 5/24 5/25 +5x Estimated Global Developers in Google Ecosystem (MM) – 5/24-5/25, Per Google 40 Computing-Related Patent Grants, USA = Exploded… Post-Netscape IPO (1995)...Again + Faster Post-ChatGPT Public Launch (2022) USA Computing-Related* Patents Granted Annually – 1960-2024, per USPTO *Uses Cooperative Patent Classification (CPC) code G06, which corresponds to computing, calculating or counting patents. Google patents data changes somewhat between each query so numbers are rounded and should be viewed as directionally accurate. Source: USA Patent & Trademark Office (USPTO) via Google Patents (4/25) 0 5,000 10,000 15,000 1960 1964 1968 1972 1976 1980 1984 1988 1992 1996 2000 2004 2008 2012 2016 2020 2024 Number of USA Computing- Related Patents Granted Per Year +6,300 more patents granted in 2003 vs. 1995 (8 years)… +1,000 more patents granted in 2022 vs. 2004 (18 years)… +6,000 more patents granted in 2024 vs. 2023 (1 year) AI Development Trending = Unprecedented 41 AI Performance = In 2024… Surpassed Human Levels of Accuracy & Realism, per Stanford HAI AI System Performance on MMLU Benchmark Test – 2019-2024, per Stanford HAI Note: The MMLU (Massive Multitask Language Understanding) benchmark evaluates a language model's performance across 57 academic and professional subjects, such as math, law, medicine, and history. It measures both factual recall and reasoning ability, making it a standard for assessing general knowledge and problem-solving in large language models. 89.8% is the generally-accepted benchmark for human performance. Stats above show average accuracy of top-performing AI models in each calendar year. Source: Papers With Code via Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) AI Development Trending = Unprecedented 42 AI Performance = In Q1:25… 73% of Responses & Rising Mistaken as Human by Testers Note: The Turing test, introduced in 1950, measures a machine’s ability to mimic human conversation. In this study, ~500 participants engaged in a three-party test format, interacting with both a human and an AI. Most discussions leaned on emotional resonance and day-to-day topics over factual knowledge. Eliza was developed in the mid-1960s by MIT professor Joseph Weizenbaum, It is considered the world's first chatbot. In January 2025, researchers successfully revived Eliza using its original code. Source: Cameron Jones and Benjamin Bergen, ‘Large Language Models Pass the Turing Test’ (3/25) via UC San Diego % of Testers Who Mistake AI Responses as Human-Generated – 3/25, per Cameron Jones / Benjamin Bergen Date Released 5/24 1/25 2/25 AI system performance consistently improving over time AI Development Trending = Unprecedented 43 AI Performance = Increasingly Realistic Conversations Simulating Human Behaviors Turing Test Conversation with GPT-4.5 – 3/25, per Cameron Jones / Benjamin Bergen Source: Cameron Jones and Benjamin Bergen, ‘Large Language Models Pass the Turing Test’ (3/25) via UC San Diego What Was Tested: The Turing Test is a concept introduced by Alan Turing in 1950 to evaluate a machine’s ability to exhibit intelligent behavior indistinguishable from that of a human. In the test, if a human evaluator cannot reliably tell whether responses are coming from a human or a machine during a conversation, the machine is said to have passed. Here, participants had to guess whether Witness A or Witness B was an AI system. Results: The conversation on the left is an example Turing Test carried out in 3/25 using GPT-4.5. During the test, participants incorrectly identified the left image (Witness A) as human with 87% certainty, saying ‘A had human vibes. B had human imitation vibes.’ A was actually AI-generated; B was human. AI Development Trending = Unprecedented 44 AI Performance = Increasingly Realistic Image Generation… Notes: Dates shown are the release dates of each Midjourney model. Source: Midjourney (4/25) & Gold Penguin, ‘How Midjourney Evolved Over Time (Comparing V1 to V6.1 Outputs)’ (9/24) AI-Generated Image: ‘Women’s Necklace with a Sunflower Pendant’ – 2/22-4/25, per Midjourney / Gold Penguin Model v1 (2/22) Model v7 (4/25) AI Development Trending = Unprecedented 45 …AI Performance = Increasingly Realistic Image Generation AI-Generated Image (2024) Source: Left – StyleGAN2 via ‘The New York Times,’ ‘Test Yourself: Which Faces Were Made by A.I.?’ (1/24); Right – Creative Commons Real Image AI-Generated vs. Real Image – 2024 AI Development Trending = Unprecedented AI Performance = Increasingly Realistic Audio Translation / Generation… 46 Note: China data may be subject to informational limitations due to government restrictions. Source: ElevenLabs (1/24 & 1/25), Similarweb (5/25) ElevenLabs AI Voice Generator – 1/23-4/25, per ElevenLabs & Similarweb When you create a new dubbing project, Dubbing Studio automatically transcribes your content, translates it into the new language, and generates a new audio track in that language. Each speaker’s original voice is isolated and cloned before generating the translation to make sure they sound the same in every language. - ElevenLabs Press Release, 1/24 Global Mobile & Desktop Website Visits, MM 0 10 20 1/23 4/23 7/23 10/23 1/24 4/24 7/24 10/24 1/25 4/25 In just two years, ElevenLabs’ millions of users have generated 1,000 years of audio content and the company’s tools have been adopted by employees at over 60% of Fortune 500 companies. - ElevenLabs Press Release, 1/25 AI Development Trending = Unprecedented ElevenLabs Monthly Global Site Visits (MM), per Similarweb – 1/23-4/25 47 …AI Performance = Evolving to Mainstream Realistic Audio Translation / Generation Note: Revenue annualized using Q1:25 results. Source: Spotify, ‘The New York Post,’ ‘Inside Spotify: CEO Daniel Ek on AI, Free Speech & the Future of Music’ (5/2/25); Spotify earnings releases; eMarketer, ‘Spotify dominates Apple and Amazon in digital audio’ (4/25) AI-Powered Audio Translation – 5/25, per Spotify Imagine if you’re a creator and you’re the world expert at something…but you happen to be Indonesian. Today, there’s a language barrier and it will be very hard if you don’t know English to be able to get to a world stage. But with AI, it might be possible in the future where you speak in your native language, and the AI will understand it and will actually real-time translate… …What will that do for creativity? For knowledge sharing? For entertainment? I think we’re in the very early innings of figuring that out… …We want Spotify to be the place for all voices. - Spotify Co-Founder & CEO Daniel Ek (5/25) In Q1:25, Spotify had 678MM Monthly Active Users and 268MM Subscribers and supported €16.8B in annualized revenue while hosting 100MM+ tracks, ~7MM podcast titles and ~1MM creative artists. AI Development Trending = Unprecedented 2/25: Spotify begins accepting audiobooks AI-translated into 29 languages from ElevenLabs 48 AI Performance = Emerging Applications Accelerating Emerging AI Applications – 11/24, per Morgan Stanley Source: Morgan Stanley, ‘GenAI: Where are We Seeing Adoption and What Matters for ‘25?’ (11/24) AI Development Trending = Unprecedented 49 AI = Benefits & Risks 50 AI Development = Benefits & Risks The widely-discussed benefits and risks of AI – top-of-mind for many – generate warranted excitement and trepidation, further fueled by uncertainty over the rapid pace of change and intensifying global competition and saber rattling.​ The pros Stuart Russell and Peter Norvig went deep on these topics in the Fourth Edition (2020) of their 1,116-page classic ‘Artificial Intelligence: A Modern Approach’ (link here), and their views still hold true. Highlights follow… …the benefits: put simply, our entire civilization is the product of our human intelligence. If we have access to substantially greater machine intelligence, the [ceiling of our] ambitions is raised substantially. The potential for AI and robotics to free humanity from menial repetitive work and to dramatically increase the production of goods and services could presage an era of peace and plenty. The capacity to accelerate scientific research could result in cures for disease and solutions for climate change and resource shortages. As Demis Hassabis, CEO of Google DeepMind, has suggested: ‘First we solve AI, then use AI to solve everything else.’ Long before we have an opportunity to ‘solve AI,’ however, we will incur risks from the misuse of AI, inadvertent or otherwise. Some of these are already apparent, while others seem likely based on current trends including lethal autonomous weapons…surveillance and persuasion…biased decision making… impact on employment…safety-critical applications…cybersecurity… AI = Benefits & Risks Source: Stuart Russell and Peter Norvig, ‘Artificial Intelligence: A Modern Approach’ 51 Success in creating AI could be the biggest event in the history of our civilization. But it could also be the last – unless we learn how to avoid the risks. Stephen Hawking, Theoretical Physicist / Cosmologist (1942-2018) AI = Benefits & Risks Source: University of Cambridge, Centre for the Future of Intelligence • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 52 1 2 3 4 5 6 7 8 Outline 53 AI User + Usage + CapEx Growth = Unprecedented 54 Consumer / User AI Adoption = Unprecedented 55 AI User Growth (ChatGPT as Foundational Indicator) = +8x to 800MM in Seventeen Months Note:OpenAI reports Weekly Active Users which are represented above. 4/25 estimate from OpenAI CEO Sam Altman’s 4/11/25 TED Talk disclosure. Source: OpenAI disclosures 0 400 800 ChatGPT Weekly Active Users, MM Consumer / User AI Adoption = Unprecedented +8x ChatGPT User Growth (MM) – 10/22-4/25, per OpenAI 56 AI Global Adoption (ChatGPT as Foundational Indicator) = Have Not Seen Likes of This Around-the-World Spread Before 0% 25% 50% 75% 100% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 Internet ChatGPT App Share of Total Current Users, % Note: Year 1 for Internet = 1990; year 33 = 2022. Year 1 for ChatGPT app = 5/23; year 3 for ChatGPT app = 5/25. ChatGPT app monthly active users (MAUs) shown. Note that ChatGPT is not available in China, Russia and select other countries as of 5/25. China data may be subject to informational limitations due to government restrictions. Includes only Android, iPhone & iPad users. Figures may understate true ChatGPT user base (e.g., desktop or mobile webpage users). Regions per United Nations definitions. Figures show % of total current users in that year – note that as year 3 for ChatGPT has not yet finished, percentages could move in coming months. Data for standalone ChatGPT app only. Country-level data may be missing for select years, as per ITU. Source: United Nations / International Telecommunications Union (3/25), Sensor Tower (5/25) Indexed Years (Internet @ 1 = 1990, ChatGPT App @ 1 = 2023) 90% @ Year 23 90% @ Year 3 Consumer / User AI Adoption = Unprecedented Internet vs. ChatGPT Users – Percent Outside North America (1990-2025), Per ITU & Sensor Tower 57 AI User Adoption (ChatGPT as Proxy) = Materially Faster vs. Internet Comparables… Note: Netflix represents streaming business. Source: BOND, ‘AI & Universities’ (2024) via company filings, press Years to Reach 100MM Users – 2000-2023 Consumer / User AI Adoption = Unprecedented 10.3 4.5 0.2 0 2 4 6 8 10 12 Netflix LinkedIn Pinterest Uber Twitter Telegram Spotify Facebook YouTube Snapchat WhatsApp Instagram Disney+ Fortnite TikTok ChatGPT Year Launched: ’00-’05 ’05-’10 ’10-’15 ’15-’20 ’20+ 58 …AI User Adoption (ChatGPT as Proxy) = Materially Faster + Cheaper vs. Other Foundational Technology Products *Public launch of ChatGPT = first release to the public as a free research preview (11/22). Note: Per Ford Corporate, the Model T could be sold for between $260 and $850. We use $850 in 1908 dollars for our figures above. For TiVo, we use the launch of consumer sales on 3/31/99, when TiVo charged $499 for its 14-hour box set. We do not count TiVo subscription costs. We also use the iPhone 1’s 4GB entry level price of $499 in 2007. Source: Heartcore Capital, CNBC, Museum of American Speed, World Bank, Ford Corporate, Gizmodo, Apple, Encyclopedia Britannica, Federal Reserve Bank of St. Louis, Wikimedia Commons, UBS Days to Reach 1MM Customers / Users – 1908-2022 ~2,500 ~1,680 74 5 0 1,500 3,000 Ford Model T (1908) TiVo (1999) iPhone (2007) ChatGPT* (2022) Days to Reach 1MM Customers / Users Purchase Price (2024 $) $29,330 $945 $756 $0 Consumer / User AI Adoption = Unprecedented 59 AI User Adoption – Time to 50% Household Penetration = Each Cycle Ramps in ~Half-the-Time…AI Following Pattern Note: 3 years for AI Era implies that the time to 50% USA Household Adoption is similarly cut in half from the previous cycle. Source: Morgan Stanley, ‘Google and Meta: AI vs. Fundamental 2H Debates’ (7/23), Our World in Data, other web sources per MS Years to 50% Adoption of Household Technologies in USA, per Morgan Stanley Consumer / User AI Adoption = Unprecedented 42 Years 20 Years 12 Years 6 Years 3 Years? 0 25 50 Second Industrial Revolution PC Era Desktop Internet Era Mobile Internet Era AI Era Years 60 Technology Ecosystem AI Adoption = Impressive 61 NVIDIA AI Ecosystem Tells Over Four Years = >100% Growth in Developers / Startups / Apps Note: GPU = Graphics Processing Unit. Source: NVIDIA (2021 & 2025) NVIDIA Computing Ecosystem – 2021-2025, per NVIDIA 2.5MM 6MM 0 3 6 Number of Developers (MM) 7K 27K 0 15 30 2021 2025 Number of AI Startups (K) Number of Applications Using GPUs (K) 1.7K 4K 0 2.5 5 +2.4x +3.9x +2.4x Technology Ecosystem AI Adoption = Impressive 62 Tech Incumbent AI Adoption = Top Priority 63 Tech Incumbent AI Focus = Talking-the-Talk… Source: Uptrends, ‘Top 15 Companies Mentioning AI on Earnings Calls’ (6/24), company earnings transcripts Mentions of ‘AI’ in Corporate Earnings Transcripts – Q1:20-Q1:24, per Uptrends Tech Incumbent AI Adoption = Top Priority 64 …Tech Incumbent AI Focus = Talking-the-Talk… Source: Amazon (4/10/25), Google (4/9/25), Techradar Generative AI is going to reinvent virtually every customer experience we know and enable altogether new ones about which we’ve only fantasized. The early AI workloads being deployed focus on productivity and cost avoidance… …Increasingly, you’ll see AI change the norms in coding, search, shopping, personal assistants, primary care, cancer and drug research, biology, robotics, space, financial services, neighborhood networks – everything. - Amazon CEO Andy Jassy in 2024 Amazon Shareholder Letter – 4/25 The chance to improve lives and reimagine things is why Google has been investing in AI for more than a decade… …We see it as the most important way we can advance our mission to organize the world's information, make it universally accessible and useful... …The opportunity with AI is as big as it gets. - Google CEO Sundar Pichai @ Google Cloud Next 2025 – 4/25 Tech Incumbent AI Adoption = Top Priority 65 …Tech Incumbent AI Focus = Talking-the-Talk… Note: On 3/28/25, Elon Musk announced that xAI had acquired X in an all-stock deal. The deal valued xAI at $80B and X at $33B ($45B less $12B debt). Source: Duolingo (5/1/25), DeepMind, Elon Musk (5/2/25), Fox News There’s three places where [GenAI is]…helping us: data creation…creating new features that were just not possible… efficiencies everywhere in the company… …I should mention something amazing about [the new Duolingo curriculum in] chess is that it really started with a team of two people, neither of whom knew how to program…and they basically made prototypes and did the whole curriculum of chess by just using AI. Also, neither of them knew how to play chess. - Duolingo Co-Founder & CEO Luis von Ahn @ Q1:25 Earnings Call – 5/25 AI with Grok is getting very good…it’s important that AI be programmed with good values, especially truth-seeking values. This is, I think, essential for AI safety… …Remember these words: We must have a maximally truth-seeking AI. - xAI Founder & CEO Elon Musk – 5/25 AI Going Full-Circle: DeepMind’s AlphaGo (2014) started with humans training machines…Duolingo Chess now has machines training humans… Tech Incumbent AI Adoption = Top Priority 66 …Tech Incumbent AI Focus = Talking-the-Talk Source: Roblox (5/1/25), NVIDIA (5/18/25) We view AI as a human acceleration tool that will allow individuals to do more... I believe long term, we will see people coupled with… the AI they use as the overall output of that person. - Roblox Co-Founder, President, CEO & Chair of Board David Baszucki @ Q1:25 Earnings Call – 5/25 Tech Incumbent AI Adoption = Top Priority I promise you, in ten years' time, you will look back and you will realize that AI has now integrated into everything. And in fact, we need AI everywhere. And every region, every industry, every country, every company, all needs AI. AI [is] now part of infrastructure. And this infrastructure, just like the internet, just like electricity, needs factories…. …And these AI data centers, if you will, are improperly described. They are, in fact, AI factories. You apply energy to it, and it produces something incredibly valuable. - NVIDIA Co-Founder & CEO Jensen Huang @ COMPUTEX 2025 – 5/25 67 ‘Traditional’ Enterprise AI Adoption = Rising Priority 68 Enterprise AI Focus – S&P 500 Companies = 50% & Rising Talking-the-Talk . Source: Goldman Sachs Global Investment Research, ‘S&P Beige Book: 3 themes from 4Q 2024 conference calls: Tariffs, a stronger US dollar, and AI’ (2/25) Quarterly Earnings Call Mentions of ‘AI’ – S&P 500 Companies (2015-2025), per Goldman Sachs Research % of S&P 500 Companies Mentioning ‘AI’ ‘Traditional’ Enterprise AI Adoption = Rising Priority 69 Enterprise AI Focus – Global Enterprises = Growth & Revenue…Not Cost Reduction Note: Survey conducted 5/24, N=427. US-based companies = 43%, Japan 15%, UK 14%, France 14%, Germany 14%. Industry mix: 18% Technology, 18% Financial Services, 17% Healthcare, 17% Manufacturing, 15% Industrials, 15% Consumer,. Revenue mix: 13% $500MM-$750MM, 25% $751MM-$1B, 36% $1B-$5B, 10% $5B-$10B, 8% $10B-$15B, 3% $15B- $20B, 5% $20B+. ‘Revenue-Focused’ and ‘Cost-Focused’ categorizations per BOND, not Morgan Stanley. Source: AlphaWise, Morgan Stanley, ‘Quantifying the AI Opportunity’ (12/24) GenAI Improvements Targeted for Global Enterprises over Next 2 Years – 2024, per Morgan Stanley % of Survey Responses 0% 25% 50% 75% Hiring Costs Headcount SG&A / Marketing Manufacturing Costs Admin Costs Margins Marketing Spend Effectivity ROIC Revenues Sales Productivity Customer Service Production / Output Revenue-Focused Cost-Focused ‘Traditional’ Enterprise AI Adoption = Rising Priority 70 Enterprise AI Focus – Global CMOs = 75% Using / Testing AI Tools % of Survey Responses 0% 25% 50% 75% Plan on Start Testing Within 1-2 Years Fully Implemented Plan on Start Testing Within 12 Months Running Initial Tests / Experiments Note: Survey question asked about the extent to which marketing executives worldwide are using generative AI for marketing activities. Survey conducted 7/24, N = 300 marketing executives at companies with 500+ employees worldwide. Survey geos: Australia, Belgium, Brazil, Canada, China, Denmark, Finland, France, Germany, Ireland, Italy, Japan, Luxembourg, Mexico, Netherlands, Norway, Poland, Saudi Arabia, Spain, Sweden, UAE, UK, & USA. Source: eMarketer, Morgan Stanley, ‘Quantifying the AI Opportunity’ (12/24) Global Chief Marketing Officer (CMO) GenAI Adoption Survey – 2024, per Morgan Stanley ‘Traditional’ Enterprise AI Adoption = Rising Priority 71 Enterprise AI Adoption = Rising Priority… Bank of America – Erica Virtual Assistant (6/18) Note: We assume a start at zero users from Erica’s launch in 6/18. Pilot users excluded. Source: Bank of America (2/21, 4/24, 2/25) Bank of America Erica Virtual Assistant – 6/18-2/25, per Bank of America Erica acts as both a personal concierge and mission control for our clients. Our data science team has made more than 50,000 updates to Erica’s performance since launch – adjusting, expanding and fine-tuning natural language understanding capabilities, ensuring answers and insights remain timely and relevant. 2 billion client interactions is a compelling milestone though this is only the beginning for Erica. - Head of Digital at Bank of America Nikki Katz, 4/24 Cumulative Interactions, MM 0 500 1,000 1,500 2,000 2,500 6/18 11/18 4/19 9/19 2/20 7/20 12/20 5/21 10/21 3/22 8/22 1/23 6/23 11/23 4/24 9/24 2/25 Cumulative Client Interactions with Erica Virtual Assistant (MM) Note: Erica is a conversational AI built into Bank of America’s mobile app that helps customers manage their finances by providing real-time insights, transaction search, bill reminders, and budgeting assistance. It has handled billions of interactions and serves as a 24/7 digital financial concierge for over 40 million clients. ‘Traditional’ Enterprise AI Adoption = Rising Priority 72 Enterprise AI Adoption = Rising Priority… JP Morgan – End-to-End AI Modernization (2020) Note: Superscript ‘2’, per JP Morgan, indicates ‘Value is described as benefit in revenue, lower expense, or avoidance of cost – majority is measured as the lift relative to prior analytical techniques with the remainder relative to a random baseline or holdout control.’ We indicate 2020 as the start year for JP Morgan’s AI Modernization (2020 Letter to Shareholders: ‘We already extensively use AI, quite successfully, in fraud and risk, marketing, prospecting, idea generation, operations, trading and in other areas—to great effect, but we are still at the beginning of this journey’). Source: JP Morgan Investor Day (5/25) JP Morgan End-to-End AI Modernization – 2023-2025E, per JP Morgan We have high hopes for the efficiency gains we might get [from AI]… …Certain key subsets of the users tell us they are gaining several hours a week of productivity, and almost by definition, the time savings is coming from less valuable tasks… …We were early movers in AI. But we’re still in the early stages of the journey. - JP Morgan CFO Jeremy Barnum, 5/25 JP Morgan Estimated Value from AI / ML ‘Traditional’ Enterprise AI Adoption = Rising Priority +35% +65% 73 Enterprise AI Adoption = Rising Priority… Kaiser Permanente – Multimodal Ambient AI Scribe (10/23) Source: Tierney, Aaron A. et al., ‘Ambient Artificial Intelligence Scribes to Alleviate the Burden of Clinical Documentation’ (3/24) & Tierney, Aaron A. et al., ‘Ambient Artificial Intelligence Scribes: Learnings after 1 Year and over 2.5 Million Uses’ (3/25) via Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) Kaiser Permanente Ambient AI Scribe – 10/23-12/24, per New England Journal of Medicine Ambient artificial intelligence (AI) scribes, which use machine learning applied to conversations to facilitate scribe-like capabilities in real time, [have] great potential to reduce documentation burden, enhance physician-patient encounters, and augment clinicians’ capabilities. The technology leverages a smartphone microphone to transcribe encounters as they occur but does not retain audio recordings. To address the urgent and growing burden of data entry, in October 2023, The Permanente Medical Group (TPMG) enabled ambient AI technology for 10,000 physicians and staff to augment their clinical capabilities across diverse settings and specialties. - New England Journal of Medicine Catalyst Research Report, 2/24 Unique Kaiser Permanente Physicians Ever Using AI Scribe & Cumulative Number of Scribe Visits ‘Traditional’ Enterprise AI Adoption = Rising Priority 74 Enterprise AI Adoption = Rising Priority… Yum! Brands – Byte by Yum! (2/25) Note: Yum! Brands names include KFC, Taco Bell, Pizza Hut, & The Habit. Byte by Yum! was officially launched in 2/25. While underlying technologies were previously in-use at restaurants in Yum!’s portfolio, the Byte by Yum! product suite had not yet officially been launched; hence, we illustratively show zero users in 2/24. Source: Yum!, ‘Introducing Byte by Yum! , an AI-driven restaurant technology platform powering customer and team member experiences worldwide’(2/25) Yum! Brands Byte by Yum! – 2/24-2/25, per Yum! Brands Backed by artificial intelligence, Byte by Yum! offers franchisees leading technology capabilities with advantaged economics made possible by the scale of Yum!. The Byte by Yum! platform includes online and mobile app ordering, point of sale, kitchen and delivery optimization, menu management, inventory and labor management, and team member tools. - Yum! Press Release, 2/25 Number of Restaurants Yum! Restaurants Using at Least One Byte by Yum! Product Byte is Yum! Brands' AI-powered restaurant management platform designed to optimize store operations by automating repetitive tasks like inventory tracking, scheduling, and food preparation alerts. It leverages machine learning to improve decision-making at the restaurant level, enhancing efficiency, reducing waste, and supporting staff productivity. ‘Traditional’ Enterprise AI Adoption = Rising Priority 0 25,000 0 5,000 10,000 15,000 20,000 25,000 2/24 2/25 75 Education / Government / Research AI Adoption = Rising Priority 76 Source: Arizona State University (8/23), Oxford University (3/25), University of Michigan (3/25), Launch Consulting (1/25) via AI Advantage Daily News, NPR (1/25) Education & Government = Increasingly Announcing AI Integrations Arizona State University’s ‘AI Acceleration’ – 8/23 Oxford Partnership – 3/25 NextGenAI – 3/25 $50MM consortium with 15 research universities (MIT, Harvard, Caltech, etc.) 5-Year Partnership on Research & AI Literacy New team of technologists creating artificial intelligence (AI) tools ChatGPT Gov – 1/25 ChatGPT tailored for USA federal agencies USA National Laboratories – 1/25 Partnering on Nuclear, Cybersecurity, & Scientific Breakthroughs Education / Government / Research AI Adoption = Rising Priority 77 Source: NVIDIA (2/25 & 5/25) Government = Increasingly Adopting Sovereign AI Policies Education / Government / Research AI Adoption = Rising Priority NVIDIA Sovereign AI Partners – 2/25, Per NVIDIA Nations are investing in AI infrastructure like they once did for electricity and Internet. - NVIDIA Co-Founder & CEO Jensen Huang, 5/25 78 Research = Rapid Ramp in FDA-Approved AI Medical Devices, per Stanford HAI Note: FY21, FY22 & FY23 USA government budget figures are actuals. FY24 data is enacted but not actual, FY25 data is requested. NIH share of total budget is requested. Source: Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25); USA Food & Drug Administration, ‘FDA Announces Completion of First AI-Assisted Scientific Review Pilot and Aggressive Agency-Wide AI Rollout Timeline’ (5/25); NITRD.gov (5/25) New AI-Enabled Medical Devices Approved by USA Food & Drug Administration – 1995-2023, per Stanford HAI & USA FDA Number of AI Medical Devices Approved Education / Government / Research AI Adoption = Rising Priority In a historic first for the [USA FDA], FDA Commissioner Martin A. Makary, M.D., M.P.H., today announced an aggressive timeline to scale use of artificial intelligence (AI) internally across all FDA centers by June 30, 2025… …To reflect the urgency of this effort, Dr. Makary has directed all FDA centers to begin deployment immediately, with the goal of full integration by the end of June. - USA FDA Press Release, 5/25 AI-Enabled Medical Devices Approved New USA FDA AI Policy (5/25) 1 0 1 1 0 0 1 0 0 1 1 0 0 5 0 2 2 3 3 6 6 18 26 64 80 114 129 160 223 0 125 250 1995 1999 2003 2007 2011 2015 2019 2023 Government R&D funding has been a key part of AI development budgets, especially in healthcare: - FY21-FY25 Federal USA AI Budget: $14.7B - FY25 Share Requested by National Institutes of Health: 34% 79 Research = 30%-80% Reduction in Medical R&D Timelines, per Insilico Medicine & Cradle Note: Pre-Clinical Candidate Status marks the point at which a lead molecule (or biologic) has satisfied all discovery-stage gates and is officially handed off to the development organization for work related to beginning human clinical trials. Figures collected from 2021-2024. Source: Cradle, Insilico Medicine via BioPharmaTrend, ‘Insilico Medicine Reports Benchmarks for its AI-Designed Therapeutics’ (2/25) AI-Driven Drug Discovery – 2021-2024, Per Insilico Medicine, Cradle & BioPharmaTrend Months to Pre-Clinical Candidate Status Education / Government / Research AI Adoption = Rising Priority Pharma companies that use Cradle are seeing a 1.5x to 12x speedup in pre-clinical research and development by using our GenAI platform to engineer biologics. - Stef van Grieken, Co-Founder & CEO of Cradle, 5/25 Months to Reach Pre-Clinical Candidate Status 0 25 50 Solid Tumors (QPCTL) Inflammatory Bowel Disease (PHD1/2) Idiopathic Pulmonary Fibrosis (TNIK) Traditional Approaches Traditional approaches can take 2.5-4 years 80 AI User + Usage + CapEx Growth = Unprecedented AI Usage – ChatGPT = Rising Rapidly Across Age Groups in USA, per Pew & Elon University Note: 7/23 data per Pew Research study on ChatGPT use, n=10,133 USA adults. Those who did not give an answer are not shown. 1/25 data per Elon University study on use of any AI models, n=500 USA adults,. Figures estimated based on overall AI tool usage adjusted for an average 72% usage rate of ChatGPT amongst respondents who use any AI tools. Actual ChatGPT penetration may vary by cohort. Note that this chart aggregates data across survey providers and as such may not be directly comparable. Source: Pew Research Center (3/26/24), Elon University (released 3/12/25), Sam Altman (5/12/25) via Fortune % of USA Adults Who Say They Have Ever Used ChatGPT – 7/23 per Pew & 1/25 per Elon University 18% 33% 21% 13% 4% 37% 55% 44% 30% 20% 0% 50% 100% All USA Adults Ages 18-29 Ages 30-49 Ages 50-64 Ages 65+ 7/23 – Per Pew 1/25 – Estimates Per Elon University % of USA Adults AI User + Usage + CapEx Growth = Unprecedented 81 A gross oversimplification is: Older people use ChatGPT as, like, a Google replacement. People in their 20s and 30s use it like a life advisor. - OpenAI Co-Founder & CEO Sam Altman (5/25) 82 Minutes per Day that USA Active Users Spend on ChatGPT App – 7/23-4/25, per Sensor Tower Note: Data represents USA App Store & Google Play Store monthly active users. Data for ChatGPT standalone app only. ChatGPT app not available in China, Russia and select other countries as of 5/25. Source: Sensor Tower (5/25) AI Engagement (ChatGPT App as Proxy) = +202% Rise in Daily Time Spent Over Twenty-One Months… Daily Minutes Spent on App, USA 0 10 20 7/23 8/23 9/23 10/23 11/23 12/23 1/24 2/24 3/24 4/24 5/24 6/24 7/24 8/24 9/24 10/24 11/24 12/24 1/25 2/25 3/25 4/25 +202% AI User + Usage + CapEx Growth = Unprecedented 83 Note: Data represents USA App Store & Google Play Store monthly active users. Data for ChatGPT standalone app only. ChatGPT app not available in China, Russia and select other countries as of 5/25. Source: Sensor Tower (5/25) …AI Engagement (ChatGPT App as Proxy) = +106% Growth in Sessions & +47% Growth in Duration Over Twenty-One Months Average Minutes / Session, USA (Blue Bars) 0 3 6 9 0 1 2 3 7/23 8/23 9/23 10/2311/2312/23 1/24 2/24 3/24 4/24 5/24 6/24 7/24 8/24 9/24 10/2411/2412/24 1/25 2/25 3/25 4/25 Average Daily Sessions / User, USA (Red Line) AI User + Usage + CapEx Growth = Unprecedented Average USA Session Duration (Minutes) & Daily Sessions per User for ChatGPT App – 7/23-4/25, per Sensor Tower 84 AI Retention (ChatGPT as Proxy) = 80% vs. 58% Over Twenty-Seven Months, per YipitData Note: Retention Rate = Percentage of users from the immediately preceding week that were users again in the current week. Data measures several million global active desktop users’ clickstream data. Data consists of users’ web requests & is collected from web services / applications, such as VPNs and browser extensions. Users must have been part of the panel for 2 consecutive months to be included. Panel is globally-representative, though China data may be subject to informational limitations due to government restrictions. Excludes anomalies in w/c 12/24/23, 12/31/23, 12/22/24, 12/29/24, 1/5/25, potentially due to holiday breaks causing less enterprise usage. Source: YipitData (5/25) Weekly Retention, % Consumer ChatGPT & Google Search Global Desktop User Retention Rates (1/23-4/25), per YipitData 50% 75% 100% ChatGPT Retention Google Search Retention +2,259 bps AI User + Usage + CapEx Growth = Unprecedented 85 AI Chatbots @ Work Tells = >72% Doing Things Quicker / Better Note: N = 5,273 USA adults who are employed part time or full time and who have only one job or have more than one but consider one of them to be their primary job were surveyed. Source: Pew Research Center (10/24) % of Employed USA Adults Using AI Chatbots Who Say Tools Have Been ______ Helpful When It Comes to… – 10/24, per Pew % of Employed USA Adults AI User + Usage + CapEx Growth = Unprecedented 0% 25% 50% 75% 100% Improving the Quality of Their Work Allowing Them to Do Things More Quickly Extremely / Very Somewhat Not Too / Not at All 86 AI Chatbots @ School Tells (ChatGPT as Proxy) = Bias to Research / Problem Solving / Learning / Advice OpenAI ChatGPT Usage Survey, USA Students Ages 18-24 – 12/24-1/25, per OpenAI Note: Data per OpenAI survey (12/24), n = 1,299 USA college and graduate students across a mix of STEM and non-STEM disciplines; only answers from 18-24 year olds used. Sample includes both AI users and non-users but excludes “AI rejectors” – defined as non-users with little to no interest in adopting AI within the next 12 months. Source: OpenAI, ‘Building an AI-Ready Workforce: A Look at College Student ChatGPT Adoption in the US’ (2/25) AI User + Usage + CapEx Growth = Unprecedented 87 AI Usage Expansion – Deep Research = Automating Specialized Knowledge Work Select AI Company Deep Research Capabilities – 12/24-2/25, per Google, OpenAI & xAI Source: Google (5/25), OpenAI (2/25), xAI (2/25), Digital Trends (1/25) Get up to speed on just about anything with Deep Research, an agentic feature in Gemini that can automatically browse up to hundreds of websites on your behalf, think through its findings, and create insightful multi-page, reports that you can turn into engaging podcast-style conversations… …It’s a step towards more agentic AI that can move beyond simple question- answering to become a true collaborative partner. - Google Deep Research Overview, launched 12/24 Google Gemini Deep Research Today we’re launching deep research in ChatGPT, a new agentic capability that conducts multi-step research on the internet for complex tasks. It accomplishes in tens of minutes what would take a human many hours… …Deep research marks a significant step toward our broader goal of developing AGI, which we have long envisioned as capable of producing novel scientific research. - OpenAI Deep Research Press Release, 2/25 OpenAI ChatGPT Deep Research xAI Grok DeepSearch To understand the universe, we must interface Grok with the world… …As a first step towards this vision, we are rolling out DeepSearch – our first agent. It's a lightning-fast AI agent built to relentlessly seek the truth across the entire corpus of human knowledge. DeepSearch is designed to synthesize key information, reason about conflicting facts and opinions, and distill clarity from complexity. - xAI Grok 3 Beta Press Release, 2/25 AI User + Usage + CapEx Growth = Unprecedented 88 AI Agent Evolution = Chat Responses → Doing Work 89 AI Agent Evolution = Chat Responses → Doing Work A new class of AI is now emerging – less assistant, more service provider. What began as basic conversational interfaces may now be evolving into something far more capable. Traditional chatbots were designed to respond to user prompts, often within rigid scripts or narrow flows. They could fetch answers, summarize text, or mimic conversation – but always in a reactive, limited frame. AI agents represent a step-change forward. These are intelligent long-running processes that can reason, act, and complete multi-step tasks on a user’s behalf. They don’t just answer questions – they execute: booking meetings, submitting reports, logging into tools, or orchestrating workflows across platforms, often using natural language as their command layer. This shift mirrors a broader historical pattern in technology. Just as the early 2000s saw static websites give way to dynamic web applications – where tools like Gmail and Google Maps transformed the internet from a collection of pages into a set of utilities – AI agents are turning conversational interfaces into functional infrastructure. Whereas early assistants needed clear inputs and produced narrow outputs, agents promise to operate with goals, autonomy and certain guardrails. They promise to interpret intent, manage memory, and coordinate across apps to get real work done. It’s less about responding and more about accomplishing. While we are early in the development of these agents, the implications are just starting to emerge. AI agents could reshape how users interact with digital systems – from customer support and onboarding to research, scheduling, and internal operations. Enterprises are leading the charge; they’re not just experimenting with agents, but deploying them, investing in frameworks and building ecosystems around autonomous execution. What was once a messaging interface is becoming an action layer. 90 Source: Google Trends via Glimpse (5/15/24), OpenAI (3/25) AI Agent Interest (Google Searches) = +1,088% Over Sixteen Months 0 250 500 1/24 2/24 3/24 4/24 5/24 6/24 7/24 7/24 8/24 9/24 10/24 11/24 12/24 12/24 1/25 2/25 3/25 4/25 5/25 Weekly Google Keyword Searches, K 3/11/25: OpenAI Introduces Developer Tools for AI Agents +1,088% AI Agent Evolution = Chat Responses → Doing Work Global Google Searches for ‘AI Agent’ (K) – 1/24-5/25, per Google Trends 91 Source: Salesforce (10/24), Salesforce Ben, Anthropic (10/24), OpenAI (1/25), Amazon (3/25) AI Agent Deployments = AI Incumbent Product Launches Accelerating OpenAI Operator (1/25 = Research Preview Release) Salesforce Agentforce (10/24 = General Release) Anthropic Claude 3.5 Computer Use (10/24 = Research Preview Release) Amazon Nova Act (3/25 = Research Preview Release) Agent Released Select Capabilities • Automated customer support • Case resolution • Lead qualification • Order tracking • Control computer screen directly to perform tasks like pulling data from websites, making online purchases, etc. • Control computer screen directly to perform tasks like pulling data from websites, making online purchases, etc. • Home automation • Information collection • Purchasing • Scheduling AI Incumbent Agent Launches AI Agent Evolution = Chat Responses → Doing Work 92 Next Frontier For AI = Artificial General Intelligence 93 Artificial General Intelligence, or AGI, refers to systems capable of performing the full range of human intellectual tasks – reasoning, planning, learning from small data samples, and generalizing knowledge across domains. Unlike current AI models, which excel within specific (albeit broad) boundaries, AGI would be able to operate fully flexibly across disciplines and solve unfamiliar problems without retraining. It represents a major milestone in AI development – one that builds on recent exponential gains in model scale, training data, and computational efficiency. Timelines for AGI remain uncertain, but expert expectations have shifted forward meaningfully in recent years. Sam Altman, CEO of OpenAI, remarked in January 2025, We are now confident we know how to build AGI as we have traditionally understood it. This is a forecast, not a dictum, but it reflects how advances in model architecture, inference* efficiency, and training scale are shortening the distance between research and frontier capability. The broader thread is clear: AI development is trending at unprecedented speed, and AGI is increasingly being viewed not as a hypothetical endpoint, but as a reachable threshold. If / when achieved, AGI would redefine what software (and related hardware) can do. Rather than executing pre-programmed tasks, AGI systems would understand goals, generate plans, and self-correct in real time. They could drive research, engineering, education, and logistics workflows with little to no human oversight – handling ambiguity and novelty with general-purpose reasoning. These systems wouldn’t require extensive retraining to handle new problem domains – they would transfer learning and operate with context, much like human experts. Additionally, humanoid robots powered by AGI would have the power to reshape our physical environment and how we operate in it. Still, the implications warrant a measured view. AGI is not a finish line, but a phase shift in capability – and how it reshapes institutions, labor, and decision-making will depend on the safeguards and deployment frameworks that accompany it. The productivity upside may be significant, but unevenly distributed. The geopolitical, ethical, and economic implications may evolve gradually, not abruptly. As with earlier transitions – from industrial to digital to algorithmic – the full consequences will be shaped not just by what the technology can do, but by how society chooses to adopt and govern it. *Inference = Fully-trained model generates predictions, answers, or content in response to user inputs. This phase is much faster and more efficient than training. Next Frontier For AI = Artificial General Intelligence 94 AI User + Usage + CapEx Growth = Unprecedented 95 To understand where technology CapEx is heading, it helps to look at where it’s been. Over the past two decades, tech CapEx has flexed upward at points through data’s long arc – first toward storage / access, then toward distribution / scale, and now toward computation / intelligence. The earliest wave saw CapEx pouring into building internet infrastructure – massive server farms, undersea cables, and early data centers that enabled Amazon, Microsoft, Google and others to lay the foundation for cloud computing. That was the first phase: store it, organize it, serve it. The second wave – still unfolding – has been about supercharging compute for data-heavy AI workloads, a natural evolution of cloud computing. Hyperscaler* CapEx budgets now tilt increasingly toward specialized chips (GPUs, TPUs, AI accelerators…), liquid cooling, and frontier data center design. In 2019, AI was a research feature; by 2023, it was a capital expenditure line item. Microsoft Vice Chair and President Brad Smith put it well in a 4/25 blog post: Like electricity and other general-purpose technologies in the past, AI and cloud datacenters represent the next stage of industrialization. The world's biggest tech companies are spending tens of billions annually – not just to gather data, but to learn from it, reason with it and monetize it in real time. It’s still about data – but now, the advantage goes to those who can train on it fastest, personalize it deepest, and deploy it widest. *Hyperscalers (large data center operators) are Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), Alibaba Cloud, Oracle Cloud Infrastructure (OCI), IBM Cloud & Tencent Cloud. AI User + Usage + CapEx Growth = Unprecedented 96 CapEx Spend – Big Technology Companies = On Rise for Years as Data Use + Storage Exploded 97 CapEx Spend @ Big Six* Tech Companies (USA) = +21% Annual Growth Over Ten Years *Note: Big Six USA technology companies include Apple, Nvidia, Microsoft, Alphabet / Google, Amazon, & Meta Platforms / Facebook. Only AWS CapEx & revenue shown for Amazon (i.e. excludes Amazon retail CapEx). AWS CapEx estimated per Morgan Stanley – equals AWS net additions to property & equipment less finance leases and obligations. Global data generation figures for 2024 are estimates. Source: Capital IQ (3/25), Hinrich Foundation (3/25) Global Data Generation, Zettabytes (Red Line) 0 30 60 90 120 150 $0 $50 $100 $150 $200 $250 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 CapEx Spend, $B (Blue Bars) As data volumes rise, CapEx required to build more hyperscale data centers, faster network infrastructure, & more compute capacity CapEx: +21% / Year Data: +28% / Year CapEx Spend – Big Technology Companies = On Rise for Years as Data Use + Storage Exploded Big Six* USA Public Technology Company CapEx Spend ($B) vs. Global Data Generation (Zettabytes) – 2014-2024, per Capital IQ & Hinrich Foundation CapEx Spend for Tech Hyperscalers = Mirrored by… +37% Annual Cloud Revenue Growth Over Ten Years 98 Note: Companies do not report “hyperscaler cloud revenue” on like-for-like basis so data represents best estimates and may not align between companies. Oracle Cloud revenue includes Cloud Services & License Support, as well as Cloud License & On-Premise License. IBM Cloud includes all ‘Infrastructure’ line items due to reporting standards. Alibaba & Tencent Cloud revenues estimated per Morgan Stanley. Source: Company disclosures, Morgan Stanley (as of 4/25) $0 $100 $200 $300 $400 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Amazon AWS Microsoft Intelligent Cloud Google Cloud Oracle Cloud IBM Cloud Alibaba Cloud Tencent Cloud Revenue, $B +37% / Year CapEx Spend – Big Technology Companies = On Rise for Years as Data Use + Storage Exploded Global Hyperscaler Cloud Revenue ($B) – 2014-2024, per Company Disclosures & Morgan Stanley Estimates 99 CapEx Spend – Big Technology Companies = Inflected With AI’s Rise 100 AI Model Training Dataset Size = 250% Annual Growth Over Fifteen Years, per Epoch AI Note: In AI language models, tokens represent basic units of text (e.g., words or sub-words) used during training. Training dataset sizes are often measured in total tokens processed. A larger token count typically reflects more diverse and extensive training data, which can lead to improved model performance – up to a point – before reaching diminishing returns. Source: Epoch AI (5/25) AI Model Training Dataset Size (Tokens) by Model Release Year – 6/10-5/25, per Epoch AI Training Dataset Size, Tokens CapEx Spend – Big Technology Companies = Inflected With AI’s Rise +250% / Year 101 CapEx Spend @ Big Six* Tech Companies = +63% Y/Y & Accelerated… 1ChatGPT WAU data as of 11/23 & 12/24 due to data availability. *Note: Big Six USA technology companies include Apple, Nvidia, Microsoft, Alphabet / Google, Amazon, & Meta Platforms / Facebook. Only AWS CapEx & revenue shown for Amazon (i.e. excludes Amazon retail CapEx). AWS CapEx estimated per Morgan Stanley – equals AWS net additions to property & equipment less finance leases and obligations. Source: Capital IQ (3/25), OpenAI disclosures (3/25) Global ChatGPT Weekly Active Users, MM (Red Line) 0 70 140 210 280 350 $0 $50 $100 $150 $200 $250 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 CapEx Spend, $B (Blue Bars) 2023-2024 Change: Big Six CapEx = +63% ChatGPT WAUs = +200%1 CapEx Spend – Big Technology Companies = Inflected With AI’s Rise Big Six* USA Public Technology Company CapEx Spend ($B) vs. Global ChatGPT Weekly Active Users (MM) – 2014-2024, per Capital IQ & OpenAI 102 …CapEx Spend @ Big Six* Tech Companies = 15% of Revenue & Accelerated vs. 8% Ten Years Ago *Note: Big Six USA technology companies include Apple, Nvidia, Microsoft, Alphabet / Google, Amazon, & Meta Platforms / Facebook. Only AWS CapEx & revenue shown for Amazon (i.e. excludes Amazon retail CapEx). AWS CapEx estimated per Morgan Stanley – equals AWS net additions to property & equipment less finance leases and obligations. Source: Capital IQ (3/25), Morgan Stanley (5/25) CapEx, $B (Blue Bars) CapEx as % of Revenue (Red Line) 0% 3% 6% 9% 12% 15% $0 $50 $100 $150 $200 $250 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 +21% / Year CapEx Spend – Big Technology Companies = Inflected With AI’s Rise Big Six* USA Public Technology Company – CapEx Spend ($B) vs. % of Revenue – 2014-2024, per Capital IQ & Morgan Stanley 103 CapEx Spend @ Amazon AWS = Cloud vs. AI Patterns 104 CapEx as % of Revenue (AWS as Proxy) – AI vs. Cloud Buildouts = 49% (2024) vs. 4% (2018) vs. 27% (2013), per Morgan Stanley Note: Figures shown represent AWS only. AWS CapEx estimated per Morgan Stanley – equals AWS net additions to property & equipment less finance leases and obligations. Source: Amazon, Morgan Stanley (5/25) Amazon AWS CapEx as % of Revenue – 2013-2024, Estimated per Morgan Stanley CapEx / Revenue, % AI / ML Infrastructure Build-Out Initial Cloud Infrastructure Build-Out 27% 4% 49% 0% 20% 40% 60% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 AWS CapEx as % of revenue decreased as upfront infrastructure investments slowed & revenue grew… will AI follow? From 2020, AWS began rapidly scaling CapEx (+30% Y/Y) to build AI / ML infrastructure, potentially restarting cycle CapEx Spend @ Amazon AWS = Cloud vs. AI Patterns 105 Tech CapEx Spend Partial Instigator = Material Improvements in GPU Performance NVIDIA GPU Performance = +225x Over Eight Years 106 1 GPT-MoE Inference Workload = A type of workload where a GPT-style model with a Mixture-of-Experts (MoE) architecture is used for inference (i.e., making predictions). Note: Annual token revenue assumes a flat per-token cost. Source: NVIDIA (5/25) Performance of NVIDIA GPU Series Over Time – 2016-2024, per NVIDIA Tech CapEx Spend Partial Instigator = Material Improvements in GPU Performance Pascal Volta Ampere Hopper Blackwell 2016 2018 2020 2022 2024 Number of GPUs 46K 43K 28K 16K 11K +225x Factory AI FLOPS 1EF 5EF 17EF 63EF 220EF Annual Inference Tokens 50B 1T 5T 58T 1,375T +30,000x Annual Token Revenue $240K $3M $24M $300M $7B DC Power 37MW 34MW 25MW 19MW 21MW +50,000x Token Per MW-Year 1.3B 2.9B 200B 3T 65T …Performance +225x over eight years while requiring 4x fewer GPUs… $1B Data Center Comparison GPT-MoE Inference Workload1 …Inference token capacity +27,500x over eight years, implying +30,000x higher theoretical token revenue… …Data center power use down 43% over eight years, leading to +50,000x greater per-unit energy efficiency For a Theoretical $1B-Scale Data Center… NVIDIA Installed GPU Computing Power = 100x+ Growth Over ~Six Years 107 Note: Analysis does not include TPUs or other specialized AI accelerators, for which less data is available. TPUs may provide comparable total computing power to NVIDIA chips. Source: Epoch AI (2/25) Simultaneous expansion of GPU / computing-related CapEx alongside rising performance-per-GPU = Exponentially-greater computing capacity Total Installed Computing Power, FLOP/s +130% / Year Tech CapEx Spend Partial Instigator = Material Improvements in GPU Performance Global Stock of NVIDIA GPU Computing Power (FLOP/s) – Q1:19-Q4:24, per Epoch AI 108 Tech CapEx Spend Beneficiary = NVIDIA Key Tech CapEx Spend Beneficiary = NVIDIA… 25% & Rising of Global Data Center CapEx, per NVIDIA 109 Note: NVIDIA data represents January FYE (e.g., 2024 = FY25 ending 1/25) vs calendar year for data center CapEx. Data presented by Jensen Huang at NVIDIA GTC 2025 (link). Source: Dell’Oro Research for CapEx (3/25); NVIDIA for data center revenue (3/25) 0% 10% 20% 30% $0 $200 $400 $600 2022 2023 2024 Global Data Center CapEx, $B (Blue Bar) NVIDIA Data Center Revenue as % of Global Data Center CapEx (Red Line) Tech CapEx Spend Beneficiary = NVIDIA Global Data Center CapEx ($B) vs. NVIDIA’s Data Center Revenue as Percent of Data Center CapEx (Global) – 2022-2024, per NVIDIA @ GTC 110 Technology Company Spend = R&D Rising Along with CapEx 111 R&D Spend @ Big Six* USA Public Tech Companies = 13% of Revenue…vs. 9% Ten Years Ago *Note: Big Six USA technology companies include Apple, Nvidia, Microsoft, Alphabet / Google, Amazon, & Meta Platforms / Facebook. R&D expense shown for Amazon, not AWS, as figures are not broken out in company financials; revenue therefore shown on like-for-like basis. Source: Capital IQ (3/25) R&D Expense, $B (Blue Bars) R&D Expense as % of Revenue (Red Line) 0% 5% 10% 15% $0 $100 $200 $300 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 +20% / Year Technology Company Spend = R&D Rising Along with CapEx Big Six* USA Public Technology Company – R&D Spend ($B) vs. % of Revenue – 2014-2024, per Capital IQ 112 Tech Big Six (USA) = Loaded With Cash to Spend on AI & CapEx Big Six* Generating Loads of Cash = +263% Growth in Free Cash Flow Over Ten Years to $389B… 113 *Note: Big Six USA technology companies include Apple, Nvidia, Microsoft, Alphabet / Google, Amazon, & Meta Platforms / Facebook. FCF calculated as cash flow from operations less capex to standardize definitions, as only some companies subtract finance leases and Amazon adjusts FCF for gains on sale of equipment. FCF shown for Amazon, not AWS, as figures are not broken out in company financials. Source: Capital IQ (3/25) $0 $50 $100 Apple NVIDIA Microsoft Google Amazon Meta 2014 2019 2024 Free Cash Flow, $B Tech Big Six (USA) = Loaded With Cash to Spend on AI & CapEx Big Six* Public Technology Companies – Free Cash Flow ($B) – 2014-2024, per Capital IQ …Big Six* Generating Loads of Cash = +103% Growth in Cash Over Ten Years to $443B 114 *Note: Big Six USA technology companies include Apple, Nvidia, Microsoft, Alphabet / Google, Amazon, & Meta Platforms / Facebook. Figure measures cash and other equivalents (e.g., short-term investments and marketable securities) on companies’ balance sheets. Source: Capital IQ (3/25) $0 $50 $100 $150 Apple NVIDIA Microsoft Google Amazon Meta 2014 2019 2024 Cash on Balance Sheet, $B Tech Big Six (USA) = Loaded With Cash to Spend on AI & CapEx Big Six* USA Public Technology Company Cash on Balance Sheet ($B) – 2014-2024, per Capital IQ 115 Tech CapEx Spend Driver = Compute Spend to Train & Run AI Models 116 Tech CapEx Spend Driver = Compute Spend to Train & Run Models To understand the evolution of AI computing economics, it’s constructive to look at where costs are concentrated – And where they’re headed. The bulk of spending in AI large language model (LLM) development is still dominated by compute – specifically, the compute needed to train and run models. Training costs remain extraordinarily high and are rising fast, often exceeding $100 million per model today. As Dario Amodei, CEO of Anthropic, noted in mid-2024, Right now, [AI model training costs] $100 million. There are models in training today that are more like a billion… I think that the training of…$10 billion models, yeah, could start sometime in 2025. Around these core compute costs sit additional high-cost layers: research, data acquisition and hosting, and a mix of salaries, general overhead, and go-to-market operations. Even as the cost to train models climbs, a growing share of total AI spend is shifting toward inference – the cost of running models at scale in real-time. Inference happens constantly, across billions of prompts, queries, and decisions, whereas model training is episodic. As Amazon CEO Andy Jassy noted in his April 2025 letter to shareholders, While model training still accounts for a large amount of the total AI spend, inference… will represent the overwhelming majority of future AI cost because customers train their models periodically but produce inferences constantly. NVIDIA Co-Founder & CEO Jensen Huang noted the same in NVIDIA’s FQ1:26 earnings call, saying Inference is exploding. Reasoning AI agents require orders of magnitude more compute. At scale, inference becomes a persistent cost center – one that grows in parallel with usage, despite declines in unit inference costs. The broader dynamic is clear: lower per-unit costs are fueling higher overall spend. As inference becomes cheaper, AI gets used more. And as AI gets used more, total infrastructure and compute demand rises – dragging costs up again. The result is a flywheel of growth that puts pressure on cloud providers, chipmakers, and enterprise IT budgets alike. The economics of AI are evolving quickly – but for now, they remain driven by heavy capital intensity, large-scale infrastructure, and a race to serve exponentially expanding usage. 117 Data Centers = Key Beneficiary of AI CapEx Spend 118 Data Centers = Key Beneficiary of AI CapEx Spend For one lens into the economics of AI infrastructure, it’s useful to look at the pace and scale of data center construction. The current wave of AI-driven demand has pushed data center spending to historic highs. According to Dell’Oro Research, global IT company data center CapEx reached $455 billion in 2024 and is accelerating. Hyperscalers and AI-first companies alike are pouring billions into building out compute-ready capacity – not just for storage, but for real-time inference and model training workloads that require dense, high-power hardware. As AI moves from experimental to essential, so too do data centers. Per NVIDIA Co-Founder and CEO Jensen Huang, These AI data centers…are, in fact, AI factories. That race is moving faster than many expected. The most striking example may be xAI’s Colossus facility in Memphis, Tennessee which went from a gutted factory to a fully operational AI data center in just 122 days. As noted on page 122, at 750,000 square feet – roughly the size of 418 average USA homes – it was built in half the time it typically takes to construct a single American house. Per NVIDIA Co-Founder & CEO Jensen Huang, What they achieved is singular, never been done before…That is, like, superhuman… 119 Data Centers = Key Beneficiary of AI CapEx Spend …These kinds of timelines are no longer the exception. With prefabricated modules, streamlined permitting, and vertical integration across electrical, mechanical, and software systems, new data centers are going up at speeds that resemble consumer tech cycles more than real estate development. But beneath that velocity lies a capital model that’s anything but simple. CapEx is driven by land, power provisioning, chips, and cooling infrastructure – especially as AI workloads push thermal and power limits far beyond traditional enterprise compute. OpEx, by contrast, is dominated by energy costs and systems maintenance, particularly for high-density training clusters that operate near constant load. Revenue is driven by compute sales – whether in the form of AI APIs, enterprise platform fees, or internal productivity gains. But payback periods are often long, especially for vertically-integrated players building ahead of demand. For newer entrants, monetization may lag build-out by quarters or even years. And then there’s the supply chain. Power availability is becoming more of a gating factor. Transformers, substations, turbines, GPUs, cables – these aren’t commodities that can be spun up overnight. In this context, data centers aren’t just physical assets – they are strategic infrastructure nodes. They sit at the intersection of real estate, power, logistics, compute, and software monetization. The companies that get this right may do more than run servers – they will shape the geography of AI economics for the next decade. 120 Data Center Buildout Construction Value, USA = +49% & Accelerated Annual Growth Over Two Years Note: All data are seasonally adjusted. Data obtained via USA Census Bureau’s Value of Construction Put in Place (VIP) Survey, which provides monthly estimates of the total dollar value of construction work done in USA. Data is annualized to avoid seasonal fluctuations. Source: USA Census Bureau $0 $10 $20 $30 $40 1/14 1/15 1/16 1/17 1/18 1/19 1/20 1/21 1/22 1/23 1/24 Annualized Value of Private Construction, $B 12/24 +28% / Year +49% / Year Data Centers = Key Beneficiary of AI CapEx Spend USA Data Center Annualized Private Construction Value ($B) – 1/14-12/24, per USA Census Bureau 121 Data Center New Construction vs. Existing Capacity, USA = +16x in New vs. +5x in Existing Over Four Years Note: Primary USA markets only (Northern Virginia, Atlanta, Chicago, Phoenix, Dallas-Ft. Worth, Hillsboro, Silicon Valley, New York Tri-State.) Source: CBRE, ‘North America Data Center Trends H2 2024’ (2/25) Data center Capacity, Megawatts 0 4,000 8,000 12,000 2020 2021 2022 2023 2024 Net Absorption Pre-Leased or Under Construction Existing capacity but newly-filled New capacity +16x +5x Data Centers = Key Beneficiary of AI CapEx Spend Data Center Capacity (Megawatts) by Real Estate Profile, USA Primary Markets – 2020-2024, per CBRE 122 Data Center Build Time (xAI Colossus as Proxy) = 122 Days vs. 234 for a Home Note: Median USA home size shown as of January 2025, per FRED. Colossus was built in a former Electrolux factory in Memphis, TN, USA. Average build time shown for single-unit buildings. Measures time between start of onsite work & completion. Data reported in 2024 but measures build times for homes started in 2023. Source: xAI, USA Census Bureau, Federal Reserve Bank of St. Louis, Wikimedia Commons 122 Days = A Fully-Operational Data Center – 2024… 750,000 Sq. Ft = Size of 418 USA Homes 122 Days = One Half-Built House – 2024 (Average Build Time = 234 Days) 750,000 Square Feet 1,792 Square Feet We were told it would take 24 months to build. So we took the project into our own hands, questioned everything, removed whatever was unnecessary, and accomplished our goal in four months. - xAI Website Data Centers = Key Beneficiary of AI CapEx Spend 123 Data Center Compute (xAI Colossus as Proxy) = 0 to 200,000 GPUs in Seven Months Data Centers = Key Beneficiary of AI CapEx Spend xAI Colossus GPUs – 4/24-11/24, per xAI Note: We assume 200,000 GPUs as of 11/30/24 per xAI’s disclosure that ‘we doubled [GPU count] in 92 days to 200K GPUs.’ xAI Colossus ran its first job across 4 data halls on 8/30/24. We assume zero GPUs as of construction start date (122 days prior to assumed opening date of 8/30/24). Source: xAI (5/25), Memphis Chamber of Commerce (12/24) We’re running the world’s biggest supercomputer, Colossus. Built in 122 days – outpacing every estimate – it was the most powerful AI training system yet. Then we doubled it in 92 days to 200k GPUs. This is just the beginning… …We doubled our compute at an unprecedented rate, with a roadmap to 1M GPUs. Progress in AI is driven by compute and no one has come close to building at this magnitude and speed. - xAI Website, 5/25 GPUs, K xAI Colossus GPUs (K) 0K 100K 200K 0 100 200 4/24 8/24 11/24 xAI ultimately plans on 1MM GPUs, per Memphis Chamber of Commerce 124 Data Centers = Electricity Guzzlers 125 Data Centers = Electricity Guzzlers AI and energy observations / quotes (in italics) here and the two pages that follow are from ‘World Energy Outlook Special Report – Energy and AI’ (link) from IEA (International Energy Agency)* – 4/10/25 To understand where energy infrastructure is heading, it helps to examine the rising tension between AI capability and electrical supply. The growing scale and sophistication of artificial intelligence is demanding an extraordinary amount of computational horsepower, primarily from AI-focused data centers. These facilities – purpose-built to train and serve models – are starting to rival traditional heavy industry in their electricity consumption. There is no AI without energy – specifically electricity (p. 3). Data centers accounted for around 1.5% of the world’s electricity consumption in 2024 (p. 14). Energy demand growth has been rapid: Globally, data centre electricity consumption has grown by around 12% per year since 2017, more than four times faster than the rate of total electricity consumption (p. 14). As power demand rises, so too does its concentration: The United States accounted for…[45% of global data centre electricity consumption], followed by China (25%) and Europe (15%)… nearly half of data centre capacity in the United States is in five regional clusters (p. 14). The flipside is true as well: Emerging and developing economies other than China account for 50% of the world’s internet users but less than 10% of global data centre capacity (p. 18)… 126 Data Centers = Electricity Guzzlers …AI’s power demands are increasing – and its progress is increasingly bottlenecked not by data or algorithms, but by the grid and strains related to demand. While AI presently places considerable demands on the energy sector, it is also already unlocking major energy efficiency and operational gains… AI is already being deployed by energy companies to transform and optimize energy and mineral supply, electricity generation and transmission, and energy consumption (p. 16). Current AI-driven demand is extremely high. This is forecast to continue, especially as capital gushes into model providers that, in turn, spend on more compute. At some point, these model builders will need to turn a profit to be able to spend more. While demand – for both compute and energy – will inevitably continue to rise as consumer and business usage does the same, data centers will ultimately only serve those who pay their bills. *IEA member countries include Australia, Austria, Belgium, Canada, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Ireland, Italy, Japan, S. Korea, Latvia, Lithuania, Luxembourg, Mexico, Netherlands, New Zealand, Norway, Poland, Portugal, Slovak Republic, Spain, Sweden, Switzerland, Republic of Türkiye, United Kingdom, and United States. IEA Association countries include Argentina, Brazil, China, Egypt, India, Indonesia, Kenya, Morocco, Senegal, Singapore, S. Africa, Thailand, and Ukraine. All data shown, unless otherwise specified, is global. Italicized text is directly quoted from the report. 127 Data Center Electricity Consumption, Global = +3x Over Nineteen Years, per IEA Data Center Energy Consumption by Data Center Type & Equipment, Global – 2005-2024, per IEA Source: International Energy Agency (IEA), ‘Energy and AI’ (4/25) Data Centers = Electricity Guzzlers 128 Data Center Electricity Consumption by Region = USA Leads, per IEA Data Center Electricity Consumption by Region – 2005-2024, per IEA Source: International Energy Agency (IEA), ‘Energy and AI’ (4/25) Data Centers = Electricity Guzzlers • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 129 1 2 3 4 5 6 7 8 Outline 130 AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising To understand where AI model economics may be heading, one can look at the mounting tension between capabilities and costs. Training the most powerful large language models (LLMs) has become one of the most expensive / capital-intensive efforts in human history. As the frontier of performance pushes toward ever-larger parameter counts and more complex architectures, model training costs are rising into the billions of dollars. Ironically, this race to build the most capable general-purpose models may be accelerating commoditization and driving diminishing returns, as output quality converges across players and differentiation becomes harder to sustain. At the same time, the cost of applying/using these models – known as inference – is falling quickly. Hardware is improving – for example, NVIDIA’s 2024 Blackwell GPU consumes 105,000x less energy per token than its 2014 Kepler GPU predecessor. Couple that with breakthroughs in models’ algorithmic efficiency, and the cost of inference is plummeting. Inference represents a new cost curve, and – unlike training costs – it’s arcing down, not up. As inference becomes cheaper and more efficient, the competitive pressure amongst LLM providers increases – not on accuracy alone, but also on latency, uptime, and cost-per-token*. What used to cost dollars can now cost pennies. And what cost pennies may soon cost fractions of a cent. The implications are still unfolding. For users (and developers), this shift is a gift: dramatically lower unit costs to access powerful AI. And as end-user costs decline, creation of new products and services is flourishing, and user and usage adoption is rising. For model providers, however, this raises real questions about monetization and profits. Training is expensive, serving is getting cheap, and pricing power is slipping. The business model is in flux. And there are new questions about the one-size-fits-all LLM approach, with smaller, cheaper models trained for custom use cases** now emerging. Will providers try to build horizontal platforms? Will they dive into specialized applications? Only time will tell. In the short term, it’s hard to ignore that the economics of general-purpose LLMs look like commodity businesses with venture-scale burn. *Cost-per-token = The expense incurred for processing or generating a single token (a word, sub-word, or character) during the operation of a language model. It is a key metric used to evaluate the computational efficiency and cost-effectiveness of deploying AI models, particularly in applications like natural language processing. **E.g., OpenEvidence 131 AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 132 AI Model Training Compute Costs = ~2,400x Growth Over Eight Years, per Epoch AI & Stanford Note: Costs are estimates. Excludes most Chinese models due to lack of reliable cost data. Source: Epoch AI via Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25); In Good Company podcast (6/24) Estimated Training Cost of Frontier AI Models – 2016-2024, per Epoch AI & Stanford Training Cost, USD (Log Scale) Approx. +2,400x Right now, [AI model training costs] $100 million. There are models in training today that are more like a billion. Right. I think if we go to $10 or $100 billion, and I think that will happen in 2025, 2026, maybe 2027… …I think that the training of…$10 billion models, yeah, could start sometime in 2025. - Anthropic Co-Founder & CEO Dario Amodei (6/24) AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 133 AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 134 To understand the trajectory of AI compute, it helps to revisit an idea from the early days of PC software. ‘Software is a gas…it expands to fill its container,’ said Nathan Myhrvold, then CTO of Microsoft in 1997. AI is proving no different. As models get better, usage increases – and as usage increases, so does demand for compute. We’re seeing it across every layer: more queries, more models, more tokens per task. The appetite for AI isn't slowing down. It’s growing into every available resource – just like software did in the age of desktop and cloud. But infrastructure is not just standing still. In fact, it's advancing faster than almost any other layer in the stack, and at unprecedented rates. As noted on page 136, NVIDIA’s 2024 Blackwell GPU uses 105,000 times less energy to generate tokens than its 2014 Kepler predecessor. It’s a staggering leap, and it tells a deeper story – not just of cost reduction, but of architectural and materials innovation that is reshaping what’s possible at the hardware level. These improvements in hardware efficiency are critical to offset the strain of increasing AI and internet usage on our grid. So far, though, they have not been enough. This trend aligns with Jevons Paradox, first proposed back in 1865* – that technological advancements that improve resource efficiency actually lead to increased overall usage of those resources. This is driving new focus on expanding energy production capacity – and new questions about the grid’s ability to manage. Yet again, we see this as one of the perpetual ‘a-ha’s’ of technology: costs fall, performance rises, and usage grows, all in tandem. This trend is repeating itself with AI. *British economist William Stanley Jevons first observed this phenomenon in 19th-century Britain, where he noticed that improvements in the efficiency of coal-powered steam engines were not reducing coal consumption but rather increasing it. In his book The Coal Question, he noted ‘It is wholly a confusion of ideas to suppose that the economical use of fuel is equivalent to diminished consumption. The very contrary is the truth.’ AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 135 AI Inference ‘Currency’ = Tokens *Assumes that the average ChatGPT interaction consumes 200 total tokens (input + output), or 150 words. Thus, 1MM tokens equates to roughly 5,000 ChatGPT responses. Source: OpenAI (1/25) Additional context: 1MM tokens = ~750,000 words…roughly • 3,500 pages of a standard book (12-point font, double-spaced) • 5,000 ChatGPT responses* AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 136 AI Inference Costs – NVIDIA GPUs = -105,000x Decline in Energy Required to Generate Token Over Ten Years Energy Consumption per Token (Joules) AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 0 25,000 50,000 Kepler (2014) Pascal (2016) Volta (2018) Ampere (2020) Hopper (2022) Blackwell (2024) -105,000x Note: Kepler released in 2012. NVIDIA materials mark performance threshold shown above for Kepler as of 2014. Source: NVIDIA Company Overview (2/25) Energy Required per LLM Token (Joules), NVIDIA GPUs – 2014-2024, per NVIDIA 137 AI Inference Costs – Serving Models = 99.7% Lower Over Two Years, per Stanford HAI Source: Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) AI Inference Price for Customers (per 1 Million Tokens) – 11/22-12/24, per Stanford HAI Note: Axis is logarithmic; every axis tick represents a 10x price change AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 138 AI Cost Efficiency Gains = Happening Faster vs. Prior Technologies Note: Price change in consumer goods and services in the United States is measured as the percentage change since 1997. Data is based on the consumer price index (CPI) for national average urban consumer prices. Per OpenAI, 100 AI ‘tokens’ generates approximately 75 words in a large language model response; data shown indexes to this number of tokens. ‘Year 0’ is not necessarily the year that the technology was introduced, but rather the first year of available data. Source: Electricity Costs – Technology and Transformation in the American Electric Utility Industry, Richard Hirsh (1989); Computer Memory Storage Costs – John C. McCallum, with data aggregated from 72 primary sources and historical company sales documents; OpenAI, Wikimedia Commons Relative Cost of Key Technologies by Year Since Launch, per OpenAI, John McCallum, & Richard Hirsh 0% 25% 50% 75% 100% 0 20 40 60 80 Electric Power Computer Memory ChatGPT: 75-Word Response % of Original Price By Year (Indexed to Year 0) AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 139 Tech’s Perpetual A-Ha = Declining Costs + Improving Performance → Rising Adoption… Note: FRED data shows ‘Consumer Price Index for All Urban Consumers: Information Technology, Hardware and Services in U.S. City Average.’ Source: USA Federal Reserve Bank of St. Louis (FRED), International Telecommunications Union (via World Bank) (4/25) 0 25 50 75 100 0 100 200 300 400 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 USA Internet Users, MM (Blue Bars) USA Consumer Price Index: Information Technology, 1/1/89 = 100 (Red Line) AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising USA Internet Users (MM) vs. Relative IT Cost – 1989-2023, per FRED & ITU 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 0 10 20 30 40 50 60 70 80 90 100 140 …Tech’s Perpetual A-Ha = Prices Fall + Performance Rises Note: A petaFLOP/s-day represents the total computational work performed by a system operating at 1 petaFLOP/s (10¹⁵ floating-point operations per second) for 24 hours, equivalent to approximately 8.64 × 10¹⁹ operations. This metric is commonly used to quantify the compute required for large-scale tasks like training machine learning models. FRED data shows ‘Consumer Price Index for All Urban Consumers: Information Technology, Hardware and Services in U.S. City Average.’ Note that, while training compute is not a direct measurement of model performance, it is typically closely correlated with performance. Source: USA Federal Reserve Bank of St. Louis (FRED); Epoch AI (5/25) Notable AI Model Training Compute, FLOP (Scatter Plot) USA Consumer Price Index: Information Technology, 1/1/89 = 100 (Red Line) +360% / Year AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising AI Model Training Compute (FLOP) vs. Relative IT Cost – 1989-2024, per Epoch AI & FRED 141 AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 142 AI Model Performance = Converging Rapidly, per Stanford HAI Performance of Top AI Models on LMSYS Chatbot Arena – 1/24-2/25, per Stanford HAI Note: The LMSYS Chatbot Arena is a public website where people compare two AI chatbots by asking them the same question and voting on which answer is better. The results help rank how well different language models perform based on human judgment. Only the highest-scoring model in any given month is shown in this comparison. Source: Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) LMSYS Arena Score AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 143 AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 144 To understand the surge in AI developer activity, it’s instructive to look at the extraordinary drop in inference costs and the growing accessibility of capable models. Between 2022 and 2024, the cost-per-token to run language models fell by an estimated 99.7% – a decline driven by massive improvements in both hardware and algorithmic efficiency. What was once prohibitively expensive for all but the largest companies is now within reach of solo developers, independent app builders, researchers on a laptop, and mom-and-pop shop employees. The cost collapse has made experimentation cheap, iteration fast, and productization feasible for virtually anyone with an idea. At the same time, performance convergence is shifting the calculus on model selection. The gap between the top-performing frontier models and smaller, more efficient alternatives is narrowing. For many use cases – summarization, classification, extraction, or routing – the difference in real-world performance is negligible. Developers are discovering they no longer need to pay a premium for a top-tier model to get reliable outputs. Instead, they can run cheaper models locally or via lower-cost API providers and achieve functionally similar results, especially when fine-tuned on task-specific data. This shift is weakening the pricing leverage of model incumbents and leveling the playing field for AI development… AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising 145 AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising …At the platform level, a proliferation of foundation models has created a new kind of flexibility. Developers can now choose between dozens of models – OpenAI’s ChatGPT, Meta’s Llama, Mistral’s Mixtral, Anthropic’s Claude, Google’s Gemini, Microsoft’s Phi, and others – each of which excels in different domains. Some are optimized for reasoning, others for speed or code generation. The result is a move away from vendor lock-in. Instead of consolidating under a single provider who can gate access or raise prices, developers are distributing their efforts across multiple ecosystems. This plurality of options is empowering a new wave of builders to choose the best-fit model for their technical or financial needs. What’s emerging is a flywheel of developer-led infrastructure growth. As more developers build AI-native apps, they also create tools, wrappers and libraries that make it easier for others to follow. New front-end frameworks, embedding pipelines, model routers, vector databases, and serving layers are multiplying at an accelerating rate. Each wave of developer activity reduces the friction for the next, compressing the time from idea to prototype and from prototype to product. In the process, the barrier to building with AI is collapsing – not just in cost, but in complexity. This is no longer just a platform shift. It’s an explosion of creativity. Technology history has shown – as memorialized by then-Microsoft President Steve Ballmer’s repeat Developers! Developers! Developers… at a 2000 Microsoft Developers Conference (link) – the platform that gets the most consistent developer user and usage momentum – and can scale and steadily improve – wins. The AI Developer Next Door 146 147 AI Tool Adoption by Developers = 63% vs. 44% Y/Y Share of Developers Currently Using AI in Development Processes – 2023-2024, per Stack Overflow Note: 2023 N=89,184; 2024 N=65,437. Respondents are global. Source: Stack Overflow Developer Surveys (5/23 & 5/24-6/24) Share of Developers, % 0% 25% 50% 75% Professional Developers Learning to Code 2023 2024 The AI Developer Next Door 148 AI Developer Repositories – GitHub = ~175% Increase Over Sixteen Months Number of AI Developer Repositories* on GitHub – 11/22-3/24, per Chip Hyuen *A repository is an online storage space where developers share and manage code, models, data, and documentation related to artificial intelligence projects. These enable collaboration, reuse, and distribution of AI tools and assets. Analysis shown includes GitHub repositories with 500+ stars. Infrastructure = tools for model serving, compute management, vector search & databases. Model development = frameworks for modeling & training, inference optimization, dataset engineering, & model evaluation. Application development = custom AI-powered applications (varied use cases). Source: Chip Hyuen via GitHub (3/24) Cumulative Number of AI Repositories The AI Developer Next Door 149 AI Developer Ecosystem – Google = +50x Monthly Tokens Processed Y/Y Note: Token usage shown across Google products & APIs. Per Google in 5/25, ‘This time last year, we were processing 9.7 trillion tokens a month across our products and APIs. Now, we’re processing over 480 trillion — that’s 50 times more…Over 7 million developers are building with Gemini, five times more than this time last year.’ Source: Google, ‘Google I/O 2025: From research to reality’ (5/25) The AI Developer Next Door This time last year, we were processing 9.7 trillion tokens a month across our products and APIs. Now, we’re processing over 480 trillion – that’s 50 times more. - Google I/O 2025 Press Release, 5/25 Monthly Tokens Processed, Trillions Google Monthly Tokens Processed (T) – 5/24-5/25, per Google 10T 480T 0 250 500 5/24 5/25 150 AI Developer Ecosystem – Microsoft Azure AI Foundry = +5x Quarterly Tokens Processed Y/Y Note: Source: Microsoft FQ3:25 earnings call (4/25) Tokens Processed, Trillions The AI Developer Next Door [Microsoft Azure AI] Foundry is the agent and AI app factory. It is now used by developers at over 70,000 enterprises and digital natives – from Atomicwork, to Epic, Fujitsu, and Gainsight, to H&R Block and LG Electronics – to design, customize, and manage their AI apps and agents. We processed over 100 trillion tokens this quarter, up 5x year-over-year – including a record 50 trillion tokens last month alone. - Microsoft FQ3:25 Earnings Call, 4/25 Microsoft Azure AI Foundry Quarterly Tokens Processed (T) – Q1:24-Q1:25, per Microsoft 20T 100T 0 50 100 Q1:24 Q1:25 151 AI Developer Use Cases = Broad & Varied Note: CI / CD pipelines are continuous integration / continuous deployment pipelines. Source: IBM, ‘AI in Software Development’ (2024); Anthropic; Katalon; AccelQ; Monday; Quill; Mintlify; Snyk; Ansible; UX Pilot; Ark Design AI AI Developer Use Cases – 2024, per IBM Code Generation Bug Detection & Fixing Testing Automation Project / Workflow Management Documentation Refactoring & Optimization Security Enhancement DevOps & CI / CD Pipelines User Experience Design Architecture Design The AI Developer Next Door 152 AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising …(Likely) Long Way to Profitability • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 153 1 2 3 4 5 6 7 8 Outline 154 It’s different this time, we'll make it up on volume, and we’ll figure out how to monetize our users in the future are typically three of the biggest danger statements in business. That said, in technology investing every once in awhile they can be gold – Amazon, Alphabet (Google), Meta (Facebook), Tesla, Tencent, Alibaba, Palantir… In AI, it may indeed be different this time, and the leader(s) will make it up on volume and be able to monetize users in the future. Though now, ‘different this time’ also means that competition is unprecedented… We have never seen so many founder-driven / assisted (ex. Apple) companies* with market capitalizations in excess of $1 trillion – most with gross margins of +50% plus free cash flow – attacking the same opportunity at the same time in a relatively transparent world, adding in high stakes competition between global powers – China and the United States. Ernest Hemingway’s phrase gradually, then suddenly from ‘The Sun Also Rises’ applies to technology tipping points. The tipping point for personal computers was the introduction of Apple’s Macintosh (1984) and Microsoft’s Windows 3.0 (1990). With the Internet it was Netscape’s IPO (1995). With the Mobile Internet it was Apple’s iPhone App Store launch (2008). With Cloud Computing it was the launch of AWS (Amazon Web Services) foundational products (2006-2009). With AI it was the launch of NVIDIA’s A100 GPU chip (2020) and OpenAI’s public version of ChatGPT (2022). In effect, the global competition for AI kicked in with the launch of China’s DeepSeek (1/25) and Jack Ma’s attendance at Chinese President Xi Jinping’s symposium of Chinese business leaders (2/25). The money to fund AI’s growth (and losses) comes from big companies with big free cash flow and big balance sheets, in addition to wealthy and ambitious capital providers from around the world. No doubt, this dynamic combination of competition / capital / entrepreneurship will rapidly advance AI, a riddle is determining which business models will be the last ones standing. *Companies include NVIDIA, Microsoft, Amazon, Alphabet (Google), Meta (Facebook) & Tesla AI Usage + Cost + Loss Growth = Unprecedented 155 Technology Disruption Pattern Recognition = Hundreds of Years of Consistent Signals AI Usage + Cost + Loss Growth = Unprecedented Technology disruption has a long-repeating rhythm: early euphoria, break-neck capital formation, bruising competition, and – eventually – clear-cut winners and losers. Alasdair Nairn’s ‘Engines That Move Markets’ (link here) distills two centuries of such cycles, and his observations are prescient for today’s AI boom. Highlights of his observations follow… There were several years of strong share-price growth when the railways were supplanting canals. The bubble of the 1840s deflated under the weight of overheated expectations and changing economic conditions… …Any technological advance which requires huge capital expenditure always runs a real risk of disappointing returns in the early years, even if it is ultimately successful... …Any technology that necessitates heavy capital expenditure and requires returns to be earned over an extended period is always going to be a high-risk undertaking – unless, that is, there is some form of protection against competition... …The winners of these competitive struggles are not always those who have the best technology, but those who can most clearly see the way that an industry or market is likely to develop… …One of the clearest lessons of corporate and investment history is that without some barrier to entry, first-mover advantage can be swiftly lost… …A theme that recurs throughout this research is that while identifying the winners from any new technology is often perilous and difficult, it is almost invariably simpler to identify who the ‘losers’ are going to be. 156 AI-Related Monetization = Very Robust Ramps 157 To understand the evolution of AI hardware strategy, we’ll look at how control over chip design is shifting from traditional vendors to the platforms that rely on them. For years, NVIDIA has been at the center of the AI hardware stack. Its GPUs (graphics processing units) became the default engine for training and inference, prized for their ability to handle highly parallel computations at scale. Its proprietary technology – and unparalleled scale – has led to industry leadership. This reliance – combined with outsized sudden demand – has created constraints. Despite NVIDIA’s rapid – and impressive – scale-up, demand for NVIDIA GPUs has outpaced supply amid industry fervor for accelerated computing. Hyperscalers and cloud providers are moving to improve their supply chains to manage long lead times. That shift is accelerating the rise of custom silicon – especially ASICs, or application-specific integrated circuits. Unlike GPUs, which are designed to support a wide range of workloads, ASICs are purpose-built to handle specific computational tasks with maximum efficiency. In AI, that means optimized silicon for matrix multiplication, token generation, and inference acceleration. Google’s TPU (Tensor Processing Unit) and Amazon’s Trainium chips are now core components of their AI stacks. Amazon claims its Trainium2 chips offer 30-40% better price-performance than standard GPU instances, unlocking more affordable inference at scale. These aren't side projects – they’re foundational bets on performance, economics, and architectural control… AI-Related Monetization = Very Robust Ramps 158 …Custom chips also reflect a broader effort to manage the economics of AI infrastructure. As Amazon CEO Andy Jassy noted in early 2025, AI does not have to be as expensive as it is today, and it won’t be in the future. Custom silicon is one lever to control these expenses. At the same time, a new ecosystem of infrastructure specialists is emerging to meet this demand. CoreWeave has become one of the fastest-scaling cloud GPU providers, repurposing gaming and Crypto hardware supply chains to serve enterprise AI customers. Oracle, long seen as a legacy IT vendor, has repositioned itself as a GPU-rich cloud platform with AI-specific offerings. Astera Labs, a lesser-known but critical player, builds high-speed interconnects that move data between GPUs and memory systems with minimal latency – an increasingly important performance constraint. These firms aren’t building foundation models, but they’re building what foundation models depend on. As compute demand compounds, they’re becoming essential infrastructure in a market where speed, availability, and efficiency are important differentiators. AI-Related Monetization = Very Robust Ramps 159 AI Monetization = Chips 160 AI Monetization…Chips = NVIDIA Quarterly Revenue +78% to $39B Y/Y… NVIDIA Quarterly Revenue, $MM Note: Gaming includes PC & console gaming. Other includes Enterprise / Pro Vis, Auto, & OEM / Other. NVIDIA’s fiscal year ends January 31. The figures in the title compare FQ4:25 to FQ4:24. Source: NVIDIA (1/25) via Morgan Stanley $0 $10,000 $20,000 $30,000 $40,000 Data Center Gaming Other Fiscal Quarter Ending AI Monetization = Chips +78% Y/Y NVIDIA Quarterly Revenue by Business Line ($B) – 1/19-1/25, per NVIDIA 161 …AI Monetization…Chips = NVIDIA Revenue +28x Over Ten Years…Big Six CapEx + R&D +6x *Note: Big Six USA technology companies include Apple, Nvidia, Microsoft, Alphabet / Google, Amazon, & Meta Platforms / Facebook. Includes CapEx for Amazon AWS + Retail as R&D expense is not regularly separated for those two business divisions. Source: Companies’ investor reports, Capital IQ (4/25) Big Six R&D + CapEx Spend, $B (Blue Bar) NVIDIA Revenue, $B (Red Line) $0 $30 $60 $90 $120 $150 $0 $100 $200 $300 $400 $500 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 AI Monetization = Chips Big Six* USA Public Technology Company R&D + CapEx Spend ($B) vs. NVIDIA Revenue ($B) – 2014-2024, per Capital IQ 162 AI Monetization…Chips = Google TPU Sales* +116% to $8.9B Y/Y, per Morgan Stanley *Figures are estimates per Morgan Stanley research. Note: Relative to GPUs, ASICs are custom-designed for specific tasks (e.g., AI model training,) whereas GPUs are general- purpose. Source: Google, Morgan Stanley, ‘GenAI Monetization – Assessing The ROI Equation’ (2/25) TPUs were purpose-built specifically for AI. TPUs are an application-specific integrated circuit (ASIC), a chip designed for a single, specific purpose: running the unique matrix and vector-based mathematics that’s needed for building and running AI models. Our first such chip, TPU v1, was deployed internally in 2015 and was instantly a hit across different parts of Google… …‘We thought we'd maybe build under 10,000 of them,’ said Andy Swing, principal engineer on our machine learning hardware systems. ‘We ended up building over 100,000.’ - Google Press Release, 7/24 Estimated Annual Sales, $B $0 $5 $10 2021 2022 2023 2024 AI Monetization = Chips Google TPU (Tensor Processing Unit) Estimated Sales – 2021-2024, per Morgan Stanley Google TPU Estimated Sales ($B) 163 AI Monetization…Chips = Amazon AWS Trainium* Sales +216% to $3.6B Y/Y, per Morgan Stanley Note: Relative to GPUs, ASICs are custom-designed for specific tasks (e.g., AI model training,) whereas GPUs are general-purpose. Figures are estimates per Morgan Stanley research. Source: Amazon AWS, Morgan Stanley, ‘GenAI Monetization – Assessing The ROI Equation’ (2/25) Amazon AWS Trainium Estimated Sales – 2024-2025, per Morgan Stanley AWS Trainium chips are a family of AI chips purpose built by AWS for AI training and inference to deliver high performance while reducing costs… AWS Trainium2 chip delivers up to 4x the performance of first-generation Trainium…[and offers] 30-40% better price performance than the current generation of GPU-based EC2 P5e and P5en instances. - Amazon AWS Trainium Overview, Accessed 5/25 Estimated Annual Sales, $B AI Monetization = Chips Amazon AWS Trainium Estimated Sales ($B) $1.1B $3.6B $0 $2 $4 2024 2025 164 AI Monetization = Compute Services 165 AI Monetization…Cloud Computing = CoreWeave Revenue +730% to $1.9B Y/Y CoreWeave Revenue – 2022-2024, per CoreWeave Source: CoreWeave (as of 5/25) We've delivered an outstanding start to 2025 on multiple fronts. Our strong first quarter financial performance caps a string of milestones including our IPO, our major strategic deal with OpenAI as well as other customer wins, our acquisition of Weights & Biases and many technical achievements… …Demand for our platform is robust and accelerating as AI leaders seek the highly performant AI cloud infrastructure required for the most advanced applications. We are scaling as fast as possible to capture that demand. The future runs on CoreWeave. - CoreWeave CEO Michael Intrator, 5/25 Revenue, $B AI Monetization = Compute Services $0 $1 $2 2022 2023 2024 Q1:25 revenues were $982MM: +420% Y/Y growth CoreWeave Revenue ($B) 166 AI Monetization…AI Infrastructure = Oracle Revenue +50x to $948MM Over Two Years Oracle AI Infrastructure Revenue – F2022-F2024, per Oracle & Morgan Stanley Estimates Source: Oracle, Morgan Stanley estimates, ‘What’s Ahead for the AI Infrastructure Cycle’ (8/24) There are many, many [AI infrastructure] customers who have come on and that haven't gotten capacity yet… …We've got at least 40 new AI bookings that are over a billion (dollars) that haven't come online yet. - Oracle CEO Safra Catz, 3/24 Revenue, $MM AI Monetization = Compute Services $0 $500 $1,000 F2022 F2023 F2024 Oracle AI Infrastructure Revenue ($MM), Estimated per Morgan Stanley 167 AI Monetization…Infrastructure Connectivity = Astera Labs Revenue +242% to $396MM Y/Y Astera Labs – 2022-2024, per Astera Labs Source: Astera Labs financial results (as of 4/25) Astera Labs delivered strong Q4 results, with revenue growing 25% versus the previous quarter, and capped off a stellar 2024 with 242% revenue growth year-over-year… …We expect 2025 to be a breakout year as we enter a new phase of growth driven by revenue from all four of our product families to support a diverse set of customers and platforms. This includes our flagship Scorpio Fabric products for head-node PCIe connectivity and backend AI accelerator scale-up clustering. - Astera Labs CEO Jitendra Mohan, 2/25 Revenue, $MM AI Monetization = Compute Services $0 $200 $400 2022 2023 2024 Astera Labs Revenue ($MM) 168 AI Monetization…Data Collection + Supercomputing = Tesla AI Training Capacity +8.5x Tesla Dojo Custom Supercomputer – 6/21-9/24, per Tesla Note: Listing capacity in ‘H100-equivalent GPUs’ means Tesla converts the aggregate AI-training throughput of Dojo and its other accelerators into the number of NVIDIA Hopper H100 data-center GPUs that would deliver the same FP8/FP16 FLOPS, giving a single, industry-standard yard-stick for compute scale. Source: Tesla Q1:23 earnings call, Tesla Q3:24 investor presentation, Data Center Dynamics, Wikimedia Commons Tesla AI Training Capacity, H100 Equivalent GPUs We’re continuing to simultaneously make significant purchases of GPUs and also putting a lot of effort into Dojo [custom supercomputer], which we believe has the potential for an order of magnitude improvement in the cost of training… …Dojo also has the potential to become a sellable service that we would offer to other companies, in the same way that Amazon Web Services offers more web services, even though it started out as a bookstore. So, I really think that the Dojo potential is very significant. - Tesla Co-Founder & CEO Elon Musk, 4/23 AI Monetization = Compute Services Tesla AI Training Capacity (H100-Equivalent GPUs) 169 AI Monetization = Data Layer 170 AI Monetization…Data Labeling & Evaluation = Scale AI Revenue +160% to $870MM Y/Y Scale AI Revenue – 2023-2024, per Scale AI Note: 2023 figures are estimates based on Joe Osborne (Head of Corporate and Product Comms at Scale AI,) who indicated, ‘We saw 160% revenue growth in 2024 from the previous year, and we secured more than $1.5 billion in new business.’ Source: Scale AI, The Information (4/25) (link) Data abundance is not the default; it’s a choice. It requires bringing together the best minds in engineering, operations, and AI. Our vision is one of data abundance, where we have the means of production to continue scaling frontier LLMs many more orders of magnitude. We should not be data-constrained in getting to GPT-10. - Scale AI Co-Founder & CEO Alexandr Wang, 5/24 Revenue, $MM AI Monetization = Data Layer We saw 160% revenue growth in 2024 from the previous year, and we secured more than $1.5 billion in new business. - Scale AI Head of Corporate and Product Comms Joe Osborne, 4/25 Scale AI Revenue ($MM) $335MM $870MM $0 $500 $1,000 2023 2024 171 AI Monetization…Data Storage / Management / Processing = VAST Data Lifetime Sales From 0 to $2B in Just Over Six Years VAST Data – 1/19-5/25, per VAST Data Source: VAST Data, Silicon Angle Everything is accelerating. The rate of AI progress is constantly increasing as model builders build on each other’s discoveries and push the boundaries ever farther. While we’ve been talking about thinking machines since early 2022, the advent of reasoning models in the last 12 months means that the era of thinking machines is actually now upon us… …We at VAST believe that the path to the greatest potential gain is to simplify and reduce the fundamental challenges that need to be resolved. If we can build a simple approach to encompass nearly all of the infrastructure layers needed for AI, without compromise… customers supremely benefit. - VAST Data CEO Renen Hallak, 5/25 AI Monetization = Data Layer Cumulative Lifetime Sales ($B) Cumulative Lifetime Sales, $B $0B $2B $0 $1 $2 1/19 5/25 172 AI-Related Cost Ramps Relative to Revenue = Can Be Head-Turning 173 AI Monetization – OpenAI = Revenue vs. Compute Expense, per The Information Note: No compute expense data available in 2022. Figures are estimates based off public reports & The Information reporting. Source: The Information (4/25 and prior) (link, link, link, link, link & link) AI-Related Cost Ramps Relative to Revenue = Can Be Head-Turning OpenAI Revenue, $B (Blue Line) -$5 $0 $5 2022 2023 2024 OpenAI Compute Expense, $B (Red Line) OpenAI Revenue & Compute Expense ($B) by Year – 2022-2024, per The Information AI Monetization – Microsoft / Amazon / Alphabet / Meta = CapEx Up…Free Cash Flow Margins Down 174 Capital Expenditure, Free Cash Flow Margin, Revenue Growth – C2023-C2024, per Capital IQ Note: FCF calculated as cash flow from operations less capex to standardize, as only some companies subtract finance leases and Amazon adjusts FCF for gains on sale of equipment. Amazon statistics shown for both AWS & Retail; FCF not broken out across subsidiaries. Source: Capital IQ (5/25) CapEx Free Cash Flow Margin Revenue Microsoft Amazon Alphabet (Google) Meta Platforms (Facebook) $35B $56B +58% $53B $83B +57% $32B $52B +63% $27B $37B +38% vs. 30% 27% -10% 6% 5% -8% 23% 21% -8% 33% 33% <1% $228B $262B +15% $575B $638B +11% $307B $350B +14% $135B $165B +22% C2023 C2024 Y/Y Change C2023 C2024 Y/Y Change C2023 C2024 Y/Y Change C2023 C2024 Y/Y Change AI-Related Cost Ramps Relative to Revenue = Can Be Head-Turning 175 So…We Have… High Revenue Growth + High Cash Burn + High Valuations + High Investment Levels = Good News for Consumers… Others TBD… 176 *Select media reports have xAI revenue being as high as $1B as of 4/25. Note: OpenAI annualized revenue estimated based upon full-year 2024 & 2025 revenue estimates as published by The Information & Bloomberg, assuming linear revenue growth. Figures are rounded. Source: Source: Pitchbook (5/25), The Information (link), Bloomberg (link & link) & CNBC (link & link) Foundation Model Estimated Revenue & Capital Raised – 5/13/25, per Pitchbook, The Information, Bloomberg, The Wall Street Journal & CNBC Select Private AI Model Companies – 5/13/25 = ~$11B+ Annualized Revenue vs. ~$95B Raised… So…We Have…High Revenue Growth + High Cash Burn + High Valuations + High Investment Levels = Good News for Consumers…Others TBD… Company Annualized Revenue ($MM) Total Raised To-Date ($MM) 9,200 (4/25 estimated) 2,000 (3/25) 120 (5/25) 63,920 (Last Raise: 3/25) 18,000 (Last Raise: 3/25) 1,410 (Last Raise: 5/25) OpenAI Anthropic Perplexity 12,130 (Last Raise: 11/24) xAI Materially North of 100* (4/25) 177 Foundation Model Estimated Revenue Multiple – 5/13/25, per Pitchbook, The Information, Bloomberg, The Wall Street Journal & CNBC …Select Private AI Model Companies – 5/13/25 = High Valuation-to-Revenue Multiples So…We Have…High Revenue Growth + High Cash Burn + High Valuations + High Investment Levels = Good News for Consumers…Others TBD… *Select media reports have xAI revenue being as high as $1B as of 4/25. Note: OpenAI annualized revenue estimated based upon full-year 2024 & 2025 revenue estimates as published by The Information & Bloomberg, assuming linear revenue growth. xAI valuation per Elon Musk. Figures are rounded. Perplexity was reported to be in advanced talks to raise capital at a $14B post-money valuation as of 5/14/25; however, as this is not finalized at time of publication, we quote their last finalized funding round here. Source: Pitchbook (5/25), The Information (link), Bloomberg (link & link) & CNBC (link & link) Annualized Revenue ($MM) Revenue Multiple 9,200 (4/25 estimated) 2,000 (3/25) 120 (5/25) 33x 31x 75x Latest Valuation ($MM) 300,000 (3/25) 61,500 (3/25) 80,000 (3/25) 9,000 (12/24) Company OpenAI Anthropic xAI Perplexity N/A Materially North of 100* (4/25) 178 Note: OpenAI figures are estimates. Next 12 months revenue multiples for companies other than OpenAI are consensus estimates per Capital IQ. OpenAI NTM revenue estimates are as of 12/24 due to data availability. Source: Capital IQ (5/15/25), Bloomberg (link) Valuation-to-Revenue Multiple – OpenAI = Looks Expensive… 0x 5x 10x 15x 20x 25x OpenAI Duolingo Meta Spotify Alphabet Pinterest Enterprise Value / Next 12 Months Revenue Estimated Enterprise Value / Next 12 Months Revenue Multiple – 5/25, per Capital IQ & Bloomberg Median = 6.9x So…We Have…High Revenue Growth + High Cash Burn + High Valuations + High Investment Levels = Good News for Consumers…Others TBD… 179 …Revenue-per-User Multiple – OpenAI = In-the-Range Note: OpenAI figures are estimates as of 4/25. All other public-company figures are as of 12/31/24, using CY2024 data. OpenAI data uses WAUs due to data availability (conservatively assumed as MAUs); other figures use MAUs. Here we assume average weekly active ChatGPT users of 300MM based off OpenAI’s 12/24 disclosure. We estimate 2024 ChatGPT revenue of $3.7B, per company estimates. Monthly active user figures are estimates for Alphabet based off website traffic measurements & global internet user data. Meta last reported MAPs for app family in Q4:23, we conservatively assume no growth since. Source: Capital IQ (12/24), The Information (4/25 and prior) (link, link, link, link & link), Semrush (11/24), Morgan Stanley, ITU, company disclosures, BOND estimates Annual Revenue per User, $ $0 $20 $40 $60 $80 OpenAI Alphabet Meta Spotify Pinterest Duolingo Median = $23 So…We Have…High Revenue Growth + High Cash Burn + High Valuations + High Investment Levels = Good News for Consumers…Others TBD… OpenAI sees high valuation despite mid-pack annual revenue per user Estimated Annual Revenue Per User ($) – 2024, per Capital IQ, Morgan Stanley, Semrush, The Information & Company Disclosures 180 So…We Have…High Revenue Growth + High Cash Burn + High Valuations + High Investment Levels = Good News for Consumers…Others TBD… As global digital user bases have grown and potential rapidity of usage traction has risen in tandem, areas of corporate investment (for companies new and old) have become increasingly competitive and capital-intensive. The AI tech cycle of creative disruption has historical analogs. Head turners of the semi-recent past include Apple’s near bankruptcy in 1997 when its market capitalization was $1.7B*, now $3.2T. Amazon.com’s near death moment happened in Q4:00 when it reported a net loss of -$545MM on revenue of $972MM. Founder and then-CEO Jeff Bezos noted in the 2000 Shareholder Report that It’s been a brutal year for many in the capital markets and certainly for Amazon.com shareholders. As of this writing, our shares are down more than 80% from when I wrote you last year. At post-loss trough in Q3:01 its market cap was $2.2B while it supported 23MM active customer accounts. The market cap is now $2.2T. All in, Amazon lost -$3B in the twenty-seven quarters between its launch in Q2:97 and the end of its first net income-positive year (2003). For its most recent twenty-seven most recent quarters (Q3:18-Q1:25), Amazon’s cumulative net income was $176B. Google’s IPO filing (April 2004) noted that in Q1:04, after having only raised a Series A funding round, it spent 22% of revenue ($86MM of $390MM) on capital expenditures – at the time it was an incomprehensibly high number. It went public at a $23B market cap, now $2.0T… *Market capitalization taken as of 7/1/97. Microsoft finalized its investment in Apple just over one month later, on 8/6/97. Note: Present market capitalization figures are shown as of 5/14/25. 181 So…We Have…High Revenue Growth + High Cash Burn + High Valuations + High Investment Levels = Good News for Consumers…Others TBD… …Uber burned -$17B* between 2016 and 2022 (and materially more before that) before its first free cash flow-positive year in 2023. In 2022, it had 131MM monthly active platform consumers. Uber’s last equity financing was a Series G. Its fully-diluted IPO market cap was $82B, now $189B. Tesla burned -$9.2B between 2009 and 2018 before becoming free cash flow positive in 2019. In the ten years between 2009 and 2018, it lost a cumulative -$5.6B delivering ~540K vehicles. It went public in 2010 at a market cap of $1.6B. From 2019-2024, it then earned $40B delivering 6.7MM vehicles. Its market cap is now $1.1T. It is important to remember – most of the time, when all is said and done – a business’s valuation should represent the present value of its future free cash flows. The aforementioned companies – with aggressive cash burn – tested this premise hard, built large-scale data-driven network effects based on product excellence / constant improvement, developed technology-driven competitive advantage and ultimately proved the naysayers wrong. Only time will tell which side of the money-making equation the current AI aspirants will land. *Measured as unlevered free cash flow. Note: Present market capitalization figures are shown as of 5/14/25. 182 Usage + Cost + Loss Growth = Unprecedented… What About Future Monetization + Profits? 183 AI Monetization Possibilities = New Entrants & / Or Tech Incumbents? 184 Consumer AI Monetization Possibilities = New Entrants & / Or Tech Incumbents? To understand where AI model economics may be heading, one can look at the mounting tension between capabilities and costs. Training the most powerful large language models (LLMs) has become one of the most expensive / capital-intensive efforts in human history. As the frontier of performance pushes toward ever-larger parameter counts and more complex architectures, model training costs are rising into the billions of dollars. Ironically, this race to build the most capable general-purpose models may be accelerating commoditization and driving diminishing returns, as output quality converges across players and differentiation becomes harder to sustain. At the same time, the cost of applying/using these models – known as inference – is falling quickly. Hardware is improving – for example, NVIDIA’s 2024 Blackwell GPU consumes 105,000x less energy per token than its 2014 Kepler GPU predecessor. Couple that with breakthroughs in models’ algorithmic efficiency, and the cost of inference is plummeting. Inference represents a new cost curve, and – unlike training costs – it’s arcing down, not up. As inference becomes cheaper and more efficient, the competitive pressure amongst LLM providers increases – not on accuracy alone, but also on latency, uptime, and cost-per-token*. What used to cost dollars can now cost pennies. And what cost pennies may soon cost fractions of a cent… *Cost-per-token = The expense incurred for processing or generating a single token (a word, sub-word, or character) during the operation of a language model. It is a key metric used to evaluate the computational efficiency and cost-effectiveness of deploying AI models, particularly in applications like natural language processing. 185 Consumer AI Monetization Possibilities = New Entrants & / Or Tech Incumbents? …The implications are still unfolding. For users (and developers), this shift is a gift: dramatically lower unit costs to access powerful AI. And as end-user costs decline, creation of new products and services is flourishing, and user and usage adoption is rising. For model providers, however, this raises real questions about monetization and profits. Training is expensive, serving is getting cheap, and pricing power is slipping. The business model is in flux. And there are new questions about the one-size-fits-all LLM approach, with smaller, cheaper models trained for custom use cases* now emerging. Additionally, traditional business moats are being disrupted. Look no further than Google. The company launched AI Overviews in May of last year – they sit above many Google search results. The company highlighted it had 1.5B AI Overviews MAUs as of 4/25…it’s notable that in the last few weeks, Google began adding advertisements to select AI Overviews. Will providers try to build horizontal platforms? Will they dive into specialized applications? Will one or two leaders drive dominant user and usage share and related monetization, be it subscriptions (easily enabled by digital payment providers), digital services, ads, etc.? Only time will tell. In the short term, it’s hard to ignore that the economics of general-purpose LLMs look like commodity businesses with venture-scale burn. *E.g., OpenEvidence 186 Specializations of Ten Leading AI Companies – 4/25, per The Wall Street Journal *Has a partnership with Oracle, SoftBank and MGX to build out the proposed Stargate data-center network. Source: Wall Street Journal, ‘Here’s How Big the AI Revolution Really Is, in Four Charts’ (4/25) Developing Models & Chatbots All 10 of these companies are building generative- AI tools that can create content including text, images and video. Building AI Infrastructure These seven companies – both tech giants and AI upstarts – are also building the hardware and data centers that provide the power and infrastructure needed to run AI systems. Providing AI Cloud Services The top cloud providers offer platforms that help businesses leverage AI tech in their own products and workflows. Consumer AI Monetization Possibilities = New Entrants & / Or Tech Incumbents? AI Company Landscape = Varying Degrees of Vertical Integration 187 AI Monetization Possibilities = New Entrants & / Or Tech Incumbents? 188 AI – New Entrants = Rapidly Laying Groundwork 189 AI Monetization…Foundation Models = Consumer Subscription Models Driving Monetization… OpenAI ChatGPT, xAI Grok, Google Gemini, Anthropic Claude & Perplexity Consumer Pricing – 5/25, per Companies OpenAI ChatGPT $0 (Free) / $20 (Plus) / $200 (Pro) per Month xAI Grok $0 (Free) / $3 (Basic) / $8 (Premium) / $40 (Premium+) per Month1 Google Gemini $0 (Free) / $19.99 (AI Pro) / $250 (AI Ultra) per Month Note: Excludes enterprise plans. 1. Grok pricing is bundled with X premium subscriptions. X premium subscriptions include additional benefits beyond improvements to Grok usage limits. 2. With annual discount. Source: OpenAI, X, Google, Anthropic, Perplexity websites (5/25) Anthropic Claude $0 (Free) / $172 (Plus) / $100 (Max) per Month Perplexity $0 (Free) / $20 (Pro) per Month AI – New Entrants = Rapidly Laying Groundwork 190 …AI Monetization…Foundation Models = Developer API Fees Driving Monetization OpenAI ChatGPT, xAI Grok, Google Gemini, Anthropic Claude & Perplexity Developer API Pricing – 5/25, per Companies OpenAI ChatGPT From $0.40 (GPT-4.1 nano) to $40 (o3) per 1MM Output Tokens xAI Grok $0.50 (grok-3-mini-beta) to $25 (grok-3-fast) per 1MM Output Tokens Google Gemini $0.15 (1.5 Flash-8B) to $15 (2.5 Pro Preview) per 1MM Output Tokens1 1. Gemini prices by prompt size. Gemini 1.5 Flash-8B = $0.15 per 1MM tokens for prompts ≤128K tokens; Gemini 2.5 Pro Preview = $15 per 1MM tokens for prompts >200K tokens. Source: OpenAI, X, Google, Anthropic, Perplexity websites (5/25) Anthropic Claude From $1.25 (Claude 3 Haiku) to $75 (Claude 3 Opus) per 1MM Output Tokens Perplexity $1 (Sonar) to $15 (Sonar Pro) per 1MM Output Tokens AI – New Entrants = Rapidly Laying Groundwork 191 AI – New Entrants = Rapid Revenue Growth 192 AI Monetization – Foundation Models = OpenAI Revenue +1,050% Annually to $3.7B Source: OpenAI disclosures (as of 4/25), The Information (4/25) (link, link, link & link) AI – New Entrants = Rapid Revenue Growth 0 10 20 10/22 8/23 6/24 4/25 ChatGPT Paid Subscribers , MM +153% / Year Paid Subscribers $0 $2 $4 2022 2023 2024 OpenAI Revenue, $B 1,050% / Year Revenue ChatGPT Paid Subscribers (MM) & Revenue ($B) – 10/22-4/25, per OpenAI & The Information 193 AI Monetization – API & Generative Search = Anthropic Annualized Revenue +20x to $2B in Eighteen Months Anthropic: API & Generative Search – 9/23-3/25, per Reuters, Bloomberg & CNBC Source: Anthropic; Reuters, ‘Anthropic forecasts more than $850 mln in annualized revenue rate by 2024-end – report’ (12/23) (link); Bloomberg, ‘Anthropic Finalizes Megaround at $61.5 Billion Valuation’ (3/25) (link); CNBC, ‘Anthropic closes $2.5 billion credit facility as Wall Street continues plunging money into AI boom’ (5/25) (link) We’ve developed Claude 3.7 Sonnet with a different philosophy from other reasoning models on the market. Just as humans use a single brain for both quick responses and deep reflection, we believe reasoning should be an integrated capability of frontier models rather than a separate model entirely. This unified approach also creates a more seamless experience for users… …we’ve optimized somewhat less for math and computer science competition problems, and instead shifted focus towards real-world tasks that better reflect how businesses actually use LLMs. - Anthropic Press Release, 2/25 Annualized Revenue, $B AI – New Entrants = Rapid Revenue Growth $0 $1 $2 9/23 12/23 3/24 6/24 9/24 12/24 3/25 6.4x / Year Annualized Revenue ($B) 194 AI Monetization – Generative Search = Perplexity Annualized Revenue +7.6x to $120MM in Fourteen Months Perplexity: Generative Search – 3/24-5/25, per Perplexity & Bloomberg Note: 3/24 annualized revenue figure is an estimate per Perplexity Co-Founder & CEO Aravind Srinivas’s 3/25 LinkedIn post saying ‘Perplexity has crossed $100m in annualized revenue…6.3x growth Y/Y and remains highly under monetized.’ Source: Lex Fridman Podcast (6/24), UC Berkeley (5/25), LinkedIn (3/25), Bloomberg, ‘AI Startup Perplexity Nears Funding at $14 Billion Value’ (5/25) (link) Perplexity is best described as an answer engine. You ask it a question, you get an answer. Except the difference is, all the answers are backed by sources. This is like how an academic writes a paper…What makes humans special is that we are creatures of curiosity. We need to expand on that and discover more knowledge using the power of AI. - Perplexity Co-Founder & CEO Aravind Srinivas, 6/24 Annualized Revenue ($MM) Annualized Revenue, $MM AI – New Entrants = Rapid Revenue Growth What if accessing information felt like talking to a personal research assistant? - Perplexity Co-Founder & CEO Aravind Srinivas, 5/25 $0 $40 $80 $120 3/24 5/24 7/24 9/24 11/24 1/25 3/25 5/25 AI Monetization – Enterprise Search + Agents = Glean Annualized Revenue +10x to $100MM in Twenty-Four Months 195 We’re honored to help some of the world’s largest companies adopt AI to transform their businesses. To truly unlock new levels of creativity, productivity, and operational efficiency, AI needs to draw on the full picture of an organization’s knowledge – and it needs to be accessible by everyone. You shouldn’t have to be a prompt engineering expert to find answers, generate content, and automate work with AI. - Glean Co-Founder & CEO Arvind Jain (9/24) Note: Glean’s fiscal year ends in January. Source: Glean (2/25, 11/24) Annual Recurring Revenue (ARR) ($MM) Annual Recurring Revenue, $MM Glean – FQ4:23-FQ4:25, per Glean $0 $50 $100 FQ4:23 FQ4:24 FQ4:25 AI – New Entrants = Rapid Revenue Growth 196 AI Monetization – 2024 vs. 2018 = 35% Faster Ramp to $5MM ARR vs. SaaS Comparables, per Stripe Source: Stripe Annual Letter (2/25) Top 100 AI Companies vs. Top 100 Saas Companies Median Time to Annualized Revenue Milestone ($MM) – 2018 vs. 2024, per Stripe AI – New Entrants = Rapid Revenue Growth Annualized Revenue, $MM $0 $1 $2 $3 $4 $5 0 10 20 30 40 Months 24 Months 37 Months 197 AI Monetization Possibilities = New Entrants & / Or Tech Incumbents? 198 AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts 199 Tech Incumbents = Optimizing Product Distribution to Roll Out AI *Meta includes Facebook, Instagram, WhatsApp, & Messenger. **Apple includes iPhones, iPads, Macs, & other Apple devices worldwide. ***As of 2021; no more recent company data available. Note: Some figures are estimates based off past company disclosures & web traffic / purchase history analytics. Different companies may define ‘users’ differently based on frequency. Source: Statcounter (2/25), Google (5/25), Meta 10Q (4/25), Apple (1/25), TikTok (7/21), LinkedIn (5/25), Microsoft (1/24), Spotify (5/25), Amazon (2/25 & 10/24), Elon Musk via X (7/23), Canva (4/25), OpenAI disclosures (4/25), Wikimedia Commons While ChatGPT Has 800MM+ Users Via Its Website & App… …Tech Incumbents Have Billions of Global Users on Devices & Platforms With Ongoing AI Product Rollouts Meta Users* 3.4B+ Apple Devices** 2.35B Google 4.9B Search Users, 3B+ Android Users, 1.5B AI Overviews Users & 1B+ Assistant Devices TikTok Users*** 1B+ Amazon 600MM+ Alexa Devices & 200MM+ Prime Subscribers X Users 500MM+ Canva Users 230MM+ AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts Spotify Users 678MM Microsoft 1B LinkedIn Members & 400MM+ Office 365 Paid Seats 200 Tech Incumbent AI Rollouts = Canva – Background Remover & Magic Media (12/19) Source: Canva announcements & press releases (2022-2024) Canva Background Remover & Magic Media – 2023-2024, per Canva One of our community’s favorite Canva features has been the one-click image Background Remover, launched in December 2019...[to] wild success and community love. - Canva Press Release, 9/22 Cumulative Uses, B Magic Media lets you turn your imagination into reality by watching your words transform into stunning, one-of-a-kind images – and now videos and graphics, too…In less than a year since launching Magic Media’s text to image, we’ve been overwhelmed by our community’s enthusiastic response, with almost 290 million images being created and applied to a range of practical use cases from social media posts to presentations, business flyers, and even logos. - Canva Press Release, 10/24 AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts 0 2 4 2023 2024 Background Remover Magic Media Number of Tool Uses (B): Background Remover & Magic Media 201 Tech Incumbent AI Rollouts = Spotify – AI DJ (2/23) Source: Company announcements (2/23, 5/23, 8/23, 11/24, 4,25, 5/25) Spotify AI DJ – 2/23-5/25, per Spotify AI DJ and music videos…are truly moving averages… AI DJ, we’re seeing amazing results, not just on quantitative metrics, but also on quality metrics, how people feel about Spotify, what they say they love about Spotify. - Spotify Co-Founder & CEO Daniel Ek, 11/24 Global Markets with AI DJ Available AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts Global Markets with AI DJ Available 0 20 40 60 Back in 2018, we said something internally that still holds true today: machine learning – what most people called AI back then – was the product… AI is really the next step in evolution, where machine learning allows personalization, AI also allows for real time interactivity and reasoning on top of your data. - Spotify Co-President, Chief Product & Technology Officer Gustav Söderström, 4/25 Tech Incumbent AI Rollouts = Microsoft – Copilot (2/23) Note: We assume zero users in the launch month. We assume 15B cumulative chats as of 12/24 due to Microsoft’s 1/24 announcement of 5B cumulative chats, and 12/24 announcement of 10B more chats being held in 2024. We assume the Verge’s announcement of ‘There have also been over 1 billion chats on Bing Chat’ as of 8/23 is wholly inclusive of Copilot chat volumes as of that date. Source: Microsoft announcements & earnings reports, The Verge citing Microsoft disclosures (8/23) Microsoft: Copilot – 8/23-12/24, per Microsoft To empower people to unlock the joy of discovery, feel the wonder of creation and better harness the world’s knowledge, today we’re improving how the world benefits from the web by reinventing the tools billions of people use every day, the search engine and the browser. Today, we’re launching an all new, AI-powered Bing search engine and Edge browser, available in preview now at Bing.com, to deliver better search, more complete answers, a new chat experience and the ability to generate content. We think of these tools as an AI copilot for the web. - Official Microsoft Blog, 2/23 Cumulative Chats, B 202 AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts 0 5 10 15 8/23 12/23 4/24 8/24 12/24 Microsoft Copilot Cumulative Chats Held (B) Tech Incumbent AI Rollouts = Meta Platforms – Meta AI (9/23) Note: We assume zero users in 11/23 per Meta’s 12/23 blog post noting, ‘To chat with our AIs, start a new message and select “Create an AI chat” on Instagram, Messenger or WhatsApp. They’re now available to anyone in the US.’ Source: Meta Platforms announcements & earnings reports Meta Platforms: Meta AI – 11/23-4/25, per Meta Platforms I expect that this is going to be the year when a highly intelligent and personalized AI assistant reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is already used by more people than any other assistant… …I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent that has coding and problem-solving abilities of around a good mid-level engineer… …Whichever company builds [a high-skill AI engineering agent] first, I think it's going to have a meaningful advantage in deploying it to advance their AI research and shape the field. - Meta Platforms CEO Mark Zuckerberg, 1/25 Meta AI Monthly Active Users, MM Meta AI Monthly Active Users (MM) 0 500 1,000 11/23 3/24 7/24 11/24 3/25 203 Q1:25 Earnings Call (4/30/25): Across our apps, there are now almost a billion monthly actives using Meta AI - Meta Platforms Cofounder & CEO Mark Zuckerberg AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts Tech Incumbent AI Rollouts = X – Grok (11/23) *Excludes X visits. China data may be subject to informational limitations due to government restrictions. Source: xAI announcements & investor filings; Elon Musk; Fox News; Similarweb (5/25) X: Grok – 12/24-4/25, per xAI & Similarweb The mission of xAI and Grok is to understand the universe. We want to answer the biggest questions. - xAI Founder & CEO Elon Musk, 2/25 Global Visits, MM Grok Global Desktop Visits* (MM) 0 50 100 150 12/24 1/25 2/25 3/25 4/25 AI with Grok is getting very good…it’s important that AI be programmed with good values, especially truth-seeking values. This is, I think, essential for AI safety… …Remember these words: We must have a maximally truth- seeking AI. - xAI Founder & CEO Elon Musk, 5/25 2/17/25: Grok 3 is released & desktop visits jump 42x M/M 204 AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts Tech Incumbent AI Rollouts = Google – Gemini & AI Overviews (12/23) Note: Gemini launched 12/23…App launched 2/24. Data shown for apps in Gemini ecosystem. User counts may differ from those as measured by third-party data providers / panels like Similarweb & Sensor Tower as they measure only visits to desktop sites and standalone mobile apps, respectively. Source: Google announcements (4/25 & 5/25) & Business Insider, ‘Google's Gemini usage is skyrocketing, but rivals like ChatGPT and Meta AI are still blowing it out of the water’ (4/25) Alphabet: Gemini & AI Overviews – 3/25-5/25, per Alphabet & Business Insider Our differentiated, full stack approach to AI continues to be central to our growth. This quarter was super exciting as we rolled out Gemini 2.5, our most intelligent AI model, which is achieving breakthroughs in performance, and it’s widely recognized as the best model in the industry. - Alphabet CEO Sundar Pichai, 4/25 Gemini Chatbot Global MAUs (MM) 205 AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts Gemini App Ecosystem Global MAUs, MM AI Overviews embedded in Google Search; @ 1.5B MAUs (4/25) Google Gemini is a family of multimodal AI models, capable of understanding and generating various types of data including text, code, audio, images, and video. Source: Google Gemini 350MM 400MM 0 200 400 3/25 5/25 Tech Incumbent AI Rollouts = Amazon – Rufus (2/24) Source: Amazon; Morgan Stanley estimates Amazon: Rufus – 12/22-3/25, per Amazon & Morgan Stanley Estimates We have so many customers now who just use Rufus to help them find a quick fact about a product. They also use Rufus to figure out how to summarize customer reviews, so they don't have to read 100 customer reviews to get a sense of what people think about that product…the personalization keeps getting much better… …And so, we expect throughout 2025, that the number of occasions where you're not sure what you want to buy and you want help from Rufus are going to continue to increase and be more and more helpful to customers. - Amazon CEO Andy Jassy, 2/25 Last Twelve Months Retail GMV, $B Amazon North America Retail Estimated Gross Merchandise Value ($B), Last 12 Months Quarter Ending 2/24: Rufus announced 206 AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts $0 $200 $400 $600 Tech Incumbent AI Rollouts = TikTok – Symphony AI Assistant (6/24) Note: Includes both mobile & desktop website visits. China data may be subject to informational limitations due to government restrictions. Source: TikTok; Similarweb (5/25) TikTok: Symphony Assistant – 1/24-4/25, per TikTok & Similarweb Creativity thrives on TikTok. When brands truly lean into creative bravery and experimentation, they are able to speak directly to their community and invite them to join in the conversation. At TikTok World 2024 we launched Symphony, our suite of ad solutions powered by generative AI… …With Symphony, businesses of all sizes, creators and agencies can blend human imagination with AI-powered efficiency to help scale content development, creativity, and productivity on TikTok. Research has proven that not only does creating TikTok-first ads boost purchase intent by +37% and brand favorability by +38%, but also 79% of TikTok users show a preference for brands that demonstrate a clear understanding of how to create content specifically for the platform. - TikTok Press Release, 6/24 Website Visits to TikTok.com, B Global Website Visits to TikTok.com (B) (Where Symphony Assistant is Hosted) 0 1 2 3 1/24 4/24 7/24 10/24 1/25 4/25 207 AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts Tech Incumbent AI Rollouts = Apple – Apple Intelligence (10/24) Note: Counts sales of iPhone 15 Pro, iPhone 15 Pro Max, & iPhone 16 devices. Figures are estimates. Source: Company announcements & investor filings; IDC via Morgan Stanley (4/25) Apple: Apple Intelligence – 9/23-3/25, per Apple & IDC Estimates Apple Intelligence builds on years of innovations we've made across hardware and software to transform how users experience our products. Apple Intelligence also empowers users by delivering personal context that's relevant to them. And importantly, Apple Intelligence is a breakthrough for privacy and AI with innovations like private cloud compute… …[in] the markets where we had rolled out Apple Intelligence…year over year performance on the iPhone 16 family was stronger than those where Apple Intelligence was not available. - Apple CEO Tim Cook, 1/25 iPhone Sales, MM Estimated Global Sales of iPhone 15 Pro / Pro Max & iPhone 16 (MM) – 9/23-3/25 Apple Intelligence-Capable Devices $0 $25 $50 $75 9/23 12/23 3/24 6/24 9/24 12/24 3/25 Quarter Ending 208 AI – Tech Incumbents = Broad & Steady Product / Feature Rollouts 209 AI – Tech Incumbents = Rapid Revenue + Customer Growth 210 AI Monetization – ‘AI Product’ = Microsoft AI Revenue +175% to $13B Y/Y Microsoft AI Product Revenue – 2023-2024, per Microsoft Note: Microsoft AI revenue likely includes Azure AI services, Microsoft 365 Copilot, GitHub Copilot, Dynamics 365 Copilot, Azure OpenAI Services, and others. Detailed breakdowns not provided on earnings calls. Source: Microsoft Press Release, ‘Microsoft Cloud and AI strength drives second quarter results’ (1/25); & other Microsoft announcements We are innovating across our tech stack and helping customers unlock the full ROI of AI to capture the massive opportunity ahead… …Already, our AI business has surpassed an annual revenue run rate of $13 billion, up 175% year-over-year. - Microsoft CEO Satya Nadella, 1/25 Annual Run-Rate Revenue, $B Estimated Microsoft AI Product Annual Run-Rate Revenue ($B) AI – Tech Incumbents = Rapid Revenue + Customer Growth ~$5B $13B $0 $5 $10 $15 2023 2024 Q1:25 Earnings Call (4/30/25): Revenue from our AI business was above expectations. Commercial bookings increased 18%. - Microsoft CFO Amy Hood 211 AI Monetization – Generative Search = xAI Annualized Revenue Up Materially in 2025 xAI: Generative Search, per xAI & The Wall Street Journal *Select media reports have xAI revenue being as high as $1B as of 4/25. Source: xAI (2/25); The Wall Street Journal, ‘Elon Musk’s xAI Startup Is Valued at $50 Billion in New Funding Round’ (11/24) (link); CNBC, ‘Musk says he’s looking to put ‘proper value’ on xAI during investor call, sources say’ (4/25) (link) We are pleased to introduce Grok 3, our most advanced model yet: blending strong reasoning with extensive pretraining knowledge. Trained on our Colossus supercluster with 10x the compute of previous state-of-the-art models, Grok 3 displays significant improvements in reasoning, mathematics, coding, world knowledge, and instruction-following tasks. - xAI Grok 3 Press Release, 2/25 Annualized Revenue ($B) Annualized Revenue, $B [Grok is a] maximally truth-seeking AI, even if that truth is sometimes at odds with what is politically correct. - xAI Founder & CEO Elon Musk, 2/25 AI – Tech Incumbents = Rapid Revenue + Customer Growth $0.1B $0.0 $0.5 $1.0 11/24 4/25 Revenue up materially in 2025* 212 AI Monetization – AI Services = Palantir USA Commercial Customers +65% to 432 Y/Y Palantir USA Commercial Customers – Q1:23-Q1:25, per Palantir Source: Palantir We achieved a $1 billion annual run rate in our US commercial business for the first time as AIP [Artificial Intelligence Platform] continues to drive both new customer conversions and existing customer expansions in the US.. - Palantir CFO David Glazer , 5/25 Palantir USA Commercial Customers Palantir USA Commercial Customers As AI models progress and improve, we continue enabling our customers to maximally leverage these models in production, capitalizing upon the rich context within the enterprise through the Ontology. We remain differentiated in our elite execution to deliver quantified exceptionalism for our customers, ever widening their advantage over the AI have-nots. - Palantir CRO & Chief Legal Officer Ryan Taylor, 5/25 AI – Tech Incumbents = Rapid Revenue + Customer Growth 0 250 500 Q1:23 Q1:24 Q1:25 213 AI Monetization Possibilities – Enterprise = Horizontal Platform & / Or Specialized Software? 214 To understand where enterprise AI monetization is headed, it helps to ask where software itself is consolidating. For decades, business software followed a familiar pattern: build a specialized tool, sell it to a narrow user base, and scale up within a vertical. This was the age of vertical SaaS – Toast for restaurants, Guidewire for insurance, Veeva for life sciences...Each tool solved a deep, narrow problem. But with the rise of foundation models and generative AI, others are gunning for these prizes. Enter the horizontal enterprise platforms – horizontal layers that combines AI-native productivity, search, communication, and knowledge management into one unified interface. Think of it as Slack meets Notion meets ChatGPT, all in one platform. Horizontal enterprise platforms could usher in a new form of monetization: not by selling siloed software licenses, but by charging for intelligence, embedded throughout the stack. The value shifts from tools to outcomes – from CRMs to automated deal summaries, from service desks to AI-powered resolution flows. These horizontal capabilities are still early, but they're already being harnessed by incumbents and upstarts alike. Microsoft is integrating Copilot across the stack. Zoom and Canva are layering GenAI into user-facing workflows, while Databricks is infusing GenAI into its data and developer stack. Meanwhile, startups like Glean are betting on AI-first workflows to challenge the suite model… AI Monetization Possibilities – Enterprise = Horizontal Platform & / Or Specialized Software? 215 …But specialist vendors aren’t standing still. If anything, they’re absorbing AI faster – embedding copilots, automating workflows, and fine-tuning models on proprietary industry data. These platforms already have the workflows, the trust, and the structured data that AI thrives on. That gives them a head start in deploying domain-specific intelligence – AI that doesn’t just summarize a meeting, but flags regulatory risks, optimizes pricing in real time, or drafts FDA-compliant documentation. In many cases, their incumbency becomes their advantage: they can roll out AI as a feature, not a product, and monetize it without changing the buying motion. The next chapter of AI monetization may not be a winner-take-all battle, but a convergence. Horizontal platforms will push breadth, stitching together knowledge across functions; specialists will push depth, delivering AI that speaks the language of compliance, contracts, and customer intent. The question isn’t whether platforms or specialists win – it’s who can abstract the right layer, own the interface, and capture the logic of work itself. In the AI era, monetization won’t just follow usage – it will follow attention, context, and control. AI Monetization Possibilities – Enterprise = Horizontal Platform & / Or Specialized Software? 216 AI Monetization Possibilities – Enterprise = Horizontal Platform & / Or Specialized Software? 217 Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 218 Enterprise SaaS Incumbent AI Rollouts = Broad & Steady Cadence Source: Uptrends.ai (6/24), company announcements & investor filings Number of Mentions of ‘AI’ on Corporate Earnings Calls – Q1:20-Q1:24, per Uptrends.ai Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 219 Enterprise SaaS Incumbent AI Rollouts = Microsoft GitHub Copilot – 6/22 Note: GitHub revenue is disclosed irregularly; 3 datapoints are from company leadership’s disclosures. Public developer launch date shown. GitHub reports annualized revenue; here, we translate this to quarterly revenue. Source: Company announcements & investor filings Microsoft GitHub Copilot – 6/17-6/24, per GitHub, Microsoft & Wells Fargo GitHub Copilot is by far the most widely adopted AI-powered developer tool. Just over two years since its general availability, more than 77,000 organizations – from BBVA, FedEx, and H&M, to Infosys and Paytm – have adopted Copilot, up 180% year-over-year. - Microsoft CEO Satya Nadella, 7/24 Revenue, $MM $0 $250 $500 6/17 6/18 6/19 6/20 6/21 6/22 6/23 6/24 We have been delighted by the early response to GitHub Copilot and vs. Code with more than 1 million sign-ups in just the first week post launch. All up, GitHub now is home to 150 million developers, up 50% over the past two years. - Microsoft CEO Satya Nadella, 1/25 GitHub Copilot Public Launch Quarter Ending Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? GitHub Revenue ($MM) 220 Enterprise SaaS Incumbent AI Rollouts = Microsoft 365 Copilot – 3/23 Note: N=61 CIOs in the USA & EU. Microsoft 365 Copilot was announced in 3/23 but was not made generally available for enterprise customers until 11/23. Source: Company announcements & investor filings, Morgan Stanley, ‘4Q24 Preview – Can Microsoft Add Clarity to the AI Monetization Question?’ (7/24) Microsoft 365 Copilot – Q2:23-Q4:24, per Microsoft & Morgan Stanley We are seeing accelerated customer adoption across all deal sizes as we win new Microsoft 365 Copilot customers and see the majority of existing enterprise customers come back to purchase more seats. When you look at customers who purchased Copilot during the first quarter of availability, they have expanded their seat collectively by more than 10x over the past 18 months. And overall, the number of people who use Copilot daily, again, more than doubled quarter over quarter. Employees are also engaging with Copilot more than ever. Usage intensity increased more than 60% quarter over quarter, and we are expanding our TAM with Copilot Chat, which was announced earlier this month. - Microsoft CEO Satya Nadella, 1/25 % of CIOs % of CIOs Expecting to Use Microsoft 365 Copilot over Next 12 Months, per Morgan Stanley Survey 0% 40% 80% Q2:23 Q4:23 Q2:24 Q4:24 Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 221 Enterprise SaaS Incumbent AI Rollouts = Adobe Firefly – 3/23 Note: We assume zero users in the launch month. Adobe Firefly was released as a public beta in March 2023. Source: Adobe announcements (9/23, 10/23, 3/24, 4/24, 10/24, 12/24, 2/25) Adobe Firefly – 5/23-4/25, per Adobe The release of the Adobe FireFly video model in February, a commercially safe generative AI video model, has been very positively received by brands and creative professionals… …User engagement has been strong with over 90% of paid users generating videos… …We're delighted with the early interest in these new offerings. Other creative professional and creator highlights include, continued strong adoption of GenAI in our products with Photoshop GenAI monthly active users at approximately 35% and Lightroom GenAI monthly active users at 30%. Users have generated over 20 billion assets with Firefly. - Adobe President of Digital Media David Wadhwani, 3/25 Cumulative Digital Assets Created, B Cumulative Number of Digital Assets Generated Using Adobe Firefly (B) 0 5 10 15 20 25 5/23 8/23 11/23 2/24 5/24 8/24 11/24 2/25 Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 222 Enterprise SaaS Incumbent AI Rollouts = Atlassian Intelligence – 4/23 Note: 12/23 users includes beta users. We assume 20,000 users based on Atlassian’s disclosure that ‘Nearly 10% of Atlassian’s 265,000+ customers have already leveraged Atlassian Intelligence through our beta program.’ Source: Atlassian announcements (4/23, 12/23, 12/24) Atlassian Intelligence – 12/23-12/24, per Atlassian Today, more than 1 million monthly active users are utilizing our Atlassian intelligence features to unlock enterprise knowledge, supercharge workflows, and accelerate their team collaboration. These features are clearly delivering value as we've seen a number of AI interactions increase more than 25x year over year… …Atlassian Intelligence [saw a] 25x improvement in the number of features used over the last year. - Atlassian Co-Founder & Co-CEO Michael Cannon, 2/25 Customers Using Atlassian Intelligence, K Atlassian Intelligence Users (K) Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? ~20K 1,000K 0 500 1,000 12/23 12/24 223 Enterprise SaaS Incumbent AI Rollouts = Zoom AI Companion – 9/23 Note: AI Companion MAUs are estimates based on company disclosures. As of 7/30/24, Zoom disclosed they had 1.2MM accounts with AI Companion activated. In Q3 2024, they disclosed 59% Q/Q growth in active accounts; in Q4 2024, they disclosed further 68% Q/Q growth. We assume zero users in the launch month. Source: Zoom announcements (9/23. 10/23, 2/24, 5/24, 7/24, 9/24, 12/24) Zoom AI Companion – 9/23-12/24, per Zoom Growth in monthly active users of Zoom AI Companion accelerated to 68% quarter over quarter, demonstrating the real value AI is providing customers. Zoom AI Companion has emerged as a driving force behind our transformation into an AI-first company… …As part of AI Companion 2.0, we added advanced agentic capabilities, including memory, reasoning, orchestration, and seamless integration with Microsoft and Google services. - Zoom Founder & CEO Eric Yuan, 2/25 Active Zoom Accounts, MM Estimated Zoom Accounts with AI Companion Activated (MM) 0 2 4 9/23 12/23 3/24 6/24 9/24 12/24 Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 224 Enterprise SaaS Incumbent AI Rollouts = Canva Magic Studio – 10/23 Note: We assume zero users in the launch month. Source: Canva announcements (10/23, 10/24, 5/25) Canva Magic Studio – 10/23-5/25, per Canva With Magic Studio there’s no need to toggle between multiple AI tools or learn lots of different software – all the best of AI is at your fingertips. Created for the 99% of the world without complex design skills, Magic Studio is jam-packed with easy- to-use AI-powered features across every part of Canva to help you work smarter. - Canva Press Release, 10/23 Cumulative Uses, B Cumulative Canva Magic Studio AI Tool Uses (B) Magic Studio is designed to supercharge creativity across our entire community – from enterprise teams to educators and nonprofits. Its easy-to-use AI features are woven into every part of Canva, enabling anyone to spark inspiration, streamline workflows, and scale their content. In fact, our AI tools have been used more than 10 billion times to date. - Canva Press Release, 10/24 Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 0B 16B 0 10 20 10/23 5/25 225 Enterprise SaaS Incumbent AI Rollouts = Salesforce Agentforce – 9/24 Note: Agentforce was announced on 9/12/24 but became generally available on 10/29/24. We assume zero users in the launch month. Source: Salesforce announcements (10/24, 12/24, 2/25) Salesforce Agentforce – 12/24-2/25, per Salesforce We ended this year with $900MM in Data Cloud and AI ARR. It grew 120% year over year. We've never seen products grow at these levels, especially Agentforce… …Just 90 days after it went live, we've already had 3,000 paying Agentforce customers who are experiencing unprecedented levels of productivity, efficiency, and cost savings… …Data Cloud is the fuel that powers Agentforce and our customers are investing in it. And Data Cloud surpassed 50 trillion, that's trillion with a T, records, doubling year over year as customers increase their consumption and investment in our data platform. - Salesforce Co-Founder & CEO Mark Benioff, 2/25 Paid Agentforce Deals Number of Paid Agentforce Deals Signed Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 1,000 3,000 0 1,500 3,000 12/24 2/25 226 Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 227 Source: Microsoft (1/24), Office365 Pros, OpenAI, The Information (4/25) (link) OpenAI ChatGPT = Potential Horizontal Enterprise Platform?... OpenAI = Next-Gen All-in-One Enterprise Platform? Microsoft Office Suite 9 Applications 400MM Paid Users Over 34 Years 1990-2024 OpenAI ChatGPT 1 Application 20MM Paid Users Over 2.5 Years 11/22-4/25 Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 228 …OpenAI ChatGPT = Potential Horizontal Enterprise Platform? Note: We assume zero users in the launch month. Source: OpenAI announcements (12/23, 4/24, 9/24, 3/25), Bloomberg (4/24), Reuters (9/24), The Wall Street Journal (3/25) ChatGPT Enterprise – 8/23-3/25, per OpenAI, Bloomberg, Reuters, & The Wall Street Journal Since ChatGPT’s launch just nine months ago, we’ve seen teams adopt it in over 80% of Fortune 500 companies. We’ve heard from business leaders that they’d like a simple and safe way of deploying it in their organization. Early users of ChatGPT Enterprise…are redefining how they operate and are using ChatGPT to craft clearer communications, accelerate coding tasks, rapidly explore answers to complex business questions, assist with creative work, and much more. ChatGPT Enterprise removes all usage caps and performs up to two times faster [vs. ChatGPT Free]… …ChatGPT Enterprise also provides unlimited access to advanced data analysis, previously known as Code Interpreter. - ChatGPT Enterprise Release Statement, 8/23 Number of Business Users, MM Horizontal Enterprise Platform = SaaS Incumbents Or Large Language Model Challengers? 0 1 2 8/23 2/24 8/24 2/25 Number of ChatGPT Business Users (MM) (Includes Enterprise / Team / Education) 229 AI Monetization Possibilities – Enterprise = Horizontal Platform & / Or Specialized Software? 230 AI Monetization – Enterprise = Specialized Software Opportunities in Fragmented Markets, per Prosus USA Industries by Number of Companies & Market Share – 2024, per Prosus Source: Prosus, ‘The Timeless Appeal of Vertical SaaS’ (3/24) AI Monetization Possibilities – Enterprise = Horizontal Platform & / Or Specialized Software? 231 AI-Enabled Specialized Software @ Large Service Industries = Growing Very Quickly… Software Engineering Product Development Healthcare Legal Customer Service Financial Services 232 AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly… Software Engineering Specialized AI – Software Engineering (Code Editor) = Anysphere Cursor AI ARR @ $1MM to $300MM in Twenty-Five Months 233 Something beautiful is happening to code…our aim with Cursor is to continue to lead this shift, by building a magical tool that will one day write all the world's software… …Already, in Cursor, hours of hunting for the right primitives are being replaced by instant answers. Mechanical refactors are being reduced to single ‘tabs.’ Terse directives are getting expanded into working source. And thousand-line changes are rippling to life in seconds. - Anysphere Press Release (8/24) …We're delighted to report that Cursor is now used by millions of programmers as their editor of choice. Our proprietary models now generate more code than almost any LLMs in the world and edit over a billion characters per day. Our business is large and fast growing, having exceeded $100MM in recurring revenue. - Anysphere Team (8/24 & 1/25) Anysphere Cursor AI – 3/23-4/25, per Anysphere Annual Recurring Revenue (ARR) ($MM) Note: Cursor launched in 4/23. We show 3/23 as the first datapoint with an assumed $0 in ARR. Source: Cursor / Anysphere (8/24, 11/24 & 1/25), Anysphere Co-Founder & CEO Michael Truell via Lenny’s Newsletter, ‘The rise of Cursor: The $300M ARR AI tool that engineers can’t stop using’ (5/1/25) Annual Recurring Revenue, $MM AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly…Software Engineering $0 $150 $300 3/23 8/23 1/24 6/24 11/24 4/25 234 AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly… Product Development 235 Specialized AI – Product Development (No-Code Product-Building) = Lovable ARR +13x to $50MM in Five Months The opportunity here is immense. We are on the verge of a paradigm shift where the barriers to building software-based products disappear. Now, anyone can become an entrepreneur, launch a product and build a business in minutes. - Frederik Cassel, Creandum, ‘Backing Lovable: Move Fast and Make Things,’ 2/25* Annual Recurring Revenue, $MM *Per Creandum website. **From Lovable Co-Founder & CEO Anton Osika’s LinkedIn posts & podcast appearances. Source: Lovable (5/25), Creandum (2/25) Note: Lovable is an AI-powered application development platform that enables users to create full-stack web applications by describing their ideas in natural language. The platform translates these descriptions into functional applications, handling frontend and backend code generation, database integration, and deployment. Lovable – 12/24-5/25 Annual Recurring Revenue (ARR)** ($MM) $0 $25 $50 12/24 1/25 2/25 3/25 4/25 5/25 AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly…Product Development 236 AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly… Healthcare Specialized AI – Healthcare (Clinical Conversations) = Abridge @ $50MM to $117MM CARR in ~Five Months 237 Yazdi Bagli, Kaiser’s EVP of IT and enterprise business services, said he believes [Kaiser Permanente’s] Abridge partnership is one of the largest generative AI deployments in health care… …The national rollout includes more than 25,000 doctors and clinicians, 40 hospitals, and north of 600 medical offices… …The feedback from doctors has been effusive: ‘It saved my marriage.’ And: ‘You’d have to take it away from my cold, dying hands.’ - Fortune Magazine (2/25) Contracted Annual Recurring Revenue (CARR) ($MM) Note: 3/25 figure is quoted as being as of Q1:25. We conservatively assume this maps to 3/25. Abridge’s CARR goes live within weeks of contracting. Source: Abridge (12/24 & 5/25), Fortune (2/25), The Information (10/24 & 5/25) (link & link) Abridge – 10/24-3/25, per Abridge & The Information Contracted Annual Recurring Revenue, $MM AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly…Healthcare We are incredibly proud of our partnership with Kaiser – where a majority of Kaiser doctors are using Abridge to summarize patient visits, with over 10 million completed to date. As one of our earliest deployments, it is a great example of how we are building alongside our many hospital partners and helping them grow with Abridge. - Abridge CFO Sagar Sanghvi (5/25) $50MM $117MM $0 $40 $80 $120 10/24 3/25 238 AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly… Legal Specialized AI – Legal (Workflows) = Harvey @ $10MM to $70MM ARR in Fifteen Months, per The Information & Business Insider 239 In 2024, we saw 4x annual recurring revenue (ARR) growth and expanded from 40 customers to 235 customers in 42 countries, including the majority of the top 10 USA law firms. We’ve also seen the legal and professional services industry shift faster than ever before. Lawyers are adopting technology at an unprecedented rate, centuries-old firms are experimenting with new business models, and enterprises are driving significant savings with AI- enabled workflows. The pace of change will only accelerate in 2025. - Harvey Co-Founder & CEO Winston Weinberg & Co-Founder & President Gabe Pereyra (2/25) Source: Harvey (2/25), The Information estimates (1/25) (link, link), & Business Insider (5/25) (link) Annual Recurring Revenue (ARR) ($MM) Harvey – 12/23-4/25, per The Information & Business Insider Annual Recurring Revenue, $MM AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly…Legal $0 $25 $50 $75 12/23 3/24 6/24 9/24 12/24 3/25 240 AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly… Customer Service Specialized AI – Customer Service (AI Support Agents) = Decagon @ ~$1MM to $10MM ARR in One Year 241 AI is often seen as destroying jobs, but at Decagon, we believe the opposite. Our AI agents are enhancing jobs, not replacing them… …In a few years, every company will have AI agents running their customer experiences. Customer support staff are no longer fielding routine tasks; they are now becoming AI managers – configuring, training and overseeing the AI agents that handle repetitive work. - Decagon Co-Founder & CEO Jesse Zhang (10/24) Note: Source: Decagon (12/23, 10/24, 12/24) Annual Recurring Revenue (ARR) ($MM) Annual Recurring Revenue, $MM Decagon – 2023-2024, per Decagon AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly…Customer Service $1MM $10MM $0 $5 $10 2023 2024 ARR growth accelerating in 2025 242 AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly… Financial Services Specialized AI – Financial Services (Research & Analysis) = AlphaSense @ ~$150MM to ~$420MM in Two Years 243 We are at a tipping point where AI-driven insights are no longer a luxury but a necessity – every company’s market value is the sum of the decisions it makes. Surpassing $400 million in ARR and our rapid growth are clear signals that businesses are recognizing the transformative power of our end-to-end market intelligence platform. As we scale, our focus remains on product and technology innovation, ensuring we deliver high-value solutions and cutting-edge AI and smart workflow capabilities to our customers. - AlphaSense Co-Founder & CEO Jack Kokko (3/25) Source: AlphaSense (3/25) Annual Recurring Revenue (ARR) ($MM) Annual Recurring Revenue, $MM AlphaSense – 2022-2024, per AlphaSense AI-Enabled Specialized Software Companies @ Large Service Industries = Growing Very Quickly…Financial Services 0 250 500 2022 2023 2024 244 Next AI Use Case Frontiers = Broad & Varied 245 Next AI Use Case Frontiers = Broad & Varied Note: List is not comprehensive. Source: Drug Development & Discovery = Insilico; Precision Manufacturing = Landing AI; Multi-Purpose Robotics = Figure AI; Autonomous Scientific Research = IBM’s RoboRXN; Supply Chain Optimization = o9 Solutions; Cybersecurity & Threat Detection = Vectra AI; Personalized Education = Khanmigo; Autonomous Finance = Kasisto; Environmental & Climate Monitoring = ClimateAI; Energy Grid Management = Uplight; BOND analysis Next AI Use Case Frontiers – 5/25 Medical Discovery & Development Precision Manufacturing Multi-Purpose Robotics Autonomous Scientific Research Supply Chain Optimization Cybersecurity & Threat Detection Personalized Education Autonomous Finance Environmental & Climate Monitoring Energy Grid Management Next AI Use Case Frontiers = Broad & Varied Highlights = Pages 246-247 246 Next AI Use Case Frontier – Protein Sequencing = Model Size +290% Annually to 98 Billion Parameters Over Four Years Note: List of models may not be comprehensive. Source: Stanford RAISE Health via Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) Next AI Use Case Frontiers = Broad & Varied Per Stanford HAI (4/25): The past year has witnessed remarkable progress in AI models applied to protein sequences. Large-scale machine learning models have improved our ability to predict protein properties, accelerating research in structural biology and molecular engineering…These AI-driven approaches have transformed protein science by minimizing reliance on costly, time-intensive experimental methods, enabling rapid exploration of protein function and design. Size of Major Protein Sequencing Models (B Parameters) – 2020-2024, per Stanford RAISE Health 0 50 100 ProGen ProtBert ProGen 2 ProT5 ESM2 ESM3 +290% / Year Number of Parameters, B 2020 2022 2023 2024 214MM Predicted Protein Structures in AFDB (2024) 247 Next AI Use Case Frontier – Protein Sequencing = Synthetically Generated Protein Data Yields 1,000x Expansion via AlphaFold Note: AFDB predicted protein structure counts may be higher as of year-end 2024. Source: Google DeepMind, RCSB Protein Data Bank (2024) Next AI Use Case Frontiers = Broad & Varied 214,121 Protein Structures in PDB (2024) Experimentally Determined Expanded Coverage with Structure Prediction • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 248 1 2 3 4 5 6 7 8 Outline 249 AI Monetization Threats = Rising Competition + Open-Source Model Momentum (& China’s Rise) 250 Rising Competition = AI Model Releases 251 On the back of Google’s ‘Attention is All You Need’ Transformers research paper in 2017, the first wave of ‘modern AI’ (read: LLMs) focused on text: models such as OpenAI’s GPT-3 and Meta’s Llama-1 showed that teaching computers to finish sentences at scale could unlock broad reasoning abilities. Yet human communication is rarely text-only, and often not even text-first. Images, audio, video, and sensor readings carry context that words alone miss, so researchers at the same companies – and peers like Google, Anthropic, and xAI, among others – began extending language models to handle additional signals. Multimodal AI models are the result. They embed text, pictures, sound, and video into a shared representation and generate outputs in any of those formats. A single query can reference a paragraph and a diagram, and the model can respond with a spoken summary or an annotated image – without switching systems. Each new modality forces models to align meaning across formats rather than optimize for one. The path to this capability unfolded stepwise: OpenAI’s CLIP paired vision and language in 2021; Meta followed with ImageBind in 2023 and Chameleon in 2024; and by 2024-2025, frontier systems such as GPT-4o, Claude 3, and Chameleon had become fully multimodal. Each new modality forced the models to align meaning across formats rather than optimize for one. The payoff is practical. A field engineer can aim a phone camera at machinery and receive a plain-language fault diagnosis; a clinician can attach an X-ray to a note and get a structured report draft; and an analyst can combine charts, transcripts, and audio clips in a single query. Compared with text-only models, multimodal systems cut context switching, capture richer detail, and enable applications – quality control, assistive tech, content creation – where visual or auditory information matters as much as words. Rising Competition = AI Model Releases 252 Large-Scale AI Multimodal* Model Competition = +1,150% Rise in Models Released Over Two Years, per Epoch AI *A multimodal AI model is one that can process and integrate multiple types of data, e.g., text, images, audio, or video, to understand and generate outputs across different modalities. **Epoch AI defines large-scale as models where their training compute is confirmed to exceed 1023 floating-point operations. An AI system can operate in more than one domain and may be double-counted across pages. Source: Epoch AI via Our World in Data (4/25), OpenAI, DeepSeek, Google Multimodal Models – Examples Large-Scale** Multimodal Models – Releases Number of Systems Released per Year 0 5 10 15 20 25 2017 2018 2019 2020 2021 2022 2023 2024 2025 (as of 5/25) +1,150% Rising Competition = AI Model Releases 253 Large-Scale AI Language Model Competition = +420% Increase in Models Released Over Two Years, per Epoch AI *Epoch AI defines large-scale as models where their training compute is confirmed to exceed 1023 floating-point operations. An AI system can operate in more than one domain and may be double-counted across pages. Many models shown are multimodal. Source: Epoch AI via Our World in Data (4/25), OpenAI, DeepSeek, Google Language Models – Examples Large-Scale* Language Models – Releases Number of Systems Released per Year 0 25 50 75 100 125 2017 2018 2019 2020 2021 2022 2023 2024 2025 (as of 5/25) +420% Rising Competition = AI Model Releases 254 Large-Scale AI Vision Model Competition = +109% Increase in Models Released Y/Y, per Epoch AI *Epoch AI defines large-scale as models where their training compute is confirmed to exceed 1023 floating-point operations. An AI system can operate in more than one domain and may be double-counted across pages. Many models shown are multimodal. Source: Epoch AI via Our World in Data (4/25), Meta, Alibaba Vision Models* – Examples Large-Scale* Image Models – Releases Meta Llama 3.2 – 9/24 Qwen2-VL – 12/24 0 10 20 30 2017 2018 2019 2020 2021 2022 2023 2024 2025 (as of 5/25) +109% Rising Competition = AI Model Releases Number of Systems Released per Year 255 Large-Scale AI Speech / Audio Model Competition = +367% Increase in Models Released Y/Y, per Epoch AI Note: An AI system can operate in more than one domain and may be double-counted across pages. Includes models without verified training compute. Many models shown are multimodal. Source: Epoch AI (5/25), Microsoft (1/23), OpenAI (5/24), Amazon, Pinterest Speech / Audio Models – Examples Speech / Audio Models – Releases 0 5 10 15 2017 2018 2019 2020 2021 2022 2023 2024 +367% Rising Competition = AI Model Releases Number of Systems Released per Year OpenAI GPT 4o Speech – 5/24 Microsoft VALL-E – 1/23 256 Large-Scale AI Video Model Competition = +120% Increase in Models Released Y/Y, per Epoch AI *Epoch AI defines large-scale as models where their training compute is confirmed to exceed 1023 floating-point operations. An AI system can operate in more than one domain and may be double-counted across pages. Many models shown are multimodal. Source: Epoch AI via Our World in Data (4/25), OpenAI, Amazon, Pinterest, Pinterest Video Models – Examples Large-Scale* Video Models – Releases OpenAI Sora – 12/24 Amazon Nova Reel – 12/24 0 5 10 15 2017 2018 2019 2020 2021 2022 2023 2024 2025 (as of 5/25) +120% Rising Competition = AI Model Releases Number of Systems Released per Year According to academic studies, 50% of the human brain is wired for visual processing. The ability for users to explore their interest visually and take action on them… is particularly relevant for Gen Z… who have been raised on an internet of visual content across images and video. - Pinterest CEO Bill Ready (5/25) 257 LLM Competition – Website Visits = OpenAI ChatGPT Biggest @ 5.1B Site Visits… OpenAI ChatGPT Global Website Visits (MM) – 5/24-4/25, per Similarweb Note: Includes desktop & mobile (non-app) website visits. China data may be subject to informational limitations due to government restrictions. Source: Similarweb (5/25) 0 2,000 4,000 6,000 5/24 6/24 7/24 8/24 9/24 10/24 11/24 12/24 1/25 2/25 3/25 4/25 chatgpt.com (OpenAI) Website Visits, MM Rising Competition = AI Model Releases 258 …LLM Competition – Website Visits = DeepSeek & xAI Grok Also Rising @ 196-480MM Visits Each DeepSeek, xAI Grok, Perplexity & Anthropic Claude Global Website Visits (MM) – 5/24-4/25, per Similarweb Note: Includes desktop & mobile (non-app) website visits. China data may be subject to informational limitations due to government restrictions. Source: Similarweb (5/25) 0 250 500 750 5/24 6/24 7/24 8/24 9/24 10/24 11/24 12/24 1/25 2/25 3/25 4/25 deepseek.com (DeepSeek) grok.com (xAI) perplexity.ai (Perplexity) claude.ai (Anthropic) Website Visits, MM xAI Grok rose rapidly as of 3/25 Rising Competition = AI Model Releases 259 LLM Competition – Product Releases During Week of May 19, 2025 = It Wasn't Just Google's Annual I/O Conference Select AI Product Announcements – 5/19/25-5/23/25, per Google, Microsoft, Anthropic & OpenAI Note: Announcements include products that were made immediately-available and forthcoming products. List is non-exhaustive. Source: Google Microsoft, Anthropic, OpenAI (5/25) Rising Competition = AI Model Releases • Gemini Live camera & screen sharing • Project Mariner computer use • Updated Gemini 2.5 Flash • Gemini 2.5 Pro • Native audio output for 2.5 Flash & Pro Previews • Thinking Budgets for Gemini 2.5 Pro • Deep Think • Project Astra capabilities • Gemini in Chrome • Deep Research improvements • Gemini Agent Mode • Google AI Pro Subscription • Google AI Ultra Subscription • Google Beam • Google Meet speech translation • Personalized Smart Replies • Jules • Imagen 4 • Veo 3 • Lyria 2 • Flow TV • Project Moohan • Glasses with Android XR • Magentic-UI • Copilot Studio multi-agent orchestration • GitHub Copilot asynchronous functioning • Azure AI Foundry expansion • NLWeb • Model Context Protocol (MCP) integration • Entra Agent ID • SQL Server 2025 • Windows Subsystem for Linux Open- Source • GitHub Copilot Chat Extension • Aurora AI-Powered Weather Forecasting • Claude Opus 4 • Claude Sonnet 4 • Acquisition of io • ‘Try on’ experiment • Agentic checkout • Gemini interactive quizzes • Canvas Create menu • LearnLM integration into Gemini 2.5 • SDK support for Model Context Protocol (MCP) definitions in Gemini API • Gemini Diffusion • SynthID Detector • Conversational tutor prototype • Google Live API audiovisual input & native audio out dialogue • Gemma 3n • AI studio enhancements • Android Studio Journeys • Android Studio Version Upgrade Agent • Wear OS 6 Developer Preview • Gemini Code Assist • New Firebase features • Google AI Edge Portal • Google Vids • Enhanced Audio Overviews • Sparkify experiment 260 AI Monetization Threats = Rising Competition + Open-Source Model Momentum (& China’s Rise) 261 AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise To understand where AI model development is headed, it helps to examine how two distinct approaches – closed-source and open-source – have evolved and diverged. In the early days of modern machine learning (2012-2018), most models were open-source, rooted in academic and collaborative traditions. But as AI systems became more powerful and commercially valuable, and as development shifted from academia to industry, a parallel movement emerged – around 2019 (when GPT-2 launched with restricted weights), the development of proprietary (closed-source) models, motivated by proprietary interests, competitive advantage, and safety concerns. Closed models follow a centralized, capital-intensive arc. These models – like OpenAI’s GPT-4 or Anthropic’s Claude – are trained within proprietary systems on massive proprietary datasets, requiring months of compute time and millions in spending. They often deliver more capable performance and easier usability, and thus are preferred by enterprises and consumers, and – increasingly – governments. However, the tradeoff is opacity: no access to weights, training data, or fine-tuning methods. What began as a research frontier became a gated product experience, served via APIs, licensed to enterprises, and defended by legal and commercial firewalls. Now, the AI race is coming full circle. As LLMs mature – and competition intensifies – we are seeing resurgence of open-source models owing to their lower costs, growing capabilities, and broader accessibility for developers and enterprises alike. These are freely available for anyone to use, modify, and build upon, and thus are generally preferred by early-stage startups, researchers / academics, and independent developers. Platforms like Hugging Face have made it frictionless to download models like Meta’s Llama or Mistral’s Mixtral, giving startups, academics, and governments access to frontier-level AI without billion-dollar budgets. Open-source AI has become the garage lab of the modern tech era: fast, messy, global, and fiercely collaborative. And China (as of Q2:25) – based on the number of large-scale AI models* released – is leading the open-source race, with three large-scale models released in 2025 – DeepSeek-R1, Alibaba Qwen-32B and Baidu Ernie 4.5**. The split has consequences. Open-source is fueling sovereign AI initiatives, local language models, and community-led innovation. Closed models, meanwhile, are dominating consumer market share and large enterprise adoption. We’re watching two philosophies unfold in parallel – freedom vs. control, speed vs. safety, openness vs. optimization – each shaping not just how AI works, but who gets to wield it. *Large-scale AI models = Models with training compute confirmed to exceed 1023 floating point operations. **To be made open-source as of 6/30/25, per Baidu. 262 Closed vs. Open-Source Models – Monthly Active Users (MAUs) = Closed Models Dominating With Consumers, per YipitData Estimated Share of Global Monthly Active Users (MAUs) Across Six Leading LLMs – 4/25, per YipitData *xAI open-sourced the Grok-1 base model in March 2024, but newer versions and full chatbot features remain proprietary. Note: Data is a subset of global internet users and absolute user data will be understated; however, given that the panel is globally-representative (with limitations on China-specific data), relative comparisons / trends are informative. Desktop users only. Figures calculate the number of users on a given platform, divided by the number of users on all platforms combined. Figures are non-deduped (i.e., users using multiple platforms may be counted twice). Data measures several million global active desktop users’ clickstream data. Data consists of users’ web requests & is collected from web services / applications, such as VPNs and browser extensions. Panel is globally-representative (with limitations on China-specific data). Users must have been part of the panel for 2 consecutive months to be included. Source: YipitData (5/25) Share of Global Consumer Users, % 0% 25% 50% 75% OpenAI: ChatGPT Google: Gemini DeepSeek xAI: Grok* Perplexity Anthropic: Claude Closed Open AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise 263 Closed vs. Open-Source Models – Compute Investment = Closed Models Higher, per Epoch AI Training Compute Resources for Open vs. Closed LLMs – 2/18-9/24, per Epoch AI Source: Epoch AI (11/24) AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise 264 Closed vs. Open-Source Models – Performance = Gap Closing…China Rising, per Epoch AI… Performance on MATH Level 5 Test, Open vs. Closed LLMs by Year Released – 6/23-4/25, per Epoch AI Note: MATH Level 5 pass@1 refers to the accuracy of an AI model on the MATH benchmark, a dataset of high school competition-level mathematics problems. Level 5 indicates the most challenging problems in the benchmark. ‘pass@1’ measures whether the model correctly solves the problem on its first attempt. Source: Epoch AI (5/25) DeepSeek R1 (1/25) scored 93% vs. o3- mini’s (1/25) score of 95% Non-Downloadable (Closed) Downloadable (Open) AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise 265 …Closed vs. Open-Source Models – Performance = Gap Closing…China Rising, per Artificial Analysis AI Model Performance by Provider – 1/25, per Artificial Analysis AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise Artificial Analysis Quality Index Score 0 50 100 Coding Quantitative Reasoning Reasing & Knowledge Scientific Reasoning & Knowledge DeepSeek OpenAI Anthropic Meta Alibaba Open Closed Closed Open Open Note: Scores are out of 100. The models for each company that are measured: for OpenAI, o1; for Alibaba, Qwen 2.5 72B; for Meta, Llama 3.1 405B; for Anthropic, Claude 3.5 Sonnet. The tests used are HumanEval, MATH-500, MMLU and GPQA Diamond. Source: Artificial Analysis via NBC News, ‘Why DeepSeek is different, in three charts’ (1/25) 266 Rising Performance of Open-Source Models + Falling Token Costs = Explosion of Usage by Developers Using AI 267 Rising Performance of Open-Source Models + Falling Token Costs = Explosion of Usage by Developers Using AI Closed-source models – like GPT-4, Claude, or Gemini – have dominated usage among consumers and large enterprises, largely because of their early performance advantage, ease of use, and broader awareness. These models came bundled in clean, productized interfaces and offered reliable outputs with minimal setup. For enterprises, they promise security and ease-of-use for non-technical employees. For consumers, they came with name recognition, fast onboarding, and polished UX. That combination has kept closed models at the center of the AI mainstream. But performance leadership is no longer a given. Open-source models are closing the gap – faster than many expected – and doing so at a fraction of the cost to users. Models like Llama 3 and DeepSeek have demonstrated competitive reasoning, coding, and multilingual abilities, while being fully downloadable, fine-tunable, and deployable on commodity infrastructure. For developers, that matters. Unlike enterprise buyers or end-users, developers care less about polish and more about raw capability, customization, and cost efficiency. And it is developers – more than any other group – who have historically been the leading edge of AI usage. The recent trend appears increasingly clear: more developers are gravitating toward low-cost, high-performance open models, using them to build apps, agents, and pipelines that once required closed APIs. Time will tell if that advantage scales beyond the developer ecosystem. Many open-source tools still lack the brand power, plug-and-play user experience (UX), and managed services that drive adoption among consumers and large organizations. But as the cost-performance ratio of open models continues to improve – and if the infrastructure to support them becomes more turnkey – those advantages could start to spread beyond the developer community. 268 Developer AI Model Activity = +3.4x Increase in Downloads of Meta Llama in Eight Months Note: 12/24 disclosure counted downloads of Llama and its derivatives. Source: Meta Platforms (8/24, 12/24, 3/25, 4/25), Stratchery podcast (5/25) Meta Llama – 8/24-4/25, per Meta Platforms Rising Performance of Open-Source Models + Falling Token Costs = Explosion of Usage by Developers Using AI I predicted that 2025 was going to be the year that open source became the largest type of model that people are developing with, and I think that’s probably going to be the case. That’s kind of how we’re thinking about this overall. - Meta Platforms CEO Mark Zuckerberg, 5/25 Meta Llama Downloads, MM Meta Llama Downloads (MM) – 8/24-4/25 0 400 800 1,200 8/24 10/24 12/24 2/25 4/25 The groundswell of support for Llama has been awesome. We announced ten weeks ago a billion downloads after the release of Llama 4. In just ten weeks, that number is now 1.2. And if you look at Hugging Face (where the downloads are happening), what’s cool is that most of these are derivatives. We have thousands of developers contributing. - Meta Platforms Chief Product Officer Chris Cox, 5/25 269 Developer AI Model Activity = +33x Increase in AI Models on Hugging Face – 11/24 vs. 3/22 AI Models Available from Hugging Face – 3/22-11/24, per Hugging Face Note: Hugging Face is an online platform that hosts and shares machine learning models, datasets, and tools – commonly used to access, test, and deploy AI models, including large language models. It has become a central hub for the open-source AI community. May include open-source and closed models. Source: Hugging Face (5/25), Meta (3/25) Number of AI Models Rising Performance of Open-Source Models + Falling Token Costs = Explosion of Usage by Developers Using AI ~35K 1.16MM +33x 3/25: 100k derivative models built off Meta Llama alone 270 AI Monetization Threats = Rising Competition + Open-Source Model Momentum (& China’s Rise) 271 As noted on page 8, Meta CTO Andrew Bosworth referred to the current state of AI as our space race and the people we’re discussing, especially China, are highly capable… In this context, it is important to remember what the stakes of the Space Race were: proving which political system could innovate faster and win the world’s trust in the process. Coming out on top in the Space Race played a role in enhancing USA’s strategic deterrence and cementing the primacy of western democratic values. The AI ‘space race,’ also has the potential to reshape the world order. China certainly knows these stakes. Back in 2015, ‘Made in China 2025,’ a new Chinese government initiative to shift the country from low-cost to high-value manufacturing in critical industries, seemed decades away. Fast forward to today, and China has dramatically accelerated its capabilities in these strategic sectors like robotics, electrification, and ‘information technology’ – best expressed by world-class artificial intelligence. Chinese AI capabilities now underpin nationally strategic areas such as battlefield logistics, target recognition, cyber operations, and autonomous decision-making platforms. In 2025, Chinese state media highlighted the integration of AI into non-combat support functions (e.g., military hospitals), while the Ministry of Science and Technology reinforced its commitment to ‘indigenous innovation’ in strategic technologies. The implications of Chinese AI supremacy would be profound. As OpenAI’s Sam Altman noted in a July 2024 Washington Post Op-Ed, If [authoritarian regimes] manage to take the lead on AI, they will force U.S. companies and those of other nations to share user data, leveraging the technology to develop new ways of spying on their own citizens or creating next-generation cyberweapons to use against other countries. AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise 272 …Meanwhile, alongside AI, broader economic trade tensions between the USA and China continue to escalate, driven by competition for control over strategic technology inputs. China, for now, remains the dominant global supplier of ‘rare earth elements’ – materials essential to advanced electronics, defense systems, and clean energy infrastructure – an imbalance that the USA is working hard to counter. Simultaneously, the USA has prioritized the reshoring of semiconductor manufacturing, supported by the CHIPS and Science Act, and bolstered its partnerships with allied nations (including Japan, South Korea and the Netherlands) to reduce reliance on Chinese supply chains. Taiwan continues to play a pivotal role in this dynamic. Despite American invention of core semiconductor technology like transistors and EUV lithography, it is Taiwan’s TSMC – the world’s most advanced semiconductor foundry – that drives global semiconductor production and is therefore central to both countries’ strategic calculations. It has taken a long time for the USA to wake up, but after two decades of inaction, both political parties are calling loudly for change. While each has taken a different approach (export controls in the Biden administration, economic nationalism and reshoring in the Trump administration), the move towards treating cutting-edge technology development as a core part of the national interest is a welcome adjustment. As Senators John Cornyn and Mark Warner noted in 2020 regarding semiconductors, America’s innovation in semiconductors undergirds our entire innovation economy…unfortunately, our complacency has allowed our competitors – including adversaries – to catch up. However, despite these measures, American intellectual property remains at risk; per OpenAI, We know PRC (China) based companies – and others – are constantly trying to distill the models of leading US AI companies…it is critically important that we are working closely with the US government to best protect the most capable models from efforts by adversaries and competitors to take US technology. What is clear, however, is that the American tone about Chinese technology has morphed since the early 2000s enthusiasm around China’s entry into the World Trade Organization (WTO). AI, semiconductors, and critical minerals, and technology developments in general, are no longer viewed solely as economic or technology assets – they represent strategic levers of national resilience and geopolitical power, core to both the USA and China. AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise 273 Public Market Capitalization Leader Tells of Last Thirty Years = Extraordinary USA Momentum… China Rising Global Public Market Capitalization Leaders – May, 2025 = 83% (25 of 30) USA-Based… 274 Source: Capital IQ (as of 5/15/25) Global Public Companies Ranked By Market Capitalization – 5/15/25, per Capital IQ Rank 2025 Company HQ Country Sector Market Cap ($B) 1 Microsoft USA Software / AI $3,368B 2 NVIDIA USA Semis / AI 3,288 3 Apple USA Hardware / AI 3,158 4 Amazon USA Internet / AI 2,178 5 Alphabet (Google) USA Internet / AI 1,997 6 Saudi Aramco Saudi Arabia Energy 1,686 7 Meta Platforms (Facebook) USA Internet / AI 1,619 8 Tesla USA Auto / AI 1,104 9 Broadcom USA Semis / AI 1,094 10 Berkshire Hathaway USA Finance 1,093 11 TSMC Taiwan Semis / AI 856 12 Walmart USA Consumer Products 771 13 JP Morgan Chase USA Finance 743 14 Visa USA Finance 678 15 Eli Lilly USA Healthcare 658 16 Tencent China Software / AI 591 17 Mastercard USA Finance 529 18 Netflix USA Internet / AI 501 19 Exxon Mobil USA Energy 468 20 Costco Wholesale USA Consumer Products 448 21 Oracle USA Hardware / AI 447 22 Procter & Gamble USA Consumer Products 381 23 Home Depot USA Consumer Products 376 24 Johnson & Johnson USA Consumer Products 360 25 SAP Germany Software / AI 343 26 Bank of America USA Finance 334 27 ICBC China Finance 330 28 AbbVie USA Healthcare 321 29 Coca-Cola USA Consumer Products 308 30 Palantir USA Software / AI 302 Public Market Capitalization Leader Tells of Last Thirty Years = Extraordinary USA Momentum…China Rising …Global Public Market Capitalization Leaders – December, 1995 = 53% (16 of 30) USA-Based 275 Source: Bloomberg (as of 5/15/25) Global Public Companies Ranked By Market Capitalization – 12/31/95, per Bloomberg Rank 1995 Company HQ Country Sector Market Cap ($B) 1 Nippon Telegraph Japan Telco $128B 2 General Electric USA Industrials 120 3 AT&T USA Telco 103 4 Exxon USA Energy 100 5 Coca-Cola USA Consumer Products 94 6 Merck USA Healthcare 81 7 Toyota Japan Automotive 79 8 Roche Switzerland Healthcare 78 9 Altria USA Consumer Products 75 10 Industrial Bank of Japan Japan Finance 71 11 MUFG Bank Japan Finance 68 12 Sumimoto Mitsui Japan Finance 66 13 Fuji Bank Japan Finance 64 14 Dai-Ichi Kangyo Bank Japan Finance 61 15 UFJ Bank Japan Finance 59 16 Novartis Switzerland Healthcare 57 17 Procter & Gamble USA Consumer Products 57 18 Johnson & Johnson USA Consumer Products 55 19 Microsoft USA Software 52 20 Walmart USA Consumer Products 51 21 IBM USA Hardware / Software 51 22 DirecTV USA Media 49 23 Intel USA Hardware 47 24 BP United Kingdom Energy 46 25 Nestle Switzerland Consumer Products 45 26 Mobil USA Energy 44 27 PepsiCo USA Consumer Products 44 28 AIG USA Finance 44 29 Shell United Kingdom Energy 44 30 Sakura Bank Japan Finance 43 Public Market Capitalization Leader Tells of Last Thirty Years = Extraordinary USA Momentum…China Rising Over the past thirty years (1995 to 2025), just six companies remained on the top 30 most highly valued publicly traded global companies – Microsoft / Walmart / Exxon Mobil / Procter & Gamble / Johnson & Johnson / Coca-Cola. New entrants are NVIDIA / Apple / Amazon / Alphabet (Google) / Saudi Aramco / Meta Platforms (Facebook) / Tesla / Broadcom / Berkshire Hathaway / TSMC / JP Morgan Chase / Visa / Eli Lilly / Tencent / Mastercard / Netflix / Costco Wholesale / Oracle / Home Depot / SAP / Bank of America / ICBC / AbbVie / Palantir. In 1995, USA had 53% (16 of 30) of the most valuable companies and 83% (25 of 30) in 2025. Japan came next with 9, now 0. Switzerland followed with 3, now 0. UK had 2, now 0. In 2025, new geographic entrants include China with 2 and Saudi Arabia / Taiwan / Germany with 1 each. 276 Public Market Capitalization Leader Tells of Last Thirty Years = Extraordinary USA Momentum…China Rising 277 Rank 2025 Company HQ Country Sector Market Cap ($B) 1 Microsoft USA Software / AI $3,368B 2 NVIDIA USA Semis / AI 3,288 3 Apple USA Hardware / AI 3,158 4 Amazon USA Internet / AI 2,178 5 Alphabet (Google) USA Internet / AI 1,997 6 Meta Platforms (Facebook) USA Internet / AI 1,619 7 Tesla USA Auto / AI 1,104 8 Broadcom USA Semis / AI 1,094 9 TSMC Taiwan Semis / AI 856 10 Tencent China Software / AI 591 11 Netflix USA Internet / AI 501 12 Oracle USA Hardware / AI 447 13 SAP Germany Software / AI 343 14 Palantir USA Software / AI 302 15 ASML Netherlands Semis / AI 300 16 Alibaba China Internet / AI 281 17 Salesforce USA Software / AI 279 18 T-Mobile USA Telco 273 19 Samsung S. Korea Hardware / AI 268 20 Cisco USA Semis / AI 256 21 IBM USA Hardware / AI 243 22 China Mobile China Telco 241 23 Reliance India Telco 216 24 ServiceNow USA Software / AI 214 25 Intuitive Surgical USA Health Tech 201 26 AT&T USA Telco 197 27 Siemens Germany Hardware / AI 194 28 Uber USA Internet / AI 189 29 AMD USA Semis / AI 186 30 Intuit USA Software / AI 185 Global Technology Companies Ranked By Market Capitalization – 5/15/25, per Capital IQ Source: Capital IQ (as of 5/15/25) Global Public Technology Market Cap Leaders – May, 2025 = 70% (21 of 30) USA-Based… Public Market Capitalization Leader Tells of Last Thirty Years = Extraordinary USA Momentum…China Rising 278 Global Technology Companies Ranked By Market Capitalization – 12/31/95, per Bloomberg …Global Public Technology Market Cap Leaders – December, 1995 = 53% (16 of 30) USA-Based Rank 1995 Company HQ Country Sector Market Cap ($B) 1 Nippon Telegraph Japan Telco $128B 2 AT&T USA Telco 103 3 Microsoft USA Software 52 4 IBM USA Hardware / Software 51 5 Intel USA Hardware 47 6 BellSouth USA Telco 43 7 HP USA Hardware 43 8 GTE USA Telco 42 9 BT United Kingdom Telco 34 10 Panasonic Japan Hardware 34 11 SingTel Singapore Telco 34 12 Motorola USA Hardware 34 13 Hitachi Japan Hardware 33 14 Verizon USA Telco 29 15 Toshiba Japan Hardware 26 16 Peraton USA Software / Hardware 25 17 Nynex USA Telco 24 18 Sony Japan Hardware 22 19 Cisco USA Hardware 21 20 Fujitsu Japan Hardware 20 21 PCCW Hong Kong Telco 20 22 NEC Japan Software 19 23 Oracle USA Hardware 18 24 MCI USA Telco 18 25 Sharp Japan Hardware 18 26 TelMex Mexico Telco 17 27 KDDI Japan Telco 17 28 US West USA Telco 17 29 Cable & Wireless USA Telco 16 30 Telekom Malaysia Malaysia Telco 16 Source: Bloomberg (as of 5/15/25) Public Market Capitalization Leader Tells of Last Thirty Years = Extraordinary USA Momentum…China Rising 279 Over the past thirty years (1995 to 2025), just five companies remained on the top 30 most highly valued publicly traded global technology companies – Microsoft / Oracle / Cisco / IBM / AT&T. New entrants are NVIDIA / Apple / Amazon / Alphabet (Google) / Meta Platforms (Facebook) / Tesla / Broadcom / TSMC / Tencent / Netflix / SAP / Palantir / ASML / Alibaba / Salesforce / T-Mobile / Samsung / China Mobile / Reliance / ServiceNow / Intuitive Surgical / Siemens / Uber / AMD / Intuit. In 1995, USA had 53% (16 of 30) of the most valuable tech companies and 70% (21 of 30) in 2025. In 1995, Japan had 30% (9 of 30) of the top tech companies and 0 in 2025. UK / Singapore / Hong Kong / Mexico / Malaysia had 1, now 0. In 2025, new geographic entrants include China with 3, Germany with 2, Taiwan with 1, Netherlands with 1, South Korea with 1 & India with 1. Note that while Taiwan has only one company on the list – TSMC – the company produces 80%-90% of the world’s most advanced semiconductors and 62%+ of global semiconductors as of Q2:24, per The Center for Strategic & International Studies & Counterpoint Research. It’s stunning how much can change in a generation… the emergence of internet connectivity was foundational to most of the new adds. The emergence of AI will have the same type of effect over the next three decades, but likely faster. Source: Center for Strategic & International Studies, ‘A Strategy for The United States to Regain its Position in Semiconductor Manufacturing’ (2/24); Counterpoint Research, ‘Global Semiconductor Foundry Market Share: Quarterly’ (3/25) Public Market Capitalization Leader Tells of Last Thirty Years = Extraordinary USA Momentum…China Rising 280 USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 281 AI Large Language Model (LLM) Leadership = USA & China Outpacing Rest of World (RoW), per Epoch AI *Hong Kong is a Special Administrative Region (SAR) of China, not an independent country. Note: Epoch AI defines AI models as ‘large-scale’ when their training compute is confirmed to exceed 1023 floating-point operations. Source: Epoch AI via Our World In Data (5/25) Cumulative Large-Scale AI Systems by Country* – 2017-2024, per Epoch AI Cumulative Large-Scale AI Systems USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 0 50 100 150 2017 2018 2019 2020 2021 2022 2023 2024 United States China Multinational United Kingdom France Canada Hong Kong Germany 282 China AI = Rapid Relevance… DeepSeek R1 – 1/20/25… Source: Reuters, ‘DeepSeek narrows China-US AI gap to three months, 01.AI founder Lee Kai-Fu says’ (3/25); China Talk Media (11/24) We believe that as the economy develops, China should gradually become a contributor instead of freeriding. In the past 30+ years of the IT wave, we basically didn’t participate in real technological innovation. We’re used to Moore’s Law falling out of the sky, lying at home waiting 18 months for better hardware and software to emerge. That’s how the Scaling Law is being treated… What we see is that Chinese AI can’t be in the position of following forever. We often say that there is a gap of one or two years between Chinese AI and the United States, but the real gap is the difference between originality and imitation. If this doesn’t change, China will always be only a follower – so some exploration is inescapable. - DeepSeek CEO Liang Wenfang, 11/24 USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 283 …China AI = Rapid Relevance… Alibaba Qwen 2.5-Max – 1/29/25… Source: Mashable, ‘Meet Alibaba’s Qwen 2.5, an AI model claiming to beat both DeepSeek and OpenAI’s ChatGPT’ (1/25); Alibaba (1/25) Qwen2.5-Max outperforms DeepSeek V3 in benchmarks such as Arena-Hard, LiveBench, LiveCodeBench, and GPQA-Diamond, while also demonstrating competitive results in other assessments, including MMLU-Pro. Our base models have demonstrated significant advantages across most benchmarks, and we are optimistic that advancements in post-training techniques will elevate the next version of Qwen2.5-Max to new heights. The scaling of data and model size not only showcases advancements in model intelligence but also reflects our unwavering commitment to pioneering research. We are dedicated to enhancing the thinking and reasoning capabilities of large language models through the innovative application of scaled reinforcement learning. - Alibaba Qwen 2.5 Press Release, 1/25 USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 284 …China AI = Rapid Relevance… Baidu Ernie 4.5 Turbo – 4/25/25 Source: Reuters, ‘Baidu launches new AI model amid mounting competition’ (4/24/25); Baidu via X, ‘Supercharging AI Innovation with More Powerful and More Affordable New Models’ (4/24/25) ERNIE 4.5 Turbo is the newest member of the flagship ERNIE foundation model family. Imagine an AI that's not just smart, but also affordable and versatile. Here's why it's turning heads: - Multimodal Prowess: It excels in handling text, images, and even videos, making it a Swiss Army knife for developers. - Cost-Effectiveness: Priced at just RMB 0.8 per million tokens for input and RMB 3.2 for output, it's 80% cheaper than its predecessor – and a fraction of the cost of leading competitors. It costs only 40% of DeepSeek V3 and just 0.2% of GPT-4.5. - High Performance: Benchmark tests show it matches GPT-4.1 and outperforms GPT-4o in most multimodal tasks – delivering high-impact results with every run. - Baidu Post on X, 4/24/25 USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 285 China AI = LLM Performance Catching Up to USA Models, per Stanford HAI… Note: The LMSYS Chatbot Arena is a public website where people compare two AI chatbots by asking them the same question and voting on which answer is better. The results help rank how well different language models perform based on human judgment. Only the highest-scoring model in any given month is shown in this comparison. Source: LMSYS via Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) Performance of Top-Scoring USA vs. Chinese AI Model on LMSYS Chatbot Arena – 1/24-2/25, per Stanford HAI & LMSYS USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 286 …China AI = LLMs Achieving Performance with Lower Training Costs, per Epoch AI… Source: Epoch AI via NBC News, ‘Why DeepSeek is Different, in Three Charts’ (1/25) LLM Training Cost by Year Released – 2022-2024, per Epoch AI & NBC News USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 287 …China AI = LLMs Increasingly Powered by Local Semiconductors… Source: Financial Times, ‘Huawei delivers advanced AI chip ‘cluster’ to Chinese clients cut off from Nvidia’ (4/29/25) Huawei has started the delivery of its advanced artificial intelligence chip ‘cluster’ to Chinese clients who are increasing orders after being cut off from Nvidia’s semiconductors because of Washington’s export restrictions… - Financial Times, 4/29/25 USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 288 …China AI = Industrial Robot Installed Base Higher vs. Rest of World… Source: International Federation of Robotics (IFR) (2024) via Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) Number of Industrial Robots Installed (China vs. Rest of World) (K) – 2023, per IFR USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 China Rest of World 289 …China AI = Industrial Robot Installed Base Higher vs. Rest of World Source: International Federation of Robotics (IFR) (2024) Number of Industrial Robots Installed (China vs. Rest of World) (K) – 2014-2023, per IFR USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 Rest of World (excl. USA & China) Number of Industrial Robots Installed, K 0 100 200 300 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 China USA 290 Robots – Industrial & Humanoid = Creating New Data @ New Scale Source: The Wall Street Journal (2/18, 5/22, 9/22, 5/25) Images of Industrial & Humanoid Robots, per The Wall Street Journal USA vs. China in Technology = China’s AI Response Time Significantly Faster vs. Internet 1995 291 China Consumer AI Usage = DeepSeek Rose Quickly 292 To understand how the generative AI market is evolving, it helps to examine the divergence in provider usage across regions, channels, and user preferences. At a global level, OpenAI’s ChatGPT remains the clear leader in both desktop and mobile user share. But underneath the surface, the market is shifting. Platforms like Anthropic’s Claude are gaining momentum, and Google’s Gemini continues to grow. xAI’s Grok posted a staggering +294% increase in global website visits month-over-month according to Similarweb – making it the fastest-growing AI assistant during the 2/25-3/25 window. Geography is also playing an increasingly central role in shaping which models win. ChatGPT dominates in most countries – excluding Russia and China, where ChatGPT cannot operate and DeepSeek is strong. China users are turning to local models at scale. According to Roland Berger Consulting, the top 10 AI apps by monthly active users in China are domestically developed…DeepSeek, Kimi, Nami AI, and ERNIE Bot are each racking up tens of millions of users. The story is different outside China, where ChatGPT leads by a wide margin. The bifurcation is clear: domestic champions are emerging in China, while global platforms dominate elsewhere. This reflects differences in regulation, language, cultural alignment, and platform reach. It’s foundational to remember how China has restricted platform access in its country. Facebook, Twitter, Google and YouTube have been unavailable to Chinese citizens since 2010 or earlier. Other restricted platforms include the likes of Instagram, WhatsApp, Wikipedia, Telegram and Spotify, and more recently, the likes of ChatGPT, Google Gemini, Anthropic Claude, Meta AI and Microsoft Copilot. Sentiment is varied too. According to Stanford HAI and Ipsos, China citizens are materially more optimistic about AI’s net benefits than their USA counterparts. 83% of Chinese respondents in 2024 said AI products and services have more benefits than drawbacks – up from 78% in 2022. In contrast, only 39% of USA respondents shared that view, with little change over the two-year period. It also reflects a deeper philosophical divide in how societies are adapting to AI: not just who builds it, but how it’s perceived and embraced. In this environment, platform choice isn’t just about price or performance. It may be increasingly shaped by national identity. China Consumer AI Usage = DeepSeek Rose Quickly 293 LLM User Share – Desktop Users = OpenAI ChatGPT Leads…DeepSeek Rose Quickly, per YipitData… Estimated Global Monthly Active Desktop User Share – 2/24-4/25, per YipitData *Chatbot only. Does not include other places Gemini is integrated. Note: User share shown across these five providers; other LLMs’ user share not shown. Desktop users only. Figures calculate the number of users on a given platform, divided by the number of users on all platforms combined. Figures are non-deduped (i.e., users using multiple platforms may be counted twice). Data is a subset of global internet users and absolute user data will be understated; however, given that the panel is globally-representative (with limitations on China- specific data), relative comparisons / trends are informative. Data measures several million global active desktop users’ clickstream data. Data consists of users’ web requests & is collected from web services / applications, such as VPNs and browser extensions. Panel is globally-representative (with limitations on China-specific data). Users must have been part of the panel for 2 consecutive months to be included. Data is non-deduped; i.e., some users may use multiple platforms. Source: YipitData (accessed 5/25) Share of Global Desktop Users, % 0% 50% 100% OpenAI: ChatGPT Google: Gemini* DeepSeek xAI: Grok Perplexity Anthropic: Claude 2/24 2/25 4/25 -1,504 bps +1,007 bps -619 bps +845 bps +198 bps China Consumer AI Usage = DeepSeek Rose Quickly +73 bps 294 …LLM User Share – Mobile App Users = OpenAI ChatGPT Leads…DeepSeek Rose Quickly, per Sensor Tower… LLMs – Global Monthly Active Mobile App User Share – 2/24-4/25, per Sensor Tower *Chatbot only. Does not include other places Gemini is integrated. Note: User share shown across these five providers; other LLMs’ user share not shown. China data may be incomplete due to reporting gaps. ChatGPT app not available in China, Russia and select other countries as of 5/25. Data is non-deduped; i.e., some users may use multiple platforms. Data for standalone apps only. Source: Sensor Tower (accessed 5/25) Share of Global App Users, % 0% 50% 100% OpenAI: ChatGPT DeepSeek Google: Gemini* xAI: Grok Perplexity Anthropic: Claude 2/24 2/25 4/25 -1,617 bps +837 bps +272 bps -9 bps +49 bps China Consumer AI Usage = DeepSeek Rose Quickly +469 bps …LLM User Share – Mobile App Downloads + Users = ChatGPT Supporting Strong Momentum… 295 Global Statistics on Apple App Store + Google Play Store – 2/25-4/25, per Sensor Tower Downloads (MM) MAUs (MM) 2/25 3/25 4/25 2/25 3/25 4/25 LLM Apps ChatGPT 56MM 80MM 124MM 378MM 432MM 530MM DeepSeek 34 20 18 43 48 55 Grok 4 14 16 3 16 31 Gemini* 16 17 15 20 21 21 Perplexity 3 4 4 10 12 14 Claude 1 1 1 3 4 3 ‘Traditional’ Apps YouTube 13 10 9 2,799 2,805 2,809 Google Chrome 9 9 7 2,369 2,380 2,387 Facebook 46 47 45 2,104 2,110 2,103 China Consumer AI Usage = DeepSeek Rose Quickly *Chatbot only. Does not include other places Gemini is integrated. Note: China data may be incomplete due to reporting gaps. ChatGPT app not available in China, Russia and select other countries as of 5/25. Data is non-deduped; i.e., some users may use multiple platforms. Data for standalone apps only. Source: Sensor Tower (accessed 5/25) 296 …LLM User Share – Query Volume = OpenAI ChatGPT Leads, per Google LLMs – Global Daily Query Volume (MM) – 3/28/25, per Google *Chatbot only. Does not include other places Gemini is integrated. Note: DeepSeek data excludes China usage. Figures are rounded. Meta AI data quoted as ‘>200M.’ Source: Google disclosed during testimony given in the remedies phase of ‘United States v. Google LLC’ (1/24/23-4/17/25). Data derived from company disclosures, Sensor Tower, AppAnnie, Similarweb, & market intelligence estimates, as reported by Business Insider, ‘Google's Gemini usage is skyrocketing, but rivals like ChatGPT and Meta AI are still blowing it out of the water’ (4/25) (link) Global Daily Queries, MM 0 400 800 1,200 OpenAI: ChatGPT Meta: Meta AI Google: Gemini* xAI: Grok DeepSeek Perplexity China Consumer AI Usage = DeepSeek Rose Quickly Top Global AI Platforms 297 China AI Users = Using Local AI Platforms, per Roland Berger Consulting Note: HQ = Headquarters. Axes for two charts are to different scales. Source: Roland Berger via AICPB, ‘Five key trends in China's generative AI market in 2025’ (3/25); China National Bureau of Statistics (1/25); USA Census Bureau (4/25) HQ HQ China Consumer AI Usage = DeepSeek Rose Quickly 0 50 100 Mooxiang Dreamina xinye ChatGLM ERNIE Bot Tencent Yuanbao Nami AI Kimi DeepSeek Doubao Top Chinese AI Platforms 0 200 400 Gemini Gemnius ChatOn Character AI Talkie AI Remini DeepSeek Nova Doubao ChatGPT Monthly Active Users, MM Monthly Active Users, MM AI Platforms – Monthly Active Users (MM), China vs. Global – 3/25, per Roland Berger Consulting 298 AI Benefits vs. Drawbacks – China vs. USA Citizens = China Materially More Optimistic Regarding Benefits Note: N = 19,504 online adults aged 16-74 across 28 countries. Source: Ipsos, 'AI Monitor 2024' (6/24) as quoted in Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) ‘Products & Services Using AI Have More Benefits than Drawbacks’ – 2022-2024, per Stanford HAI & Ipsos 0% 50% 100% China USA 2022 2024 % of Respondents that ‘Agree’ China Consumer AI Usage = DeepSeek Rose Quickly • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 299 1 2 3 4 5 6 7 8 Outline 300 For the most part, we have focused on AI momentum and monetization of desktop / mobile software… AI momentum and monetization in our physical world is, in some respects, even more head-turning. We are entering an era where intelligence is not just embedded in digital applications, but also in vehicles, machines, and defense systems. Beyond the rise of digital agents, the world is increasingly experiencing the rise of physical agents. Self-driving fleets like Waymo’s and Tesla’s Full Self-Driving (FSD) beta are no longer science projects confined to test tracks – they’re revenue-generating deployments, logging millions of driverless miles with increasingly autonomous software loops. The stack beneath them is getting smarter, and the data is more vast and richer. Applied Intuition, for example, is building simulation platforms and software-defined vehicle systems that abstract autonomy away from hardware – so manufacturers can ship intelligence as easily as parts. Per Uber CEO Dara Khosrowshahi, Fast forward 15, 20 years, I think that the autonomous driver is going to be a better driver than the human driver. They will have trained on lifetimes of driving that no person can, they’re not going to be distracted. We are seeing the early architecture of AI-native infrastructure for the physical world. In defense, companies like Anduril are redefining what defense looks like – shipping autonomous drones and counter-intrusion systems with AI in every edge node, not just the command center. In agriculture, companies like Carbon Robotics are putting AI into the dirt – using computer vision to eliminate weeds without herbicides. We believe that these are examples of a broader shift: a world where AI turns capital assets into software endpoints. Intelligence, once confined to screens and dashboards, becomes kinetic. AI & Physical World Ramps = Fast + Data-Driven 301 Physical World AI – Vertically-Integrated Electric Vehicles (Tesla) = ~100x Increase in Fully Self-Driven Miles Over Thirty-Three Months Tesla Vertically-Integrated Electric Vehicles Source: Tesla Disclosures & Q1:25 Investor Deck For full self-driving, we’ve released version 12, which is a complete architectural rewrite compared to prior versions. This is end-to-end artificial intelligence… …And it really is…quite a profound difference… …So, this is the first time AI is being used, not just for object perception, but for path planning and vehicle controls. We replaced 330,000 lines of C++ code with neural nets. It's really quite remarkable. So, as a side note, I think Tesla is probably the most probably the most efficient company in the world for AI inference. Out of necessity. - Tesla CEO Elon Musk, 1/24 Tesla Cumulative Full Self-Driving Miles Driven, MM AI & Physical World Ramps = Fast + Data-Driven 0 2,000 4,000 6/22 9/22 12/22 3/23 6/23 9/23 12/23 3/24 6/24 9/24 12/24 3/25 Tesla Cumulative Fully Self-Driven Miles (MM) – 6/22-3/25, per Tesla 302 Physical World AI – Fully-Autonomous Vehicles (Waymo) = 0% to 27% Share of San Francisco Rideshares Over Twenty Months, per YipitData Waymo Fully-Autonomous Vehicles Note: Data derived from USA-user email receipt panel composed of >1mm monthly transacting USA email accounts from all available domains. Paid rides only. Numbers are estimates due to sample size. Source: Waymo, Tech Brew (1/25), Fast Company (3/25), YipitData (4/4/25) [We are creating] an end-to-end, very, very robust, and large end-to-end system that’s multi-modal in its foundation so that perception planning and prediction… can become even more robust than it is today. - Waymo Co-CEO Tekedra Mawakana, 1/25 % of San Francisco Gross Bookings Estimated Market Share (Gross Bookings) – 8/23-4/25, San Francisco Operating Zone, per YipitData 0% 25% 50% 75% 8/23 12/23 4/24 8/24 12/24 4/25 Waymo Uber Lyft What we’ve done in San Francisco is prove to ourselves – and to the world – that not only does autonomy work, but it works at scale in a market and can be a viable commercial product. - Waymo Co-CEO Dmitri Dolgov, 3/25 AI & Physical World Ramps = Fast + Data-Driven 303 Physical World AI –Vehicle Intelligence (Applied Intuition) = Serving Automotive, Trucking, Construction & Defense Applied Intuition Vehicle Intelligence Note: OEM = Original Equipment Manufacturer. Source: Applied Intuition Number of Top Auto OEMs Served Applied Intuition Top Global Auto OEMs Served – 2016-2024, per Applied Intuition* Within the last few years, we’ve seen massive advances in artificial intelligence that will have groundbreaking impacts on the industries that Applied Intuition serves. Our role as a leader in the ecosystem is to bring the best of what Silicon Valley has to offer to our global customer base. - Applied Intuition Co-Founder & CEO Qasar Younis, 3/24 We've seen accelerating adoption of our AI-powered tools, autonomy software, and vehicle operating system as traditional OEMs are seeing strong ROI. The Defense sector is also looking for vehicle intelligence solutions. We've provided our off-road autonomy stack for defense for several years, and have expanded our defense tech product portfolio significantly over the past year. - Applied Intuition Co-Founder & CTO Peter Ludwig, 5/25 AI & Physical World Ramps = Fast + Data-Driven * Applied Intuition serves a broad base of customers in different verticals, such as Porsche / Toyota (auto), Traton / Isuzu (trucking), Caterpillar (construction) and several US military branches (defense). 0 18 0 10 20 2016 2024 304 Physical World AI – USA Defense (Anduril) = +2x Y/Y Revenue Growth for Last Two Years Anduril AI-Enabled Autonomous USA Defense Systems Source: Anduril, Forbes, TechCrunch, CNBC Annual Revenue, $MM Anduril Estimated Revenue ($MM) – F2020-F2024, per News Reports $0 $500 $1,000 F2020 F2021 F2022 F2023 F2024 At Anduril, we firmly believe that today’s most pressing national security challenges cannot be solved without AI- enabled systems and autonomy at scale. These systems will help to keep our service members safe and empower them to make better decisions at the speed of modern warfare… …When developed and deployed properly, [AI and autonomous systems] can make warfare more proportional, more precise, and less indiscriminate than it has ever been before. - Anduril Co-Founder & CEO Brian Schimpf, 12/23 AI & Physical World Ramps = Fast + Furious 305 Physical World AI = AI-Driven Mining Exploration (KoBold Metals) = Reversing Trend in Exploration Inefficiency KoBold Metals AI-Driven Mining Exploration Source: KoBold Metals, Wired (12/22) Mineral Deposit Discoveries per $B of Exploration Spend – 1975-2023, per KoBold Metals We're looking to expand and diversify the supply of these metals all over the world, but we're taking a totally different approach [from conventional mining companies]. Two-thirds of our team are software engineers or data scientists. - KoBold Metals Co-Founder & CEO Kurt House, 12/22 KoBold’s Machine Prospector technology combines never before used datasets with conventional geochemical, geophysical, & geological data in statistical association models to identify prospects. KoBold’s technology accelerates exploration by efficiently screening large regions & makes our search more effective by identifying the most promising locations. - KoBold Metals Website Discoveries per $B of Exploration Spend 0 4 8 12 16 1975 1983 1991 1999 2007 2015 2023 AI & Physical World Ramps = Fast + Furious KoBold Metals Industry Average 306 Physical World AI – Agricultural Modernization (Carbon Robotics) = 230K+ Acres Weeded / 100K+ Gallons of Glyphosate Prevented Carbon Robotics AI-Driven Agricultural Modernization Source: Carbon Robotics, Organic Produce Network (12/22), GeekWire (3/25) The LaserWeeder leverages our sophisticated laserweeding technology, driven by AI deep learning models and computer vision software, to efficiently identify, target, and eliminate weeds by zapping them at the meristem. The implement can cover up to 2 acres per hour and shoot up to 200,000 weeds. - Carbon Robotics Founder & CEO Paul Mikesell, 12/22 We learned from farmers that their biggest challenges continue to be around labor and labor availability. If they could, they would run everything 24/7. They would run everything every minute of farming season to get as much done as possible. - Carbon Robotics Founder & CEO Paul Mikesell, 3/25 Carbon Robotics Cumulative Fleet Acres Weeded (K) – 1/23-5/25, per Carbon Robotics Cumulative Fleet Acres Weeded, K 0 50 100 150 200 250 AI & Physical World Ramps = Fast + Furious 307 Physical World AI – Intelligent Grazing (Halter) = +150% Net-New Livestock Collars Contracted Y/Y Halter AI-Driven Intelligent Grazing *2025 figures annualized as of Q1:25. Source: Halter (5/25) We’ve seen firsthand the care and dedication ranchers have for their land and animals. We’ve also seen how agriculture, one of the oldest and most vital industries, has yet to receive the full benefits of modern technology. This leaves enormous opportunity for ranchers to unlock greater productivity and sustainability across their operations. We believe grazing management holds the key. Effective rotational grazing enables more efficient use of natural resources and increased productivity, while also enhancing soil health and improving root structures to sequester more carbon. We don’t believe more productivity needs to come at the cost of sustainability. We can do good for ranchers, and the planet. - Halter (as of 5/25) Halter Net New Collars Contracted (K) – 2023-2025*, per Halter Net New Collars Contracted, K AI & Physical World Ramps = Fast + Data-Driven 0 200 400 2023 2024 2025* • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 308 1 2 3 4 5 6 7 8 Outline 309 Thanks to the rise in low-cost satellite-driven Internet connectivity / access, the potential for the 2.6B (or 32% of the world’s population) that is not online to come online is increasing. These new users will start from scratch with AI functionality. Wow! When these new users come online, they likely won’t be met by browsers and search bars. They’ll start with AI – and in their native language. Imagine a ‘first experience’ of the internet that doesn’t involve typing a query into a search engine but instead talking to a machine that talks back. Imagine skipping the traditional application layer entirely, with an agent-driven interface managing disparate tech platforms from one place while understanding users’ local language, context, and intent. An agent-first internet experience could upend existing tech hierarchies, disintermediating dominant platforms and redistributing value. In this model, the winners wouldn’t be those who own the app, but those who own the interface. Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before 310 Global Internet Users = Epic Growth Over Past Thirty-Three Years, per ITU Note: 2021 data interpolated due to data gaps for select nations. Regions are per United Nations definitions. Data is occasionally unavailable for select nations in select years, which may lead to trendline choppiness or minor discrepancies vs. global user figures. Source: United Nations / International Telecommunications Union (3/25) Internet Users by World Region (B) – 1990-2022, per ITU 0 2 4 6 1990 1994 1998 2002 2006 2010 2014 2018 2022 Internet Users, B East Asia & Pacific Sub-Saharan Africa South Asia North America Middle East & North Africa Latin America & Caribbean Europe & Central Asia Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before 311 Global Internet Penetration = 68% vs. 16% Nineteen Years Ago, per ITU Source: United Nations / International Telecommunications Union (3/25) Global Internet Penetration – 2005-2024, per ITU 16% 68% 0% 25% 50% 75% 100% 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Internet Penetration, Global, % Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before 312 Global Internet Penetration by Region @ +70% = All Regions Except South Asia + Sub-Saharan Africa, per ITU Note: Data unavailable for South Asia region for 2023. 2021 data interpolated due to data gaps for select nations. Regions are per United Nations definitions. Data is occasionally unavailable for select nations in select years, which may lead to trendline choppiness. Source: United Nations / International Telecommunications Union (3/25) Regional Internet Penetration – 2005-2023, per ITU Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before Internet Penetration by Region, % 0% 25% 50% 75% 100% 2005 2007 2009 2011 2013 2015 2017 2019 2021 2023 North America Europe & Central Asia East Asia & Pacific Latin America & Caribbean Middle East & North Africa South Asia Sub-Saharan Africa 313 Global Internet Penetration by Population Density = 83% of Urban Dwellers Online vs. 48% Rural Source: United Nations / International Telecommunications Union (3/25) Internet Penetration By Urban Status – 2019-2024, per ITU Internet Penetration by Urban Status, % Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before 72% 83% 31% 48% 0% 25% 50% 75% 100% 2019 2020 2021 2022 2023 2024 Urban Rural 314 Global Internet Users @ 5.5B = +6% Y/Y & Accelerating, per ITU Source: United Nations / International Telecommunications Union (3/25) Global Internet Users (B) vs. Y/Y Growth – 2005-2024, per ITU Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before 0% 8% 16% 24% 0 2 4 6 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Internet Users, Global, B (Blue Bars) Y/Y Growth, % (Red Line) 315 ChatGPT Mobile App @ 530MM MAUs in Twenty-Three Months = Global Growth We Have Not Seen Likes Of Before Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before ChatGPT App Monthly Active Users (MAUs) (MM) – 5/23-4/25, per Sensor Tower 0 200 400 600 ChatGPT App Monthly Active Users, MM East Asia & Pacific Sub-Saharan Africa South Asia North America Middle East & North Africa Latin America & Caribbean Europe & Central Asia Note: Regions are per United Nations definitions. ChatGPT app not available in China, Russia and select other countries as of 5/25. Includes only Android, iPhone & iPad users. Figures may understate true ChatGPT user base (e.g., desktop or mobile webpage users). Data for standalone app only. Source: Sensor Tower (5/25) 316 ChatGPT Mobile App – Top User Countries = India @ 14%...USA @ 9%...Indonesia @ 6%, per Sensor Tower Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before ChatGPT Mobile App Monthly Active Users (MM), Top 10 Countries – 5/23-4/25, per Sensor Tower Note: Regions are per United Nations definitions. ChatGPT app not available in China, Russia and select other countries as of 5/25. Includes only Android, iPhone & iPad users. Figures may understate true ChatGPT user base (e.g., desktop or mobile webpage users). Data for standalone app only. Source: Sensor Tower (5/6/25) ChatGPT App Monthly Active Users, MM 0 100 200 300 5/23 6/23 7/23 8/23 9/23 10/23 11/23 12/23 1/24 2/24 3/24 4/24 5/24 6/24 7/24 8/24 9/24 10/24 11/24 12/24 1/25 2/25 3/25 4/25 India Pakistan Mexico Egypt Brazil Indonesia USA Country % of Global Users (4/25) 13.5% 3.0% 3.5% 3.9% 5.4% 5.7% 8.9% Germany 3.0% France Vietnam 2.9% 2.6% 317 DeepSeek Mobile App @ 54MM MAUs in Four Months = Growth Concentrated in China (34% Users) & Russia (9%) Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before 0 10 20 30 40 50 60 1/25 2/25 3/25 4/25 China Egypt Brazil Indonesia USA India Russia Note: Regions are per United Nations definitions. Includes only Android, iPhone & iPad users. Figures may understate true DeepSeek user base (e.g., desktop or mobile webpage users). Data for standalone app only. Data may be incomplete for China, Russia, and select other countries due to informational restrictions. Source: Sensor Tower (5/6/25) Country % of Global Users (4/25) 33.9% 2.7% 3.1% 3.5% 4.4% 6.9% 9.2% DeepSeek Mobile App Monthly Active Users (MAUs) (MM) – 1/25-4/25, per Sensor Tower DeepSeek App Monthly Active Users, MM Others 36.2% 318 New Internet User Growth = Enabled by AI + Satellites Cold War / Space Race (1957-1991) Post-Cold War (1992-2007) Commercial + National Renaissance (2008-2024) Orbital / Satellite Launch Market Share, Global = SpaceX Rising 319 New Internet User Growth = Enabled by AI + Satellites Orbital Launches by Year & Country – 1957-2025, per SpaceX, Space Stats & USA FAA Note: Orbital launches from other celestial bodies than Earth are not included (e.g., Apollo LM ascents from the Moon’s surface). Source: SpaceX public announcements (1/25), Space Stats (3/25), USA Federal Aviation Administration (3/25) 0 100 200 300 SpaceX United States (Excluding SpaceX) China Russia Others Launches per Year SpaceX Starlink @ 5MM+ Subscribers = +202% Annual Growth Over 3.2 Years 320 Starlink Global Number of Subscribers (MM) – 2021-2024, per SpaceX Announcements Source: SpaceX public announcements Starlink Global Subscribers, MM SpaceX: Announced 5MM+ subscribers on X (2/25) New Internet User Growth = Enabled by AI + Satellites 0 1 2 3 4 5 2021 2022 2023 2024 SpaceX Starlink Ecosystem = Coverage Expanding Globally 321 Starlink Global Coverage – 5/25, per SpaceX Source: SpaceX website (5/25) New Internet User Growth = Enabled by AI + Satellites Starlink = Unlocking Previously-Inaccessible Internet Access in AI Era 322 Select Global Starlink Use Cases – 4/25, per SpaceX Coco, Monterrey, Mexico Starlink's technology has enabled Coco's operations, delivering high- speed, reliable internet that bridges the digital divide in rural Mexico. Through our streamlined community WiFi services, we're not just offering connectivity, we're opening a window to the world for hundreds in remote areas. With Starlink, we've boosted connection speeds and efficiency, transforming disconnected regions into digitally engaged communities. Chile School District [Our] school went from slow, ineffective connectivity for even 2-3 computer stations, to having high- speed internet where all 36 of our children can have effective internet connectivity simultaneously...a class- changing event for our teachers and students. Brightline Trains, USA Starlink gave us the new beginning we were looking for. It gave us connectivity we can be proud to share with our guests. It gave us the knowledge we needed to continue to build better train connectivity beyond the satellite [internet] itself…and, most of all, it gave us a new beginning for train enthusiasts to get excited about because it is doable, it is maintainable, [and] it is as exciting as it seems. Seaspan Corporation, Global Deploying SpaceX Starlink's low Earth orbit, low-latency, high bandwidth service across our fleet is a major milestone in addressing connectivity challenges in an industry with a global and mobile workforce. It allows us to treat our vessels no differently than remote offices, supporting crew safety and wellness – and it enables us to develop new solutions that were technically and financially unviable just a few years ago. Source: SpaceX website (4/25) New Internet User Growth = Enabled by AI + Satellites • Seem Like Change Happening Faster Than Ever? Yes, It Is • AI User + Usage + CapEx Growth = Unprecedented • AI Model Compute Costs High / Rising + Inference Costs Per Token Falling = Performance Converging + Developer Usage Rising • AI Usage + Cost + Loss Growth = Unprecedented • AI Monetization Threats = Rising Competition + Open-Source Momentum + China’s Rise • AI & Physical World Ramps = Fast + Data-Driven • Global Internet User Ramps Powered by AI from Get-Go = Growth We Have Not Seen Likes of Before • AI & Work Evolution = Real + Rapid 323 1 2 3 4 5 6 7 8 Outline 324 AI & Work Evolution = Real + Rapid AI is foundationally changing the way we work. Alongside growth in physical automation (think adoption of robots and drones), we are now also seeing the rise of cognitive automation, where AI systems can reason, create, and solve problems. The ramifications are widespread. The pace of improvement in AI's cognitive ability is astounding. In the three years since ChatGPT’s 11/22 public launch, we've gone from the reasoning capabilities of a high school student to those of a PhD candidate. Professions centered on intaking large bodies of structured, historical data and outputting rules-based decisions and judgement, fall squarely in the core competency of generative AI. In this emerging landscape, a unit of labor could shift from human hours to computational power. Data centers and foundation models – in many instances – could dictate the availability and quality of certain types of labor. As a result, some tout an 'agentic future' where AI agents replace humans in many white-collar jobs. Although possible, history and pattern recognition suggest the role of humans is enduring and compelling. Technology-forward leaps have typically driven productivity and efficiency gains and more – but new – jobs. That said, this time it’s happening faster. In an extreme, entirely agentic future, humans maintain a role in the system, pivoting towards oversight, guidance, and training. Imagine facilities filled with humans teaching robots intricate movements or offices full of workers providing reinforcement learning* human feedback (RLHF) to optimize algorithms. This is not conjecture. Companies like Physical Intelligence and Scale AI, respectively, are building powerful businesses based on this view of the world. The idea of the human workforce re-configured to teach and refine machines as a primary function might sound dystopic. But it’s worth remembering historical parallels. Fifty years ago, this prospect of rows of cubicles and uniformed office workers sitting quietly in front of LED computers ten hours a day likely sounded equally dystopic. Yet here we are. Technology has constantly redefined and evolved the nature of work and productivity…AI is no different. *Reinforcement Learning = An ML approach where agents learn by receiving rewards or penalties for actions. 325 AI Impact on Business = Diverse & Broad Note: Global data shown. Source: NVIDIA Industries That Could Be Affected by AI, per NVIDIA AI & Work Evolution = Real + Rapid 326 AI In Workforce – Shopify = Reflexive AI Usage Is Now a Baseline Expectation… Source: Tobi Lutke via X (4/25), Shopify AI & Work Evolution = Real + Rapid We are entering a time where more merchants and entrepreneurs could be created than any other in history. We often talk about bringing down the complexity curve to allow more people to choose this as a career. Each step along the entrepreneurial path is rife with decisions requiring skill, judgement and knowledge. Having AI alongside the journey and increasingly doing not just the consultation, but also doing the work for our merchants is a mind-blowing step function change here. Our task here at Shopify is to make our software unquestionably the best canvas on which to develop the best businesses of the future. We do this by keeping everyone cutting edge and bringing all the best tools to bear so our merchants can be more successful than they themselves used to imagine. For that we need to be absolutely ahead. Reflexive AI usage is now a baseline expectation at Shopify. Maybe you are already there and find this memo puzzling. In that case you already use AI as a thought partner, deep researcher, critic, tutor, or pair programmer. I use it all the time, but even I feel I'm only scratching the surface. It’s the most rapid shift to how work is done that I’ve seen in my career… …Using AI effectively is now a fundamental expectation of everyone at Shopify. It's a tool of all trades today, and will only grow in importance. Frankly, I don't think it's feasible to opt out of learning the skill of applying AI in your craft; you are welcome to try, but I want to be honest I cannot see this working out today, and definitely not tomorrow. Stagnation is almost certain, and stagnation is slow-motion failure. If you're not climbing, you're sliding… Shopify Co-Founder & CEO Tobias Lütke in Internal Memo on AI – 3/25 327 …AI In Workforce – Duolingo = Duolingo Is Going to be AI-First Source: Duolingo via LinkedIn (4/25) AI & Work Evolution = Real + Rapid I’ve said this in Q&As and many meetings, but I want to make it official: Duolingo is going to be AI-first. AI is already changing how work gets done. It’s not a question of if or when. It’s happening now. When there’s a shift this big, the worst thing you can do is wait. In 2012, we bet on mobile. While others were focused on mobile companion apps for websites, we decided to build mobile-first because we saw it was the future. That decision helped us win the 2013 iPhone App of the Year and unlocked the organic word-of-mouth growth that followed… …AI isn’t just a productivity boost. It helps us get closer to our mission. To teach well, we need to create a massive amount of content, and doing that manually doesn’t scale. One of the best decisions we made recently was replacing a slow, manual content creation process with one powered by AI. Without AI, it would take us decades to scale our content to more learners. We owe it to our learners to get them this content ASAP… …Being AI-first means we will need to rethink much of how we work. Making minor tweaks to systems designed for humans won’t get us there…We can’t wait until the technology is 100% perfect. We’d rather move with urgency and take occasional small hits on quality than move slowly and miss the moment. We’ll be rolling out a few constructive constraints to help guide this shift…: • …AI use will be part of what we look for in hiring • AI use will be part of what we evaluate in performance reviews • Headcount will only be given if a team cannot automate more of their work • Most functions will have specific initiatives to fundamentally change how they work… Duolingo Co-Founder & CEO Luis von Ahn in All-Hands Memo on AI – 4/25 AI Adoption @ USA Firms = Rising… 328 Note: Question asked was ‘In the last six months, did this business use Artificial Intelligence (AI) in producing goods or services?’ BTOS data are representative of all employer businesses in the USA economy, excluding farms. The BTOS sample consists of approximately 1.2MM businesses with biweekly data collection. Source: Census Bureau’s BTOS (Business Trends & Outlook Survey) via Goldman Sachs Global Investment Research, ‘2025 Q1: Adoption Makes Modest Progress, Labor Impacts Still Negligible’ (3/25) % of USA Firms Using AI – 3/25, per USA Census Bureau & Goldman Sachs Research AI & Work Evolution = Real + Rapid …AI Adoption @ USA Firms = +21% Q/Q @ ~7% of Companies (Q1:25) 329 Change in % of USA Firms Using AI – Q4:24-Q1:25, per USA Census Bureau & Goldman Sachs Research Note: Question asked was ‘In the last six months, did this business use Artificial Intelligence (AI) in producing goods or services?’ BTOS data are representative of all employer businesses in the USA economy, excluding farms. The BTOS sample consists of approximately 1.2MM businesses with biweekly data collection. Source: Census Bureau’s BTOS (Business Trends & Outlook Survey) via Goldman Sachs Global Investment Research, ‘2025Q1: Adoption Makes Modest Progress, Labor Impacts Still Negligible’ (3/25) AI & Work Evolution = Real + Rapid 330 AI Impact on Workforce = Employers Adopting AI to Drive Productivity Improvements Objectives of Corporate AI / LLM Initiatives – Q3:23-Q3:24, per Morgan Stanley & AlphaWise AI & Work Evolution = Real + Rapid Source: Morgan Stanley, ‘GenAI: Where are We Seeing Adoption and What Matters for ‘25?’ (11/24) % of Survey Responses 0% 10% 20% 30% Q3:23 Q2:24 Q3:24 Broader Internal Employee Productivity (e.g., CoPilot) Specialized Worker Labor Savings / Productivity Improvement (e.g., Contact Center, Financial Processes Simplification) Customer-Facing Applications to Drive Additional Revenues Customer-Facing Applications to Drive Better Customer Satisfaction Lower Risk Within the Organization Faster Product Development (e.g., Drug Discovery, Model Development, Software Development) N/A, Not Evaluating Recent Innovations in Artificial Intelligence At This Time 331 AI Impact on Workforce = Seeing Productivity Gains, per Stanford HAI Note: Left chart: N = 5,179 customer support agents. Right chart: N = 1,018 scientists. Source: Erik Brynjolfsson et al., ‘Generative AI at Work’ (2/25) via Nestor Maslej et al., ‘The AI Index 2025 Annual Report,’ AI Index Steering Committee, Stanford HAI (4/25) Impacts of AI on Worker Productivity – 4/23, per Stanford HAI AI & Work Evolution = Real + Rapid 2.6 2.97 0 1 2 3 Did Not Use AI Used AI Hourly Chats per Customer Support Agent +14% 332 Employment Evolution – 1/18-4/25 = AI Job Postings +448% Over 7 Years While Non-AI IT Jobs -9% Note: 'AI Job' refers to a job posting that requires AI skills. AI skills requirement in job postings determined using University of Maryland’s language processing model. USA-based jobs only. Figures are rounded. Source: University of Maryland’s UMD-LinkUp AIMaps (in collaboration with Outrigger Group) (2/25) Change in USA Job Postings, Indexed to 1/18, % -50% 150% 350% 550% 2018 2019 2020 2021 2022 2023 2024 2025 USA AI Job Postings (All) USA Non-AI IT Job Postings Change in USA AI & Non-AI IT Job Postings – 1/18-4/25, per University of Maryland & LinkUp AI & Work Evolution = Real + Rapid 333 Employment Evolution – Q2:22-Q2:24 = AI-Related Job Titles +200% Over Two Years Note: The data in this report is sourced from ZoomInfo’s proprietary professional contacts database – a leading platform that detects more than 1.5MM personnel changes per day. To compile the trends in job titles, ZoomInfo’s data scientists analyzed announcements from hundreds of companies detailing their AI titles from 1/1/22 through 6/30/24. ZoomInfo’s database includes 100MM companies, 340MM professionals, & 11MM C-Suite leaders. Source: ZoomInfo (8/24) Cumulative # of New Global Job Titles With AI Terms Newly-Added – Q2:22-Q2:24, per ZoomInfo Cumulative Job Titles 0 60,000 120,000 Q2:22 Q3:22 Q4:22 Q1:23 Q2:23 Q3:23 Q4:23 Q1:24 Q2:24 ‘Traditional’ Enterprise AI Adoption = Rising Priority 334 Employment Evolution – Apple = 600+ Openings for Generative AI Jobs Source: Apple (4/25) Apple Job Postings Related to ‘Generative AI’ – 5/25 Example job description: As a member of the team you will be responsible for bringing innovative ideas and applying modern machine learning methods to solve problems that matter. From ideation to productization, you will participate in the full development cycle of core technologies, including handwriting and text recognition, handwriting synthesis, document understanding, freeform drawing recognition and generation. The ideal candidate should have experience in computer vision, speech recognition, deep learning, and/or other applications of machine learning systems. Tech Incumbent AI Adoption = Top Priority Note: Here we define the start of the PC Era as 1981 (launch of IBM PC). We define the start of the desktop internet era as 1995 (Netscape’s IPO). We define the start of the mobile internet era as 2007 (the launch of Apple’s iPhone). We define the start of the AI Era as 2022 (the public launch of ChatGPT). Source: Federal Reserve Bank of St. Louis (2024) Relative Change in USA Non-Farm Employment & Labor Productivity – 1947-2024, per Federal Reserve Bank of St. Louis Change in USA Non-Farm Employment & Labor Productivity Indexed to 1947, % 0 2.5 5 1947 1951 1955 1959 1963 1967 1971 1975 1979 1983 1987 1991 1995 1999 2003 2007 2011 2015 2019 2023 +31% since 2000 +89% since 2000 USA Nonfarm Labor Productivity USA Nonfarm Employment Minicomputer / PC Era (1981-1994) Desktop Internet Era (1995-2006) Mobile Internet Era (2007-2021) AI Era (2022+) 335 AI & Work Evolution = Real + Rapid Technology Cycles USA Labor Productivity = Has Happened Alongside Job Growth Over Seventy-Seven Years 336 AI In Workforce – NVIDIA = You’re Not Going to Lose…Your Job to an AI…[But] to Somebody Who Uses AI Source: Milken Institute (5/25) NVIDIA Co-Founder & CEO Jensen Huang @ Milken Institute Global Conference – 5/25 AI & Work Evolution = Real + Rapid All of you have heard a lot about [AI] job displacement. Every job will be affected. Some jobs will be lost, some jobs will be created, but every job will be affected. And immediately it is unquestionable, you're not going to lose a job – your job to an AI, but you're going to lose your job to somebody who uses AI… …But let me give you the two extremes that you might want to consider as well. Computer technology, computer science has benefited about 30 million people. There are about 30 million people in the world who know how to program and use this technology to its extreme… …The other eight, seven and a half billion people don't. I'll put on the table that, in fact, artificial intelligence is the greatest opportunity for us to close the technology divide. And let me prove it to you. You know, if we just look in this room, it's very unlikely that more than a handful of people know how to program with C++, and an equal number know how to program in C. And yet, 100 percent of you know how to program in AI. And the reason for that is because the AI will speak whatever language you wanted to speak… …The number of people who are using ChatGPT and Gemini Pro and these AIs kind of demonstrate that, in fact, this is one of the easiest to use technologies in history… …The other extreme that I will say is that, remember, we’re – we have a shortage of labor. We have a shortage of workers. We don't have an abundance of workers. We have a shortage of and for the very first time in history, we actually have – we can imagine the opportunity to close that gap to put 30-40 million workers back into the workforce that otherwise the world doesn't have. And so you could argue that artificial intelligence is probably our best way to increase the GDP, the global GDP, and so those are two other ways to look at it. In the meantime, I would recommend 100% of everybody you know take advantage of AI and don't be that person who ignores this technology. 337 Imagine, for a moment, how different your next week would look if there were no internet. Every facet of modern life – how we work, how we communicate, how we govern, and more – would likely be turned on its head. The internet has been woven into so many facets of life, big and small, that – for many – it is difficult to imagine a world without it. In the next decade or two, imagining a world without AI will likely feel the same. Artificial intelligence is reshaping the modern landscape at breakneck speed. What began as research has scaled into emerging core infrastructure across industries – powering everything from customer support to software development, scientific discovery, education, and manufacturing. This document has aimed to map the pace and breadth of AI’s expansion, with particular focus on usage trends, cost dynamics, infrastructure buildout, and early monetization models. The through-line is clear: AI is accelerating, touching more domains, and becoming more embedded in how work gets done. Catalyzing this growth is the global availability of easy-to-use multimodal AI tools (like ChatGPT) on pervasive mobile devices, augmented by a steep decline in inference costs and an explosion in model availability. Both closed and open-source tools are now widely accessible and increasingly capable, enabling solo developers, startups, and enterprises alike to experiment and deploy with minimal friction. Meanwhile, large tech incumbents are weaving AI deeper into their products – rolling out copilots, assistants, and even agents that reframe how users engage with technology. Whether through embedded intelligence in SaaS or agentic workflows in consumer apps, the interface layer is being rewritten in real time. On the compute side, investment continues to scale dramatically. Capital expenditures across major cloud providers, chipmakers, and hyperscalers have hit new highs, driven by the race to enable real-time, high-volume inference at scale. The investment is not just in chips, but also in new data centers, networking infrastructure, and energy systems to support growing demand. Whether this level of capital expenditure persists remains to be seen, but as AI moves closer to the edge – in vehicles, farms, labs, and homes – the distinction between digital and physical infrastructure continues to blur. The global race to build and deploy frontier AI systems is increasingly defined by the strategic rivalry between the United States and China. While USA companies have led the charge in model innovation, custom silicon, and cloud-scale deployment to-date, China is advancing quickly in open-source development, national infrastructure, and state-backed coordination. Both nations view AI not only as an economic tailwind but also as a lever of geopolitical influence. These competing AI ecosystems are amplifying the urgency for sovereignty, security, and speed… Summary… 338 …In this environment, innovation is not just a business advantage; it is national posture. As Microsoft Vice Chair and President Brad Smith recently noted, Given the nature of technology markets and their potential network effects, this race between the U.S. and China for international influence likely will be won by the fastest first mover. Hence, the United States needs a smart international strategy to rapidly support American AI around the world… …The Chinese wisely recognize that if a country standardizes on China’s AI platform, it likely will continue to rely on that platform in the future. The best response for the United States is not to complain about the competition but to ensure we win the race ahead. This will require that we move quickly and effectively to promote American AI as a superior alternative. And it will need the involvement and support of American allies and friends. Lastly, AI is changing how we interact with the world around us. With affordable satellite connectivity expanding access to remote and underserved regions, the next wave of internet users will likely come online through AI-native experiences – skipping traditional app ecosystems and jumping straight into conversational, multimodal agents. Similarly, AI uptake is accelerating in the workplace and has the potential to shape how people spend the one third of their lives at work. As usage patterns evolve and unit costs decline, we may be witnessing the early stages of an internet where intelligence is the default interface – accessible, contextual, and increasingly personal. This is all amplified by the growing flow and transparency of information and capital – and the increasing examples of weaponization. It comes at a time when global powers are more openly asserting autocracy-versus-democracy agendas. As technology and geopolitics increasingly intertwine, uncertainty is rising. One thing is certain – it’s gametime for AI, and it’s only getting more intense… and the genie is not going back in the bottle. …Summary 339 BOND is a global technology investment firm that supports visionary founders throughout their entire life cycle of innovation and growth. BOND's founding partners have backed industry pioneers including Airbnb, AlphaSense, Applied Intuition, Canva, DocuSign, DoorDash, KoBold Metals, Meta (Facebook), Instacart, Peloton, Plaid, Revolut, Slack, Spotify, Square, Stripe, Twitter, Uber, & VAST Data. This document, including the information contained herein, has been compiled for informational purposes only & does not constitute an offer to sell or a solicitation of an offer to purchase any security. Such offer or solicitation shall only be made pursuant to offering documents related to such security, if any. The document relies on data + insights from a wide range of sources, including public + private companies, market research firms + government agencies. We cite specific sources where data is public; the document is also informed by non-public information + insights. We disclaim any + all warranties, express or implied, with respect to the document. We do not take a view on the relative veracity of data sources or inconsistencies expressed or implied therefrom. No document content should be construed as professional advice of any kind (including legal or investment advice). We may post updates, revisions, or clarifications of this document on BOND’s website (www.bondcap.com). BOND owns or has owned significant equity positions in certain of the companies referenced in this document. Data Provided Under License to BOND
====================================================================================================
Artificial Intelligence (AI): At a Glance | Britannica Search Britannica Click here to search Search Britannica Click here to search SUBSCRIBE SUBSCRIBE Login https://premium.britannica.com/premium-membership/?utm_source=premium&utm_medium=nav-login-box&utm_campaign=evergreen SUBSCRIBE Home History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Games & Quizzes Videos On This Day One Good Fact Dictionary New Articles History & Society Lifestyles & Social Issues Philosophy & Religion Politics, Law & Government World History Science & Tech Health & Medicine Science Technology Biographies Browse Biographies Animals & Nature Birds, Reptiles & Other Vertebrates Bugs, Mollusks & Other Invertebrates Environment Fossils & Geologic Time Mammals Plants Geography & Travel Geography & Travel Arts & Culture Entertainment & Pop Culture Literature Sports & Recreation Visual Arts Image Galleries Podcasts Summaries Top Questions Britannica Kids Ask the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Videos Artificial Intelligence (AI): At a Glance Table of Contents Introduction References & Edit History Images For Students artificial intelligence summary Contents artificial intelligence Image generated by the Stable Diffusion model from the prompt “the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings,” which is the definition of artificial intelligence (AI) in the Encyclopædia Britannica article on the subject. Stable Diffusion is trained on a large set of images paired with textual descriptions and uses natural language processing (NLP) to generate an image. (more) Artificial Intelligence (AI): At a Glance Ask the Chatbot a Question More Actions Print Cite verified Cite While every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions. Select Citation Style MLA APA Chicago Manual of Style Copy Citation Share Share Share to social media Facebook X URL https://www.britannica.com/topic/Artificial-Intelligence-AI-At-a-Glance-2235722 Feedback Feedback Corrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login). Feedback Type Select a type (Required) Factual Correction Spelling/Grammar Correction Link Correction Additional Information Other Your Feedback Submit Feedback Thank you for your feedback Our editors will review what you’ve submitted and determine whether to revise the article. External Websites Ask the Chatbot a Question Written and fact-checked by The Editors of Encyclopaedia Britannica Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree. They write new content and verify and edit content received from contributors. The Editors of Encyclopaedia Britannica Article History Table of Contents Table of Contents Ask the Chatbot Artificial intelligence (AI) is a computer ’s ability to do tasks commonly associated with human intelligence. The term is applied to the project of developing systems endowed with intellectual processes, such as the ability to reason, discover meaning, generalize, or learn from past experience. Computers can carry out very complex tasks with great proficiency. However, despite advances in computer processing speed and memory capacity, as yet no programs can match full human flexibility over wider domains or in tasks requiring much everyday knowledge. Such broad humanlike intelligence is called artificial general intelligence (AGI) or strong AI. The earliest theoretical work on AI was done by British mathematician Alan Turing in the 1940s, and the first AI programs were developed in the early 1950s. With the steady growth of processing power and computer memory since then, in the early 21st century, AI has advanced to the point where programs can classify images (e.g., PReLU-net), master games such as chess (AlphaZero), carry on conversations ( ChatGPT ), and create an image from a text prompt (DALL-E). AI has proved helpful to humans in specific tasks, such as medical diagnosis, search engines , voice or handwriting recognition, and chatbots, in which it has attained the performance levels of human experts and professionals. AI also comes with risks, including the potential for workers in some fields to lose their jobs as more tasks become automated . Read Britannica’s full article on artificial intelligence (AI) and its latest advances here. The Editors of Encyclopaedia Britannica This article was most recently revised and updated by Erik Gregersen .
====================================================================================================
Google AI - How we're making AI helpful for everyone Discover how AI can be helpful, from work to everyday life Explore products chevron_right Experience AI-first products Chat with Gemini Your personal, proactive AI assistant AI Mode Ask anything, any way, in Google Search NotebookLM The ultimate tool for understanding Flow An AI filmmaking tool for creatives Try AI features Ask Maps Google Maps Conversational AI tool YouTube Gemini Live on mobile Android Ask Photos Google Photos Help me write in Gmail and Docs Google Workspace Browse with built-in AI Chrome Try our latest experiments Project Astra Your universal AI assistant Project Mariner Explore the future of in-brower agents Whisk Visualize and remix ideas Find more on Google Labs Build with Google AI Explore our full AI stack chevron_right Start building Get started building with our next-gen AI models and tools Google AI Studio Build with our latest AI models Vertex AI A platform built for enterprise Gemini API Integrate our AI models into your apps Discover models Build with cutting-edge Google DeepMind models Gemini Our most intelligent AI models Gemma Our state-of-the-art open models Veo Our state-of-the-art text-to-video model Imagen Our highest quality text-to-image model Lyria Our latest text-to-audio model Code with AI assistance Accelerate development with integrated AI code assistance Colab Jules Gemini Code Assist Android Studio Chrome DevTools Firebase Studio Tackling the most challenging problems in computer science Explore research chevron_right Frontier AI Building the future of AI-powered products and scientific discovery Learn more Foundational ML Exploring theory and application of ML in language, speech and more Learn more Health Transforming healthcare and medicine with AI Learn more Quantum AI Building best-in-class quantum computing Learn more Science Enabling scientific innovation in biology, chemistry, physics, and earth science Learn more Sustainability Driving sustainable innovation through technology Learn more We’re building and deploying AI responsibly Responsibility and safety Ensuring AI safety through proactive security, even against evolving threats Learn more Policy Our AI policy perspectives, priorities, and working alongside partners Learn more Building for everyone Working together to build AI that’s helpful for everyone Learn more We're committed to improving the lives of as many people as possible Why AI Boldly pursued, AI transforms lives globally when built and used responsibly Learn more Our AI Journey For over 20 years, Google has worked to make AI helpful for everyone Learn more AI Principles Our commitment to developing technology responsibly Learn more For organizations Our AI tools enable your organization to work smarter and make better decisions Learn more Learn AI Skills Learn essential AI skills through courses, certifications, and more Learn more Products Build Research Responsibility Societal impact About Discover how AI can be helpful, from work to everyday life Explore products chevron_right Experience AI-first products Chat with Gemini Your personal, proactive AI assistant AI Mode Ask anything, any way, in Google Search NotebookLM The ultimate tool for understanding Flow An AI filmmaking tool for creatives Try AI features Ask Maps Google Maps Conversational AI tool YouTube Gemini Live on mobile Android Ask Photos Google Photos Help me write in Gmail and Docs Google Workspace Browse with built-in AI Chrome Try our latest experiments Project Astra Your universal AI assistant Project Mariner Explore the future of in-brower agents Whisk Visualize and remix ideas Find more on Google Labs Build with Google AI Explore our full AI stack chevron_right Start building Get started building with our next-gen AI models and tools Google AI Studio Build with our latest AI models Vertex AI A platform built for enterprise Gemini API Integrate our AI models into your apps Discover models Build with cutting-edge Google DeepMind models Gemini Our most intelligent AI models Gemma Our state-of-the-art open models Veo Our state-of-the-art text-to-video model Imagen Our highest quality text-to-image model Lyria Our latest text-to-audio model Code with AI assistance Accelerate development with integrated AI code assistance Colab Jules Gemini Code Assist Android Studio Chrome DevTools Firebase Studio Tackling the most challenging problems in computer science Explore research chevron_right Frontier AI Building the future of AI-powered products and scientific discovery Learn more Foundational ML Exploring theory and application of ML in language, speech and more Learn more Health Transforming healthcare and medicine with AI Learn more Quantum AI Building best-in-class quantum computing Learn more Science Enabling scientific innovation in biology, chemistry, physics, and earth science Learn more Sustainability Driving sustainable innovation through technology Learn more We’re building and deploying AI responsibly Responsibility and safety Ensuring AI safety through proactive security, even against evolving threats Learn more Policy Our AI policy perspectives, priorities, and working alongside partners Learn more Building for everyone Working together to build AI that’s helpful for everyone Learn more We're committed to improving the lives of as many people as possible Why AI Boldly pursued, AI transforms lives globally when built and used responsibly Learn more Our AI Journey For over 20 years, Google has worked to make AI helpful for everyone Learn more AI Principles Our commitment to developing technology responsibly Learn more For organizations Our AI tools enable your organization to work smarter and make better decisions Learn more Learn AI Skills Learn essential AI skills through courses, certifications, and more Learn more Products Discover how AI can be helpful, from work to everyday life Explore products chevron_right Experience AI-first products Chat with Gemini Your personal, proactive AI assistant AI Mode Ask anything, any way, in Google Search NotebookLM The ultimate tool for understanding Flow An AI filmmaking tool for creatives Try AI features Ask Maps Google Maps Conversational AI tool YouTube Gemini Live on mobile Android Ask Photos Google Photos Help me write in Gmail and Docs Google Workspace Browse with built-in AI Chrome Try our latest experiments Project Astra Your universal AI assistant Project Mariner Explore the future of in-brower agents Whisk Visualize and remix ideas Find more on Google Labs Build Build with Google AI Explore our full AI stack chevron_right Start building Get started building with our next-gen AI models and tools Google AI Studio Build with our latest AI models Vertex AI A platform built for enterprise Gemini API Integrate our AI models into your apps Discover models Build with cutting-edge Google DeepMind models Gemini Our most intelligent AI models Gemma Our state-of-the-art open models Veo Our state-of-the-art text-to-video model Imagen Our highest quality text-to-image model Lyria Our latest text-to-audio model Code with AI assistance Accelerate development with integrated AI code assistance Colab Jules Gemini Code Assist Android Studio Chrome DevTools Firebase Studio Research Tackling the most challenging problems in computer science Explore research chevron_right Frontier AI Building the future of AI-powered products and scientific discovery Learn more Foundational ML Exploring theory and application of ML in language, speech and more Learn more Health Transforming healthcare and medicine with AI Learn more Quantum AI Building best-in-class quantum computing Learn more Science Enabling scientific innovation in biology, chemistry, physics, and earth science Learn more Sustainability Driving sustainable innovation through technology Learn more Responsibility We’re building and deploying AI responsibly Responsibility and safety Ensuring AI safety through proactive security, even against evolving threats Learn more Policy Our AI policy perspectives, priorities, and working alongside partners Learn more Building for everyone Working together to build AI that’s helpful for everyone Learn more Societal impact About We're committed to improving the lives of as many people as possible Why AI Boldly pursued, AI transforms lives globally when built and used responsibly Learn more Our AI Journey For over 20 years, Google has worked to make AI helpful for everyone Learn more AI Principles Our commitment to developing technology responsibly Learn more For organizations Our AI tools enable your organization to work smarter and make better decisions Learn more Learn AI Skills Learn essential AI skills through courses, certifications, and more Learn more Try Google AI Studio Try Gemini Google AI Google AI Learn about all of our AI Google DeepMind Explore the frontier of AI Google Labs Try our AI experiments Google Research Explore our research Gemini app Chat with Gemini Google AI Studio Build with our next-gen AI models Products Build Research Responsibility Societal impact About Try Google AI Studio Try Gemini Homepage - I/O 2025 Get started Ask Gemini Search with AI Mode Build an app Create an image Generate video Learn with NotebookLM Gemini 2.5 Flash and Pro are now stable and GA, and the new 2.5 Flash-Lite is now in preview June 2025 Models Try in Google AI Studio chevron_right Automate multiple tasks simultaneously with Project Mariner May 2025 Products Try now chevron_right Introducing Veo 3, our state-of-the-art video generation model May 2025 Products Learn more chevron_right Gemini Robotics On-Device brings AI to local robotic devices June 2025 Research Learn more chevron_right Gemini 2.5 is getting even better with Deep Think, a mode for highly-complex areas like math and coding May 2025 Build Learn more chevron_right Gemini Diffusion generates content significantly faster than our fastest model so far May 2025 Build Learn more chevron_right AI Mode is starting to roll out to everyone in the US May 2025 Build Try now chevron_right Create with Flow, the only AI filmmaking tool designed for Veo, Imagen and Gemini May 2025 Products Create with Flow chevron_right Create images with Imagen 4, our most capable text-to-image model, now in the Gemini app May 2025 Products Try in Gemini chevron_right Dive deeper on your research questions with Deep Search May 2025 Products Learn more chevron_right Use our AI coding agent Jules to do tasks you don't want to do. Now available globally May 2025 Build Try now chevron_right Identify AI-generated content with SynthID Detector May 2025 Research Learn more chevron_right Products See all products Latest For knowledge For creativity For productivity For students For experimenting Talk with Gemini about what you see, on Android and iOS Try Gemini Live chevron_right Vibe code and get creative with Canvas in the Gemini app Try now chevron_right Create cinematic clips, scenes and stories with Veo 3 Create with Flow chevron_right Virtually try on clothes in Google Search Try now chevron_right Try Imagen 4 to create high-fidelity images with text prompts Try in Gemini chevron_right Create videos with Veo 3 for greater realism and fidelity Learn more chevron_right chevron_left chevron_right Build an understanding of complex topics with Deep Research Chat with Gemini chevron_right Ask tough questions and let Google do the heavy lifting for you Try AI Mode in Google Search Experience a supercharged browser with built-in AI Download Chrome chevron_right See how ideas relate with Mind Maps Try NotebookLM chevron_right Ask Maps for inspiration on things to do, curated by Gemini Learn more chevron_right Learn while you watch, with interactive AI on YouTube Learn more chevron_right chevron_left chevron_right Create videos with Veo 3 for greater realism and fidelity Learn more chevron_right Create cinematic clips, scenes and stories with Veo 3 Create with Flow chevron_right Visualize and remix ideas using both text and image prompts Try Whisk chevron_right Generate clips to add to your YouTube Shorts with Dream Screen Learn more chevron_right Uncover creative possibilities with text and language Try TextFX chevron_right Make custom emoji using your own photos Explore on Android devices chevron_right chevron_left chevron_right Generate, optimize, and preview code with the help of Gemini Try Canvas in Gemini chevron_right Create beautiful documents and refine your writing with AI Try Gemini in Google Docs chevron_right Automate multiple tasks simultaneously with Project Mariner Try now chevron_right Quickly get summaries and insights from all of your documents Try NotebookLM chevron_right Surface valuable insights and find quick facts, across your files Try Gemini in Google Drive chevron_right Draft, summarize and organize with AI to conquer your inbox Try Gemini in Gmail chevron_right chevron_left chevron_right Study smarter, not harder. Use Gemini to test your knowledge Chat with Gemini chevron_right Deepen understanding of new topics with AI responses Try in AI Mode in Google Search chevron_right Discover additional sources on topics to support your studies Try NotebookLM chevron_right Get step by step homework help with Google Lens Try Google Lens chevron_right chevron_left chevron_right Explore the future of agents in browsers in Project Mariner Try now chevron_right Discover the future capabilities of a universal AI assistant with Project Astra Join trusted tester waitlist chevron_right Explore new possibilities for your career Try Career Dreamer chevron_right Listen to an AI-powered audio update - made just for you Try Daily Listen chevron_right Turn your generated images into videos with Whisk Animate Try Whisk Animate chevron_right chevron_left chevron_right Build Explore our full AI stack Build with Google AI Studio Start building something new, with cutting-edge AI models and tools Try Google AI Studio chevron_right View Gemini API docs chevron_right Build with Vertex AI Explore 200+ models on our enterprise platform with tools and features for AI development Try Vertex AI chevron_right Try the latest models View all models Gemini Our most intelligent AI models TRY IT IN Gemini app chevron_right Google AI Studio chevron_right Vertex AI Studio chevron_right Learn more call_made Gemma A family of lightweight, state-of-the art open models TRY IT IN Google AI Studio chevron_right Learn More call_made Veo Our state-of-the-art video generation model TRY IT IN Gemini app chevron_right Flow chevron_right Google AI Studio chevron_right Vertex AI Studio chevron_right Learn More call_made Imagen Our best text-to-image model yet, engineered for creativity TRY IT IN Gemini app chevron_right Whisk chevron_right Google AI Studio chevron_right Vertex AI Studio chevron_right Learn More call_made Lyria Our latest music generation model TRY IT IN MusicFX DJ chevron_right Google AI Studio chevron_right Vertex AI Studio chevron_right Learn More call_made chevron_left chevron_right Research View all research AlphaGenome: AI for better understanding the genome June 2025 Google DeepMind Learn more Weather Lab: supporting better tropical cyclone prediction with AI June 2025 Google DeepMind Google Research Learn more Gemini Robotics On-Device brings AI to local robotic devices June 2025 Google DeepMind Learn more LICONN: helping unlock and expedite new discoveries about the brain and neurological disease May 2025 Google Research Learn more Follow us Making AI helpful for everyone Products Discover how AI can be helpful, from work to everyday life For knowledge For creativity For productivity For students For experimenting Explore products Build Get started building with cutting-edge AI models and tools Start building Code with AI assistance Leverage frameworks and tools Build with Google AI Research Tackling the most challenging problems in computer science Health Science Sustainability Explore more research Responsibility We’re building and deploying AI responsibly Responsibility and safety Policy Building for everyone Social impact About We're committed to improving the lives of as many people as possible Why AI Our AI Journey AI Principles For organizations Learn AI Skills About Google Google Products Privacy Terms Manage cookies
====================================================================================================
The present and future of AI Skip to main content Main navigation Academics Faculty & Research News Events Offices & Services About Us Information For Alumni Industry Partners & Recruiters Prospective Students Shortcuts Employment & Jobs Visit Us Make a Gift Search Search Menu News News Events All News Stories The present and future of AI Finale Doshi-Velez on how AI is shaping our lives and how we can shape AI By Leah Burrows | Press contact October 19, 2021 Facebook Twitter Email LinkedIn Finale Doshi-Velez, the John L. Loeb Professor of Engineering and Applied Sciences. (Photo courtesy of Eliza Grinnell/Harvard SEAS) How has artificial intelligence changed and shaped our world over the last five years? How will AI continue to impact our lives in the coming years? Those were the questions addressed in the most recent report from the One Hundred Year Study on Artificial Intelligence (AI100), an ongoing project hosted at Stanford University, that will study the status of AI technology and its impacts on the world over the next 100 years. The 2021 report is the second in a series that will be released every five years until 2116. Titled “Gathering Strength, Gathering Storms,” the report explores the various ways AI is increasingly touching people’s lives in settings that range from movie recommendations and voice assistants to autonomous driving and automated medical diagnoses . Barbara Grosz , the Higgins Research Professor of Natural Sciences at the Harvard John A. Paulson School of Engineering and Applied Sciences (SEAS) is a member of the standing committee overseeing the AI100 project and Finale Doshi-Velez , Gordon McKay Professor of Computer Science, is part of the panel of interdisciplinary researchers who wrote this year’s report. We spoke with Doshi-Velez about the report, what it says about the role AI is currently playing in our lives, and how it will change in the future. Q: Let's start with a snapshot: What is the current state of AI and its potential? Doshi-Velez: Some of the biggest changes in the last five years have been how well AIs now perform in large data regimes on specific types of tasks. We've seen [DeepMind’s] AlphaZero become the best Go player entirely through self-play, and everyday uses of AI such as grammar checks and autocomplete, automatic personal photo organization and search, and speech recognition become commonplace for large numbers of people. In terms of potential, I'm most excited about AIs that might augment and assist people. They can be used to drive insights in drug discovery, help with decision making such as identifying a menu of likely treatment options for patients, and provide basic assistance, such as lane keeping while driving or text-to-speech based on images from a phone for the visually impaired. In many situations, people and AIs have complementary strengths. I think we're getting closer to unlocking the potential of people and AI teams. There's a much greater recognition that we should not be waiting for AI tools to become mainstream before making sure they are ethical. Finale Doshi-Velez Gordon McKay Professor of Computer Science Q: Over the course of 100 years, these reports will tell the story of AI and its evolving role in society. Even though there have only been two reports, what's the story so far? There's actually a lot of change even in five years. The first report is fairly rosy. For example, it mentions how algorithmic risk assessments may mitigate the human biases of judges. The second has a much more mixed view. I think this comes from the fact that as AI tools have come into the mainstream — both in higher stakes and everyday settings — we are appropriately much less willing to tolerate flaws, especially discriminatory ones. There's also been questions of information and disinformation control as people get their news, social media, and entertainment via searches and rankings personalized to them. So, there's a much greater recognition that we should not be waiting for AI tools to become mainstream before making sure they are ethical. Q: What is the responsibility of institutes of higher education in preparing students and the next generation of computer scientists for the future of AI and its impact on society? First, I'll say that the need to understand the basics of AI and data science starts much earlier than higher education! Children are being exposed to AIs as soon as they click on videos on YouTube or browse photo albums. They need to understand aspects of AI such as how their actions affect future recommendations. But for computer science students in college, I think a key thing that future engineers need to realize is when to demand input and how to talk across disciplinary boundaries to get at often difficult-to-quantify notions of safety, equity, fairness, etc. I'm really excited that Harvard has the Embedded EthiCS program to provide some of this education. Of course, this is an addition to standard good engineering practices like building robust models, validating them, and so forth, which is all a bit harder with AI. I think a key thing that future engineers need to realize is when to demand input and how to talk across disciplinary boundaries to get at often difficult-to-quantify notions of safety, equity, fairness, etc. Finale Doshi-Velez Gordon McKay Professor of Computer Science Q: Your work focuses on machine learning with applications to healthcare, which is also an area of focus of this report. What is the state of AI in healthcare? A lot of AI in healthcare has been on the business end, used for optimizing billing, scheduling surgeries, that sort of thing. When it comes to AI for better patient care, which is what we usually think about, there are few legal, regulatory, and financial incentives to do so, and many disincentives. Still, there's been slow but steady integration of AI-based tools, often in the form of risk scoring and alert systems. In the near future, two applications that I'm really excited about are triage in low-resource settings — having AIs do initial reads of pathology slides, for example, if there are not enough pathologists, or get an initial check of whether a mole looks suspicious — and ways in which AIs can help identify promising treatment options for discussion with a clinician team and patient. Q: Any predictions for the next report? I'll be keen to see where currently nascent AI regulation initiatives have gotten to. Accountability is such a difficult question in AI, it's tricky to nurture both innovation and basic protections. Perhaps the most important innovation will be in approaches for AI accountability. Topics: AI / Machine Learning , Computer Science Cutting-edge science delivered direct to your inbox. Join the Harvard SEAS mailing list. Subscribe Scientist Profiles Finale Doshi-Velez Herchel Smith Professor of Computer Science Press Contact Leah Burrows | 617-496-1351 | lburrows@seas.harvard.edu Related News Jun 6, 2025 Modeling electric response of materials, a million atoms at a time Machine-learning framework predicts effects of electric fields AI / Machine Learning , Computational Science & Engineering , Data Sciences , Materials , Materials Science & Mechanical Engineering Jun 5, 2025 AI for power, and power for AI Inaugural symposium unites researchers across SEAS AI / Machine Learning , Applied Computation , Applied Mathematics , Computational Science & Engineering , Data Sciences , Computer Science , Electrical Engineering , Environmental Science & Engineering May 28, 2025 2025 Commencement photos Images from the 374th Harvard Commencement on Thursday, May 29 Academics , Applied Mathematics , Applied Physics , Computational Science & Engineering , Data Sciences , Bioengineering , Computer Science , Electrical Engineering , Environmental Science & Engineering , Materials Science & Mechanical Engineering Harvard John A. Paulson School of Engineering and Applied Sciences 150 Western Ave, Allston, MA 02134 29 Oxford Street, Cambridge, MA 02138 Footer - Social Media Links Facebook Twitter Instagram YouTube LinkedIn © 2025 President and Fellows of Harvard College Footer Diversity Mission Trademark Notice Accessibility Policy Privacy Policy
====================================================================================================
What is AI? Tutorials Exercises Certificates Services Menu Search field ×  Sign In ★ +1 Get Certified For Teachers Spaces Plus Get Certified For Teachers Spaces Plus My W3Schools Tutorials Exercises Certificates Services Spaces Get Certified Plus Academy Logout     × Tutorials Tutorials filter input × HTML and CSS Learn HTML Tutorial Reference Learn CSS Tutorial Reference Learn RWD Tutorial Learn Bootstrap Overview Learn W3.CSS Tutorial Reference Learn Sass Tutorial Reference Learn Colors Tutorial Reference Learn Icons Tutorial Reference Learn SVG Tutorial Reference Learn Canvas Tutorial Reference Learn Graphics Tutorial Learn Character Sets Reference Learn How To Tutorial Data Analytics Learn AI Tutorial Learn Generative AI Tutorial Learn ChatGPT-3.5 Tutorial Learn ChatGPT-4 Tutorial Learn Google Bard Tutorial Learn Machine Learning Tutorial Learn DSA Tutorial Learn Data Science Tutorial Learn NumPy Tutorial Learn Pandas Tutorial Learn SciPy Tutorial Learn Matplotlib Tutorial Learn Statistics Tutorial Learn Excel Tutorial Learn Google Sheets Tutorial Web Building Create a Website HOT! Create a Server NEW Where To Start Web Templates Web Statistics Web Certificates Web Development Introduction to Programming Code Editor Test Your Typing Speed Play a Code Game Cyber Security Accessibility Join our Newsletter JavaScript Learn JavaScript Tutorial Reference Learn React Tutorial Learn jQuery Tutorial Reference Learn Vue Tutorial Reference Learn AngularJS Tutorial Reference Learn JSON Tutorial Reference Learn AJAX Tutorial Learn AppML Tutorial Reference Learn W3.JS Tutorial Reference Web Building Create a Website HOT! Create a Server NEW Where To Start Web Templates Web Statistics Web Certificates Web Development Introduction to Programming Code Editor Test Your Typing Speed Play a Code Game Cyber Security Accessibility Join our Newsletter Backend Learn Python Tutorial Reference Learn SQL Tutorial Reference Learn MySQL Tutorial Reference Learn PHP Tutorial Reference Learn Java Tutorial Reference Learn C Tutorial Reference Learn C++ Tutorial Reference Learn C# Tutorial Learn R Tutorial Learn Kotlin Tutorial Learn Rust Tutorial Learn Go Tutorial Learn Django Tutorial Reference Learn PostgreSQL Tutorial Learn TypeScript Tutorial Learn ASP Tutorial Reference Learn Node.js Tutorial Reference Learn Raspberry Pi Tutorial Learn Git Tutorial Learn Bash Tutorial Learn MongoDB Tutorial Learn XML Tutorial Reference Data Analytics Learn AI Tutorial Learn Generative AI Tutorial Learn ChatGPT-3.5 Tutorial Learn ChatGPT-4 Tutorial Learn Google Bard Tutorial Learn Machine Learning Tutorial Learn DSA Tutorial Learn Data Science Tutorial Learn NumPy Tutorial Learn Pandas Tutorial Learn SciPy Tutorial Learn Matplotlib Tutorial Learn Statistics Tutorial Learn Excel Tutorial Learn Google Sheets Tutorial Web Building Create a Website HOT! Create a Server NEW Where To Start Web Templates Web Statistics Web Certificates Web Development Introduction to Programming Code Editor Test Your Typing Speed Play a Code Game Cyber Security Accessibility Join our Newsletter × Exercises Excercises filter input × HTML and CSS HTML Exercise Quiz CSS Exercise Quiz Bootstrap 3 Exercise Quiz Bootstrap 4 Exercise Quiz Bootstrap 5 Exercise Quiz Data Analytics DSA Exercise Quiz NumPy Exercise Quiz Pandas Exercise Quiz SciPy Exercise Quiz Excel Exercise What is an Exercise? What is a Quiz? JavaScript JavaScript Exercise Quiz React Exercise Quiz jQuery Exercise Quiz Vue Exercise Quiz Backend Python Exercise Quiz SQL Exercise Quiz MySQL Exercise Quiz PHP Exercise Quiz Java Exercise Quiz C Exercise Quiz C++ Exercise Quiz C# Exercise Quiz R Exercise Quiz Kotlin Exercise Quiz Django Exercise Quiz Node.js Exercise Quiz PostgreSQL Exercise Quiz TypeScript Exercise Quiz Git Exercise Quiz Bash Exercise Quiz Go Exercise MongoDB Exercise Data Analytics DSA Exercise Quiz NumPy Exercise Quiz Pandas Exercise Quiz SciPy Exercise Quiz Excel Exercise What is an Exercise? What is a Quiz? × Certificates Filter field for certifications × HTML and CSS HTML Certificate Course CSS Certificate Course Bootstrap 3 Certificate Course Bootstrap 4 Certificate Course Bootstrap 5 Certificate Data Analytics DSA Certificate Data Analytics Course NumPy Certificate Course Pandas Certificate Course Excel Certificate Social Media Course What is a Certificate? Programs Full Access Best Value! Front End Certificate Course Web Dev. Certificate Course Web App Certificate Course Web Design Certificate Course JavaScript JavaScript Certificate Course React Certificate Course jQuery Certificate Course Vue Certificate Programs Full Access Best Value! Front End Certificate Course Web Dev. Certificate Course Web App Certificate Course Web Design Certificate Course Programs Full Access Best Value! Front End Certificate Course Web Dev. Certificate Course Web App Certificate Course Web Design Certificate Course Backend Python Certificate Course SQL Certificate Course MySQL Certificate PHP Certificate Course Java Certificate Course C Certificate C++ Certificate Course C# Certificate Course R Course Django Certificate NodeJS Certificate TypeScript Certificate Course XML Certificate Course Cyber Security Certificate Course Accessibility Certificate Course Data Analytics DSA Exam Data Analytics Course NumPy Course Pandas Course Excel Certificate Social Media Course What is a Certificate? × All Our Services Services filter input × W3Schools offers a wide range of services and products for beginners and professionals, helping millions of people everyday to learn and master new skills. Free Tutorials Enjoy our free tutorials like millions of other internet users since 1999 References Explore our selection of references covering all popular coding languages Create a Website Create your own website with W3Schools Spaces - no setup required Exercises Test your skills with different exercises Quizzes Test yourself with multiple choice questions Get Certified Document your knowledge Log in / Sign Up Create a free W3Schools Account to Improve Your Learning Experience My Learning Track your learning progress at W3Schools and collect rewards Upgrade Become a PLUS user and unlock powerful features (ad-free, hosting, support,..) Where To Start Not sure where you want to start? Follow our guided path Code Editor (Try it) With our online code editor, you can edit code and view the result in your browser Videos Learn the basics of HTML in a fun and engaging video tutorial Templates We have created a bunch of responsive website templates you can use - for free! Web Hosting Host your own website, and share it to the world with W3Schools Spaces Create a Server Create your own server using Python, PHP, React.js, Node.js, Java, C#, etc. How To's Large collection of code snippets for HTML, CSS and JavaScript CSS Framework Build fast and responsive sites using our free W3.CSS framework Browser Statistics Read long term trends of browser usage Typing Speed Test your typing speed Color Picker Use our color picker to find different RGB, HEX and HSL colors. Code Game W3Schools Coding Game! Help the lynx collect pine cones Newsletter Join our newsletter and get access to exclusive content every month For Teachers Contact us about W3Schools Academy for educational institutions For Businesses Contact us about W3Schools Academy for your organization Contact Us About sales: sales@w3schools.com About errors: help@w3schools.com     × ❮ ❯ HTML CSS JAVASCRIPT SQL PYTHON JAVA PHP HOW TO W3.CSS C C++ C# BOOTSTRAP REACT MYSQL JQUERY EXCEL XML DJANGO NUMPY PANDAS NODEJS DSA TYPESCRIPT ANGULAR GIT POSTGRESQL MONGODB ASP AI R GO KOTLIN SASS VUE GEN AI SCIPY CYBERSECURITY DATA SCIENCE INTRO TO PROGRAMMING BASH RUST Machine Learning ML Intro ML and AI ML Languages ML JavaScript ML Examples ML Linear Graphs ML Scatter Plots ML Perceptrons ML Recognition ML Training ML Testing ML Learning ML Terminology ML Data ML Clustering ML Regressions ML Deep Learning ML Brain.js TensorFlow TFJS Tutorial TFJS Operations TFJS Models TFJS Visor Example 1 Ex1 Intro Ex1 Data Ex1 Model Ex1 Training Example 2 Ex2 Intro Ex2 Data Ex2 Model Ex2 Training JS Graphics Graph Intro Graph Canvas Graph Plotly.js Graph Chart.js Graph Google Graph D3.js History History of Intelligence History of Languages History of Numbers History of Computing History of Robots History of AI Job Replacements Theory of Mind Mathematics Mathematics Linear Functions Linear Algebra Vectors Matrices Tensors Statistics Statistics Descriptive Variability Distribution Probability Artificial Intelligence ❮ Previous Next ❯ Artificial Intelligence Is a Contrast to Human Intelligence What is Artificial Intelligence? Artificial Intelligence suggest that machines can mimic humans in: Talking Thinking Learning Planning Understanding Artificial Intelligence is also called Machine Intelligence and Computer Intelligence . Arthur Samuel 1959: "Machine Learning is a subfield of computer science that gives computers the ability to learn without being programmed" Arthur Samuel, IBM Journal of Research and Development, Vol. 3, 1959. Wikipedia 2022: Artificial intelligence is intelligence demonstrated by machines. Unlike natural intelligence displayed by humans and animals, which involves consciousness and emotionality. Investopedia 2022: Artificial intelligence refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. IBM 2022: Artificial intelligence leverages computers and machines to mimic the problem-solving and decision-making capabilities of the human mind. Britannica 2022: Artificial intelligence is the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings, .... such as the ability to reason, discover meaning, generalize, or learn from past experience. Artificial Intelligence (AI) Artificial Intelligence is a scientific discipline embracing several Data Science fields ranging from narrow AI to strong AI, including machine learning, deep learning, big data and data mining. Artificial Intelligence Narrow AI Machine Learning Neural Networks Big Data Deep Learning Strong AI Narrow AI Narrow Artificial Intelligence is limited to narrow (specific) areas like most of the AI we have around us today: Email spam Filters Text to Speech Speech Recognition Self Driving Cars E-Payment Google Maps Text Autocorrect Automated Translation Chatbots Social Media Face Detection Visual Perception Search Algorithms Robots Automated Investment NLP - Natural Language Processing Flying Drones IBM's Dr. Watson Apple's Siri Microsoft's Cortana Amazon's Alexa Netflix's Recommendations Narrow AI is also called Weak AI . Weak AI: Built to simulate human intelligence. Strong AI: Built to copy human intelligence. Strong AI Strong Artificial Intelligence is the type of AI that mimics human intelligence. Strong AI indicates the ability to think, plan, learn, and communicate. Strong AI is the theoretical next level of AI: True Intelligence . Strong AI moves towards machines with self-awareness, consciousness, and objective thoughts. ✔ One need not decide if a machine can "think". One need only decide if a machine can act as intelligently as a human. Alan Turing ❮ Previous Next ❯ ★ +1 Track your progress - it's free! Log in Sign Up COLOR PICKER PLUS SPACES GET CERTIFIED FOR TEACHERS FOR BUSINESS CONTACT US × Contact Sales If you want to use W3Schools services as an educational institution, team or enterprise, send us an e-mail: sales@w3schools.com Report Error If you want to report an error, or if you want to make a suggestion, send us an e-mail: help@w3schools.com Top Tutorials HTML Tutorial CSS Tutorial JavaScript Tutorial How To Tutorial SQL Tutorial Python Tutorial W3.CSS Tutorial Bootstrap Tutorial PHP Tutorial Java Tutorial C++ Tutorial jQuery Tutorial Top References HTML Reference CSS Reference JavaScript Reference SQL Reference Python Reference W3.CSS Reference Bootstrap Reference PHP Reference HTML Colors Java Reference Angular Reference jQuery Reference Top Examples HTML Examples CSS Examples JavaScript Examples How To Examples SQL Examples Python Examples W3.CSS Examples Bootstrap Examples PHP Examples Java Examples XML Examples jQuery Examples Get Certified HTML Certificate CSS Certificate JavaScript Certificate Front End Certificate SQL Certificate Python Certificate PHP Certificate jQuery Certificate Java Certificate C++ Certificate C# Certificate XML Certificate     FORUM ABOUT ACADEMY W3Schools is optimized for learning and training. Examples might be simplified to improve reading and learning. Tutorials, references, and examples are constantly reviewed to avoid errors, but we cannot warrant full correctness of all content. While using W3Schools, you agree to have read and accepted our terms of use , cookie and privacy policy . Copyright 1999-2025 by Refsnes Data. All Rights Reserved. W3Schools is Powered by W3.CSS .
====================================================================================================
Artificial Intelligence Tutorial | AI Tutorial - GeeksforGeeks Skip to content Courses DSA to Development GATE 2026 Prep Get 3 IBM Certifications For Working Professionals Interview 101: DSA & System Design Data Science Training Program JAVA Backend Development (Live) Data Analytics Training DevOps Engineering (LIVE) Data Structures & Algorithms in Python For Students Placement Preparation with DSA Data Science (Live) Data Structure & Algorithm-Self Paced (C++/JAVA) Master Competitive Programming Full Stack Development with React & Node JS (Live) Full Stack Development Data Science & ML Program All Courses Tutorials Python Java Data Structures & Algorithms ML & Data Science Interview Corner Programming Languages Web Development GATE CS Subjects DevOps And Linux School Learning Practice Practice Coding Problems GfG 160: Free DSA Practice Problem of the Day ETS TOEFL: Scholarship Contest All Contests and Events Jobs Become a Mentor Apply Now! Post Jobs Job-A-Thon: Hiring Challenge Notifications Mark all as read All View All Notifications Mark all as read All Unread Read You're all caught up!! Data Science IBM Certification Data Science Data Science Projects Data Analysis Data Visualization Machine Learning ML Projects Deep Learning NLP Computer Vision Artificial Intelligence Sign In ▲ Open In App Explore GfG Courses Share Your Experiences AI ML DS - How To Get Started? Data Analysis (Analytics) Tutorial Machine Learning Tutorial Deep Learning Tutorial Natural Language Processing (NLP) Tutorial Computer Vision Tutorial Data Science Tutorial Artificial Intelligence Tutorial | AI Tutorial AI ML DS Interview Series AI ML DS - Projects DSA to Development Course Artificial Intelligence Tutorial | AI Tutorial Last Updated : 25 Jun, 2025 Comments Improve Suggest changes Like Article Like Report Artificial Intelligence (AI) refers to the simulation of human intelligence in machines which helps in allowing them to think and act like humans. It involves creating algorithms and systems that can perform tasks which requiring human abilities such as visual perception, speech recognition, decision-making and language translation. Types of Artificial Intelligence Artificial Intelligence (AI) is classified into: Types of AI Based on Capabilities Types of AI Based on Functionalities What is an AI Agent? An AI agent is a software or hardware entity that performs actions autonomously with the goal of achieving specific objectives. AI agent types of AI Agents Problem Solving in AI Problem-solving is a fundamental aspect of AI which involves the design and application of algorithms to solve complex problems systematically. 1. Search Algorithms in AI Search algorithms navigate through problem spaces to find solutions. Search algorithms Breadth-First Search (BFS) Depth-First Search (DFS) Uniform Cost Search (UCS) Bidirectional search Greedy Best-First Search A Search* Algorithm 2. Local Search Algorithms Local search algorithms operates on a single current state (or a small set of states) and attempt to improve it incrementally by exploring neighboring states. Local search algorithms Hill-Climbing Search Algorithm Local Beam Search 3. Adversarial Search in AI Adversarial search deal with competitive environments where multiple agents (often two) are in direct competition with one another such as in games like chess, tic-tac-toe or Go. Adversarial search Minimax Algorithm Alpha-Beta Pruning 4. Constraint Satisfaction Problems Constraint Satisfaction Problem (CSP) is a problem-solving framework that involves variables each with a domain of possible values and constraints limiting the combinations of variable values. Constraint Satisfaction Problem (CSP) Constraint Propagation in CSP’s Backtracking Search for CSP’s Knowledge, Reasoning and Planning in AI Knowledge representation in Artificial Intelligence (AI) refers to the way information, knowledge and data are structured, stored and used by AI systems to reason, learn and make decisions. Common techniques for knowledge representation include : Knowledge representation in Artificial Intelligence (AI) Semantic Networks Frames Ontologies Logical Representation First Order Logic in Artificial Intelligence First Order Logic (FOL) is use to represent knowledge and reason about the world. It allows for the expression of more complex statements involving objects, their properties and the relationships between them. First Order Logic (FOL) Knowledge Representation in First Order Logic Syntax and Semantics of First Order Logic Inference Rules in First Order Logic Reasoning in Artificial Intelligence Reasoning in Artificial Intelligence (AI) is the process by which AI systems draw conclusions, make decisions or infer new knowledge from existing information. Types of reasoning used in AI are: Reasoning in Artificial Intelligence (AI) Types of Reasoning in AI Deductive Reasoning Inductive Reasoning Abductive Reasoning Fuzzy Reasoning Planning in AI Planning in AI generates a sequence of actions that an intelligent agent needs to execute to achieve specific goals or objectives. Some of the planning techniques in artificial intelligence includes: Planning in AI Forward State Space Search Markov Decision Processes (MDPs) Hierarchical State Space Search (HSSS) Uncertain Knowledge and Reasoning Uncertain Knowledge and Reasoning in AI refers to the methods and techniques used to handle situations where information is incomplete, ambiguous or uncertain. For managing uncertainty in AI following methods are used: Uncertain Knowledge and Reasoning in AI Dempster-Shafer Theory Probabilistic Reasoning Fuzzy Logic Neural Networks with dropout Types of Learning in AI Learning in Artificial Intelligence (AI) refers to the process by which a system improves its performance on a task over time through experience, data or interaction with the environment. 1. Supervised Learning In Supervised Learning model are trained on labeled dataset to learn the mapping from inputs to outputs. Various algorithms are: Supervised Learning Linear Regression Logistic Regression Decision Trees Support Vector Machines (SVM) k-Nearest Neighbors Naïve Bayes Random Forests 2. Semi-supervised learning In Semi-supervised learning the model uses both labeled and unlabeled data to improve learning accuracy. Semi-supervised learning 3. Unsupervised Learning In Unsupervised Learning the model is trained on unlabeled dataset to discover patterns or structures. Unsupervised Learning K-Means Clustering Principal Component Analysis (PCA) Hierarchical Clustering DBSCAN (Density-Based Spatial Clustering of Applications with Noise) 4. Reinforcement Learning In Reinforcement Learning the agent learns through interactions with an environment using feedbacks. Reinforcement Learning Q-Learning Deep Q-Networks (DQN) Markov decision processes (MDPs) Bellman equation 5. Deep Learning Deep Learning focuses on using neural networks with many layers to model and understand complex patterns and representations in large datasets. Deep Learning Neurons Single Layer Perceptron Multi-Layer Perceptron Artificial Neural Networks (ANNs) Feedforward Neural Networks (FNN) Convolutional Neural Networks (CNN) Recurrent Neural Networks (RNNs) Long Short-Term Memory (LSTM) networks Gated Recurrent Units Networks (GRU) Probabilistic models Probabilistic models in AI deals with uncertainty making predictions and modeling complex systems where uncertainty and variability play an important role. These models help in reasoning, decision-making and learning from data. Probabilistic models Naive Bayes Classifier Monte Carlo Methods Expectation-Maximization (EM) Algorithm Communication, Perceiving and Acting in AI and Robotics Communication in AI and robotics helps in the interaction between machines and their environments which uses natural language processing. Perceiving helps machines using sensors and cameras to interpret their surroundings accurately. Acting in robotics includes making informed decisions and performing tasks based on processed data. 1. Natural Language Processing (NLP) Speech Recognition Natural Language Generation Chatbots Machine Translation 2. Computer Vision Image Recognition Facial Recognition Optical Character Recognition 3. Robotics Generative AI Generative AI focuses on creating new data examples that resemble real data, effectively learning the distribution of data to generate similar but distinct outputs. Large Language Models GPT (Generative Pre-trained Transformer) BERT (Bidirectional Encoder Representations from Transformers) T5 (Text-to-Text Transfer Transformer) Conditional GAN (cGAN) CycleGAN Style GANs We've covered the AI tutuorial which is important for developing intelligent systems and helps in making the perfect balance of simplicity and capability. Comment More info Advertise with us Next Article AI ML DS Interview Series K kartik Follow Improve Article Tags : Artificial Intelligence AI-ML-DS Tutorials Like 631k+ interested Geeks DSA to Development: A Complete Guide Explore 470k+ interested Geeks Complete Machine Learning & Data Science Program Explore Corporate & Communications Address: A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) Registered Address: K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305 Advertise with us Company About Us Legal Privacy Policy Careers In Media Contact Us Corporate Solution Campus Training Program Explore Job-A-Thon Offline Classroom Program DSA in JAVA/C++ Master System Design Master CP Videos Tutorials Python Java C++ PHP GoLang SQL R Language Android DSA Data Structures Algorithms DSA for Beginners Basic DSA Problems DSA Roadmap DSA Interview Questions Competitive Programming Data Science & ML Data Science With Python Machine Learning ML Maths Data Visualisation Pandas NumPy NLP Deep Learning Web Technologies HTML CSS JavaScript TypeScript ReactJS NextJS NodeJs Bootstrap Tailwind CSS Python Tutorial Python Examples Django Tutorial Python Projects Python Tkinter Web Scraping OpenCV Tutorial Python Interview Question Computer Science GATE CS Notes Operating Systems Computer Network Database Management System Software Engineering Digital Logic Design Engineering Maths DevOps Git AWS Docker Kubernetes Azure GCP DevOps Roadmap System Design High Level Design Low Level Design UML Diagrams Interview Guide Design Patterns OOAD System Design Bootcamp Interview Questions School Subjects Mathematics Physics Chemistry Biology Social Science English Grammar Databases SQL MYSQL PostgreSQL PL/SQL MongoDB Preparation Corner Company-Wise Recruitment Process Aptitude Preparation Puzzles Company-Wise Preparation More Tutorials Software Development Software Testing Product Management Project Management Linux Excel All Cheat Sheets Courses IBM Certification Courses DSA and Placements Web Development Data Science Programming Languages DevOps & Cloud Programming Languages C Programming with Data Structures C++ Programming Course Java Programming Course Python Full Course Clouds/ Devops DevOps Engineering AWS Solutions Architect Certification Salesforce Certified Administrator Course GATE 2026 GATE CS Rank Booster GATE DA Rank Booster GATE CS & IT Course - 2026 GATE DA Course 2026 GATE Rank Predictor @GeeksforGeeks, Sanchhaya Education Private Limited , All rights reserved We use cookies to ensure you have the best browsing experience on our website. By using our site, you acknowledge that you have read and understood our Cookie Policy & Privacy Policy Got It ! Improvement Suggest changes Suggest Changes Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal. Create Improvement Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all. Suggest Changes min 4 words, max Words Limit:1000 Thank You! Your suggestions are valuable to us. What kind of Experience do you want to share? Interview Experiences Admission Experiences Career Journeys Work Experiences Campus Experiences Competitive Exam Experiences
====================================================================================================
What is AI? / Basic Questions Professor John McCarthy Father of AI What is AI? / Basic Questions Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable. Q. Yes, but what is intelligence? A. Intelligence is the computational part of the ability to achieve goals in the world. Varying kinds and degrees of intelligence occur in people, many animals and some machines. Q. Isn't there a solid definition of intelligence that doesn't depend on relating it to human intelligence? A. Not yet. The problem is that we cannot yet characterize in general what kinds of computational procedures we want to call intelligent. We understand some of the mechanisms of intelligence and not others. Q. Is intelligence a single thing so that one can ask a yes or no question ``Is this machine intelligent or not?''? A. No. Intelligence involves mechanisms, and AI research has discovered how to make computers carry out some of them and not others. If doing a task requires only mechanisms that are well understood today, computer programs can give very impressive performances on these tasks. Such programs should be considered ``somewhat intelligent''. Q. Isn't AI about simulating human intelligence? A. Sometimes but not always or even usually. On the one hand, we can learn something about how to make machines solve problems by observing other people or just by observing our own methods. On the other hand, most work in AI involves studying the problems the world presents to intelligence rather than studying people or animals. AI researchers are free to use methods that are not observed in people or that involve much more computing than people can do. Q. What about IQ? Do computer programs have IQs? A. No. IQ is based on the rates at which intelligence develops in children. It is the ratio of the age at which a child normally makes a certain score to the child's age. The scale is extended to adults in a suitable way. IQ correlates well with various measures of success or failure in life, but making computers that can score high on IQ tests would be weakly correlated with their usefulness. For example, the ability of a child to repeat back a long sequence of digits correlates well with other intellectual abilities, perhaps because it measures how much information the child can compute with at once. However, ``digit span'' is trivial for even extremely limited computers. However, some of the problems on IQ tests are useful challenges for AI. Q. What about other comparisons between human and computer intelligence? Arthur R. Jensen [ Jen98 ], a leading researcher in human intelligence, suggests ``as a heuristic hypothesis'' that all normal humans have the same intellectual mechanisms and that differences in intelligence are related to ``quantitative biochemical and physiological conditions''. I see them as speed, short term memory, and the ability to form accurate and retrievable long term memories. Whether or not Jensen is right about human intelligence, the situation in AI today is the reverse. Computer programs have plenty of speed and memory but their abilities correspond to the intellectual mechanisms that program designers understand well enough to put in programs. Some abilities that children normally don't develop till they are teenagers may be in, and some abilities possessed by two year olds are still out. The matter is further complicated by the fact that the cognitive sciences still have not succeeded in determining exactly what the human abilities are. Very likely the organization of the intellectual mechanisms for AI can usefully be different from that in people. Whenever people do better than computers on some task or computers use a lot of computation to do as well as people, this demonstrates that the program designers lack understanding of the intellectual mechanisms required to do the task efficiently. Q. When did AI research start? A. After WWII, a number of people independently started to work on intelligent machines. The English mathematician Alan Turing may have been the first. He gave a lecture on it in 1947. He also may have been the first to decide that AI was best researched by programming computers rather than by building machines. By the late 1950s, there were many researchers on AI, and most of them were basing their work on programming computers. Q. Does AI aim to put the human mind into the computer? A. Some researchers say they have that objective, but maybe they are using the phrase metaphorically. The human mind has a lot of peculiarities, and I'm not sure anyone is serious about imitating all of them. Q. What is the Turing test? A. Alan Turing's 1950 article Computing Machinery and Intelligence [ Tur50 ] discussed conditions for considering a machine to be intelligent. He argued that if the machine could successfully pretend to be human to a knowledgeable observer then you certainly should consider it intelligent. This test would satisfy most people but not all philosophers. The observer could interact with the machine and a human by teletype (to avoid requiring that the machine imitate the appearance or voice of the person), and the human would try to persuade the observer that it was human and the machine would try to fool the observer. The Turing test is a one-sided test. A machine that passes the test should certainly be considered intelligent, but a machine could still be considered intelligent without knowing enough about humans to imitate a human. Daniel Dennett's book Brainchildren [ Den98 ] has an excellent discussion of the Turing test and the various partial Turing tests that have been implemented, i.e. with restrictions on the observer's knowledge of AI and the subject matter of questioning. It turns out that some people are easily led into believing that a rather dumb program is intelligent. Q. Does AI aim at human-level intelligence? A. Yes. The ultimate effort is to make computer programs that can solve problems and achieve goals in the world as well as humans. However, many people involved in particular research areas are much less ambitious. Q. How far is AI from reaching human-level intelligence? When will it happen? A. A few people think that human-level intelligence can be achieved by writing large numbers of programs of the kind people are now writing and assembling vast knowledge bases of facts in the languages now used for expressing knowledge. However, most AI researchers believe that new fundamental ideas are required, and therefore it cannot be predicted when human-level intelligence will be achieved. Q. Are computers the right kind of machine to be made intelligent? A. Computers can be programmed to simulate any kind of machine. Many researchers invented non-computer machines, hoping that they would be intelligent in different ways than the computer programs could be. However, they usually simulate their invented machines on a computer and come to doubt that the new machine is worth building. Because many billions of dollars that have been spent in making computers faster and faster, another kind of machine would have to be very fast to perform better than a program on a computer simulating the machine. Q. Are computers fast enough to be intelligent? A. Some people think much faster computers are required as well as new ideas. My own opinion is that the computers of 30 years ago were fast enough if only we knew how to program them. Of course, quite apart from the ambitions of AI researchers, computers will keep getting faster. Q. What about parallel machines? A. Machines with many processors are much faster than single processors can be. Parallelism itself presents no advantages, and parallel machines are somewhat awkward to program. When extreme speed is required, it is necessary to face this awkwardness. Q. What about making a ``child machine'' that could improve by reading and by learning from experience? A. This idea has been proposed many times, starting in the 1940s. Eventually, it will be made to work. However, AI programs haven't yet reached the level of being able to learn much of what a child learns from physical experience. Nor do present programs understand language well enough to learn much by reading. Q. Might an AI system be able to bootstrap itself to higher and higher level intelligence by thinking about AI? A. I think yes, but we aren't yet at a level of AI at which this process can begin. Q. What about chess? A. Alexander Kronrod, a Russian AI researcher, said ``Chess is the Drosophila of AI.'' He was making an analogy with geneticists' use of that fruit fly to study inheritance. Playing chess requires certain intellectual mechanisms and not others. Chess programs now play at grandmaster level, but they do it with limited intellectual mechanisms compared to those used by a human chess player, substituting large amounts of computation for understanding. Once we understand these mechanisms better, we can build human-level chess programs that do far less computation than do present programs. Unfortunately, the competitive and commercial aspects of making computers play chess have taken precedence over using chess as a scientific domain. It is as if the geneticists after 1910 had organized fruit fly races and concentrated their efforts on breeding fruit flies that could win these races. Q. What about Go ? A. The Chinese and Japanese game of Go is also a board game in which the players take turns moving. Go exposes the weakness of our present understanding of the intellectual mechanisms involved in human game playing. Go programs are very bad players, in spite of considerable effort (not as much as for chess). The problem seems to be that a position in Go has to be divided mentally into a collection of subpositions which are first analyzed separately followed by an analysis of their interaction. Humans use this in chess also, but chess programs consider the position as a whole. Chess programs compensate for the lack of this intellectual mechanism by doing thousands or, in the case of Deep Blue, many millions of times as much computation. Sooner or later, AI research will overcome this scandalous weakness. Q. Don't some people say that AI is a bad idea? A. The philosopher John Searle says that the idea of a non-biological machine being intelligent is incoherent. He proposes the Chinese room argument . The philosopher Hubert Dreyfus says that AI is impossible. The computer scientist Joseph Weizenbaum says the idea is obscene, anti-human and immoral. Various people have said that since artificial intelligence hasn't reached human level by now, it must be impossible. Still other people are disappointed that companies they invested in went bankrupt. Q. Aren't computability theory and computational complexity the keys to AI? [Note to the layman and beginners in computer science: These are quite technical branches of mathematical logic and computer science, and the answer to the question has to be somewhat technical.] A. No. These theories are relevant but don't address the fundamental problems of AI. In the 1930s mathematical logicians, especially Kurt Gödel and Alan Turing, established that there did not exist algorithms that were guaranteed to solve all problems in certain important mathematical domains. Whether a sentence of first order logic is a theorem is one example, and whether a polynomial equations in several variables has integer solutions is another. Humans solve problems in these domains all the time, and this has been offered as an argument (usually with some decorations) that computers are intrinsically incapable of doing what people do. Roger Penrose claims this. However, people can't guarantee to solve arbitrary problems in these domains either. See my Review of The Emperor's New Mind by Roger Penrose . More essays and reviews defending AI research are in [ McC96a ]. In the 1960s computer scientists, especially Steve Cook and Richard Karp developed the theory of NP-complete problem domains. Problems in these domains are solvable, but seem to take time exponential in the size of the problem. Which sentences of propositional calculus are satisfiable is a basic example of an NP-complete problem domain. Humans often solve problems in NP-complete domains in times much shorter than is guaranteed by the general algorithms, but can't solve them quickly in general. What is important for AI is to have algorithms as capable as people at solving problems. The identification of subdomains for which good algorithms exist is important, but a lot of AI problem solvers are not associated with readily identified subdomains. The theory of the difficulty of general classes of problems is called computational complexity. So far this theory hasn't interacted with AI as much as might have been hoped. Success in problem solving by humans and by AI programs seems to rely on properties of problems and problem solving methods that the neither the complexity researchers nor the AI community have been able to identify precisely. Algorithmic complexity theory as developed by Solomonoff, Kolmogorov and Chaitin (independently of one another) is also relevant. It defines the complexity of a symbolic object as the length of the shortest program that will generate it. Proving that a candidate program is the shortest or close to the shortest is an unsolvable problem, but representing objects by short programs that generate them should sometimes be illuminating even when you can't prove that the program is the shortest. Go to next page on Branches of AI . "I don't see that human intelligence is something that humans can never understand." ~ John McCarthy, March 1989 Articles Books and Reviews Notes on AI Slides What is AI? Top | John McCarthy's Original Website | We invite you to send comments and feedback
====================================================================================================
Artificial Intelligence (AI): What it is and why it matters | SAS Skip to main content Software Learn Support Partners About Us SAS Innovate Try SAS Software SAS Viya Platform SAS Viya Platform Overview Data Management Explore and Model Deploy Insights Why SAS Viya? How to Buy Try it Now Solutions Solutions Artificial Intelligence (AI) Fraud IoT Marketing Risk Management All Products & Solutions Industries Industries Banking Public Sector Insurance Health Care Life Sciences Manufacturing All Industries Explore Explore Try/Buy Contracting with SAS Why SAS? Customer Stories Generative AI Solutions Consulting Managed Cloud Services Learn Training Training Overview Train My Team Course Catalog Free Training Books My Training Academics Academics Academic Programs Free Academic Software Educators Students Certification Certification Choose a Credential Free Practice Exams Exam Preparation My Certification Explore Explore Communities Events Ask the Expert All Webinars Video Tutorials YouTube Channel Use Your Software Support Communities Communities SAS Viya SAS Programming Statistical Procedures New SAS Users Administrators All Communities Documentation Documentation By Product Installation & Configuration SAS Viya Administration SAS Viya Programming System Requirements All Documentation Support & Services Support & Services Downloads Knowledge Base Starter Kit Support by Product Support Services All Support & Services Explore Explore Blogs User Groups Webinars Video Tutorials YouTube Channel MySAS Partners About Us Company Company Overview Annual Report Leadership Vision & Mission Office Locations Careers Careers Overview Culture Internships Search Jobs News & Events News & Events Newsroom Newsletters Blogs Events Explore Explore Brand Communities Trust Center Contact Us SAS Innovate SAS Viya Platform Overview Data Management Explore and Model Deploy Insights Why SAS Viya? How to Buy Try it Now Try it now Solutions Artificial Intelligence (AI) Fraud IoT Marketing Risk Management All Products & Solutions Industries Banking Public Sector Insurance Health Care Life Sciences Manufacturing All Industries Explore Try/Buy Contracting with SAS Why SAS? Customer Stories Generative AI Solutions Consulting Managed Cloud Services Software Success Discover free resources and tailored guides to help you optimize your software experience. Learn to use your software Training Overview Train My Team Course Catalog Free Training Books My Training Academics Academic Programs Free Academic Software Educators Students Certification Choose a Credential Free Practice Exams Exam Preparation My Certification Explore Communities Events Ask the Expert All Webinars Video Tutorials YouTube Channel Communities SAS Viya SAS Programming Statistical Procedures New SAS Users Administrators All Communities Documentation By Product Installation & Configuration SAS Viya Administration SAS Viya Programming System Requirements All Documentation Support & Services Downloads Knowledge Base Starter Kit Support by Product Support Services All Support & Services Explore Blogs User Groups Webinars Video Tutorials YouTube Channel MySAS Overview Partner Program Find a Partner Sign Into PartnerNet Why SAS? Learn why SAS is the world's most trusted analytics platform, and why analysts, customers and industry experts love SAS. Learn more about SAS Company Overview Annual Report Leadership Vision & Mission Office Locations Careers Overview Culture Internships Search Jobs News & Events Newsroom Newsletters Blogs Events Explore Brand Communities Trust Center Contact Us sas.com sas.com support.sas.com documentation.sas.com blogs.sas.com communities.sas.com developer.sas.com Search Select Your Region Visit the Cary, NC, US corporate headquarters site Americas Europe Middle East & Africa Asia Pacific View our worldwide contacts list for help finding your region Americas Brasil Canada (English) Canada (Français) Colombia México United States Europe Belgium Česká Republika Danmark Deutschland España France Iceland Ireland Italia Nederland Norge Österreich Polska Portugal România Россия Schweiz (Deutsch) Suisse (Français) Suomi Sverige Türkiye Україна United Kingdom Middle East & Africa Middle East Saudi Arabia South Africa Asia Pacific Australia 中国 (简体中文) Hong Kong India 日本 대한민국 Malaysia New Zealand Philippines Singapore 台灣 (繁體中文) Thailand (English) ประเทศไทย (ภาษาไทย) Search Worldwide Sites Contact Us SAS Sites Sign In Hi ! Sign Out Sign In Create Profile My SAS Get access to My SAS, trials, communities and more. Sign Out Edit Profile My SAS Get access to My SAS, trials, communities and more. SAS Sites sas.com Support Blogs Communities Developer Curiosity Videos Documentation Learn Brand PartnerNet Merchandise SAS Insights Analytics Insights Artificial Intelligence History Today's World Who Uses It How It Works Next Steps AI Solutions Artificial Intelligence What it is and why it matters Artificial intelligence (AI) makes it possible for machines to learn from experience, adjust to new inputs and perform human-like tasks. Most AI examples that you hear about today – from chess-playing computers to self-driving cars – rely heavily on deep learning and natural language processing . Using these technologies, computers can be trained to accomplish specific tasks by processing large amounts of data and recognizing patterns in the data. History Today's World Who Uses It How It Works Next Steps Artificial Intelligence History The term artificial intelligence was coined in 1956, but AI has become more popular today thanks to increased data volumes, advanced algorithms, and improvements in computing power and storage. Early research in the 1950s explored topics like problem solving and symbolic methods. In the 1960s, the US Department of Defense took interest in this type of work and began training computers to mimic basic human reasoning. For example, the Defense Advanced Research Projects Agency (DARPA) completed street mapping projects in the 1970s. And DARPA produced intelligent personal assistants in 2003, long before Siri, Alexa or Cortana were household names. This early work paved the way for the automation and formal reasoning that we see in computers today, including decision support systems and smart search systems that can be designed to complement and augment human abilities. While Hollywood movies and science fiction novels depict AI as human-like robots that take over the world, the current evolution of this technology isn’t that scary – or quite that smart. Instead, AI has evolved to provide many specific benefits in every industry. Keep reading for examples in health care, retail and more. Today's generative AI technologies have made the benefits of AI clear to a growing number of professionals. LLM-powered assistants are showing up inside many existing software products, from forecasting tools to marketing stacks. The fast adoption of GenAI has also raised questions and concerns about AI anxiety , AI hallucinations and AI ethics . As a result, trustworthy AI and responsible AI discussions are becoming crucial in every industry. 1950s–1970s Neural Networks Early work with neural networks stirs excitement for “thinking machines.” machine-learning 1980s–2010s Machine Learning Machine learning becomes popular. 2011–2020s Deep Learning Deep learning breakthroughs drive AI boom. Present Day Generative AI Generative AI, a disruptive tech, soars in popularity. What is generative AI? "With generative AI, we're entering a new era of human and machine interaction," says Marinela Profi, an AI marketing manager at SAS. Generative AI learns from billions of data points and generates new content based on human prompts. Hear Profi discuss real-world examples of generative AI across industries, including use cases using large language models (LLMs), synthetic data generation and digital twins. Learn about the risks and benefits of this new frontier in AI. x Why is artificial intelligence important? Automates repetitive learning and discovery through data. Instead of automating manual tasks, artificial intelligence performs frequent, high-volume, computerized tasks. And it does so reliably and without fatigue. Of course, humans are still essential to set up the system and ask the right questions. Adds intelligence to existing products. Many products you already use will be improved with artificial intelligence capabilities, much like Siri was added as a feature to a new generation of Apple products. Automation, conversational platforms, bots and smart machines can be combined with large amounts of data to improve many technologies. Upgrades at home and in the workplace, range from security intelligence and smart cams to investment analysis. Adapts through progressive learning algorithms to let the data do the programming. Artificial intelligence finds structure and regularities in data so that algorithms can acquire skills. Just as an algorithm can teach itself to play chess, it can teach itself what product to recommend next online. And the models adapt when given new data. Analyzes more and deeper data using neural networks that have many hidden layers. Building a fraud detection system with five hidden layers used to be impossible. All that has changed with incredible computer power and big data . You need lots of data to train deep learning models because they learn directly from the data. Achieves incredible accuracy through deep neural networks. For example, your interactions with Alexa and Google are all based on deep learning. And these products keep getting more accurate the more you use them. In the medical field, AI techniques from deep learning and object recognition can now be used to pinpoint cancer on medical images with improved accuracy. Gets the most out of data. When algorithms are self-learning, the data itself is an asset. The answers are in the data – you just have to apply artificial intelligence to find them. With this tight relationship between data and AI , your data becomes more important than ever. If you have the best data in a competitive industry, even if everyone is applying similar techniques, the best data will win. But using that data to innovate responsibly requires trustworthy AI . And that means your AI systems should be ethical, equitable and sustainable. Artificial Intelligence in Today's World Pondering AI podcast Is artificial intelligence always biased? Does AI need humans? What will AI do next? Join Kimberly Nevala to ponder AI’s progress with a diverse group of guests, including innovators, activists and data experts. Listen to podcast Your journey to GenAI success Our research shows that organizations that embrace GenAI are seeing significant benefits. Find out how organizations are using GenAI to drive innovation, new conversational experiences and operational efficiency. Check out the report Read results of the SAS GenAI market research Five AI technologies that you need to know Read our quick overview of the key technologies fueling this tech craze. This useful introduction offers short descriptions and examples for machine learning, natural language processing and more. Read the article How Artificial Intelligence Is Being Used Every industry has a high demand for AI capabilities – including systems that can be used for automation, learning, legal assistance, risk notification and research. Specific uses across industries include: Health Care AI applications can provide personalized medicine and X-ray readings. Personal health care assistants can act as life coaches, reminding you to take your pills, exercise or eat healthier. More health care solutions Retail AI provides virtual shopping capabilities that offer personalized recommendations and discuss purchase options with the consumer. Stock management and site layout technologies will also be improved with AI. More retail solutions Manufacturing AI can analyze factory IoT data as it streams from connected equipment to forecast expected load and demand using recurrent networks, a specific type of deep learning network used with sequence data. More manufacturing solutions Banking Artificial Intelligence enhances the speed, precision and effectiveness of human efforts. In financial institutions, AI techniques can be used to identify which transactions are likely to be fraudulent, adopt fast and accurate credit scoring, as well as automate manually intense data management tasks. More banking solutions AI has been an integral part of SAS software for years. Today we help customers in every industry capitalize on advancements in AI, and we’ll continue embedding AI technologies like machine learning and deep learning in solutions across the SAS portfolio. Jim Goodnight CEO SAS WildTrack and SAS: Saving endangered species one footprint at a time. Flagship species like the cheetah are disappearing. And with them, the biodiversity that supports us all. WildTrack is exploring the value of artificial intelligence in conservation – to analyze footprints the way indigenous trackers do and protect these endangered animals from extinction. Learn more x How Artificial Intelligence Works AI works by combining large amounts of data with fast, iterative processing and intelligent algorithms, allowing the software to learn automatically from patterns or features in the data. This broad field of study includes many theories, methods and technologies, as well as the following major subfields: machine-learning Machine Learning Machine learning automates analytical model building. It uses methods from neural networks, statistics, operations research and physics to find hidden insights in data without explicitly being programmed for where to look or what to conclude. Neural Networks A neural network is a type of machine learning that is made up of interconnected units (like neurons) that processes information by responding to external inputs, relaying information between each unit. The process requires multiple passes at the data to find connections and derive meaning from undefined data. Deep Learning Deep learning uses huge neural networks with many layers of processing units, taking advantage of advances in computing power and improved training techniques to learn complex patterns in large amounts of data. Common applications include image and speech recognition. Additionally, several technologies enable and support AI: Computer vision relies on pattern recognition and deep learning to recognize what’s in a picture or video. When machines can process, analyze and understand images, they can capture images or videos in real time and interpret their surroundings. Natural language processing (NLP) is the ability of computers to analyze, understand and generate human language, including speech. The next stage of NLP is natural language interaction, which allows humans to communicate with computers using normal, everyday language to perform tasks. Graphical processing units provide the heavy compute power that’s required for iterative processing. Training neural networks requires big data plus compute power. The internet of things generates massive amounts of data from connected devices, most of it unanalyzed. Automating models with AI will allow us to use more of it. Advanced algorithms are being developed and combined in new ways to analyze more data faster and at multiple levels. This intelligent processing is key to identifying and predicting rare events, understanding complex systems and optimizing unique scenarios. APIs, or application programming interfaces , are portable packages of code that make it possible to add AI functionality to existing products and software packages. They can add image recognition capabilities to home security systems and Q&A capabilities that describe data, create captions and headlines, or call out interesting patterns and insights in data. Is AI becoming autonomous? As technology advances, AI agents have become increasingly autonomous, integrating with LLMs to enhance decision-making, optimize processes and provide real-time insights. AI agents work on a spectrum of autonomy, ranging from use cases where human oversight is required to scenarios where humans can be out of the loop. Learn more about AI agents and how they work. Next Steps See how Artificial Intelligence solutions augment human creativity and endeavors. SAS AI Solutions Featured capability for ARTIFICIAL INTELLIGENCE SAS ® Visual Machine Learning AI is simplified when you can prepare data for analysis, develop models with modern machine-learning algorithms and integrate text analytics all in one product. Plus, you can code projects that combine SAS with other languages, including Python, R, Java or Lua. Try it for free Recommended reading Article How to drill a better hole with analytics From drilling holes to preventing health care fraud, learn about some of the new technologies SAS has patented with IoT and machine learning technologies. Article 3 Essential Steps for Ethical AI Will artificial intelligence benefit humanity or usher in a series of unintended consequences? AI ethics may be one way to ensure artificial intelligence is used for good. Research Nerd in the herd: protecting elephants with data science A passionate SAS data scientist uses machine learning to detect tuberculosis in elephants. Find out how her research can help prevent the spread of the disease. Home SAS Insights Analytics Insights Artificial Intelligence (AI): What it is and why it matters Home SAS Insights Analytics Insights Artificial Intelligence (AI): What it is and why it matters SAS data and AI solutions provide our global customers with knowledge they can trust in the moments that matter, inspiring bold new innovations across industries. Contact Us Follow Us Facebook Twitter LinkedIn YouTube RSS Explore Accessibility Careers Certification Communities Company Data Management Developers Documentation For Educators Events Industries My SAS Newsroom Products SAS Viya Solutions Students Support & Services Training Try/Buy Video Tutorials Why SAS? What is... What is... Analytics Artificial Intelligence Data Management Data Science Generative AI Responsible Innovation Privacy Statement Terms of Use Trust Center ©2025 SAS Institute Inc. All Rights Reserved. Contact Us Share Subscribe Share this Share this page with friends or colleagues. Email Facebook Twitter LinkedIn Back to Top
====================================================================================================
Artificial Intelligence | NSF - National Science Foundation Skip to main content An official website of the United States government Here's how you know Here's how you know Official websites use .gov A .gov website belongs to an official government organization in the United States. Secure .gov websites use HTTPS. A lock ( Lock Locked padlock ) or https:// means you've safely connected to the .gov website. Share sensitive information only on official, secure websites. Learn about updates on NSF priorities and the agency's implementation of recent executive orders . Search Menu Search search Find Funding Funding Search Award Search NSF-wide Initiatives Research Experiences for Undergraduates Where to Start For Everyone For Early-Career Researchers For Postdoctoral Fellows For Graduate Students For Undergraduates For Industry For Entrepreneurs How to Apply Preparing Your Proposal Submitting Your Proposal Proposal & Award Policies & Procedures Guide (PAPPG) Additional Resources Research.gov Grants.gov How We Make Funding Decisions Manage Your Award Getting Started Request a Change to Your Award Report Your Outcomes Proposal & Award Policies & Procedures Guide (PAPPG) Additional Resources Research.gov NSF Public Access Repository Who to Contact With Questions Focus Areas Explore All Focus Areas Arctic and Antarctic Astronomy and Space Biology Chemistry Computing Creating a STEM Workforce Earth and Environment Education and Training Engineering Facilities and Infrastructure Materials Research Mathematics People and Society Physics Research Partnerships Technology News & Events News & Announcements NSF Impacts Science Matters Blog For the Press Upcoming Events NSF 75th Anniversary NSF Grants Conference About About NSF Visit NSF Contact Us Our Directorates & Offices How NSF Is Organized Biological Sciences (BIO) Computer & Information Science & Engineering (CISE) Engineering (ENG) Geosciences (GEO) Integrative Activities (OIA) International Science & Engineering (OISE) Mathematical & Physical Sciences (MPS) Social, Behavioral & Economic Sciences (SBE) STEM Education (EDU) Technology, Innovation & Partnerships (TIP) National Center for Science & Engineering Statistics (NCSES) National Science Board (NSB) Artificial Intelligence View image credit & caption Home Our Focus Areas Artificial Intelligence The U.S. National Science Foundation has invested in artificial intelligence research since the early 1960s, setting the technical and conceptual foundations driving today’s AI innovations. AI-driven discoveries and technologies are transforming Americans' daily lives and promising practical solutions to global challenges, from food production and supply chains to healthcare and education. As a major federal funder of AI research, NSF is making investments that will catalyze new discoveries, translate this knowledge into the hands of the American enterprise and build the workforce needed to drive U.S. global leadership and economic competitiveness. Find funding in AI On this page What is artificial intelligence? Brought to you by NSF What we support National AI Research Institutes National AI Research Resource Pilot Developing the AI workforce of the future Featured funding Featured news Additional resources What is artificial intelligence? How does AI affect our daily lives? How does it work in simple terms? Can we trust AI chatbots? In this 10-minute video, Michael Littman, NSF division director for Information and Intelligent Systems, looks at where the field of artificial intelligence has been and where it's going. Brought to you by NSF NSF's decades of sustained investments have ensured the continual advancement of AI research. Pioneering work supported by NSF includes: Reinforcement learning Which improves the conversational ability of chatbots and trains self-driving cars, among other uses. Neural networks Which enable computer understanding of human speech and the analysis of visual scenes. Large language models Which power generative AI systems like ChatGPT. Collaborative filtering Which fuels content recommendation on the world's largest marketplaces and content platforms, from Amazon to Netflix. AI-driven learning Which has led to the development of virtual teachers (both digital and robotic) that incorporate speech, gesture, gaze and facial expression. Learn how NSF helped build the foundations of AI What we support With investments of over $700 million each year, NSF is: Fostering the next-generation of breakthroughs We invest in fundamental AI research, accelerate AI-powered discovery across all fields of science and engineering and deepen the understanding of economic and societal implications of widespread AI adoption. Translating AI research to impact We expand pathways to transition AI innovations into practice and power regional innovation and economic development. Empowering AI innovation through research infrastructure We provide the research community with access to integrated computational, data and software resources with hands-on support and training. Building a world-class workforce for the AI era We invest in the creation of educational tools, materials, curricula, scholarships and fellowships to enhance learning and create an AI-ready workforce. Forging partnerships to accelerate progress We partner with other federal agencies, industry and nonprofits to leverage expertise; identify use cases; and improve access to data, tools and other resources. National AI Research Institutes Launched in 2020, the NSF-led National Artificial Intelligence Research Institutes program consists of 27 AI institutes that connect over 500 funded and collaborative institutions across the U.S. and around the world. The AI institutes focus on different aspects of AI research, including but not limited to: Foundations of machine learning. Agriculture and food systems. AI and advanced cybersecurity. Human-AI interaction and collaboration. AI-augmented learning. Learn more by reading the 2020 , 2021 , 2023 and 2024 AI Institutes announcements or visiting the AI Institutes Virtual Organization . National AI Research Institutes: Interactive Map (PDF, 8.8 MB) AI Institutes Booklet (PDF, 14.86 MB) Hear from the AI Research Institutes At the Edge of Artificial Intelligence This episode of NSF's Discovery Files podcast features three 2023 AI Research Institutes awardees discussing their work. The Frontier of Artificial Intelligence This Discovery Files episode features 2023 AI Research Institutes awardees applying AI to education, agriculture and weather forecasting. National AI Research Resource Pilot As part of the "National AI Initiative Act of 2020," the National AI Research Resource (NAIRR) Task Force was charged with creating a roadmap for a shared research infrastructure that would drive AI innovation and discovery by providing U.S.-based researchers, educators and students with significantly expanded access to computational resources, high-quality data, educational tools and user support. The NSF-led interagency NAIRR Pilot brings together government-supported, industry and other contributed resources to demonstrate the NAIRR concept and deliver needed resources to the U.S. research and education community, including the full range of institutions of higher education and federally funded startups and small businesses. Learn about the NAIRR pilot The NAIRR Pilot is accelerating AI and AI-driven science in areas such as: Improving the accuracy, quality and robustness of AI models. Enhancing AI model security. Early detection of agricultural pests . Assessing personalized risks for Alzheimer’s disease. Facilitating robotic movement through deep vegetation. Implementation Plan for a National Artificial Intelligence Research Resource (PDF, 3.02 MB) Developing the AI workforce of the future NSF programs are preparing the current and next generations of AI-capable innovators and workers by investing in them at every stage. For example: At the preK-12 stage, NSF programs such as Discovery Research PreK-12, Innovative Technology Experiences for Students and Teachers and Computer Science for All provide hands-on learning experiences to get students interested in AI, computer science and careers in STEM. The NSF Advanced Technical Education program supports the education of skilled technical workers at 2-year institutions. The NSF Experiential Learning for Emerging and Novel Technologies program provides participants at any career stage with the training and knowledge needed to succeed in STEM careers. The NSF Advancing Informal STEM Learning program supports public understanding of STEM including in technologies such as AI. NSF also supports scholarship, fellowship and traineeship programs that provide financial support, mentorship and hands-on training. Featured funding Computer and Information Science and Engineering: Core Programs Supports foundational and use-inspired research in AI, data science and human-computer interaction — including human language technologies, computer vision, human-AI interaction, and theory of machine learning. America's Seed Fund (SBIR/STTR) Supports startups and small businesses to translate research into products and services, including AI systems and AI-based hardware , for the public good. Cyber-Physical Systems Supports research on engineered systems with a seamless integration of cyber and physical components, such as computation, control, networking, learning, autonomy, security, privacy and verification, for a range of application domains. Division of Molecular and Cellular Biosciences Core Programs Supports research on living systems at the molecular, subcellular and cellular levels. Core areas supported include cellular dynamics and function; genetic mechanisms; molecular biophysics; and systems and synthetic biology. Engineering Design and Systems Engineering Supports fundamental research on the design of engineered artifacts — devices, products, processes, platforms, materials, organizations, systems and systems of systems. Foundations for Digital Twins as Catalyzers of Biomedical Technological Innovation Supports interdisciplinary research projects that explore the mathematical and engineering foundations behind the development and use of digital twins in biomedical and healthcare applications. Advancing Research at the intersection of Biology and Artificial Intelligence (AI)/Machine Learning (ML) Encourages proposals that advance biological research through use of Artificial Intelligence/Machine Learning (AI/ML) or through development of AI/ML methods using biological data and systems. Research on Innovative Technologies for Enhanced Learning Supports early-stage research in emerging technologies such as AI, robotics and immersive or augmenting technologies for teaching and learning that respond to pressing needs in real-world educational environments. Secure and Trustworthy Cyberspace Supports research addressing cybersecurity and privacy, drawing on expertise in one or more of these areas: computing, communication and information sciences; engineering; economics; education; mathematics; statistics; and social and behavioral sciences. Smart and Connected Communities Supports use-inspired research that addresses communities' social, economic and environmental challenges by integrating intelligent technologies with the natural and built environments. Smart Health and Biomedical Research in the Era of Artificial Intelligence Supports the development of new methods that intuitively and intelligently collect, sense, connect, analyze and interpret data from individuals, devices and systems. Explore more funding in AI NSF directorates supporting AI research Computer and Information Science and Engineering (CISE) Engineering (ENG) Technology, Innovation and Partnerships (TIP) Mathematical and Physical Sciences (MPS) Social, Behavioral and Economic Sciences (SBE) STEM Education (EDU) Geosciences (GEO) Biological Sciences (BIO) International Science and Engineering (OISE) Integrative Activities (OIA) Featured news Impacts Protein Data Bank: Key to the Molecules of Life Decades of support for the Protein Data Bank facilitated the development of AlphaFold2, a tool that uses AI to predict protein shapes — accelerating medical breakthroughs and leading to a Nobel Prize for its inventors . NSF Stories Sparking curiosity in the future semiconductor workforce June 17, 2025 NSF Stories Training AI to see more like humans June 17, 2025 NSF Stories Preparing science educators to use and teach AI in the classroom May 13, 2025 Explore more AI news Additional resources Expanding the Frontiers of AI: Fact Sheet Learn how NSF is driving cutting-edge research on AI. AI Impacts from Investments: Fact Sheet An overview of NSF’s history of investments in artificial intelligence and how those investments fueled the innovative technologies we use today. NAIRR Pilot Explore opportunities for researchers, educators and students, including AI-ready datasets, pre-trained models and other NAIRR pilot resources. CloudBank Allows the research and education community to access cloud computing platforms. One Hundred Year Study on Artificial Intelligence A study focused on understanding and anticipating how AI will ripple through every aspect of how people work, live and play. National Artificial Intelligence Initiative A coordinated federal approach to accelerate AI research and the integration of AI systems across all sectors of the economy and society. Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence Details actions for the responsible use of AI, harnessing AI for public benefit while mitigating its risks. Memorandum on Advancing the United States’ Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence Focuses on harnessing AI models and AI-enabled technologies in the federal government, while protecting human rights, civil rights, civil liberties, privacy and safety. Top 2415 Eisenhower Ave Alexandria, VA 22314 (703) 292-5111 Sign up for email updates Footer About Us About NSF Careers Our Directorates & Offices National Science Board Contact Us What's New News & Announcements Events Science Matters Blog Information For Funding Seekers NSF Awardees Congress Media Educators Panelists Resources Documents & Reports Budget, Performance & Financial Reporting Public Access Stopping Harassment Research Security Scientific Integrity Research.gov Required Policy Links Vulnerability disclosure Inspector General Privacy FOIA No FEAR Act USA.gov Accessibility Plain language
====================================================================================================
wsj.com Please enable JS and disable any ad blocker
====================================================================================================
Artificial Intelligence Definition | DeepAI DeepAI AI Chat AI Image Generator AI Video AI Music Voice Chat AI Photo Editor Login Account Settings AI Image Generator AI Video Generator AI Music Generator AI Chat AI Photo Editor Pricing Glossary Docs Login Upgrade to DeepAI Pro More access to the best models × Artificial Intelligence ‹ Anomaly Detection Association Learning › 876 share What is Artificial Intelligence? Artificial intelligence is the application of rapid data processing, machine learning , predictive analysis, and automation to simulate intelligent behavior and problem solving capabilities with machines and software. It is intelligence of machines and computer programs, versus natural intelligence, which is intelligence of humans and animals. Machines and programs that use artificial intelligence are typically designed to read and interpret a data input and then respond to it by using predictive analytics or machine learning. Artificial Intelligence and Machine Learning Machine learning and artificial intelligence are very related and often confused as being one and the same. In short, machine learning is the science and approach that enables the creation of artificially intelligent machines and programs. Artificial intelligence frequently uses machine learning techniques to improve the system's ability to "learn" and better interpret and react to inputs. Many in the field only consider a system to be "intelligent" when it uses machine learning to learn and improve. Applications of Artificial Intelligence There are many applications for artificial intelligence being used today, and many more that are being researched. A few of the more popular uses of artificial intelligence systems today are in industries like healthcare, automotive technology, and video games, to name a few. Below are a few of the common uses of artificial intelligence in the industries where it is already gaining popularity. Healthcare In healthcare, the number of applications for artificial intelligence is expanding rapidly. Artificial intelligence is currently being used to interpret lab results in blood tests and genetic testing. There are also efforts being made to use AI to interpret medical imaging, such as X-rays and MRI results. Aviation Artificial intelligence is commonly used in flight simulations and simulated aircraft warfare. Many aircrafts are also equipped with sensors which feed data to a system that uses AI to evaluate the mechanical 'health' of the aircraft. Automotive Artificial intelligence is a growing component of the automotive industry. Many companies, like Tesla, are incorporating self-driving technology into their vehicles. Self-driving vehicles use AI to read data of the vehicle's surroundings and respond to other drivers, lines on the road, and similar feedback read by the vehicle's sensors. Finance Financial institutions have been using artificial intelligence to analyze market trends and even automate trades based on various market indicators and triggers. Many banks and financial institutions have also been using AI algorithms and neural network systems to identify fraudulent bank and credit charges, and then trigger human managed investigations. Video Games Many debate how much AI is truly used in video games. This is because machine learning techniques are rarely used and games typically only choose between a handful of automated responses, rather than actually "learning" to defeat their opponents. However, as gameplay has grown in complexity, so has the AI programming that governs it. AI is most commonly seen when the game player interacts with non-player characters in a game. Actions of these characters are often governed by complex AI algorithms that depend on the game player's actions. Applications to Other Industries As stated above, artificial intelligence is really the application of machine learning, predictive analysis, and automation, so its applications are vast. AI has been spreading rapidly to technology driven industries, so it is quickly becoming an important element of several other major industries, including: Manufacturing - AI is being used to automate the building of vehicles and other large machinery and equipment Marketing - AI solutions are being used to analyze user behavior and more effectively target potential customers Employee Recruiting - AI technology is now frequently used to match employers to job seekers Transportation - GPS systems and city planners use AI programs to identify and suggest the most efficient routes As time goes on and artificial intelligence techniques become more widely understood and accessible, more industries will surely benefit from the efficiency and scaling effects that AI can provide. How Does Artificial Intelligence Work? Artificial intelligence "works" by combining several approaches to problem solving from mathematics, computational statistics, machine learning, and predictive analytics. A typical artificial intelligence system will take in a large data set as input and quickly process the data using intelligent algorithms that learn and improve each time a new dataset is processed. After this training procedure is completely, a model is produced that, if successfully trained, will be able to predict or to reveal specific information from new data. In order to fully understand how an artificial intelligence system quickly and "intelligently" processes new data, it is helpful to understand some of the main tools and approaches that AI systems use to solve problems. Below are the most common techniques used in artificial intelligence systems today: Neural Networks Neural networks – or more specifically, artificial neural networks – are computing systems that progressively improve their ability to complete a task without specific programming on the task. The approach that these artificial neural networks use is based on the method that actual biological neural networks in human brains use to solve problems. Read more about artificial neural networks . Statistical Learning and Classification A classifier is a function that uses pattern recognition and pattern matching to identify the closest match. In supervised learning , the classifier will attempt to match the pattern out of a limited set of options. In unsupervised learning , there is no predefined pattern that the classification function needs to be used with. Classifiers are ideal for artificial intelligence applications because their predictive models are adjusted and improved as they process more new data. Read more about classifiers and statistical learning . Optimized Search Tactics Typically exhaustively scanning through every possible solution is not a very efficient way to solve a problem, especially in artificial intelligence applications where speed may be very important. However, it is possible to apply rules of thumb or heuristics to prioritize possible solutions and complete the problem solving process more quickly. Some search algorithms will also use mathematical optimization to solve problems. Mathematical optimization is an approach that involves taking a best guess to the solution based on limited information, and then evaluating "nearby" solutions until the best answer is reached. This can be thought of as using "blind hill climbing" as an approach to reach the solution, or "top of the hill." There are many other approaches to search optimization, including beam search, simulated annealing, random optimization, and evolutionary computation , which more specifically includes various swarm intelligence algorithms and evolutionary algorithms . Other Artificial Intelligence Techniques Various approaches in artificial intelligence design and programming have been taken from concepts in logic programming and automated reasoning . These techniques allow programs to "reason" through problems. There have also been many models and approaches designed for situations where information is uncertain or incomplete. Some of these tools include Bayesian networks , hidden Markov models , Kalman filters , decision theory and analysis, and Markov decision processes . Even certain programming languages, like Prolog, have been adapted to be used in artificial intelligence applications. History of Artificial Intelligence Advances in artificial intelligence and the science behind it can be broken into a few main chapters, described below: AI in Fiction Works of fiction detailing inanimate beings that display consciousness date back centuries. However, the first meaningful milestones in the history of artificial intelligence are tied to the invention of the computer and the early study of formal and mechanical reasoning. Turing and Early Theory of Computation Study of the theory of computation suggested that machines would be able to simulate a wide range of deductive acts through binary operations. The Turing-Church thesis eventually proposed that any "effectively calculable function is a computable function", meaning that anything that a human can calculate through an algorithmic process, a machine can too calculate. These ideas eventually led researchers in neurology and cybernetics to begin exploring the idea of building an electronic brain. Walter Pitts and Warren McCullouch formally proposed designs for artificial neurons in 1943. Dartmouth and the Formalization of AI Research In 1956, at a workshop at Dartmouth college, several leaders from universities and companies began to formalize the study of artificial intelligence. This group of individuals included Arthur Samuel from IBM, Allen Newell and Herbert Simon from CMU, and John McCarthy and Marvin Minsky from MIT. This team and their students began developing some of the early AI programs that learned checkers strategies, spoke english, and solved word problems, which were very significant developments. Increased Computing Power Enables AI Revolution After this initial burst of progress in the 1950's, little more progress was made until the late 90's, when increases in computing power made it possible to apply machine learning techniques that were very slow when computational resources were more limited. This led to artificial intelligence / machine learning techniques being applied to several fields, including medical diagnosis, data mining, and logistics planning. Continued and steady progress has been made since, with such milestones as IBM's Watson winning Jeopardy! and the release of Xbox Kinect which reads and responds to body motion and voice control. Additionally, artificial intelligence based code libraries that enable image and speech recognition are becoming more widely available and easier to use. Thus, these AI techniques, that were once unusable because of limitations in computing power, have become accessible to any developer willing to learn how to use them. If you are interested in learning more about some of these machine learning resources and APIs, or using them to build artificial intelligence into an application, explore this list of resources . × Login Please sign up or login with your details Login Sign up Continue with Google Or login with email Login Forgot password? Click here to reset Go back Unlock AI power with DeepAI PRO $4.99 /month Subscribe See Full Pricing × Out of credits Refill your membership to continue using DeepAI $5.00 USD $5.00 USD $10.00 USD $20.00 USD $50.00 USD $100.00 USD $200.00 USD $500.00 USD $1000.00 USD Add Credits Share Share your generations with friends X Facebook Linkedin Reddit × Sign in with Google × Use your Google Account to sign in to DeepAI Continue × Consider DeepAI Pro World's best value AI at $5 per month Smarter AI Chat Highest quality AI Images, Videos, and Music 100% Ad-free Subscribe
====================================================================================================
What is Artificial Intelligence(AI)? - GeeksforGeeks Skip to content Courses DSA to Development GATE 2026 Prep Get 3 IBM Certifications For Working Professionals Interview 101: DSA & System Design Data Science Training Program JAVA Backend Development (Live) Data Analytics Training DevOps Engineering (LIVE) Data Structures & Algorithms in Python For Students Placement Preparation with DSA Data Science (Live) Data Structure & Algorithm-Self Paced (C++/JAVA) Master Competitive Programming Full Stack Development with React & Node JS (Live) Full Stack Development Data Science & ML Program All Courses Tutorials Python Java Data Structures & Algorithms ML & Data Science Interview Corner Programming Languages Web Development GATE CS Subjects DevOps And Linux School Learning Practice Practice Coding Problems GfG 160: Free DSA Practice Problem of the Day ETS TOEFL: Scholarship Contest All Contests and Events Jobs Become a Mentor Apply Now! Post Jobs Job-A-Thon: Hiring Challenge Notifications Mark all as read All View All Notifications Mark all as read All Unread Read You're all caught up!! Data Science IBM Certification Data Science Data Science Projects Data Analysis Data Visualization Machine Learning ML Projects Deep Learning NLP Computer Vision Artificial Intelligence Sign In ▲ Open In App Explore GfG Courses Share Your Experiences Artificial Intelligence Tutorial | AI Tutorial What is Artificial Intelligence(AI)? History of AI Types of AI Types of Artificial Intelligence (AI) Types of AI Based on Capabilities: An In-Depth Exploration Types of AI Based on Functionalities Agents in AI Problem Solving in AI Search Algorithms in AI Uninformed Search Algorithms in AI Informed Search Algorithms in Artificial Intelligence Local Search Algorithm in Artificial Intelligence Adversarial Search Algorithms in Artificial Intelligence (AI) Constraint Satisfaction Problems (CSP) in Artificial Intelligence Knowledge, Reasoning and Planning in AI How do knowledge representation and reasoning techniques support intelligent systems? First-Order Logic in Artificial Intelligence Types of Reasoning in Artificial Intelligence What is the Role of Planning in Artificial Intelligence? Representing Knowledge in an Uncertain Domain in AI Learning in AI Supervised Machine Learning What is Unsupervised Learning? Semi-Supervised Learning in ML Reinforcement Learning Self-Supervised Learning (SSL) Introduction to Deep Learning Natural Language Processing (NLP) - Overview Computer Vision Tutorial Artificial Intelligence in Robotics Generative AI Generative Adversarial Network (GAN) Variational AutoEncoders What are Diffusion Models? Transformers in Machine Learning DSA to Development Course What is Artificial Intelligence(AI)? Last Updated : 22 Apr, 2025 Comments Improve Suggest changes Like Article Like Report Artificial Intelligence (AI) refers to the technology that allows machines and computers to replicate human intelligence. It enables systems to perform tasks that require human-like decision-making, such as learning from data, identifying patterns, making informed choices and solving complex problems. AI improves continuously by utilizing methods like machine learning and deep learning. In real-world applications, AI is used in healthcare for diagnosing diseases, finance for fraud detection, e-commerce for personalized recommendations and transportation for self-driving cars. It also powers virtual assistants like Siri and Alexa, chatbots for customer support and manufacturing robots that automate production processes. Artificial Intelligence (AI) operates on a core set of concepts and technologies that enable machines to perform tasks that typically require human intelligence. Here are some foundational concepts: Machine Learning (ML) Machine Learning is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed to perform a task, a machine learning model uses algorithms to identify patterns within data and improve its performance over time without human intervention. Generative AI Generative AI refers to a type of artificial intelligence designed to create new content, whether it's text, images, music, or even video. Unlike traditional AI, which typically focuses on analyzing and classifying data, generative AI goes a step further by using patterns it has learned from large datasets to generate new, original outputs. Essentially, it "creates" rather than just "recognizes." How Generative AI Works Generative AI works through complex algorithms and deep learning models, often using techniques like neural networks. These networks are trained on vast amounts of data, allowing the AI to understand the underlying structure and patterns within the data. Here’s a breakdown of how it works: Training on Large Datasets Generative AI models are trained on massive datasets, which could include anything from text (like books or articles) to images or even music. During the training process, the AI learns the relationships and patterns in the data, enabling it to generate new content based on what it has learned. Neural Networks and Deep Learning At the heart of generative AI is deep learning, a subset of machine learning that mimics how our brain processes information. These deep neural networks consist of multiple layers, which process the input data in stages to detect patterns and learn the complexities of the data. Creating New Content Once trained, generative AI can create new content by predicting what comes next based on the patterns it has learned. For instance, when generating text, it might predict the next word or phrase based on previous input. In image generation, it could produce entirely new images by blending elements it has learned from its training data. Feedback Loop and Refinement Generative AI often works in a feedback loop, where it refines its creations through multiple iterations. The more data the AI is exposed to, the better it becomes at creating content that is relevant, coherent, and realistic. Natural Language Processing (NLP) Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and interact with human language in a way that feels natural. Essentially, NLP allows machines to read, interpret and respond to text or speech the way humans do. It's the technology behind things like chatbots, voice assistants (such as Alexa or Siri) and even autocorrect on your phone. NLP involves a combination of linguistics (the study of language) and computer science to process and analyze human language. Expert Systems Expert Systems are a type of artificial intelligence designed to replicate the decision-making ability of a human expert in a specific field. They use a combination of stored knowledge and logical reasoning to make decisions, solve problems or provide recommendations. An expert system works by following a set of predefined "if-then" rules, which are based on the knowledge of experts in the field. How Does AI Work? AI works by simulating human intelligence in machines through algorithms, data and models that enable them to perform tasks that would typically require human intervention. Here's a simplified breakdown: Data Collection : AI systems rely on vast amounts of data. This data can come from various sources, like images, texts or sensor readings. For example, if we're building an AI that recognizes cats in images, we'd need a large dataset of labeled images of cats. Processing and Learning : Machine learning (ML), a subset of AI, uses algorithms to analyze the data. The system learns patterns from the data by training a model. For instance, an AI system might learn the features of a cat, like its shape, ears and whiskers, by being exposed to thousands of labeled images of cats and non-cats. Model Training : The AI model undergoes training using the data. In this process, the model adjusts its parameters based on the input data and the desired output. The more data and training time, the more accurate the model becomes. Decision Making : After training, the AI can make decisions or predictions based on new, unseen data. For example, it might predict whether an image contains a cat, based on the patterns it learned from previous training data. Feedback and Improvement : In many AI systems, particularly in reinforcement learning, feedback is used to improve performance over time. The system's actions are continuously evaluated and adjustments are made to improve future performance. To read about how AI work in detail, refer to article: How Does AI Work? Types of AI (Artificial Intelligence) AI can be classified into two main categories based on its capabilities and functionalities. Based on Capabilities: Narrow AI (Weak AI) : This type of AI is designed to perform a specific task or a narrow set of tasks, such as voice assistants or recommendation systems. It excels in one area but lacks general intelligence. General AI (Strong AI) : General AI is a theoretical concept where AI can perform any intellectual task that a human can do. It demonstrates human-like reasoning and understanding across multiple domains, making it capable of tackling a wide variety of tasks. Superintelligent AI : Superintelligent AI is a hypothetical form of AI that would surpass human intelligence in all areas. It would be capable of performing tasks more efficiently and effectively than humans. Based on Functionalities: Reactive Machines : Reactive machines are AI systems that respond to specific tasks or situations but do not store memories or improve over time. They are programmed to react in a fixed way without learning from past experiences. Limited Memory : Limited memory AI can store and learn from past experiences to make better decisions in the future. Self-driving cars are an example, as they use historical data to navigate and adapt to changing environments. Theory of Mind : The theory of mind is a theoretical type of AI that would be able to understand emotions, beliefs, intentions and other mental states. This would allow the AI to interact with humans in a more natural and empathetic manner. Self-Aware AI : Self-aware AI is a hypothetical form of AI that possesses consciousness and self-awareness. It would have an understanding of its own existence and could make decisions based on that awareness. To read about Types of AI in detail, refer to article: Types of AI . AI Models AI models are computer programs that learn to perform tasks by recognizing patterns in data, similar to how our brains learn from experience. They are trained on large datasets and then use what they’ve learned to make decisions, whether it’s identifying faces in a photo, translating languages or generating text. There are different kinds of AI models based on how they learn: 1. Supervised Learning Models In Supervised learning , the AI is provided with a set of examples where both the input and the desired output are known. For example, to teach an AI to recognize handwritten numbers, we would show it many images of handwritten digits, each labeled with the correct number (0-9). Over time, the model adjusts its internal settings (called weights) to minimize the difference between its predictions and the correct labels given by the "teacher." This method works well when you have large amounts of high-quality, labeled data and is commonly used for tasks like image classification, speech recognition and spam detection. 2. Unsupervised Learning Models In Unsupervised Learning models, the AI is given input data without labels or explicit instructions on what to look for. Its task is to find hidden patterns, clusters, or structures on its own. For instance, if you give an unsupervised model a collection of news articles, it might automatically group them into categories like sports, politics, or entertainment, without anyone telling it those categories. This type of learning is helpful for uncovering new insights in data, reducing dimensions for visualization, and spotting unusual patterns, such as fraud or other anomalies. 3. Reinforcement Learning Models Reinforcement learning works differently from the other two methods. In this case, there isn’t a teacher providing the “correct” answer. Instead, the AI learns through a system of rewards and penalties. For example , in a video game, an agent might start by making random movements and gradually learn which actions lead to winning by receiving points or rewards. Over time, the model develops a strategy (or policy) to maximize its rewards. This type of learning is used in fields like robotics, game-playing (such as AlphaGo), and even automated trading systems. B enefits of AI The widespread use of Artificial Intelligence (AI) has brought numerous advantages across various sectors and aspects of our daily lives. Here are some of the primary benefits of AI: Efficiency and Automation : AI can automate repetitive tasks, reducing human error and saving time. This leads to increased productivity and allows humans to focus on more complex tasks. Improved Decision Making : AI can analyze vast amounts of data quickly and provide insights, helping businesses and organizations make better, data-driven decisions. Personalization : AI can be used to offer personalized experiences in areas like retail, entertainment and online services, improving user satisfaction. For example , recommendation systems on platforms like Netflix or Amazon suggest products or content based on individual preferences. 24/7 Availability : Unlike humans, AI systems can operate around the clock without breaks. This is particularly useful in customer support, monitoring and other services that require constant attention. Data Analysis and Pattern Recognition : AI excels at processing large datasets and recognizing patterns that may be difficult for humans to identify. This is especially beneficial in fields like healthcare, finance and marketing. Artificial Intelligence Use Cases Artificial Intelligence has many practical applications across various industries and domains, including: Retail : AI enhances personalized shopping experiences, manages inventory, forecasts demand and powers chatbots for customer service. Platforms like Amazon and Netflix use recommendation systems to suggest products or content based on user behavior. Manufacturing : AI is utilized in predictive maintenance, quality control, process optimization and supply chain management. It helps identify machine faults before they happen and optimizes production lines for efficiency. Customer Service : AI-driven chatbots and virtual assistants are widely used for providing round-the-clock customer support. These systems handle routine inquiries, troubleshoot common problems and escalate more complex issues to human agents. Marketing and Advertising : AI helps segment audiences, predict customer behavior, optimize ad targeting and improve content personalization. It ensures businesses deliver the right message to the right audience at the optimal time. Agriculture : AI is applied to monitor crop health, optimize irrigation and predict harvest times. AI-powered drones and sensors analyze field data to detect issues like pest infestations or nutrient deficiencies, supporting precision farming. Human Resources : AI streamlines recruitment by screening resumes, matching candidates and scheduling interviews. It can also assess employee performance and predict retention risks, aiding HR departments in making data-driven decisions. To read about Applications of AI in detail, refer to our article: Application of Artificial Intelligence . Comment More info Advertise with us Next Article History of AI P Palak Jain Improve Article Tags : Computer Subject Artificial Intelligence AI-ML-DS Like 631k+ interested Geeks DSA to Development: A Complete Guide Explore 470k+ interested Geeks Complete Machine Learning & Data Science Program Explore Corporate & Communications Address: A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) Registered Address: K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305 Advertise with us Company About Us Legal Privacy Policy Careers In Media Contact Us Corporate Solution Campus Training Program Explore Job-A-Thon Offline Classroom Program DSA in JAVA/C++ Master System Design Master CP Videos Tutorials Python Java C++ PHP GoLang SQL R Language Android DSA Data Structures Algorithms DSA for Beginners Basic DSA Problems DSA Roadmap DSA Interview Questions Competitive Programming Data Science & ML Data Science With Python Machine Learning ML Maths Data Visualisation Pandas NumPy NLP Deep Learning Web Technologies HTML CSS JavaScript TypeScript ReactJS NextJS NodeJs Bootstrap Tailwind CSS Python Tutorial Python Examples Django Tutorial Python Projects Python Tkinter Web Scraping OpenCV Tutorial Python Interview Question Computer Science GATE CS Notes Operating Systems Computer Network Database Management System Software Engineering Digital Logic Design Engineering Maths DevOps Git AWS Docker Kubernetes Azure GCP DevOps Roadmap System Design High Level Design Low Level Design UML Diagrams Interview Guide Design Patterns OOAD System Design Bootcamp Interview Questions School Subjects Mathematics Physics Chemistry Biology Social Science English Grammar Databases SQL MYSQL PostgreSQL PL/SQL MongoDB Preparation Corner Company-Wise Recruitment Process Aptitude Preparation Puzzles Company-Wise Preparation More Tutorials Software Development Software Testing Product Management Project Management Linux Excel All Cheat Sheets Courses IBM Certification Courses DSA and Placements Web Development Data Science Programming Languages DevOps & Cloud Programming Languages C Programming with Data Structures C++ Programming Course Java Programming Course Python Full Course Clouds/ Devops DevOps Engineering AWS Solutions Architect Certification Salesforce Certified Administrator Course GATE 2026 GATE CS Rank Booster GATE DA Rank Booster GATE CS & IT Course - 2026 GATE DA Course 2026 GATE Rank Predictor @GeeksforGeeks, Sanchhaya Education Private Limited , All rights reserved We use cookies to ensure you have the best browsing experience on our website. By using our site, you acknowledge that you have read and understood our Cookie Policy & Privacy Policy Got It ! Improvement Suggest changes Suggest Changes Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal. Create Improvement Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all. Suggest Changes min 4 words, max Words Limit:1000 Thank You! Your suggestions are valuable to us. What kind of Experience do you want to share? Interview Experiences Admission Experiences Career Journeys Work Experiences Campus Experiences Competitive Exam Experiences
====================================================================================================
What Is Artificial Intelligence (AI)? Types, and Advantages
====================================================================================================
Introduction - Artificial Intelligence (AI) - LibGuides at University of Texas at Austin Skip to Main Content University of Texas Libraries LibGuides UT Libraries Artificial Intelligence (AI) Introduction Search this Guide Search Artificial Intelligence (AI) Introduction Introduction Generative AI Tools Benefits and Limitations Prompt Engineering Ethics and Privacy Publishing Copyright Evaluating AI Tools and Output Academic Integrity and Citation Researching AI Teaching Information and AI Literacy Workshops Credits About this Guide This guide provides an introduction to artificial intelligence (AI), with a focus on generative AI. You’ll find explanations of the benefits and limitations as well as support to use, cite, research, and teach with artificial intelligence. AI tools and the legal and ethical landscape surrounding their use are changing rapidly. We will periodically update this guide and provide the date of last update to inform your use. Updated: January 2025 Glossary of AI Terms Artificial Intelligence (AI) Artificial intelligence refers to the development of computer systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and natural language understanding. Types of Artificial Intelligence Chatbot A chatbot is a software application that uses natural language processing (NLP) and machine learning to simulate conversation with humans, either via text or voice interfaces. Generative AI Generative artificial intelligence refers to algorithms and models that can generate new content or data, such as images, videos, music, or text, based on patterns learned from existing information. Machine Learning (ML) Machine learning is a subset of artificial intelligence that involves training computer systems to learn from data and improve their performance over time through experience. Natural Language Processing (NLP) NLP is a subfield of artificial intelligence that deals with the interaction between computers and human language, including text and speech processing, sentiment analysis, machine translation, and dialogue systems. Large Language Model (LLM) A large language model is a type of machine learning model that is trained on vast amounts of text data to generate language outputs that are coherent and contextually appropriate. Using Large Language Models (LLMs) Hallucination In the context of AI, hallucination refers to the phenomenon where a model generates inaccurate or imaginary output that cannot be explained by its training data, often due to overfitting or underfitting . Prompt A prompt is a specific task or question that is given to an AI system to elicit a response or output. Prompt Engineering Prompt engineering is the process of designing and refining prompts to elicit desired responses or behaviors from AI systems, in order to improve their performance and versatility. Understanding Large Language Models (LLMs) Parameters Parameters are settings or values that are adjusted during the training process to optimize the performance of an AI model, such as the learning rate, regularization strength, or number of hidden layers. Temperature In the context of generative AI, temperature refers to a parameter that controls the "randomness" or "diversity" of generated samples, with higher temperatures resulting in more diverse and less predictable outputs. Tokens In Natural Language Processing and machine learning, tokens refer to individual words or phrases in a text dataset, which are used as input features for models to analyze and understand the meaning of the text. Training Data Training data is the set of examples or inputs used to train an AI system, which helps the model learn patterns and relationships in the data and make predictions or decisions. These definitions were generated using the Llama 2 large language model and reviewed for accuracy by a Libraries staff member. Generating content like this can be done efficiently using a large language model, but it is important to remember to review the output carefully and acknowledge the source. Contact Us Email a Librarian Send us your questions or comments Campus Resources and Policies General: Guidance for Using Artifical Intelligence (Enterprise Technology) - a compilation of existing guideline, policies and resources about AI in teaching and learning Information Technology Services' AI Tools (list of tools gathered by ITS) The Artificial Intelligence Lab (Research center on campus offering talks, projects and publications) Resources for Instructors: Generative AI in Teaching and Learning (Center for Teaching & Learning) Requiring Generative AI in the Classroom (Office of Academic Technology, Academic Affairs) AI Detection Software Guidance (Office of Academic Technology, Academic Affairs) Your Syllabus > Grading Policy> Optional: Artificial Intelligence (syllabus statements recommended by the Office of Student Conduct and Academic Integrity) Statement on Artificial Intelligence in Writing Flag Classes (Faculty Writing Committee) Statement on Artificial Intelligence Tools in Art and Design Courses (UT AI Tools Taskforce - Art & Design Subcommittee) Resources for Students: ChatGPT and Other Large Language Models (University Writing Center) Addresing the Limitations of Using Generative AI for Learning (Office of Academic Technology, Academic Affairs) Ethical Artificial Intelligence Program (Graduate program) Engineering and Computational Learning of Artificial Intelligence in Robotics (ECLAIR) (Undergraduate student group) Research Libraries Guiding Principles for Artificial Intelligence The UT Libraries endorses the Research Libraries Guiding Principles for Artificial Intelligence from the Association of Research LIbraries . Last Updated: Jun 17, 2025 1:50 PM URL: https://guides.lib.utexas.edu/AI Print Page Login to LibApps Report a problem Tags: AI , AI ethics , artificial intelligence , chatgpt , dall-e , elicit , gemini , github copilot , llama , research rabbit This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 Generic License .
====================================================================================================
Just a moment... Enable JavaScript and cookies to continue
====================================================================================================
Artificial Intelligence - Harvard University Skip to main content Harvard University 1 site notification Learn about our lawsuits to protect our students and researchers Search Search Quick Links A to Z index Menu Academics Academics Academics Learning at Harvard can happen for every type of learner, at any phase of life. Degree programs Academics Degree programs Browse all of our undergraduate concentrations and graduate degrees. Undergraduate Degrees Graduate Degrees Other Professional and Lifelong Learning Harvard Online Harvard Schools Academics Visit each School for information on admissions and financial aid. Explore more Harvard College Harvard Business School Harvard Division of Continuing Education Harvard Divinity School Harvard Faculty of Arts and Sciences Harvard Kenneth C. Griffin Graduate School of Arts and Sciences Harvard Graduate School of Design Harvard Graduate School of Education Harvard John A. Paulson School of Engineering and Applied Sciences Harvard Kennedy School Harvard Law School Harvard Medical School Harvard Radcliffe Institute Harvard School of Dental Medicine Harvard T.H. Chan School of Public Health Campus Campus Harvard's Campus Get tickets to our next game, hours and locations for our libraries and museums, and information about your next career move. Libraries Campus Explore our libraries Arnold Arboretum Horticultural Library Baker Library and Special Collections Biblioteca Berenson Botany Libraries Cabot Science Library Countway Library Dumbarton Oaks Research Library Ernst Mayr Library Fine Arts Library Frances Loeb Library Fung Library Gutman Library Harvard Divinity School Library Harvard Film Archive Harvard Law School Library Harvard Map Collection Harvard University Archives Harvard-Yenching Library HKS Library and Knowledge Services Houghton Library Lamont Library Loeb Music Library Robbins Library of Philosophy Schlesinger Library on the History of Women in America Tozzer Library Widener Library Woodberry Poetry Room Museums Campus Explore our museums The Arnold Arboretum Carpenter Center for the Visual Arts Collection of Historical Scientific Instruments Graduate School of Design Exhibitions Harvard Art Museums Harvard Forest Harvard Museum of Natural History The Harvard Museum of the Ancient Near East Harvard Museums of Science and Culture Harvard University Herbaria Mineralogical and Geological Museum Museum of Comparative Zoology The Peabody Museum of Archaeology and Ethnology Warren Anatomical Museum Athletics Work at Harvard Events Commencement In Focus In Focus In Focus Explore a curated examination of Harvard's research, scholarly work, and community. Recent topics include: Ideas to Enterprise In Focus Ideas to Enterprise Across Harvard’s campus, our students turn ideas into ventures that solve problems and create value. Venture in What's inside How innovation moves from lab to market The 2025 Harvard President’s Innovation Challenge winners Commencement 2025 In Focus Celebrating the Class of 2025 Join the celebration for Harvard University’s 374th Commencement and explore the amazing scholarship of our graduates. Explore the ceremony What's inside? Meet the class of 2025 Abraham Verghese is the 2025 Commencement speaker Earth Day In Focus Earth Day The Harvard community is rising to the challenge of protecting our planet. Across all of our Schools we are advancing research to create real-world climate solutions. Welcome to Earth What's inside? How can we protect plants from future threats? What are the long-term effects of wildfires? Visit Visit Visit Harvard Ideas and assistance for your trip to our campus. Tours Maps and directions Tour Providers About About About Harvard Learn how Harvard is structured, explore our long history, and discover our extended community. History of Harvard About History of Harvard Harvard is perhaps best-known because of its enduring history of innovation in education. But even die-hard Harvard buffs are not likely to know all of these Harvard firsts and historical snippets. Learn more about Harvard's history History timeline Nobel Laureates Honorary Degrees Harvard shields Leadership and governance About Learn about our Leadership President Officers and Deans Harvard Corporation Board of Overseers University Professorships Endowment Belonging Harvard in the Community Harvard in the World News News The Harvard Gazette Official news from Harvard University about science, medicine, art, campus life, University issues, and broader national and global concerns. Trending News Stories News Read more news Good genes are nice, but joy is better Harvard study, almost 80 years old, has proved that embracing community helps us live longer, and be happier Reading skills — and struggles — manifest earlier than thought New finding underscores need to intervene before kids start school, say researchers How market reactions to recent U.S. tariffs hint at start of global shift for nation Economist updates literature on optimal American import-tax rate in world of interconnected trade, investment Sign up for the Daily Gazette Navigation Quick Links A to Z index Find a person Events Media Relations Alumni Give Now Emergency Harvard University Close Artificial Intelligence In Focus Artificial Intelligence The Enhanced Body Veterans Food Artificial Intelligence From health care to education, policy to art, artificial intelligence is rapidly changing our world and our daily lives. Are we ready? Explore the AI episode of “Harvard Thinking” This image was created using generative AI The big questions Explore more lingering questions about artificial intelligence throughout the page. Is AI coming for your job? Harvard Business School faculty members discuss how artificial intelligence could reshape how work gets done. How should artificial intelligence be regulated? A Harvard Kennedy School expert explores how regulation and other tools can ensure that AI tools work for everyone. Is AI-created art actually art? Harvard writers, animators, architects, musicians, and mixed-media artists explain whether they see AI as a threat, collaborator, or tool. The futurists Find more AI researchers at Harvard Nikita Roy As a data scientist, journalist, and AI expert, Nikita launched the Newsroom Robots podcast as a space for the news industry to actively discuss AI. Learn more about AI in the newsroom Learn more about AI in the newsroom Kanaka Rajan Kanaka joins Harvard’s Kempner Institute, where she will research artificial intelligence and machine learning to better understand the enduring mysteries of the brain. Read more about the new faculty member Read more about the new faculty member Anant Agarwal Anant Agarwal, founder of the online learning platform edX, explains that educators must learn to incorporate AI in their classrooms to properly prepare students for the future. Explore the podcast episode Explore the podcast episode Shira Zilberstein As a Ph.D. student in sociology, Shira explores the challenges to implementing AI in a way that improves access to quality healthcare while avoiding issues of privacy and bias. Learn more about machine learning in healthcare Learn more about machine learning in healthcare Can AI get an M.D.? From diagnosing diseases to predicting patient outcomes, new AI models could have a major impact on the quality and efficiency of healthcare. Learn more from Harvard Medical School Some of the most pressing questions in medicine can be advanced through the application of AI in the clinic.” Isaac Kohane Harvard Medical School Meet this biomedical informatics expert This image was created with generative AI The future of healthcare Harvard Medical School professor Jagmeet Singh’s new book explains how the practice of medicine will become increasingly virtual, aided by digital technologies like artificial intelligence, telehealth, and wearable devices. The future of healthcare AI is already changing dentistry AI is already changing dentistry Forecasting the next viral outbreak Forecasting the next viral outbreak AI offers harmful advice on eating disorders AI offers harmful advice on eating disorders These doctors aren’t sweating AI—yet These doctors aren’t sweating AI—yet Can a jack-of-all-trades AI reshape medicine? Can a jack-of-all-trades AI reshape medicine? Does AI have a place in schools? Harvard Graduate School of Education has collected advice for teachers, parents, guardians, and students on how AI can be a helpful part of the learning experience. Play with AI tools Don’t be afraid to experiment and “geek out” with the technology. Learn how AI actually works AI is trained using existing data from the internet , which leads to the potential problem of “garbage in, garbage out.” Use AI tools to spark the imagination If students can turn to AI language models for quick and easy answers then there is a problem with the lesson. Understand cheating with AI tools People who cheat would have cheated without AI, the tools are just making it easier. How can we future-proof the future? Researchers across Harvard are exploring how we can better understand artificial intelligence to ensure we can utilize its potential and avoid harm. Learn about Harvard’s secure AI sandbox Understanding how intelligence works Working to advance the understanding of the nature of intelligence, the Kempner Institute is bringing researchers across disciplines like computational theory, AI and machine learning, neuroscience, and cognitive science together to develop next generation AI systems. Learn more about the Kempner Institute Empowering more users During her Radcliffe fellowship, Fernanda Viégas is exploring new modes of human/AI interaction to help drive improvements in lay user agency and control of AI systems. Explore the Radcliffe video Explore the Radcliffe video Creating technical oversight New research and collaboration at the Berkman Klein Center is leading the way to developing effective mechanisms for accountable technical oversight. Read how to regulate tools like ChatGPT Read how to regulate tools like ChatGPT Ensuring responsible use Given how regulation lags technological capabilities and how quickly the AI landscape is changing, the burden of ensuring that these tools are used safely and ethically will often fall to the individual and companies. Read more from Harvard Business Review Read more from Harvard Business Review You may also like Related In Focus topics Gadgets Quantum Everything The Accessible World Security & Brand Report Copyright Infringement Report Security Issue Trademark Notice Website Accessibility Digital Accessibility Privacy statement Get In Touch Contact Harvard Maps & Directions Jobs Copyright © 2025 The President and Fellows of Harvard College Instagram TikTok LinkedIn Facebook YouTube
====================================================================================================
Artificial Intelligence - Our World in Data Our World in Data Browse by topic Data Insights Resources About Subscribe Donate Gdoc / Admin Artificial Intelligence By: Charlie Giattino , Edouard Mathieu , Veronika Samborska , and Max Roser Introduction Key Insights Research & Writing Charts Endnotes Cite This Work Reuse This Work Artificial intelligence (AI) systems already greatly impact our lives — they increasingly shape what we see, believe, and do. Based on the steady advances in AI technology and the significant recent increases in investment, we should expect AI technology to become even more powerful and impactful in the following years and decades. It is easy to underestimate how much the world can change within a lifetime, so it is worth taking seriously what those who work on AI expect for the future. Many AI experts believe there is a real chance that human-level artificial intelligence will be developed within the following decades, and some think it will exist much sooner. How such powerful AI systems are built and used will be very important for the future of our world and our own lives. All technologies have positive and negative consequences, but with AI, the range of these consequences is extraordinarily large: the technology has immense potential for good. Still, it comes with significant downsides and high risks. A technology that has such an enormous impact needs to be of central interest to people across our entire society. But currently, the question of how this technology will get developed and used is left to a small group of entrepreneurs and engineers. With our publications on artificial intelligence, we want to help change this status quo and support a broader societal engagement. On this page, you will find key insights, articles, and charts of AI-related metrics that let you monitor what is happening and where we might be heading. We hope that this work will be helpful for the growing and necessary public conversation on AI. Related topics Technological Change Research and Development Economic Growth Key Insights on Artificial Intelligence AI systems perform better than humans in language and image recognition in some tests AI systems can generate increasingly better images and text The last decades saw a continuous exponential increase in the computation used to train AI As training computation increased, large language models have become much more powerful AI made profound advances with few resources – now investments have increased substantially AI hardware production, especially CPUs and GPUs, is concentrated in a few key countries AI systems perform better than humans in language and image recognition in some tests The language and image recognition capabilities of artificial intelligence (AI) systems have developed rapidly. This chart zooms into the last two decades of AI development. The plotted data stems from several tests in which human and AI performance were evaluated in different domains, including handwriting recognition, speech recognition, image recognition, reading comprehension, language understanding, and predictive reasoning. Within each domain, the initial performance of the AI is set to –100. Human performance is used as a baseline, set to zero. When the AI’s performance crosses the zero line, it scored more points than humans. Just 10 years ago, no machine could reliably provide language or image recognition at a human level. However, AI systems have become much more capable and are now beating humans in these domains, at least in some tests. What you should know about this data This chart relies on data published by Kiela et al. in Dynabench: Rethinking Benchmarking in NLP (2021) and Plotting Progress in AI (2023). They provide detailed information on the benchmarks used to evaluate AI systems. The chart shows that the speed at which these AI technologies developed increased over time. Systems for which development was started early – handwriting and speech recognition – took more than a decade to approach human-level performance, while more recent AI developments led to systems that overtook humans in only a few years. However, one should not overstate this point. To some extent, this is dependent on when the researchers started to compare machine and human performance. One could have started evaluating the system for language understanding much earlier, and its development would appear much slower in this presentation of the data. It is important to remember that while these are remarkable achievements and show very rapid gains, they are the results of specific benchmarking tests. Outside of tests, AI models can fail in surprising ways and do not reliably achieve performance comparable to human capabilities. AI systems can generate increasingly better images and text This series of nine images shows how these have developed over just the last nine years. None of the people in these images exist; all were generated by an AI system. This is one of the critical evolutions of AI systems in recent years: not only do they perform well on recognition tasks, but they can also generate new images and text with remarkable proficiency. Even more importantly, since 2021, the highest-performing AI systems – such as DALL·E or MidJourney – can generate high-quality, faithful images based on complex textual descriptions. The ninth image in the bottom right shows that even the most challenging prompts – such as “A Pomeranian is sitting on the King’s throne wearing a crown. Two tiger soldiers are standing next to the throne” – are turned into photorealistic images within seconds. A key takeaway from this overview is the speed at which this change happened. The first image is just eight years older than the last. In the coming years, AI systems’ ability to easily generate vast amounts of high-quality text and images could be great – if it helps us write emails faster or create beautiful illustrations – or harmful – if it enables phishing and misinformation, and sparks incidents and controversies . Download image The last decades saw a continuous exponential increase in the computation used to train AI Current AI systems result from decades of steady advances in this technology. Each small circle on this chart represents one AI system. The circle’s position on the horizontal axis indicates when the AI system was made public, and its position on the vertical axis shows the amount of computation used to train it. It’s shown on a logarithmic scale. Training computation is measured in total floating point operations, or “FLOP” for short. One FLOP is equivalent to one addition, subtraction, multiplication, or division of two decimal numbers. All AI systems shown on this chart rely on machine learning to be trained, and in these systems, training computation is one of the three fundamental factors that drive the system's capabilities. Other critical factors are the algorithms, the input data , and the parameters used during training. The chart shows that over the last decade, the amount of computation used to train the largest AI systems has increased exponentially. More recently, the pace of this change has increased. We discuss this data in more detail in our article on the history of artificial intelligence . As training computation increased, large language models have become much more powerful The recent evolution of AI, particularly large language models, is closely tied to the surge in computational power. Each dot on this chart represents a distinct language model. The horizontal axis shows the training computation used (on a logarithmic scale), measured in total floating point operations (“FLOP”). The vertical axis indicates the model's performance on the Massive Multitask Language Understanding (MMLU) benchmark, an extensive knowledge test composed of thousands of multiple-choice questions across 57 diverse subjects, from science to history. As training computation has risen, so has performance on these knowledge tests. OpenAI's GPT-4, released in 2023, achieved an 86% accuracy on the MMLU benchmark. This far exceeds the 34.5% accuracy achieved by non-expert humans, and comes close to the 89.8% accuracy estimated for hypothetical human experts 1 who excel across all 57 subjects covered in the test. 2 AI made profound advances with few resources – now investments have increased substantially AI technology has become much more powerful over the past few decades. In recent years, it has found applications in many different domains. A lot of this was achieved with only small investments. But this has increased dramatically in recent years. Investments in 2021 were about 30 times larger than a decade earlier. Given how rapidly AI developed in the past – despite its limited resources – we might expect AI technology to become much more powerful in the coming decades, now that the resources dedicated to its development have increased so substantially. AI hardware production, especially CPUs and GPUs, is concentrated in a few key countries The machines that power AI systems rely heavily on specific hardware. These include central processing units (CPUs) and graphics processing units (GPUs), which allow them to analyze and process vast amounts of information. More than 90% of these chips are designed and assembled in only a handful of countries: the United States, Taiwan, China, South Korea, and Japan. While reporting on AI tends to focus on software and algorithmic improvements, a few countries could, therefore, dictate the direction and evolution of AI technologies through their influence on hardware. Research & Writing Artificial intelligence is transforming our world — it is on all of us to make sure that it goes well How AI gets built is currently decided by a small group of technologists. As this technology is transforming our lives, it should be in all of our interest to become informed and engaged. Max Roser The brief history of artificial intelligence: The world has changed fast – what might be next? Despite their brief history, computers and AI have fundamentally changed what we see, what we know, and what we do. Little is as important for the future of the world, and our own lives, as how this history continues. Max Roser Scaling up: how increasing inputs has made artificial intelligence more capable The path to recent advanced AI systems has been more about building larger systems than making scientific breakthroughs. Veronika Samborska More Articles on Artificial Intelligence Artificial intelligence has advanced despite having few resources dedicated to its development – now investments have increased substantially Max Roser AI timelines: What do experts in artificial intelligence expect for the future? Max Roser Technology over the long run: zoom out to see how dramatically the world can change within a lifetime Max Roser Key Charts on Artificial Intelligence See all charts on this topic Annual global corporate investment in artificial intelligence, by type Annual granted patents related to artificial intelligence, by industry Annual private investment in artificial intelligence NetBase Quid Artificial intelligence: Performance on knowledge tests vs. training computation Computation used to train notable artificial intelligence systems, by domain Cumulative number of large-scale AI models by domain since 2017 Cumulative number of large-scale AI systems by country since 2017 Exponential growth of computation in the training of notable AI systems Exponential growth of datapoints used to train notable AI systems Exponential growth of parameters in notable AI systems GPU computational performance per dollar Hardware and energy cost to train notable AI systems Highest chess rating ever achieved by computers Market share for logic chip production, by manufacturing stage Number of large-scale AI systems released per year Test scores of AI systems on various capabilities relative to human performance Top performing AI systems in coding, math, and language-based knowledge tests Affiliation of research teams building notable AI systems, by year of publication Annual industrial robots installed in top five countries Annual patent applications related to AI per million people Annual patent applications related to AI, by status Annual patent applications related to artificial intelligence Annual private investment in artificial intelligence CSET Annual private investment in artificial intelligence, by focus area NetBase Quid Annual professional service robots installed globally, by application area Annual scholarly publications on artificial intelligence Computation used to train notable AI systems, by affiliation of researchers Cumulative AI-related bills passed into law since 2016, as of 2024 Datapoints used to train notable artificial intelligence systems Domain of notable artificial intelligence systems, by year of publication Global annual number of reported artificial intelligence incidents and controversies Global investment in generative AI Global views about AI's impact on society in the next 20 years, by demographic group Global views about the safety of riding in a self-driving car, by demographic group How worried are Americans about their work being automated? ImageNet: Top-performing AI systems in labeling images Industrial robots: Annual installations and total in operation Newly-funded artificial intelligence companies Parameters in notable artificial intelligence systems Scholarly publications on artificial intelligence per million people Share of artificial intelligence jobs among all job postings Share of companies using artificial intelligence technology Training computation vs. parameters in notable AI systems, by domain Training computation vs. parameters in notable AI systems, by researcher affiliation Views about AI's impact on society in the next 20 years Views about the safety of riding in a self-driving car Views of Americans about robot vs. human intelligence Annual attendance at major artificial intelligence conferences Protein folding prediction accuracy Chart 1 of 49 Endnotes We write “hypothetical” because no single person could perform this well across such varied tests. The authors based their analysis on expert performance on a subset of the tests for which there is human performance data – with “experts” considered to have the 95th percentile scores – and imagined a hypothetical person who would perform at this very high level across all tasks. Hendrycks, Dan, et al. "Measuring massive multitask language understanding." arXiv preprint arXiv:2009.03300 (2020). https://arxiv.org/abs/2009.03300 Cite this work Our articles and data visualizations rely on work from many different people and organizations. When citing this topic page, please also cite the underlying data sources. This topic page can be cited as: Charlie Giattino, Edouard Mathieu, Veronika Samborska, and Max Roser (2023) - “Artificial Intelligence” Published online at OurWorldinData.org. Retrieved from: 'https://ourworldindata.org/artificial-intelligence' [Online Resource] BibTeX citation @article{owid-artificial-intelligence, author = {Charlie Giattino and Edouard Mathieu and Veronika Samborska and Max Roser}, title = {Artificial Intelligence}, journal = {Our World in Data}, year = {2023}, note = {https://ourworldindata.org/artificial-intelligence} } Reuse this work freely All visualizations, data, and code produced by Our World in Data are completely open access under the Creative Commons BY license . You have the permission to use, distribute, and reproduce these in any medium, provided the source and authors are credited. The data produced by third parties and made available by Our World in Data is subject to the license terms from the original third-party authors. We will always indicate the original source of the data in our documentation, so you should always check the license of any such third-party data before use and redistribution. All of our charts can be embedded in any site. Our World in Data is free and accessible for everyone. Help us do this work by making a donation. Donate now Our World in Data is a project of Global Change Data Lab , a nonprofit based in the UK (Reg. Charity No. 1186433). Our charts, articles, and data are licensed under CC BY , unless stated otherwise. Tools and software we develop are open source under the MIT license . Third-party materials, including some charts and data, are subject to third-party licenses. See our FAQs for more details. Explore Topics Data Insights Resources Latest Articles SDG Tracker Teaching with OWID About About Us Organization Funding Team Jobs FAQs RSS Feeds Research & Writing Data Insights Follow us Privacy policy Legal disclaimer Grapher license
====================================================================================================
What is AI (artificial intelligence)? | Live Science Skip to main content Open menu Close menu Live Science Live Science Search Search Live Science Sign in View Profile Sign out RSS Sign up to our newsletter Newsletter Space Health Planet Earth Animals Archaeology Physics & Math Technology Human Behavior Chemistry More Science news Opinion Life's Little Mysteries Science quizzes About us Newsletters Follow us Story archive Trending 'Spiderwebs' on Mars Salmon-hat wearing orcas massage with kelp Mystery of Queen Hapshepsut's statues Vera C. Rubin Observatory 1st pictures Earth from space Recommended reading Artificial Intelligence What is artificial superintelligence (ASI)? Artificial Intelligence AI 'hallucinates' constantly, but there's a solution Artificial Intelligence Scientists discover major differences in how humans and AI 'think' — and the implications could be significant Artificial Intelligence New study claims AI 'understands' emotion better than us Artificial Intelligence AI can handle tasks twice as complex every few months Artificial Intelligence What is the Turing test? Artificial Intelligence AI is just as overconfident and biased as humans can be, study shows Artificial Intelligence What is artificial intelligence (AI)? References By Edd Gent published 14 April 2024 This exciting field of computer science focuses on technologies that mimic human intelligence — with AI systems becoming way more prevalent in recent years. When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works . (Image credit: BlackJack3D via Getty Images) Artificial intelligence (AI) refers to any technology exhibiting some facets of human intelligence, and it has been a prominent field in computer science for decades. AI tasks can include anything from picking out objects in a visual scene to knowing how to frame a sentence, or even predicting stock price movements. Scientists have been trying to build AI since the dawn of the computing era . The leading approach for much of the last century involved creating large databases of facts and rules and then getting logic-based computer programs to draw on these to make decisions. But this century has seen a shift, with new approaches that get computers to learn their own facts and rules by analyzing data. This has led to major advances in the field. Over the past decade, machines have exhibited seemingly "superhuman" capabilities in everything from spotting breast cancer in medical images , to playing the devilishly tricky board games Chess and Go — and even predicting the structure of proteins . You may like What is artificial superintelligence (ASI)? AI 'hallucinates' constantly, but there's a solution Scientists discover major differences in how humans and AI 'think' — and the implications could be significant Since the large language model (LLM) chatbot ChatGPT burst onto the scene late in 2022, there has also been a growing consensus that we could be on the cusp of replicating more general intelligence similar to that seen in humans — known as artificial general intelligence (AGI). "It really cannot be overemphasized how pivotal a shift this has been for the field," said Sara Hooker, head of Cohere For AI, a non-profit research lab created by the AI company Cohere. How does AI work? While scientists can take many approaches to building AI systems, machine learning is the most widely used today. This involves getting a computer to analyze data to identify patterns that can then be used to make predictions. The learning process is governed by an algorithm — a sequence of instructions written by humans that tells the computer how to analyze data — and the output of this process is a statistical model encoding all the discovered patterns. This can then be fed with new data to generate predictions. Many kinds of machine learning algorithms exist, but neural networks are among the most widely used today. These are collections of machine learning algorithms loosely modeled on the human brain , and they learn by adjusting the strength of the connections between the network of "artificial neurons" as they trawl through their training data. This is the architecture that many of the most popular AI services today, like text and image generators, use. Most cutting-edge research today involves deep learning , which refers to using very large neural networks with many layers of artificial neurons. The idea has been around since the 1980s — but the massive data and computational requirements limited applications. Then in 2012, researchers discovered that specialized computer chips known as graphics processing units (GPUs) speed up deep learning. Deep learning has since been the gold standard in research. "Deep neural networks are kind of machine learning on steroids," Hooker said. "They're both the most computationally expensive models, but also typically big, powerful, and expressive" Not all neural networks are the same, however. Different configurations , or "architectures" as they're known, are suited to different tasks. Convolutional neural networks have patterns of connectivity inspired by the animal visual cortex and excel at visual tasks. Recurrent neural networks, which feature a form of internal memory, specialize in processing sequential data. The algorithms can also be trained differently depending on the application. The most common approach is called "supervised learning," and involves humans assigning labels to each piece of data to guide the pattern-learning process. For example, you would add the label "cat" to images of cats. In "unsupervised learning," the training data is unlabelled and the machine must work things out for itself. This requires a lot more data and can be hard to get working — but because the learning process isn't constrained by human preconceptions, it can lead to richer and more powerful models. Many of the recent breakthroughs in LLMs have used this approach. The last major training approach is "reinforcement learning," which lets an AI learn by trial and error. This is most commonly used to train game-playing AI systems or robots — including humanoid robots like Figure 01 , or these soccer-playing miniature robots — and involves repeatedly attempting a task and updating a set of internal rules in response to positive or negative feedback. This approach powered Google Deepmind 's ground-breaking AlphaGo model. What is generative AI? Despite deep learning scoring a string of major successes over the past decade, few have caught the public imagination in the same way as ChatGPT's uncannily human conversational capabilities. This is one of several generative AI systems that use deep learning and neural networks to generate an output based on a user's input — including text , images , audio and even video . Text generators like ChatGPT operate using a subset of AI known as "natural language processing" (NLP). The genesis of this breakthrough can be traced to a novel deep learning architecture introduced by Google scientists in 2017 called the "transformer." Transformer algorithms specialize in performing unsupervised learning on massive collections of sequential data — in particular, big chunks of written text. They're good at doing this because they can track relationships between distant data points much better than previous approaches, which allows them to better understand the context of what they're looking at. "What I say next hinges on what I said before — our language is connected in time," said Hooker. "That was one of the pivotal breakthroughs, this ability to actually see the words as a whole." LLMs learn by masking the next word in a sentence before trying to guess what it is based on what came before. The training data already contains the answer so the approach doesn't require any human labeling, making it possible to simply scrape reams of data from the internet and feed it into the algorithm. Transformers can also carry out multiple instances of this training game in parallel, which allows them to churn through data much faster. By training on such vast amounts of data, transformers can produce extremely sophisticated models of human language — hence the "large language model" moniker. They can also analyze and generate complex, long-form text very similar to the text that a human can generate. It's not just language that transformers have revolutionized. The same architecture can also be trained on text and image data in parallel, resulting in models like Stable Diffusion and DALL-E, that produce high-definition images from a simple written description. Transformers also played a central role in Google Deepmind's AlphaFold 2 model, which can generate protein structures from sequences of amino acids. This ability to produce original data, rather than simply analyzing existing data is why these models are known as "generative AI." Narrow AI vs artificial general intelligence (AGI): What's the difference? People have grown excited about LLMs due to the breadth of tasks they can perform. Most machine learning systems are trained to solve a particular problem — such as detecting faces in a video feed or translating from one language to another. These models are known as “narrow AI” because they can only tackle the specific task they were trained for. Most machine learning systems are trained to solve a particular problem —, such as detecting faces in a video feed or translating from one language to another —, to a superhuman level, in that they are much faster and perform better than a human could. But LLMs like ChatGPT represent a step-change in AI capabilities because a single model can carry out a wide range of tasks. They can answer questions about diverse topics, summarize documents, translate between languages and write code. This ability to generalize what they've learned to solve many different problems has led some to speculate LLMs could be a step toward AGI, including DeepMind scientists in a paper published last year. AGI refers to a hypothetical future AI capable of mastering any cognitive task a human can, reasoning abstractly about problems, and adapting to new situations without specific training. AI enthusiasts predict once AGI is achieved, technological progress will accelerate rapidly — an inflection point known as "the singularity" after which breakthroughs will be realized exponentially. There are also perceived existential risks , ranging from massive economic and labor market disruption to the potential for AI to discover new pathogens or weapons. But there is still debate as to whether LLMs will be a precursor to an AGI, or simply one architecture in a broader network or ecosystem of AI architectures that is needed for AGI. Some say LLMs are miles away from replicating human reasoning and cognitive capabilities. According to detractors, these models have simply memorized vast amounts of information , which they recombine in ways that give the false impression of deeper understanding; it means they are limited by training data and are not fundamentally different from other narrow AI tools. Nonetheless, it's certain LLMs represent a seismic shift in how scientists approach AI development, said Hooker. Rather than training models on specific tasks, cutting-edge research now takes these pre-trained, generally capable models and adapts them to specific use cases. This has led to them being referred to as "foundation models." "People are moving from very specialized models that only do one thing to a foundation model, which does everything," Hooker added. "They're the models on which everything is built." How is AI used in the real world? Technologies like machine learning are everywhere. AI-powered recommendation algorithms decide what you watch on Netflix or YouTube — while translation models make it possible to instantly convert a web page from a foreign language to your own. Your bank probably also uses AI models to detect any unusual activity on your account that might suggest fraud, and surveillance cameras and self-driving cars use computer vision models to identify people and objects from video feeds. But generative AI tools and services are starting to creep into the real world beyond novelty chatbots like ChatGPT. Most major AI developers now have a chatbot that can answer users' questions on various topics, analyze and summarize documents, and translate between languages. These models are also being integrated into search engines — like Gemini into Google Search — and companies are also building AI-powered digital assistants that help programmers write code, like Github Copilot . They can even be a productivity-boosting tool for people who use word processors or email clients. RELATED STORIES — MIT scientists have figured out how to make popular AI image generators 30 times faster — Scientists create AI models that can talk to each other and pass on skills with limited human input — Researchers gave AI an 'inner monologue' and it massively improved its performance Chatbot-style AI tools are the most commonly found generative AI service, but despite their impressive performance, LLMs are still far from perfect. They make statistical guesses about what words should follow a particular prompt. Although they often produce results that indicate understanding, they can also confidently generate plausible but wrong answers — known as " hallucinations ." While generative AI is becoming increasingly common, it's far from clear where or how these tools will prove most useful. And given how new the technology is, there's reason to be cautious about how quickly it is rolled out, Hooker said. "It's very unusual for something to be at the frontier of technical possibility, but at the same time, deployed widely," she added. "That brings its own risks and challenges." Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Edd Gent Social Links Navigation Live Science Contributor Edd Gent is a British freelance science writer now living in India. His main interests are the wackier fringes of computer science, engineering, bioscience and science policy. Edd has a Bachelor of Arts degree in Politics and International Relations and is an NCTJ qualified senior reporter. In his spare time he likes to go rock climbing and explore his newly adopted home. Read more What is artificial superintelligence (ASI)? AI 'hallucinates' constantly, but there's a solution Scientists discover major differences in how humans and AI 'think' — and the implications could be significant New study claims AI 'understands' emotion better than us AI can handle tasks twice as complex every few months What is the Turing test? Latest in Artificial Intelligence AI hallucinates more frequently the more advanced it gets. Is there any way of stopping it? Advanced AI reasoning models generate up to 50 times more carbon dioxide than common LLMs New study claims AI 'understands' emotion better than us Your devices feed AI assistants and harvest personal data even if they’re asleep. Here's how to know what you're sharing. Hurricanes and sandstorms can be forecast 5,000 times faster thanks to new Microsoft AI model Cutting-edge AI models from OpenAI and DeepSeek undergo 'complete collapse' when problems get too difficult, study reveals Latest in References The San Andreas Fault: Facts about the crack in California's crust that could unleash the 'Big One' HIV/AIDS: Facts about the viral infection that attacks the immune system The sun: Facts about the bright star at the center of the solar system Human evolution: Facts about the past 300,000 years of Homo sapiens Sleep: Facts about how and why we sleep Aliens: Facts about extraterrestrial life and how scientists are looking for it LATEST ARTICLES 1 'God-king' born from incest in ancient Ireland wasn't a god or a king, new study finds 2 Mysterious 'rogue' objects discovered by James Webb telescope may not actually exist, new simulations hint 3 40,000-year-old mammoth tusk boomerang is oldest in Europe — and possibly the world 4 James Webb telescope discovers its first planet — a Saturn-size 'shepherd' still glowing red hot from its formation 5 Fungus that may have caused 'King Tut's curse' shows promise in treating cancer Live Science is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site . About Us Contact Future's experts Terms and conditions Privacy policy Cookies policy Accessibility Statement Advertise with us Web notifications Careers Editorial standards How to pitch a story to us © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036. Close Please login or signup to comment Please wait... Login Sign Up
====================================================================================================
Artificial Intelligence Overview Home Whiteboard Online Compilers Practice Articles AI Assistant Jobs Tools Corporate Training Chapters Categories AI, ML, and Data Science Programming Languages Web Development Languages DevOps Databases Computer Science Subjects Python Technologies Software Testing Cyber Security All Categories Back Artificial Intelligence Machine Learning ML With Python Data Science Statistics NLP Neural Networks TensorFlow PyTorch Matplotlib NumPy Pandas SciPy Big Data Analytics See all Back Learn Python Learn Java Learn C++ Learn C Learn PHP Learn Go Learn Kotlin Learn R Learn ASP.Net Learn C#.Net Learn VB.Net Learn Scala Learn Swift Learn Perl Learn Ruby Learn Rust Learn Lua See all Back Learn HTML Learn CSS Learn JavaScript Learn jQuery ReactJs NodeJs Wordpress AngularJs Learn PHP Django Learn JSON Codeigniter TypeScript Learn Ajax Bootstrap Learn Sass AppML See all Back GIT AWS Docker Kubernetes Azure Gitlab Jira Gerrit Ansible Bugzilla Chef SaltStack OpenShift Puppet UNIX Linux Admin Ubuntu See all Back DBMS SQL PL/SQL MySQL TinyDB SQL Server MongoDB PostgreSQL SQLite Redis PHP MyAdmin MariaDB CouchDB DB2 See all Back Computer Fundamentals Operating System DBMS DSA Computer Networks Software Engineering Computer Graphics Data Mining Digital Marketing SEO Digital Circuits Discrete Mathematics Cryptography Cloud Computing Compiler Design Embedded Systems Microprocessors See all Back Python NumPy Pandas Matplotlib Django PyQt PyCharm Pillow OpenCV Seaborn ML with Python SciPy See all Back Software Testing Jira Selenium TestRail Postman Cucumber Cypress Watir Agile jMeter See all Back Blockchain Information Security Computer Security Internet Security Network Security Wireless Security See all Library Courses Certifications Login SQL HTML CSS Javascript Python Java C C++ PHP Scala C# Tailwind CSS Node.js MySQL MongoDB PL/SQL Swift Bootstrap R Machine Learning Blockchain Angular React Native Computer Fundamentals Compiler Design Operating System Data Structure and Algorithms Computer Network DBMS Excel Artificial Intelligence Tutorial AI - Home AI - Overview AI - History & Evolution AI - Types AI - Terminology AI - Tools & Frameworks AI - Applications AI - Real Life Examples AI - Ethics & Bias AI - Challenges Branches in AI AI - Research Areas AI - Machine Learning AI - Natural Language Processing AI - Computer Vision AI - Robotics AI - Fuzzy Logic Systems AI - Neural Networks AI - Evolutionary Computation AI - Swarm Intelligence AI - Cognitive Computing Intelligent Systems in AI AI - Intelligent Systems AI - Components of Intelligent Systems AI - Types of Intelligent Systems Agents & Environment AI - Agents and Environments Problem Solving in AI AI - Popular Search Algorithms AI - Constraint Satisfaction AI - Constraint Satisfaction Problem AI - Formal Representation of CSPs AI - Types of CSPs AI - Methods for Solving CSPs AI - Real-World Examples of CSPs Knowledge in AI AI - Knowledge Based Agent AI - Knowledge Representation AI - Knowledge Representation Techniques AI - Propositional Logic AI - Rules of Inference AI - First-order Logic AI - Inference Rules in First Order Logic AI - Knowledge Engineering in FOL AI - Unification in First Order Logic (FOL) AI - Resolution in First Order Logic (FOL) AI - Forward Chaining and backward chaining AI - Backward Chaining vs Forward Chaining Expert Systems in AI AI - Expert Systems AI - Applications of Expert Systems AI - Advantages & Limitations of Expert Systems AI - Applications AI - Predictive Analytics AI - Personalized Customer Experiences AI - Manufacturing Industry AI - Healthcare Breakthroughs AI - Decision Making AI - Business AI - Banking AI - Autonomous Vehicles AI - Automotive Industry AI - Data Analytics AI - Marketing Artificial Intelligence Resources Artificial Intelligence - Quick Guide Artificial Intelligence - Interview Questions & Answers AI - Useful Resources Artificial Intelligence - Discussion Selected Reading UPSC IAS Exams Notes Developer's Best Practices Questions and Answers Effective Resume Writing AI Based Resume Builder Personal AI Study Assistant Generate Coding Logic HR Interview Questions Computer Glossary Who is Who Artificial Intelligence - Overview Previous Quiz Next Since the invention of computers or machines, their capability to perform various tasks has continued to increase rapidly. Humans have achieved the power of computer systems in terms of their diverse working domains, their increasing speed, and reducing size with respect to time. A branch of computer science named Artificial Intelligence is to build machines or computers that are as intelligent as people. What is Artificial Intelligence? Artificial intelligence is the technology that allows systems to replicate human behavior and thoughts. At its core, AI uses algorithms to train datasets that will generate AI models that let computer systems perform tasks like recommending songs, googling route directions, or providing text translations betweentwo languages. A few examples of AI are ChatGPT , Google Translate, Tesla, Netflix, and many more. According to the father of artificial intelligence, John McCarthy, it is The science and engineering of making intelligent machines, especially intelligent computer programs.. History of AI Artificial Intelligence has evolved since its inception in the mid-20th century. Initially, AI focused on automating simple tasks, and with advancements in machine learning and deep learning, it made significant improvements in understanding and processing data. Today, AI influences various fields, including healthcare, finance, and automobiles. Some of the key milestones in the history of AI are − Year Milestone 1923 Karel apek play named Rossum's Universal Robots (RUR) opens in London, first use of the word "robot" in English. 1956 John McCarthy , a professor at Dartmouth College coined the term "Artificial Intelligence". 1966 Joseph Weizenbaum created ELIZA , that used natural language processing to make conversations with humans. 1997 Deep Blue was the first program to beat a human chess champion, Gray Kasparov. 2012 AlexNet is a convolution neural network (CNN) architecture that was designed by Alex Krizhevsky. 2020 OpenAI started beta testing GPT-3 , a model that uses deep learning to create code, content, and other creative tasks. Goals of AI The potential of AI is basically to mimic human skills and traits and apply them to machines. While the main objective of AI is to create a core technology that is able to allow computer systems to process intelligently and independently. Below are the essential goals of AI − To Create Expert Systems To Implement Human Intelligence in Machines To Develop Problem-Solving Ability To Allow Continuous Learning To Encourage Social Intelligence and Creativity What Contributes to AI? AI is a field that combines various scientific and technological disciplines, which include Computer Science, Biology, Psychology, Linguistics, Mathematics, and Engineering. The main objective of AI is to develop computer programs that can perform tasks with reasoning, learning, and solving problems similar to human intelligence. AI Programming vs. Traditional Coding Below is the difference between AI programming and traditional coding − AI Programming Traditional Coding Can deal with complex, undefined problems. Can handle only well-defined, predictable problems. Uses data-driven methods and algorithms. Relies on explicit logic and rules. Produces models that make predictions or decisions. Generates specific functional software Utilizes frameworks and libraries like TensorFlow , PyTorch . Commonly uses languages like Python , Java . Involves validation of model accuracy. Focuses on debugging and unit testing. Models learn patterns from data. Programs execute pre-defined instructions. What is an AI Technique? AI techniques refer to methods and algorithms that are used to create smart systems that perform tasks requiring human-like intelligence. Some of these techniques are Machine Learning , Natural Language Processing , Computer Vision and others. These AI techniques use the knowledge efficiently in such a way that − It should be perceivable by the people who provide it. It should be easily modifiable to correct errors. Elevate the speed of execution of the complex program it is equipped with. Applications of AI AI has been dominant in the following fields − Gaming − AI plays a crucial role in strategic games such as chess, poker, tic-tac-toe, etc., where machine can think of large number of possible positions based on heuristic knowledge. Natural Language Processing − It enables machines to interact with humans in natural language. Expert Systems − It is an AI based software that enables decision-making ability similar to a human expert. Computer Vision − These systems understand, interpret, and comprehend visual input on the computer. Speech Recognition − Some intelligent systems are capable of hearing and comprehending the language in terms of sentences and their meanings while a human talks to it. It can handle different accents, slang words, noise in the background, change in humans noise due to cold, etc. Handwriting Recognition − The handwriting recognition software reads the text written on paper by a pen or on screen by a stylus. It can recognize the shapes of the letters and convert it into editable text. Intelligent Robots − Robots are able to perform the tasks given by a human. They have sensors to detect physical data from the real world such as temperature, movement, and sound. They have efficient processors, and huge memory, to exhibit intelligence. In addition, they are capable of learning from their mistakes and they can adapt to new environment. Challenges in AI The main challenges in implementing AI includes − Data Quality and Accessibility − AI requires large, high-quality, and relevant datasets for effective learning. Technical Expertise − Implementing AI algorithms and models requires skilled professionals. Ethical and Legal Concerns − It is important to make sure that the AI systems are fair, unbiased, and don't harm anyone's safety. Integration − Integrating AI with existing systems can be complex. Cost − Developing and maintaining of AI infrastructure can be expensive. Future of AI As technology advances, we could witness greater integration of AI into our lives, and a more interactive relationship between humans and AI. Along with technology advancement is the need for ethical and privacy considerations including bias, privacy, and job displacement to help ensure that AI is beneficial to society as a whole. The four key trends that define the future of AI include − Rise of Multimodal Emergence of Agentic platforms for AI Deployment Optimization of AI's performance Democratize AI Access. Some of the other notable AI technologies that are going to shape various industries in the near future are rapid development of Generative AI and highlighting its transformative impact on various various industries. Print Page Previous Next Advertisements TOP TUTORIALS Python Tutorial Java Tutorial C++ Tutorial C Programming Tutorial C# Tutorial PHP Tutorial R Tutorial HTML Tutorial CSS Tutorial JavaScript Tutorial SQL Tutorial TRENDING TECHNOLOGIES Cloud Computing Tutorial Amazon Web Services Tutorial Microsoft Azure Tutorial Git Tutorial Ethical Hacking Tutorial Docker Tutorial Kubernetes Tutorial DSA Tutorial Spring Boot Tutorial SDLC Tutorial Unix Tutorial CERTIFICATIONS Business Analytics Certification Java & Spring Boot Advanced Certification Data Science Advanced Certification Cloud Computing And DevOps Advanced Certification In Business Analytics Artificial Intelligence And Machine Learning DevOps Certification Game Development Certification Front-End Developer Certification AWS Certification Training Python Programming Certification COMPILERS & EDITORS Online Java Compiler Online Python Compiler Online Go Compiler Online C Compiler Online C++ Compiler Online C# Compiler Online PHP Compiler Online MATLAB Compiler Online Bash Terminal Online SQL Compiler Online Html Editor ABOUT US OUR TEAM CAREERS JOBS CONTACT US TERMS OF USE PRIVACY POLICY REFUND POLICY COOKIES POLICY FAQ'S Tutorials Point is a leading Ed Tech company striving to provide the best learning material on technical and non-technical subjects. © Copyright 2025. All Rights Reserved.
====================================================================================================
Artificial intelligence - Simple English Wikipedia, the free encyclopedia Jump to content Main menu Main menu move to sidebar hide Getting around Main page Simple start Simple talk New changes Show any page Help Contact us About Wikipedia Special pages Search Search Appearance Give to Wikipedia Create account Log in Personal tools Give to Wikipedia Contribute Create account Log in Pages for logged out editors learn more Talk Contents move to sidebar hide Beginning 1 Origin of name 2 Laws 3 History 4 Uses 5 Domains 6 Types and classes 7 Controversies 8 Other information 9 Related pages 10 Books 11 References Toggle the table of contents Artificial intelligence 167 languages Afrikaans Alemannisch አማርኛ العربية Aragonés Արեւմտահայերէն অসমীয়া Asturianu Avañe'ẽ Azərbaycanca تۆرکجه বাংলা 閩南語 / Bân-lâm-gú Башҡортса Беларуская Беларуская (тарашкевіца) भोजपुरी Bikol Central Български Boarisch བོད་ཡིག Bosanski Brezhoneg Буряад Català Чӑвашла Cebuano Čeština Cymraeg Dansk الدارجة Deutsch Eesti Ελληνικά English Español Esperanto Estremeñu Euskara فارسی Fiji Hindi Français Furlan Gaeilge Gaelg Gàidhlig Galego 贛語 Gĩkũyũ गोंयची कोंकणी / Gõychi Konknni 한국어 Hausa Հայերեն हिन्दी Hrvatski Ido Igbo Ilokano Bahasa Indonesia Interlingua Interlingue IsiZulu Íslenska Italiano עברית Jawa ಕನ್ನಡ ქართული کٲشُر Қазақша Kiswahili Kreyòl ayisyen Kriyòl gwiyannen Kurdî Кыргызча ລາວ Latina Latviešu Lëtzebuergesch Lietuvių Ligure Limburgs La .lojban. Lombard Magyar Madhurâ Македонски Malagasy മലയാളം Malti मराठी მარგალური مصرى Bahasa Melayu Minangkabau Монгол မြန်မာဘာသာ Nederlands Nedersaksies नेपाली नेपाल भाषा 日本語 Nordfriisk Norsk bokmål Norsk nynorsk Occitan ଓଡ଼ିଆ Oʻzbekcha / ўзбекча ਪੰਜਾਬੀ پنجابی ပအိုဝ်ႏဘာႏသာႏ پښتو Patois ភាសាខ្មែរ Picard Piemontèis Plattdüütsch Polski Português Qaraqalpaqsha Qırımtatarca Reo tahiti Ripoarisch Română Runa Simi Русиньскый Русский Саха тыла Scots Shqip සිංහල سنڌي Slovenčina Slovenščina Ślůnski کوردی Српски / srpski Srpskohrvatski / српскохрватски Suomi Svenska Tagalog தமிழ் Татарча / tatarça తెలుగు ไทย Тоҷикӣ Türkçe Türkmençe Українська اردو ئۇيغۇرچە / Uyghurche Vèneto Tiếng Việt Võro Walon Winaray 吴语 ייִדיש 粵語 Zazaki Žemaitėška 中文 Betawi Kadazandusun Fɔ̀ngbè ꠍꠤꠟꠐꠤ ⵜⴰⵎⴰⵣⵉⵖⵜ ⵜⴰⵏⴰⵡⴰⵢⵜ Change links Page Talk English Read Change Change source View history Tools Tools move to sidebar hide Actions Read Change Change source View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Make a book Download as PDF Page for printing In other projects Wikimedia Commons Meta-Wiki Wikidata item Appearance move to sidebar hide From Simple English Wikipedia, the free encyclopedia Part of a series on Artificial intelligence (AI) Major goals Artificial general intelligence Intelligent agent Recursive self-improvement Planning Computer vision General game playing Knowledge reasoning Natural language processing Robotics AI safety Approaches Machine learning Symbolic Deep learning Bayesian networks Evolutionary algorithms Hybrid intelligent systems Systems integration Applications Bioinformatics Deepfake Earth sciences Finance Generative AI Art Audio Music Government Healthcare Mental health Industry Translation Military Physics Projects Philosophy Artificial consciousness Chinese room Friendly AI Control problem / Takeover Ethics Existential risk Turing test Uncanny valley History Timeline Progress AI winter AI boom Glossary Glossary v t e Artificial intelligence ( AI or A.I. ) is a computer program or a machine that is able to learn and mimic human cognition . [ 1 ] [ 2 ] Sometimes, AI is used to talk about neural networks or deep learning . Artificial intelligence is a system's ability to understand external data , to learn from that data, and to use what it has learned to achieve specific goals or tasks through adaptation . [ 3 ] Artificial intelligence is widely applied in speech recognition , image recognition , robotics , autonomous systems , natural language processing , machine translation , predictive analytics , medical diagnostics , fraud detection , and the control of physical processes . Origin of name [ change | change source ] John McCarthy came up with the name, "artificial intelligence" in 1956. Intelligence allows an organism to act in a meaningful way in its environment. It includes the ability to get sensory inputs, and to react to these. Laws [ change | change source ] The European Union made a law (2024's second quarter) about artificial intelligence . It is the world's first law that regulates AI. [ 4 ] Connecticut and Colorado tried to pass laws (in 2024) regarding use of AI. [ 5 ] History [ change | change source ] AI research started with a conference at Dartmouth College in 1956. It was a month-long brainstorming session many people who like AI came to. At the conference, they wrote programs which were able to beat humans at checkers or solving word problems. The Department of Defense started giving a lot of money to AI research, and labs were created all over the world. In a paper on AI, mathematician James Lighthill wrote " no aspect of the discipline has so far seen discoveries generated the huge influence that was previously anticipated In no part of the field have the discoveries made so far produced the major impact that was then promised." [1] . The governments of the US and UK decided to spend money on other projects which caused little new research to be done. This was known as an "AI winter." [ 6 ] In the 90s and early 2000s, AI became important again in data mining and medical diagnosis. This was possible because of faster computers and focusing on solving more specific problems. Deep Blue, a chess computer that became famous (1997) In 1997, the chess computer Deep Blue became the first computer program to beat chess world champion Garry Kasparov . In 2011, IBM Watson beat the top two Jeopardy! players Brad Rutter and Ken Jennings . In 2016, Google's AlphaGo beat top Go player Lee Sedol 4 out of 5 times. The idea is perhaps much older. Julien Offray de La Mettrie (1709-1751) was a materialist thinker of the Enlightenment . In his work of 1748, L'Homme Machine, he had the idea that both matter and life organized themselves. [ 7 ] He is seen as one of the precursors of Darwin's theory of evolution . [ 8 ] Today, one field of artificial intelligence, called strong artificial intelligence wants to build a machine that can think like a person. [ 9 ] However, weak artificial intelligence is about building a system that can support a human. One of the key problems is to make systems that can model wikt:uncertainity . Most of the time, this is done with probability theory and statistics . Uses [ change | change source ] Artificial intelligence is used in many different areas today. Healthcare (see Artificial intelligence in healthcare ) AI helps doctors diagnose diseases and find treatments for patients. Industry-specific tasks; AI applications are used to solve problems in a workplace , industry, or institutions . Finance : Banks use AI to find fraud and make trading decisions. Customer service : Many companies use AI chatbots to answer customer questions and provide support. Personal assistants : AI assistants like Siri and Alexa help people manage their daily tasks. Entertainment : AI is used in video games to create smart, responsive characters and stories that change in fun ways based on what the player does. AI is used to create videos now-a-days by using different models like Sora . Those subjects are part of Game artificial intelligence . Military ( Military artificial intelligence ) Generative AI (or Generative artificial intelligence ) Some software has become well-known, such as ChatGPT (a chatbot and virtual assistant ). Domains [ change | change source ] There are different domains of artificial intelligence. Pattern recognition like speech , writing, and handwriting Knowledge engineering like logic programming and inference engines Expert systems for question answering and Chatbots Machine learning Artificial neural networks and deep learning Computer vision Robotics General game playing Artificial life Types and classes [ change | change source ] Researchers Kaplan and Haenlein say there are three types of AI system: analytical, human-inspired, and humanized artificial intelligence. [ 3 ] Analytical A.I. has similarities with cognitive intelligence which tries to understand the world and make decisions based on that. Human-inspired A.I. which tries to be more "human" with cognitive intelligence with emotional intelligence . Humanized A.I. is able to understand human social activity and is able to be self aware [ 10 ] Controversies [ change | change source ] In 2025, a municipality in Norway made a report in regard to permanently closing down schools; The report used ghost source (or fictitious sources); Those sources were claimed to be the works of two (named) professors; The municipality admitted that the report was made [partly] by A.I.; The process of closing down schools, has stopped (as of March). [ 11 ] An official that was involved, resigned (or left her job) one month later. [ 12 ] (See Hallucination, artificial intelligence ) Other information [ change | change source ] Trivia sections are NOT encouraged under Wikipedia guidelines . Please improve this article by integrating relevant items and removing inappropriate ones. Researchers didn't know how difficult several issues were. They still couldn't offer computers things like emotions or common sense . Faster computers, deep learning, and more data have made AI popular throughout the world. [ 13 ] An great intelligent machine is flexible and perceives what is around it. It would use what it learns to make its chance of success at some goal better. [ 14 ] AI has been successful with decoding human speech , [ 1 ] playing games (like chess and Go ), self-driving cars , and understanding complex data. [ 15 ] Someday, AI researchers hope to create computer programs that can learn, solve problems, and think logically. [ 16 ] [ 17 ] So far, most AI programs only do what computers can do well like searching databases or doing calculations. AI is not able to sense and understand what is happening around itself because of problems with what computers can do. AI involves many different fields like computer science , mathematics , linguistics , psychology , neuroscience , and philosophy . Researchers hope to make a "general artificial intelligence" which can solve many problems instead of focusing on just one. Researchers are also trying to make creative and emotional AI which could create art. Alan Turing wrote in 1950 "I propose to consider the question 'can machines think'?" [ 18 ] He said the question should be changed from if a machine "thinks" to "whether or not it is possible for machinery to show intelligent behavior". [ 18 ] Alan Turing also created the Turing test . This is a very general test. If a human cannot tell if at the other end of the line, there is a machine or a human answering questions, the machine is intelligent. The authors of Artificial Intelligence: A Modern Approach agree with Turing that AI must be defined by "acting" and not "thinking". [ 19 ] But they don't think the test compares machines to people . " Aeronautical engineering texts do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons. ' " [ 20 ] AI founder John McCarthy agreed, writing that "Artificial intelligence is not, by definition, simulation of human intelligence". [ 21 ] [ 22 ] Computers can do some things like learning and problem solving , but not in the same way as people do. [ 1 ] Interestingly, advancements in AI have expanded its applications, including the use of Large language models (LLMs) to "humanize" AI-generated text. This reflects a growing interest in bridging the gap between machine outputs and human-like expression. [ 23 ] AI and machine learning technology is used in applications including: search engines , recommendation systems , virtual assistants , autonomous vehicles , automatic language translation , facial recognition , image labeling , advertising, and driving internet traffic . One interesting use of AI is in helping people with their personal relationships. For example, ChatGPT is a powerful AI tool that can create human-like text and assist in many communication tasks. [ 22 ] Optical character recognition is no longer thought of as an example of "artificial intelligence" since it's now commonly used. Related pages [ change | change source ] Data mining Information storage systems (or Computer data storage ) OpenAI (a company) Books [ change | change source ] Russell, Stuart J. ; Norvig, Peter. (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0134610993 . LCCN 20190474 . Rich, Elaine ; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0070087705 . References [ change | change source ] ↑ 1.0 1.1 1.2 Russell, Stuart J. & Norvig, Peter 2003. Artificial intelligence: a modern approach . 2nd ed, Upper Saddle River, New Jersey: Prentice Hall. ISBN 0-13-790395-2 ↑ "Andreas Kaplan, Artificial Intelligence, Business and Civilization: Our Fate Made in Machines, Routledge, 2022" . ↑ 3.0 3.1 Kaplan, Andreas; Haenlein, Michael (January 2019). "Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence" . Business Horizons . 62 (1): 15– 25. doi : 10.1016/j.bushor.2018.08.004 . ISSN 0007-6813 . S2CID 158433736 . ↑ https://sciencebusiness.net/news/worlds-first-artificial-intelligence-law-moves-closer-passage-european-parliament ↑ "Two unlikely states are leading the charge on regulating AI" . politico.com . Retrieved 26 June 2025 . ↑ Bolat, Sarkan. "AI Course" . Retrieved 16 November 2021 . ↑ La Mettrie: Réflexions philosophiques sur l’origine des animaux , 1749 (anonym) ↑ Michel Bottolier: Hommage : De La Mettrie à Darwin Volltext , 11. September 2009 auf Libres Penseurs de France ↑ Nils J. Nilsson: The Quest for Artificial Intelligence. A History of Ideas and Achievements . Cambridge University Press, New York 2009. ↑ "Artificial Intelligence: More Than a Natural Intelligence?" . 16 November 2019. ↑ https://www.nettavisen.no/nyheter/ki-skandale-i-tromso-kommune-ikke-hyggelig-a-bli-tatt-med-buksa-nede/s/5-95-2358224 . Retrieved 27 March 2025 ↑ https://www.nrk.no/tromsogfinnmark/kari-henriksen-trekker-seg-etter-behandlingen-av-ny-barnehage--og-skolestruktur-i-tromso-1.17397149 . Retrieved 2025-04-28 ↑ Kaplan, Andreas; Haenlein, Michael (2020). "Rulers of the world, unite! The challenges and opportunities of artificial intelligence" . Business Horizons . 63 : 37– 50. doi : 10.1016/j.bushor.2019.09.003 . S2CID 211456730 . ↑ Hutter, Marcus 2005. Universal artificial intelligence . Berlin: Springer. ISBN 978-3-540-22139-5 ↑ Nilsson, Nils 1998. Artificial intelligence: a new synthesis . Morgan Kaufmann. ISBN 978-1-55860-467-4 ↑ Kurzweil, Ray 1999. The age of spiritual machines . Penguin Books. ISBN 0-670-88217-8 . ↑ Kurzweil, Ray 2005. The singularity is near . Viking Press ↑ 18.0 18.1 Turing (1950) , p. 1. sfnp error: no target: CITEREFTuring1950 ( help ) ↑ Russell & Norvig (2021) , chpt. 2. ↑ Russell & Norvig (2021) , p. 3. ↑ Maker (2006) . sfnp error: no target: CITEREFMaker2006 ( help ) ↑ 22.0 22.1 Verified Vibe (8 January 2025), 2025 AI Predictions: Innovation, Cybersecurity & the Future of Tech , retrieved 8 January 2025 ↑ "How to humanize AI content" . Rephrasy . Retrieved 29 December 2024 . v t e Artificial intelligence Concepts Parameter Hyperparameter Loss functions Regression Bias–variance tradeoff Double descent Overfitting Clustering Gradient descent SGD Quasi-Newton method Conjugate gradient method Backpropagation Attention Convolution Normalization Batchnorm Activation Softmax Sigmoid Rectifier Gating Weight initialization Regularization Datasets Augmentation Reinforcement learning Q-learning SARSA Imitation Diffusion Autoregression Adversary Hallucination /Hallucination Applications Machine learning In-context learning Artificial neural network Deep learning Language model Large language model NMT Artificial general intelligence Implementations Audio–visual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis ElevenLabs Speech recognition Facial recognition AlphaFold Text-to-image models Latent diffusion model DALL-E Flux Ideogram Midjourney Stable Diffusion Text-to-video models Sora Dream Machine VideoPoet Whisper Text Word2vec Seq2seq GloVe BERT T5 Llama Chinchilla AI PaLM GPT 1 J 2 3 ChatGPT 4 4o o1 Claude Gemini Grok LaMDA BLOOM Project Debater IBM Watson IBM Watsonx Granite PanGu-Σ Decisional AlphaGo AlphaZero OpenAI Five Self-driving car MuZero Action selection AutoGPT Robot control People Alan Turing Claude Shannon Allen Newell Herbert A. Simon Frank Rosenblatt Marvin Minsky John McCarthy Nathaniel Rochester Seymour Papert Joseph Weizenbaum Bernard Widrow Paul Werbos Yoshua Bengio Alex Graves Ian Goodfellow Stephen Grossberg Demis Hassabis Geoffrey Hinton Yann LeCun Fei-Fei Li Andrew Ng Jürgen Schmidhuber David Silver Ilya Sutskever Organizations Anthropic DeepMind DeepSeek EleutherAI Hugging Face Kuaishou Meta AI Mila MiniMax Mistral AI MIT CSAIL OpenAI Runway xAI Architectures Neural Turing machine Differentiable neural computer Transformer Vision transformer (ViT) Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network (CNN) Residual neural network (RNN) Highway network Mamba Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network (GNN) v t e Existential risk from artificial intelligence Concepts Consequentialism Technological singularity AGI AI alignment AI capability control AI safety AI takeover Effective accelerationism Ethics of artificial intelligence Existential risk from artificial general intelligence Friendly artificial intelligence Instrumental convergence Intelligence explosion Longtermism Machine ethics Suffering risks Superintelligence Organizations OpenAI Alignment Research Center Center for AI Safety Center for Applied Rationality Center for Human-Compatible Artificial Intelligence Centre for the Study of Existential Risk EleutherAI Future of Humanity Institute Future of Life Institute Google DeepMind Humanity+ Institute for Ethics and Emerging Technologies Leverhulme Centre for the Future of Intelligence Machine Intelligence Research Institute People Scott Alexander Sam Altman Yoshua Bengio Nick Bostrom Paul Christiano Eric Drexler Sam Harris Stephen Hawking Dan Hendrycks Geoffrey Hinton Bill Joy Shane Legg Elon Musk Steve Omohundro Huw Price Martin Rees Stuart J. Russell Jaan Tallinn Max Tegmark Frank Wilczek Roman Yampolskiy Eliezer Yudkowsky Other Statement on AI risk of extinction Human Compatible Open letter on artificial intelligence (2015) Our Final Invention The Precipice Superintelligence: Paths, Dangers, Strategies Do You Trust This Computer? Artificial Intelligence Act v t e Computer science Hardware Printed circuit board Peripheral Integrated circuit Systems on Chip (SoCs) Very Large Scale Integration Energy consumption (Green computing) Electronic design automation Hardware acceleration Computer systems organization Computer architecture Embedded system Real-time computing Dependability Networks Network architecture Network protocol Network components Network scheduler Network performance evaluation Network service Software organization Interpreter Middleware Virtual machine Operating system Software quality Software notations and tools Programming paradigm Programming language Compiler Domain-specific language Modeling language Software framework Integrated development environment Software configuration management Software library Software repository Software development Control variable Software development process Requirements analysis Software design Software construction Software deployment Software engineering Software maintenance Programming team Open-source model Theory of computation Model of computation Formal language Automata theory Computability theory Computational complexity theory Logic Semantics Algorithms Algorithm design Analysis of algorithms Algorithmic efficiency Randomized algorithm Computational geometry Mathematics of computing Discrete mathematics Probability Statistics Mathematical software Information theory Mathematical analysis Numerical analysis Theoretical computer science Information systems Database management system Information storage systems Enterprise information system Social information systems Geographic information system Decision support system Process control system Multimedia information system Data mining Digital library Computing platform Digital marketing World Wide Web Information retrieval Security Cryptography Formal methods Security hacker Security services Intrusion detection system Hardware security Network security Information security Application security Human–computer interaction Interaction design Social computing Ubiquitous computing Visualization Accessibility Concurrency Concurrent computing Parallel computing Distributed computing Multithreading Multiprocessing Artificial intelligence Natural language processing Computer vision Search methodology Control method Knowledge representation and reasoning Automated planning and scheduling Philosophy of artificial intelligence Distributed artificial intelligence Machine learning Supervised learning Reinforcement learning Unsupervised learning Multi-task learning Cross-validation Graphics Animation Graphics processing unit Virtual reality Rendering Photograph manipulation Mixed reality Image compression Solid modeling Applied computing E-commerce Computational chemistry Computational biology Digital art Video games Word processing Quantum Computing Enterprise software Computational mathematics Computational physics Computational social science Computational engineering Differentiable computing Computational healthcare Electronic publishing Cyberwarfare Electronic voting Operations research Educational technology Document management v t e Differentiable computing Concepts Clustering Regression Backpropagation Autoregression Gradient descent SGD Overfitting Hallucination Adversary Attention Convolution Loss functions Batchnorm Activation Softmax Sigmoid Rectifier Regularization Datasets Augmentation Diffusion Differentiable function Differentiable programming Information geometry Statistical manifold Automatic differentiation Neuromorphic engineering Pattern recognition Tensor calculus Computational learning theory Inductive bias Applications Machine learning In-context learning Artificial neural network Deep learning Scientific computing Artificial Intelligence Language model Large language model Hardware IPU TPU VPU Memristor SpiNNaker Software libraries TensorFlow PyTorch Keras Theano JAX Flux.jl MindSpore Implementations Audio–visual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis Speech recognition Facial recognition AlphaFold Text-to-image models DALL-E Midjourney Stable Diffusion Text-to-video models Sora VideoPoet Whisper Verbal Word2vec Seq2seq BERT Gemini LaMDA Bard NMT Project Debater IBM Watson IBM Watsonx Granite GPT-1 GPT-2 GPT-3 GPT-4 ChatGPT GPT-J Chinchilla AI PaLM BLOOM LLaMA PanGu-Σ Decisional AlphaGo AlphaZero Q-learning SARSA OpenAI Five Self-driving car MuZero Action selection Auto-GPT Robot control People Yoshua Bengio Alex Graves Ian Goodfellow Stephen Grossberg Demis Hassabis Geoffrey Hinton Yann LeCun Fei-Fei Li Andrew Ng Jürgen Schmidhuber David Silver Ilya Sutskever Organizations Anthropic EleutherAI Google DeepMind Hugging Face OpenAI Meta AI Mila MIT CSAIL Huawei Architectures Neural Turing machine Differentiable neural computer Transformer Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network Residual neural network Mamba Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network v t e Emerging technologies Authority control : National Spain France BnF data Germany Israel United States Latvia Japan Czech Republic Retrieved from " https://simple.wikipedia.org/w/index.php?title=Artificial_intelligence&oldid=10356590 " Categories : Articles with trivia sections Artificial intelligence Hidden categories: Harv and Sfn no-target errors Use dmy dates from March 2025 Articles with BNE identifiers Articles with BNF identifiers Articles with BNFdata identifiers Articles with GND identifiers Articles with J9U identifiers Articles with LCCN identifiers Articles with LNB identifiers Articles with NDL identifiers Articles with NKC identifiers This page was last changed on 27 June 2025, at 02:01. Text is available under the Creative Commons Attribution-ShareAlike License and the GFDL ; additional terms may apply. See Terms of Use for details. Privacy policy About Wikipedia Disclaimers Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Artificial intelligence 167 languages Add topic
====================================================================================================
What is artificial intelligence? | Brookings Experts Events Research Programs Research & Commentary Newsletters For Media About Us Leadership Careers Our Commitments Our Finances Diversity, Equity, and Inclusion BI Press WashU at Brookings Donate Home U.S. Trade Policy U.S. Trade Policy U.S. Economy Banking & Finance Economic Indicators Federal Fiscal & Tax Policy Federal Reserve Labor & Unemployment Regulatory Policy Retirement Social Safety Net State & Local Finance U.S. Trade Policy Explore topic China’s transshipment of goods to the US China’s transshipment of goods to the US How a pivot on US tariffs could deliver a better outcome on trade How a pivot on US tariffs could deliver a better outcome on trade Can Trump bring manufacturing back to the US? Can Trump bring manufacturing back to the US? International Affairs International Affairs International Affairs Democracy, Conflict, & Governance Diplomacy & Multilateralism Foreign Politics & Elections Fragile States Geopolitics Humanitarian & Disaster Assistance Migrants, Refugees & Internally Displaced Persons Trafficking & Illicit Trade U.S. Foreign Policy Explore topic Beyond the NATO summit, key questions remain for European security Beyond the NATO summit, key questions remain for European security How can the president put soldiers on the streets of Los Angeles? How can the president put soldiers on the streets of Los Angeles? Privacy under siege: DOGE’s one big, beautiful database Privacy under siege: DOGE’s one big, beautiful database U.S. Government & Politics U.S. Government & Politics U.S. Government & Politics Campaigns & Elections Congress Courts & Law Government Reform Political Parties Political Polarization Presidency Public Opinion U.S. Democracy Explore topic How can the president put soldiers on the streets of Los Angeles? How can the president put soldiers on the streets of Los Angeles? The US Department of Education is far behind on producing key statistics The US Department of Education is far behind on producing key statistics Privacy under siege: DOGE’s one big, beautiful database Privacy under siege: DOGE’s one big, beautiful database Technology & Information Technology & Information Technology & Information Artificial Intelligence Cryptocurrency Cybersecurity Internet & Telecommunications Media & Journalism Privacy Social Media Space Exploration Technology Policy & Regulation Explore topic Privacy under siege: DOGE’s one big, beautiful database Privacy under siege: DOGE’s one big, beautiful database Should consumers and businesses use AI assistants? Should consumers and businesses use AI assistants? Attacks on research and development could hamper technological innovation Attacks on research and development could hamper technological innovation Race in Public Policy Race in Public Policy Society & Culture Children & Families Crime, Justice & Safety Demographics & Population Economic Security & Mobility Human Rights & Civil Liberties Immigrants & Immigration Race in Public Policy Religion & Society Social Equity & Inclusion Explore topic The impact of deportation policy changes on Latino immigrant communities The impact of deportation policy changes on Latino immigrant communities Introducing the Black Business Parity Dashboard from the Center for Community Uplift at Brookings Metro Introducing the Black Business Parity Dashboard from the Center for Community Uplift at Brookings Metro What if Black businesses were equitably represented in every metro area in America? What if Black businesses were equitably represented in every metro area in America? Topics Business & Workforce Cities & Communities Climate & Energy Defense & Security Education Global Economy & Development Health Care International Affairs Society & Culture Technology & Information U.S. Economy U.S. Government & Politics Regions Africa Asia & the Pacific Europe & Eurasia Latin America & the Caribbean Middle East & North Africa North America Search Home U.S. Trade Policy International Affairs U.S. Government & Politics Technology & Information Race in Public Policy All Topics All Regions Experts Events Research Programs About Us Research & Commentary Newsletters Careers For Media Search Home What is artificial intelligence? Contact Contact Jessica Harris [email protected] 202.238.3507 Share Share Bluesky Streamline Icon: https://streamlinehq.com Bluesky Search Sections Sections Contact Contact Jessica Harris [email protected] 202.238.3507 Share Share Bluesky Streamline Icon: https://streamlinehq.com Bluesky Subscribe to the Center for Technology Innovation Newsletter Sign Up Research What is artificial intelligence? Darrell M. West Darrell M. West Senior Fellow - Governance Studies , Center for Technology Innovation (CTI) , Center for Effective Public Management (CEPM) , Douglas Dillon Chair in Governmental Studies October 4, 2018 10 min read Bluesky Streamline Icon: https://streamlinehq.com Bluesky Print Sections Toggle section navigation Sections Contact Jessica Harris [email protected] 202.238.3507 Print A Blueprint for the Future of AI: 2018-2019 Read more from A Blueprint for the Future of AI: 2018-2019 More On Technology & Information Sub-Topics Artificial Intelligence Program Governance Studies Center Center for Technology Innovation (CTI) Project Artificial Intelligence and Emerging Technology Initiative Editor's note: This report is part of “ A Blueprint for the Future of AI ,” a series from the Brookings Institution that analyzes the new challenges and potential policy solutions introduced by artificial intelligence and other emerging technologies. Few concepts are as poorly understood as artificial intelligence. Opinion surveys show that even top business leaders lack a detailed sense of AI and that many ordinary people confuse it with super-powered robots or hyper-intelligent devices. Hollywood helps little in this regard by fusing robots and advanced software into self-replicating automatons such as the Terminator’s Skynet or the evil HAL seen in Arthur Clarke’s “2001: A Space Odyssey,” which goes rogue after humans plan to deactivate it. The lack of clarity around the term enables technology pessimists to warn AI will conquer humans, suppress individual freedom, and destroy personal privacy through a digital “1984.” Part of the problem is the lack of a uniformly agreed upon definition. Alan Turing generally is credited with the origin of the concept when he speculated in 1950 about “thinking machines” that could reason at the level of a human being. His well-known “ Turing Test ” specifies that computers need to complete reasoning puzzles as well as humans in order to be considered “thinking” in an autonomous manner. Turing was followed up a few years later by John McCarthy , who first used the term “artificial intelligence” to denote machines that could think autonomously. He described the threshold as “getting a computer to do things which, when done by people, are said to involve intelligence.” Since the 1950s, scientists have argued over what constitutes “thinking” and “intelligence,” and what is “fully autonomous” when it comes to hardware and software. Advanced computers such as the IBM Watson already have beaten humans at chess and are capable of instantly processing enormous amounts of information. The lack of clarity around the term enables technology pessimists to warn AI will conquer humans, suppress individual freedom, and destroy personal privacy through a digital “1984.” Today, AI generally is thought to refer to “machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment, and intention.” According to researchers Shubhendu and Vijay , these software systems “make decisions which normally require [a] human level of expertise” and help people anticipate problems or deal with issues as they come up. As argued by John Allen and myself in an April 2018 paper, such systems have three qualities that constitute the essence of artificial intelligence: intentionality, intelligence, and adaptability. In the remainder of this paper, I discuss these qualities and why it is important to make sure each accords with basic human values. Each of the AI features has the potential to move civilization forward in progressive ways. But without adequate safeguards or the incorporation of ethical considerations, the AI utopia can quickly turn into dystopia. Intentionality Artificial intelligence algorithms are designed to make decisions, often using real-time data. They are unlike passive machines that are capable only of mechanical or predetermined responses. Using sensors, digital data, or remote inputs, they combine information from a variety of different sources, analyze the material instantly, and act on the insights derived from those data. As such, they are designed by humans with intentionality and reach conclusions based on their instant analysis. An example from the transportation industry shows how this happens. Autonomous vehicles are equipped with LIDARS (light detection and ranging) and remote sensors that gather information from the vehicle’s surroundings. The LIDAR uses light from a radar to see objects in front of and around the vehicle and make instantaneous decisions regarding the presence of objects, distances, and whether the car is about to hit something. On-board computers combine this information with sensor data to determine whether there are any dangerous conditions, the vehicle needs to shift lanes, or it should slow or stop completely. All of that material has to be analyzed instantly to avoid crashes and keep the vehicle in the proper lane. Related Content How artificial intelligence is transforming the world Technology & Information How artificial intelligence is transforming the world Darrell M. West, John R. Allen April 24, 2018 How to improve cybersecurity for artificial intelligence Technology & Information How to improve cybersecurity for artificial intelligence Josephine Wolff June 9, 2020 How to improve technical expertise for judges in AI-related litigation Technology & Information How to improve technical expertise for judges in AI-related litigation Melissa Whitney November 7, 2019 With massive improvements in storage systems, processing speeds, and analytic techniques, these algorithms are capable of tremendous sophistication in analysis and decisionmaking. Financial algorithms can spot minute differentials in stock valuations and undertake market transactions that take advantage of that information. The same logic applies in environmental sustainability systems that use sensors to determine whether someone is in a room and automatically adjusts heating, cooling, and lighting based on that information. The goal is to conserve energy and use resources in an optimal manner. As long as these systems conform to important human values, there is little risk of AI going rogue or endangering human beings. Computers can be intentional while analyzing information in ways that augment humans or help them perform at a higher level. However, if the software is poorly designed or based on incomplete or biased information, it can endanger humanity or replicate past injustices. Intelligence AI often is undertaken in conjunction with machine learning and data analytics, and the resulting combination enables intelligent decisionmaking. Machine learning takes data and looks for underlying trends. If it spots something that is relevant for a practical problem, software designers can take that knowledge and use it with data analytics to understand specific issues. For example, there are AI systems for managing school enrollments . They compile information on neighborhood location, desired schools, substantive interests, and the like, and assign pupils to particular schools based on that material. As long as there is little contentiousness or disagreement regarding basic criteria, these systems work intelligently and effectively. Figuring out how to reconcile conflicting values is one of the most important challenges facing AI designers. It is vital that they write code and incorporate information that is unbiased and non-discriminatory. Failure to do that leads to AI algorithms that are unfair and unjust. Of course, that often is not the case. Reflecting the importance of education for life outcomes, parents, teachers, and school administrators fight over the importance of different factors. Should students always be assigned to their neighborhood school or should other criteria override that consideration? As an illustration, in a city with widespread racial segregation and economic inequalities by neighborhood, elevating neighborhood school assignments can exacerbate inequality and racial segregation. For these reasons, software designers have to balance competing interests and reach intelligent decisions that reflect values important in that particular community. Making these kinds of decisions increasingly falls to computer programmers. They must build intelligent algorithms that compile decisions based on a number of different considerations. That can include basic principles such as efficiency, equity, justice, and effectiveness. Figuring out how to reconcile conflicting values is one of the most important challenges facing AI designers. It is vital that they write code and incorporate information that is unbiased and non-discriminatory. Failure to do that leads to AI algorithms that are unfair and unjust. Adaptability The last quality that marks AI systems is the ability to learn and adapt as they compile information and make decisions. Effective artificial intelligence must adjust as circumstances or conditions shift. This may involve alterations in financial situations, road conditions, environmental considerations, or military circumstances. AI must integrate these changes in its algorithms and make decisions on how to adapt to the new possibilities. One can illustrate these issues most dramatically in the transportation area. Autonomous vehicles can use machine-to-machine communications to alert other cars on the road about upcoming congestion, potholes, highway construction, or other possible traffic impediments. Vehicles can take advantage of the experience of other vehicles on the road, without human involvement, and the entire corpus of their achieved “experience” is immediately and fully transferable to other similarly configured vehicles. Their advanced algorithms, sensors, and cameras incorporate experience in current operations, and use dashboards and visual displays to present information in real time so human drivers are able to make sense of ongoing traffic and vehicular conditions. A similar logic applies to AI devised for scheduling appointments. There are personal digital assistants that can ascertain a person’s preferences and respond to email requests for personal appointments in a dynamic manner. Without any human intervention, a digital assistant can make appointments, adjust schedules, and communicate those preferences to other individuals. Building adaptable systems that learn as they go has the potential of improving effectiveness and efficiency. These kinds of algorithms can handle complex tasks and make judgments that replicate or exceed what a human could do. But making sure they “learn” in ways that are fair and just is a high priority for system designers. Conclusion In short, there have been extraordinary advances in recent years in the ability of AI systems to incorporate intentionality, intelligence, and adaptability in their algorithms. Rather than being mechanistic or deterministic in how the machines operate, AI software learns as it goes along and incorporates real-world experience in its decisionmaking. In this way, it enhances human performance and augments people’s capabilities. Of course, these advances also make people nervous about doomsday scenarios sensationalized by movie-makers. Situations where AI-powered robots take over from humans or weaken basic values frighten people and lead them to wonder whether AI is making a useful contribution or runs the risk of endangering the essence of humanity. With the appropriate safeguards, countries can move forward and gain the benefits of artificial intelligence and emerging technologies without sacrificing the important qualities that define humanity. There is no easy answer to that question, but system designers must incorporate important ethical values in algorithms to make sure they correspond to human concerns and learn and adapt in ways that are consistent with community values. This is the reason it is important to ensure that AI ethics are taken seriously and permeate societal decisions. In order to maximize positive outcomes, organizations should hire ethicists who work with corporate decisionmakers and software developers, have a code of AI ethics that lays out how various issues will be handled, organize an AI review board that regularly addresses corporate ethical questions, have AI audit trails that show how various coding decisions have been made, implement AI training programs so staff operationalizes ethical considerations in their daily work, and provide a means for remediation when AI solutions inflict harm or damages on people or organizations. Through these kinds of safeguards, societies will increase the odds that AI systems are intentional, intelligent, and adaptable while still conforming to basic human values. In that way, countries can move forward and gain the benefits of artificial intelligence and emerging technologies without sacrificing the important qualities that define humanity. Author Darrell M. West Senior Fellow - Governance Studies , Center for Technology Innovation (CTI) , Center for Effective Public Management (CEPM) , Douglas Dillon Chair in Governmental Studies @ The Brookings Institution is committed to quality, independence, and impact. We are supported by a diverse array of funders . In line with our values and policies , each Brookings publication represents the sole views of its author(s). More On Technology & Information Sub-Topics Artificial Intelligence Program Governance Studies Center Center for Technology Innovation (CTI) Project Artificial Intelligence and Emerging Technology Initiative Privacy under siege: DOGE’s one big, beautiful database Privacy Privacy under siege: DOGE’s one big, beautiful database Stephanie K. Pell, Josie Stewart, Brooke Tanner June 25, 2025 Should consumers and businesses use AI assistants? Artificial Intelligence Should consumers and businesses use AI assistants? Darrell M. West June 24, 2025 Attacks on research and development could hamper technological innovation Technology & Information Attacks on research and development could hamper technological innovation Nicol Turner Lee, Josie Stewart June 23, 2025 Get the latest from Brookings Sign Up twitter facebook linkedin youtube instagram The Brookings Institution is a nonprofit organization based in Washington, D.C. Our mission is to conduct in-depth, nonpartisan research to improve policy and governance at local, national, and global levels. Donate Research Programs Governance Studies Economic Studies Foreign Policy Global Economy and Development Brookings Metro About Us Leadership Careers Brookings Institution Press WashU at Brookings Contact Brookings Research & Commentary Experts Events Books Podcasts Newsletters Privacy Policy, Updated August 2024 Terms of Use, Updated August 2024 Copyright 2025 The Brookings Institution
====================================================================================================
Artificial Intelligence (AI) - Tpoint Tech Tutorials × Python Python Tutorial Django Tutorial Numpy Tutorial Pandas Tutorial Tkinter Tutorial Pytorch Tutorial Flask Tutorial OpenCV Tutorial Java Java Tutorial Servlet Tutorial JSP Tutorial Spring Boot Tutorial Spring Framework Tutorial Hibernate Tutorial JavaFX Tutorial Java Web Services Tutorial .Net Framework .Net Framework Tutorial C# Tutorial ASP.Net Tutorial ADO.Net Tutorial WPF Tutorial AI, ML and Data Science Artificial Intelligence Tutorial Machine Learning Tutorial Data Science Tutorial Deep Learning Tutorial TensorFlow Tutorial Artificial Neural Network Tutorial Matplotlib Tutorial Python Scipy Tutorial Cloud Technology Cloud Computing Tutorial AWS Tutorial Microsoft Azure Tutorial Salesforce Tutorial GCP Tutorial B.Tech and MCA DBMS Tutorial Data Structures Tutorial Operating System Tutorial Computer Network Tutorial DAA Tutorial Computer Organization Tutorial Software Engineering Tutorial Data Mining Tutorial Web Technology HTML Tutorial CSS Tutorial JavaScript Tutorial Jquery Tutorial Angular 8 Tutorial React Tutorial React Native Tutorial Node.js Tutorial PHP PHP Tutorial MySQL Tutorial Laravel Tutorial WordPress Tutorial CodeIgniter Tutorial Software Testing Software Testing Tutorial Selenium Tutorial JIRA Tutorial JMeter Tutorial Postman Tutorial TestNG Tutorial SoapUI Tutorial Cucumber Tutorial Interview × Technical Interview Python Interview Questions Java Interview Questions .Net Interview Questions C++ Interview Questions React Interview Questions Node.js Interview Questions Angular Interview Questions SQL Interview Questions HR Interview Questions Java Interview Spring Boot Interview Questions Spring Interview Questions Hibernate Interview Questions JDBC Interview Questions Servlet Interview Questions Maven Interview Questions Jenkins Interview Questions Python Django Interview Questions Pandas Interview Questions Express.js Interview Questions Python Coding Interview Questions Python Interview Questions for 5 Years Web Interview HTML Interview Questions CSS Interview Questions JavaScript Interview Questions Jquery Interview Questions PHP Interview Questions Laravel Interview Questions AJAX Interview Questions Front-End Developer Interview Questions jQuery Interview Questions Database Interview DBMS Interview Questions SQL Interview Questions PL/SQL Interview Questions Oracle Interview Questions MySQL Interview Questions MongoDB Interview Questions Redis Interview Questions B.Tech / MCA DBMS Interview Questions Operating System Interview Questions OOPs Interview Questions DSA Interview Questions Computer Networks Interview Questions Important Interview C Interview Questions Power BI Interview Questions C# Interview Questions Excel Interview Questions C# Interview Questions Machine Learning Interview Questions AWS Interview Questions Microservices Interview Questions MySQL Interview Questions Software Testing Interview Manual Testing Interview Questions Selenium Interview Questions API Testing Interview Questions ETL Testing Interview Questions Mobile Testing Interview Questions Company Interviews IBM Interview Questions Adobe Interview Questions Microsoft Interview Questions Amazon Interview Questions TCS Interview Questions Wipro Interview Questions Accenture Interview Questions Compiler × Online Compilers Python Online Compiler Java Online Compiler PHP Online Compiler C Online Compiler C++ Online Compiler HTML Online Compiler JavaScript Online Compiler TypeScript Online Compiler R Online Compiler Swift Online Compiler Kotlin Online Compiler Go Online Compiler C# Online Compiler Perl Online Compiler Groovy Online Compiler HTML, CSS & JavaScript Online Editor Multiple Choice Questions Python MCQ Java MCQ PHP MCQ C Programming MCQ C++ MCQ HTML mcq JavaScript MCQ SQL MCQ Operating System MCQ Computer Fundamental MCQ Computer Network MCQ DBMS MCQ Data Structure MCQ Software Engineering MCQ Cloud Computing MCQ Artificial Intelligence MCQ Python Java JavaScript SQL C C++ HTML CSS React Node.js Spring Boot C# PHP MySQL MongoDB AI ML DSA DBMS OS Aptitude Reasoning Artificial Intelligence Artificial Intelligence (AI) Applications of Artificial Intelligence Features of Artificial Intelligence History of Artificial Intelligence Examples of Artificial Intelligence Types of Artificial Intelligence Advantages and Disadvantages of Artificial Intelligence Future of Artificial Intelligence Importance of Artificial Intelligence Difference between Artificial Intelligence and Human Intelligence Domains of Artificial Intelligence How does Artificial Intelligence Work? Intelligent Agent What are AI Agents? Types of Agents in AI Intelligent Agent in AI Agent and Environment in AI Turing Test in AI Peas In AI Problem-solving Search Algorithms Uninformed Search Algorithm A* Search Algorithm in Artificial Intelligence Hill Climbing Algorithm Means-Ends Analysis Adversarial Search Adversarial search Mini-Max Algorithm in Artificial Intelligence Alpha-Beta Pruning Knowledge Represent Knowledge Based Agent Knowledge Representation Knowledge Representation Techniques Propositional Logic Rules of Inference The Wumpus world knowledge base for Wumpus World First-order logic Knowledge Engineering in FOL Inference in First-Order Logic Unification in FOL Resolution in FOL Forward Chaining and backward chaining Difference between Backward Chaining and Forward Chaining Reasoning in AI Inductive vs. Deductive reasoning Uncertain Knowledge R. Probabilistic Reasoning in AI Bayes theorem in AI Bayesian Belief Network Subsets of AI Subsets of AI Expert Systems NLP Tutorial AI in Real World AI in Healthcare AI in Education AI in Agriculture AI in Marketing AI in Business AI in Banking AI in Manufacturing AI in Civil Engineering AI in HR AI in Medicine AI In E-commerce AI in Software Testing AI in Transportation Artificial Intelligence MCQ Artificial Intelligence MCQ Misc AI Essay Machine Translation in Artificial Intelligence Engineering Applications of AI MBA in Artificial Intelligence Ontological Engineering in Artificial Intelligence Robotics and AI Opportunities and Challenges for Artificial Intelligence in India Semantics of Propositional Logic in Artificial Intelligence Languages used in AI Syntax of Propositional Logic in Artificial Intelligence Approaches of Artificial Intelligence The Role and Benefits of AI in Cloud Computing Scope of Artificial Intelligence Truth Maintenance System in Artificial Intelligence Uniform Cost Search in Artificial Intelligence Artificial Intelligence Jobs Artificial Intelligence for Kids Amazon CloudFront Artificial Intelligence Case Studies 2025 Goals of Artificial Intelligence Artificial Intelligence for Smart Billing Can Artificial Intelligence replace Human Intelligence Artificial Intelligence Models Axiomatic System in Artificial Intelligence Artificial Intelligence Stocks in India Best Artificial Intelligence Company in Kerala Bidirectional Search Algorithm in Artificial Intelligence Fuzzy Logic in Artificial Intelligence Companies Working on Artificial Intelligence Greedy Best-First Search in Artificial Intelligence Artificial Intelligence Future Ideas How many Proposition Symbols are there in Artificial Intelligence? Government Jobs in Artificial Intelligence in India How to Make Your Own AI (Artificial Intelligence)? What is the Role of Planning in Artificial Intelligence Jarvis Artificial Intelligence Software AI as a Service Negotiation and Bargaining in Artificial Intelligence Passive Reinforcement Learning in AI AI Tools Stochastic Games in Artificial Intelligence Cognitive AI Temporal Logic in Artificial Intelligence Introduction of Seaborn Temporal Models in Artificial Intelligence Natural Language ToolKit (NLTK) Top 10 Artificial Intelligence Cryptocurrency Coins Best books for ML What is Quantum AI (Artificial Intelligence)? AI companies of India will lead in 2022 Which Business Case is Better Solved by Artificial Intelligence? Constraint Satisfaction Problems in Artificial Intelligence Will Artificial Intelligence Take Away Jobs? How artificial intelligence will change the future Artificial Intelligence and Automation Problem Solving Techniques in AI Artificial Intelligence for Inclusive Growth Artificial Intelligence in Car Industry Artificial Intelligence in Automotive Industry Classical Planning in Artificial Intelligence Depth Limited Search in Artificial Intelligence Artificial Intelligence in Gaming Industry Does Artificial Intelligence Require Coding? Frame Problem in Artificial Intelligence Monotonic Vs. Non-Monotonic Reasoning in AI PhD in Artificial Intelligence Procedural Vs. Declarative Knowledge in Artificial Intelligence Activation Functions in Neural Networks Top 10 Artificial Intelligence Mini Projects Boston Housing Kaggle Challenge with Linear Regression Artificial Intelligence for Big Data Analytics What are OpenAI and ChatGPT Artificial Intelligence in 5G Networks Chatbot vs. Conversational AI Artificial Intelligence Jobs in Mumbai Iterative Deepening A* Algorithm (IDA*) Best Artificial Intelligence Colleges in Kolkata Iterative Deepening Search (IDS) or Iterative Deepening Depth First Search (IDDFS) Exhaustive Search in Artificial Intelligence Genetic Algorithm in Soft Computing Expert Vs. Traditional Systems in AI AI and data privacy International Joint Conference on Artificial Intelligence Future of Devops Is Artificial Intelligence a Threat to Humans? How Machine Learning is Used on Social Media Platforms in 2023 Multi-Agent Planning in Artificial Intelligence Machine learning and climate change Search Strategies in Artificial Intelligence The Green Tech Revolution Uncertainty in Artificial Intelligence (AI) GoogleNet in AI Utility Functions in Artificial Intelligence AlexNet in Artificial Intelligence Advantages and Disadvantages of AI Images Basics of LiDAR - Light Detection and Ranging Artificial Intelligence Art Explainable AI (XAI) Artificial Intelligence in Power Station Synthetic Image Generation Artificial Intelligence Law What is Deepfake in Artificial Intelligence Artificial Intelligence vs. Cybersecurity What is Generative AI: Introduction Constraint Propagation in Artificial Intelligence Artificial Intelligence in Power System Operation and Optimization Difference Between Natural and Artificial Intelligence Customer Segmentation with LLM Difference Between the Semantic Web and Artificial Intelligence (AI) Liquid Neural Networks in Artificial Intelligence Graph Search in Artificial Intelligence Propositional Logic Inferences in Artificial Intelligence Impact of Artificial Intelligence on Society Text Generation using Gated Recurrent Unit Networks Importance of Data Drift Detection Viterbi Algorithm in NLP Markov Decision Processes in Artificial Intelligence What are the benefits of Artificial Intelligence for devops Principles of Artificial Intelligence AI Tech Stack Siri Speech Recognition in Artificial Intelligence Top 10 AI Applications in Digital Marketing in 2025 Types of AI Algorithms and How Do They Work Viva Questions on Artificial Intelligence AI Ethics (AI Code of Ethics) Why Building an AI Decentralized Autonomous Organization (AI DAO)? Pros and Cons of AI-Generated Content Artificial Intelligence in Endodontics Top 10+ Jobs in AI and the Right Artificial Intelligence Skills You Need to Stand Out Artificial Intelligence in Orthodontics AIOps (artificial intelligence for IT operations) Artificial Intelligence Salary in the USA Best Artificial Intelligence Books for Beginners How AI can Transform Industrial Safety Certainty Factor in Artificial Intelligence Current Trends in Artificial Intelligence in 2025 Generative AI Is Artificial Intelligence Good or Bad? NLTK WordNet Process Learning in Artificial Intelligence What is Auto-GPT Rationality in Artificial Intelligence Artificial Super Intelligence (ASI) Simple Reflex Agent in Artificial Intelligence AI hallucination Situation Calculus in Artificial Intelligence How to Learn AI from Scratch Symbolic Reasoning in Artificial Intelligence What is Dilated Convolution? Top 10 AI Tools for Animation Explainable Artificial Intelligence(XAI) Unification in Artificial Intelligence (AI) AI Content Generator What is Perception in Artificial Intelligence? Artificial Intelligence Project Ideas for Beginners Apache Spark in Artificial Intelligence Beatoven.ai: Make Music AI Artificial Intelligence Courses in Canada Google Lumiere AI Artificial Intelligence Courses in Chennai Handling Missing Data in Decision Tree Models Impacts of Artificial Intelligence in Everyday Life Leverage Artificial Intelligence in K-12 Education OpenAI DALL-E Editor Interface The Impact of Artificial Intelligence on Employment Water Jug Problem in AI The Role of Artificial Intelligence in Literature What are the Ethical Problems in Artificial Intelligence Types of Environments in Artificial Intelligence Difference between Depth First Search, Breadth First Search, and Depth Limit Search in AI Types of Neural Networks in Artificial Intelligence How To Humanize AI Text for Free Use of Artificial Intelligence in Computer Science 5 Algorithms that Demonstrate Artificial Intelligence Bias Philosophy of Artificial Intelligence Artificial Intelligence - Boon or Bane AI in Image Processing Character AI AI in Management Information System 18 of the best large language models in 2024 Artificial Intelligence in Accounting AI Issues Artificial Intelligence in Ancient India - Texts and Vedas Explainable AI Artificial Intelligence in Defense Conceptual Dependency in AI Artificial Intelligence in Indian Railways Artificial Intelligence in Instrumentation Problem characteristics in ai Artificial Intelligence in IoT (Internet of Things) Top degree programs for studying artificial Intelligence Artificial Intelligence in Judiciary AI Upscaling Artificial Intelligence in Mechanical Engineering Artificial Intelligence combined with decentralized technologies Artificial Intelligence in Indian Navy Ambient Intelligence How Big Data and Artificial Intelligence Work Together? Federated Learning Linguistic Intelligence in AI Neuromorphic Computing Role of Business Analyst in Artificial Intelligence Bias Mitigation in AI Semantic Network in Artificial Intelligence Neural Architecture Search Vacuum World Problem in Artificial Intelligence Top Artificial Intelligence Techniques AI in Mobile App Development Best First Search in Artificial Intelligence Artificial Intelligence for Mechatronics Top 10 Must-Read Books for Artificial Intelligence Artificial Intelligence in Maintenance What are the Core Subjects in Artificial Intelligence Artificial Intelligence in Mineral Exploration Artificial Intelligence in Navigation Systems Artificial Intelligence Engineer Salary in India Role of Artificial Intelligence in ISRO Artificial Intelligence in Dentistry The Role of AI in Media and Entertainment des.ai.gn - Augmenting Human Creativity with Artificial Intelligence The Role of Artificial Intelligence in Marketing Research Best Artificial Intelligence Courses in 2024 Artificial Intelligence in Sales Forecasting Difference Between Data Science and Artificial Intelligence Best AI Learning Tools for Kids in 2025 Narrow Artificial Intelligence Limitations of Artificial Intelligence What is OpenAI Roadmap to Artificial Intelligence Best First Search Algorithm in Artificial Intelligence Artificial Intelligence in Malta Decision Theory in Artificial Intelligence Artificial Intelligence (AI) in Nuclear Medicine 8 Queens Problem in Artificial Intelligence Artificial Intelligence (AI) in Nursing AI for Disaster Response Artificial Intelligence in Oil and Gas Industry AI in Bioinformatics Artificial Intelligence in Pathology Amazing Facts About AI Artificial Intelligence in Scientific Research Artificial Intelligence Ethics The Role of AI in Performance Management AI in Cyber Security Statistical Learning in Artificial Intelligence Artificial Intelligence Test Automation Tools The Use of AI in Patient Recruitment Artificial Intelligence for Power Electronics Best Artificial Intelligence Games Artificial Intelligence in Physiotherapy Best Colleges for Artificial Intelligence in Tamil Nadu Artificial Intelligence in Portfolio Management Difference between Cloud Computing and Artificial Intelligence Artificial Intelligence in the Poultry Industry Artificial Intelligence in Public Sector Fundamentals of Artificial Intelligence Artificial Intelligence in Quality Control Game Playing in Artificial Intelligence Artificial Intelligence in Remote Sensing Hierarchical Planning in Artificial Intelligence Artificial Intelligence in Revenue Cycle Management How can AI be used to create artificial data Artificial Intelligence in Validation and Reconciliation How to use Artificial Intelligence The Role of AI in Rural Development Information Extraction in Artificial Intelligence The Use of AI in Payroll Industry Local Search Algorithm in Artificial Intelligence Artificial Intelligence in Power Plants Problem Solving Agents in Artificial Intelligence Artificial Intelligence for Smart Building Production System in Artificial Intelligence Artificial Intelligence in the Security Market STRIPS in Artificial Intelligence Artificial Intelligence in Shipping Industry The Return of Artificial Intelligence Reading Answers Artificial Intelligence in Social Networking Tic-Tac-Toe Problem in Artificial Intelligence Artificial Intelligence in Social Sciences Top 10 Artificial Intelligence Companies in India Artificial Intelligence in Software Engineering Top 10 Characteristics of Artificial Intelligence Artificial Intelligence in Sports Prediction Top 15 Artificial Intelligence (AI) Tools Artificial Intelligence in Textile Industry Top Artificial Intelligence Colleges in India Artificial Intelligence in the 21st Century What is Natural Language Processing in Artificial Intelligence The Potential of Artificial Intelligence in Sharepoint Online Why do people Use Swarm Intelligence Artificial Intelligence in Printing Industry Artificial Intelligence in Cancer Detection Artificial Intelligence and Industry 4.0 Artificial Intelligence in Corporate Training Artificial Intelligence in Information Systems Artificial Intelligence in Trading Artificial Intelligence in Power Generation Current Status of Artificial Intelligence Artificial Intelligence in Smart Grid Default Reasoning in Artificial Intelligence Artificial Intelligence in Social Media Artificial Intelligence in Space Research How to Avoid Accidents Using Artificial Intelligence Artificial Intelligence in Surgery Promises and Perils Inductive Learning in Artificial Intelligence Artificial Intelligence in the Hospitality Industry Knowledge Representation Issues in Artificial Intelligence Artificial Intelligence in Traffic Management Artificial Intelligence in Veterinary Medicine Artificial Intelligence in Wireless Communications SOP for Artificial Intelligence Stock Market Prediction Using Artificial Intelligence The Role of Artificial Intelligence in Web Development Artificial Intelligence and Natural Stupidity Artificial Intelligence and the Future of International Law Artificial Intelligence in Inventory Management Artificial Intelligence in Retail Business Artificial Intelligence in Self-Driving Cars Artificial Intelligence in Sports Artificial Intelligence in Telecommunication Artificial Intelligence in Wind Energy Systems Artificial Intelligence Institutes in Pune Artificial Intelligence Market Size, Share, Trends and Growth Impact of AI in the Indian Army The Role of Artificial Intelligence in Internal Audit Top 10 Interesting Facts About Artificial Intelligence Types of Environments in AI Use of Artificial Intelligence in Tax Administration Artificial Intelligence and Unemployment Artificial Intelligence Careers & Job Outlook in 2025 Artificial Intelligence in Insurance - Use Cases Artificial Intelligence in Ophthalmology Artificial Intelligence in Procurement Artificial Intelligence in the Petroleum Industry Artificial Intelligence in the Workplace Artificial Intelligence in VLSI Design Artificial Intelligence Institutes in Delhi Artificial Intelligence Institutes in Gurgaon Artificial Intelligence Legal Issues Artificial Intelligence Master Thesis Topics Artificial Intelligence Methods for Software Engineering Artificial Intelligent Interface Benefits of Artificial Intelligence in Accounting Examples of Artificial Intelligence in the Manufacturing Industry How Businesses can Measure AI Success using KPIs? Intelligent Systems in Artificial Intelligence Role of AI in the Mortgage Industry Role of Artificial Intelligence in Modern Society The Role of Artificial Intelligence in Waste Management What is Rejection Sampling? Artificial Intelligence Institutes in India Artificial Intelligence Lab Equipment Autonomous Agents in Artificial Intelligence Benefits of AI in E-Commerce Best YouTube Channels to Learn Artificial Intelligence Introduction To Generative AI The Impact of Artificial Intelligence on Language Learning Top 10 Artificial Intelligence Courses for Lawyers AI Layers AI Methods BFS and DFS Examples in Artificial Intelligence Career Growth in Artificial Intelligence How Blockchain and AI Complement each other? Characteristics of Artificial Intelligence Problems Computational Learning Theory in Artificial Intelligence Skolemization in Artificial Intelligence What is White Label AI? What Stephen Hawking Said about Artificial Intelligence? Casual AI-Enabling Data-Driven Decisions Artificial Intelligence Courses in the USA Environmental Impact of Artificial Intelligence Artificial Intelligence in Electronics Engineering Artificial Intelligence Operating System (AIOS) Deductive Reasoning in Artificial Intelligence Should We Fear Artificial Intelligence? What Business Problems Can Artificial Intelligence Solve? Artificial Intelligence in Mobile Phones Artificial Intelligence in Digital Marketing Artificial Intelligence in Finance How to Learn Artificial Intelligence Artificial Intelligence in Organic Farming Best Artificial Intelligence (AI) Tools in 2025 Importance of AI in Education Mathematics in Artificial Intelligence State Space Search in Artificial Intelligence What is Artificial Intelligence Bias Who is the Father of Artificial Intelligence SOP for MS in Artificial Intelligence Top AI Penny Stocks in India What is AI in Data Analytics Artificial Intelligence in Business Management Related Tutorials Tensorflow Tutorial PyTorch Tutorial Data Science Tutorial Reinforcement Learning next → Artificial Intelligence (AI) Tutorial 25 Apr 2025 | 9 min read Artificial Intelligence (AI) can be formulated as an emerging branch of computer science concerned with the creation of actual intelligent systems that mimic different human competencies. Offensive uses include voice assistance, self-driving cars, recommendation systems and diagnoses. It encompasses elements of machine learning, data science, robotics and other areas to design systems that can learn, infer and act. That is why it is important to understand properly the meaning of the main concept of AI as well as the possibilities and outcomes to expect in practice. What is Artificial Intelligence (AI)? Artificial intelligence, as a computer science discipline, works to develop machines that execute duties that require human cognitive abilities. The human-related operations encompass learning combined with reasoning alongside problem-solving and perception and decision-making paths. AI merges the words "Artificial", describing human-made components, and "Intelligence", referring to thinking capabilities to generate machines that emulate human thought processes. Definition: "It is a branch of computer science by which we can create intelligent machines that can behave like a human, think like humans, and be able to make decisions." Artificial intelligence is the ability of a computer to learn, reason, and solve problems like a human being. Artificial intelligence is remarkable because it allows you to design a computer with preprogrammed algorithms that can operate with your intellect without requiring you to preprogram it to accomplish any tasks. Why Artificial Intelligence? AI is important because: It solves real-world problems in areas like healthcare, marketing, and traffic management. It helps you create your virtual assistant, like Cortana, Google Assistant , Siri , etc. It allows robots to work in conditions that may be either hazardous to human life or are impossible for a human being to access. It promotes creativity and creates a number of opportunities for further development of technology and its usage. History of AI It is very interesting to know that the concept of intelligent machines has existed even in ancient civilizations, myths, and structures like the Egyptian pyramids. Information about symbolic reasoning was researched by philosophers Aristotle and Ramon Llull. In the 1800s-1900s, Charles Babbage and Ada Lovelace introduced the concept of utilizing programmable machines. In the period of 1940s, John Von Neumann invented stored-program computers and McCullochs& Pitts introduced ideas of neural networks. After the Second World War, particularly in the 1950s, Alan Turing came up with the Turing Test. The term 'AI' was first used in 1956 at Dartmouth College, and the first AI system was known as the logic theorist. What Comprises of Artificial Intelligence? AI is actually not limited to computer science; it includes several domains that mimic human intelligence. Intelligence includes reasoning, learning, problem-solving, perception and language understanding. To achieve this, AI leverages on a number of fields, such as: Mathematics Biology Psychology Sociology Computer Science Neuroscience Statistics These fields work together to develop intelligent systems capable of human-like behaviour. Types of Artificial Intelligence Artificial Intelligence is divided into different types, mostly determined by two key factors: capabilities and functionality. AI Type 1: Based on Capabilities Weak AI or Narrow AI: This type of AI can be used to solve certain problems and focus on a particular kind of job. It is only effective when it is used in a specific area and does not produce the same results when applied in other areas. It applies to smart products, known as virtual assistants such as Siri, systems engaged in image recognition, and IBM 's Watson. General AI: General AI, also known as Strong AI, on the other hand, refers to machines capable of achieving any action that a man is capable of accomplishing. It is planning to attain human-like features such as intelligence characteristics like reasoning and learning processes. This is another type of AI that is still under research and has not been developed to its realization. Super AI: An advanced artificial intelligence in which every domain is superior to that of humans in terms of their decision-making power, problem-solving skills, learning capabilities, as well as their feelings and emotions. It is the final stage of AI development, and it does not currently exist in the world. AI Type 2: Based on Functionality Reactive Machines: This type of AI processes the current input data and does not have any previous experience. They follow pre-defined rules. Some of the most widely known examples include IBM's chess machine known as Deep Blue and the Go-playing computer termed Google's AlphaGo. Limited Memory: Many of them use the earlier information to establish something for a limited period. Some of the concrete samples include self-driving cars that follow other vehicles, the speed, and the road condition of the environment. Theory of Mind: The purpose of this AI is to comprehend the feelings, desires or even gestures of people. As previously stated, it is still part of the theoretical research and has not been fully realized. Self-Awareness: The final type of artificial intelligence that remains at the level of theory is even more superior to human intelligence as it would have consciousness and feelings. People would consider this level of AI as a significant level of advancement in technology as well as in knowledge. Advantages of AI The following are some main advantages of Artificial Intelligence: High Accuracy with less error: AI machines or systems have a low incidence of error and are highly accurate because they make their decisions based on experience or knowledge. High-Speed: AI systems are able to make decisions quickly and with extreme speed; as a result, they are able to defeat a chess champion in a chess game. High reliability: AI systems are incredibly dependable and capable of accurately repeating the same task over and again. Beneficial for hazardous environments: AI devices can be useful in dangerous environments where utilizing humans might be harmful, such as defusing a bomb or researching the ocean floor. Digital Assistant: AI has a number of applications, for instance, in the current generation of E-commerce websites where AI technology can be used to show products in accordance with consumers' demands. Useful as a public utility: Artificial intelligence (AI) has the potential to be highly helpful for public utilities like self-driving cars, which can make our travels safer and less complicated, face recognition for security, natural language processing to speak to people in their native tongue, etc. Enhanced Security: AI can indeed be very beneficial in improving security issues because of its ability to scan security threats when they are happening and counteract them to prevent affecting the firm and organization's information and machinery. Aid in Research: AI is useful to the research process as it helps researchers analyze large data sets in areas such as astronomy, genomics, and materials science in a timely manner. Disadvantages of AI There are drawbacks to any technology, including artificial intelligence. The drawbacks of AI are as follows: Expensive: Since the AI requires regular maintenance to adjust to modern standards, the hardware and software costs are relatively high. Unable to think creatively: However, to this date, robots cannot be said to possess creativity because their operations are limited to specific instructions and programs given to them. No feelings or emotions: These robots can be incredible performers, but one thing they don't possess is feelings, which are essential for the formation of friendly relationships with humans. Consequently, there is a probability that such users may be unsafe if not provided adequate care. Increased reliance on machines: In today's society, one can observe that people's minds are gradually failing due to their tight connection with devices. Lack of Original Creativity: Nevertheless, although the growth rate within humans is amazing or even inspiring, artificial intelligence computers can hardly be compared to human intelligence in terms of creativity and inventiveness. Complexity: The creation and sustained operation of artificial intelligence may be quite difficult and require certain skills. For this reason, some persons or organizations may have it hard in being able to employ them as a result. Job Concerns: This means that it will not stop at replacing basic professions only; it may also impose on specific skilled professions. It is for this reason that many people in a number of parts are anxious about losing their jobs due to this. Challenges of AI AI has several benefits, but it also has some challenges that must be solved: Doing the Right Thing: AI has to make the right decisions, but sometimes it does not do that. It can be wrong or perform acts that are undesirable or not objectively right. There is a need to improve the decision-making ability of artificial intelligence and increase the 'good choice' factor of artificial intelligence. Government and AI: Sometimes governments employ AI surveillance on people. This can threaten the concept of freedom; therefore, we have to ensure that they include the aspects of artificial intelligence in a good manner. Bias in AI: Sometimes, AI seems to be partial, for instance, when identifying the facial features of different people. This is rather disadvantageous, speaking of which this affects individuals who are not 'like most people'. AI and Social Media: Social media feeds are controlled by AI. However, sometimes, it reveals some probably false or even a little cruel information. It is important for 'AI' to show the right things. Legal and Regulatory Challenges: With the advancement of AI, there is inadequate legislative and regulatory law to cover most of the issues that surround AI, such as accountability and responsibility. AI Tools and Services AI tools and services for various applications are developing rapidly, and this development has some roots in 2012, which is related to the appearance of the AlexNet neural network. This made a new epoch of high-performance AI possible by the utilization of GPUs and large data sets. This highlighted the largest change in training neural networks with large quantities of data on multiple GPU s at once, which became more efficient. Transformers: Google used a large number of standard computers with specialized processors called GPUs to develop AI more effectively. Transformers were made feasible by this discovery. Transformers enable AI to learn from unlabelled data, much like a computer learning to comprehend English. Hardware Advancements: Businesses such as Nvidia enhanced these GPUs' internal mechanisms. They improved their ability to handle the mathematical tasks that AI must perform. AI became a million times better thanks to the collaboration of computer data centres, smarter AI software, and improved hardware! Nvidia is also collaborating with cloud services providers to ensure that others can apply this mighty AI without a problem. GPTs: Earlier, if a company wanted to incorporate AI in its operations, it had to build it from the ground up, which was costly and would take a lot of time. These days, companies like OpenAI , Nvidia, Microsoft , and Google provide pre-trained AI models. The specific models can be fine-tuned on such tasks more efficiently and at a lower expense. This assists businesses in adopting AI at a faster pace and with fewer risks involved in the process. AI in the Cloud: It is not always easy to use AI because it requires a lot of data processing in the cloud. Some of the largest cloud computing firms, such as Amazon, Google, Microsoft, IBM and Oracle , are helping to ease this problem. There, it offers AI services for the difficult components of the task, such as data preparation, training of models for AI and integrating AI into applications. Advanced AI for Everyone: Some organizations develop excellent AI modes and publish them. For instance, OpenAI has models ranging from certain ones that are proficient in negotiating to others proficient in language comprehension, image creation, and even coding. The former is Nvidia, and the latter is not affiliated with a single cloud firm. Other people have come up with different ways of producing special models of AI for various occupations and professions. The English Club has been likened to a vast toolbox that contains a number of strong implements in a range of activities. Prerequisite Before studying artificial intelligence, you need to be familiar with the following basics to help you grasp the ideas: Any computer language, including Python, Java, C, C++, etc. (but proficiency in Python will be helpful) Understanding fundamental concepts in mathematics, including probability theory, derivatives, etc. Conclusion Artificial Intelligence (AI) today has become an integral part of society that affects functionality based on technical support. AI impacts are present in all spheres of human lives, including healthcare, education, transportation, and entertainment. The level of AI integration that exists is the kind of application that has the hope of assisting in addressing major problems as well as enhancing people's performance. However, it also raises some important social and ethical issues of job loss, privacy invasion, and responsibility. For enhanced and desirable results, especially in the improvement of human life, AI should be developed morally and ethically. By studying AI, one assumes the ability to live directly in a future that is expected to be characterized by artificial intelligence. Next Topic Applications of Artificial Intelligence (AI) next → Related Posts Applications of Artificial Intelligence (AI) Artificial Intelligence is a rapidly growing technology that is penetrating the contemporary world through solutions to numerous problems within different sectors. Taking health care, education, finance, entertainment, and agriculture as some of the sample sectors, there is significant improvement in efficiency, accuracy, and convenience... 7 min read Difference between Artificial Intelligence and Human Intelligence This topic discusses the definition of both Artificial Intelligence (AI) and Human Intelligence (HI) and differentiates them. AI and HI are two such ideas that are likely to be compared and contrasted. AI is a field that is concerned with designing machines or computer programs... 4 min read How does Artificial Intelligence Work? How does AI (Artificial Intelligence) Work? What is Artificial Intelligence? Artificial intelligence known as AI is a term used for systems. These systems or machines. These machines mimic human intelligence. They do it to perform tasks. They can improve themselves, too. They improve based on the information... 7 min read Examples of Artificial Intelligence Examples of AI (Artificial Intelligence) The term &quot;Artificial Intelligence&quot; refers to the simulation of human intelligence processes by machines, especially computer systems. It also includes Expert systems, voice recognition, machine vision, and natural language processing (NLP). AI programming focuses on three cognitive aspects, such as learning, reasoning,... 13 min read Importance of Artificial Intelligence (AI) Artificial Intelligence is basically understood as one of the fundamentals in the current technology that is inclusive in various domains, including healthcare, finance, transport and entertainment. It advances very quickly and is beginning to be used at many of the places where machines learn... 5 min read Future of Artificial Intelligence Future of AI (Artificial Intelligence) Undoubtedly, Artificial Intelligence (AI) is a revolutionary field of computer science, which is ready to become the main component of various emerging technologies like big data, robotics, and IoT. It will continue to act as a technological innovator in the coming... 10 min read Features of Artificial Intelligence (AI) Artificial intelligence is no longer about the renowned concepts of science fiction but a transformative power that changes industries&#39; faces, improves life at hand and pushes boundaries on the potential ability residing in technology. Originally rooted in complex algorithms and computational power, AI grew... 7 min read Domains of Artificial Intelligence Domains of AI (Artificial Intelligence) AI is no longer the buzzword that we used to hear. It is a fast-evolving technology that has now become a part of our lives. It is changing the way we live, work, and the way we interact with the world.... 16 min read Types of Artificial Intelligence Types of AI (Artificial Intelligence) Artificial Intelligence can be divided in various types, there are mainly two types of main categorization which are based on capabilities and based on functionally of AI. Following is flow diagram which explain the types of AI. AI type-1: Based on Capabilities 1.... 3 min read Advantages and Disadvantages of Artificial Intelligence Advantages and Disadvantages of Artificial Intelligence (AI) Artificial Intelligence (AI) has affected several industries by advancing their performance, decreasing the margin of errors, and improving decision-making. It saves time through outsourcing activities, handling big volumes of data, and enabling others, such as smart devices and self-driving... 6 min read Subscribe to Tpoint Tech We request you to subscribe our newsletter for upcoming updates. Subscribe We provides tutorials and interview questions of all technology like java tutorial, android, java frameworks Contact info G-13, 2nd Floor, Sec-3, Noida, UP, 201301, India hr@tpointtech.com +91-9599086977 Follow us Tutorials Java Data Structures C Programming C++ Tutorial C# Tutorial PHP Tutorial HTML Tutorial JavaScript Tutorial jQuery Tutorial Spring Tutorial Interview Questions Microsoft Amazon Adobe Intuit Accenture Cognizant Capgemini Wipro Tcs Infosys Online Compiler C R C++ Php Java Html Swift Python JavaScript TypeScript Latest Post | Tutorials List | Privacy Policy | About Us | Contact Us © Copyright 2011 - 2025 TpointTech.com. All Rights Reserved.
====================================================================================================
Artificial Intelligence (Stanford Encyclopedia of Philosophy) Stanford Encyclopedia of Philosophy Menu Browse Table of Contents What's New Random Entry Chronological Archives About Editorial Information About the SEP Editorial Board How to Cite the SEP Special Characters Advanced Tools Contact Support SEP Support the SEP PDFs for SEP Friends Make a Donation SEPIA for Libraries Entry Navigation Entry Contents Bibliography Academic Tools Friends PDF Preview Author and Citation Info Back to Top Artificial Intelligence First published Thu Jul 12, 2018 Artificial intelligence (AI) is the field devoted to building artificial animals (or at least artificial creatures that – in suitable contexts – appear to be animals) and, for many, artificial persons (or at least artificial creatures that – in suitable contexts – appear to be persons). [ 1 ] Such goals immediately ensure that AI is a discipline of considerable interest to many philosophers, and this has been confirmed (e.g.) by the energetic attempt, on the part of numerous philosophers, to show that these goals are in fact un/attainable. On the constructive side, many of the core formalisms and techniques used in AI come out of, and are indeed still much used and refined in, philosophy: first-order logic and its extensions; intensional logics suitable for the modeling of doxastic attitudes and deontic reasoning; inductive logic, probability theory, and probabilistic reasoning; practical reasoning and planning, and so on. In light of this, some philosophers conduct AI research and development as philosophy. In the present entry, the history of AI is briefly recounted, proposed definitions of the field are discussed, and an overview of the field is provided. In addition, both philosophical AI (AI pursued as and out of philosophy) and philosophy of AI are discussed, via examples of both. The entry ends with some de rigueur speculative commentary regarding the future of AI. 1. The History of AI 2. What Exactly is AI? 3. Approaches to AI 3.1 The Intelligent Agent Continuum 3.2 Logic-Based AI: Some Surgical Points 3.3 Non-Logicist AI: A Summary 3.4 AI Beyond the Clash of Paradigms 4. The Explosive Growth of AI 4.1 Bloom in Machine Learning 4.2 The Resurgence of Neurocomputational Techniques 4.3 The Resurgence of Probabilistic Techniques 5. AI in the Wild 6. Moral AI 7. Philosophical AI 8. Philosophy of Artificial Intelligence 8.1 “Strong” versus “Weak” AI 8.2 The Chinese Room Argument Against “Strong AI” 8.3 The Gödelian Argument Against “Strong AI” 8.4 Additional Topics and Readings in Philosophy of AI 9. The Future Bibliography Academic Tools Other Internet Resources Online Courses on AI Related Entries 1. The History of AI The field of artificial intelligence (AI) officially started in 1956, launched by a small but now-famous DARPA -sponsored summer conference at Dartmouth College, in Hanover, New Hampshire. (The 50-year celebration of this conference, AI@50 , was held in July 2006 at Dartmouth, with five of the original participants making it back. [ 2 ] What happened at this historic conference figures in the final section of this entry.) Ten thinkers attended, including John McCarthy (who was working at Dartmouth in 1956), Claude Shannon, Marvin Minsky, Arthur Samuel, Trenchard Moore (apparently the lone note-taker at the original conference), Ray Solomonoff, Oliver Selfridge, Allen Newell, and Herbert Simon. From where we stand now, into the start of the new millennium, the Dartmouth conference is memorable for many reasons, including this pair: one, the term ‘artificial intelligence’ was coined there (and has long been firmly entrenched, despite being disliked by some of the attendees, e.g., Moore); two, Newell and Simon revealed a program – Logic Theorist (LT) – agreed by the attendees (and, indeed, by nearly all those who learned of and about it soon after the conference) to be a remarkable achievement. LT was capable of proving elementary theorems in the propositional calculus. [ 3 ] [ 4 ] Though the term ‘artificial intelligence’ made its advent at the 1956 conference, certainly the field of AI, operationally defined (defined, i.e., as a field constituted by practitioners who think and act in certain ways), was in operation before 1956. For example, in a famous Mind paper of 1950, Alan Turing argues that the question “Can a machine think?” (and here Turing is talking about standard computing machines: machines capable of computing functions from the natural numbers (or pairs, triples, … thereof) to the natural numbers that a Turing machine or equivalent can handle) should be replaced with the question “Can a machine be linguistically indistinguishable from a human?.” Specifically, he proposes a test, the “ Turing Test ” (TT) as it’s now known. In the TT, a woman and a computer are sequestered in sealed rooms, and a human judge, in the dark as to which of the two rooms contains which contestant, asks questions by email (actually, by teletype , to use the original term) of the two. If, on the strength of returned answers, the judge can do no better than 50/50 when delivering a verdict as to which room houses which player, we say that the computer in question has passed the TT. Passing in this sense operationalizes linguistic indistinguishability. Later, we shall discuss the role that TT has played, and indeed continues to play, in attempts to define AI. At the moment, though, the point is that in his paper, Turing explicitly lays down the call for building machines that would provide an existence proof of an affirmative answer to his question. The call even includes a suggestion for how such construction should proceed. (He suggests that “child machines” be built, and that these machines could then gradually grow up on their own to learn to communicate in natural language at the level of adult humans. This suggestion has arguably been followed by Rodney Brooks and the philosopher Daniel Dennett (1994) in the Cog Project. In addition, the Spielberg/Kubrick movie A.I. is at least in part a cinematic exploration of Turing’s suggestion. [ 5 ] ) The TT continues to be at the heart of AI and discussions of its foundations, as confirmed by the appearance of (Moor 2003). In fact, the TT continues to be used to define the field, as in Nilsson’s (1998) position, expressed in his textbook for the field, that AI simply is the field devoted to building an artifact able to negotiate this test. Energy supplied by the dream of engineering a computer that can pass TT, or by controversy surrounding claims that it has already been passed, is if anything stronger than ever, and the reader has only to do an internet search via the string turing test passed to find up-to-the-minute attempts at reaching this dream, and attempts (sometimes made by philosophers) to debunk claims that some such attempt has succeeded. Returning to the issue of the historical record, even if one bolsters the claim that AI started at the 1956 conference by adding the proviso that ‘artificial intelligence’ refers to a nuts-and-bolts engineering pursuit (in which case Turing’s philosophical discussion, despite calls for a child machine, wouldn’t exactly count as AI per se), one must confront the fact that Turing, and indeed many predecessors, did attempt to build intelligent artifacts. In Turing’s case, such building was surprisingly well-understood before the advent of programmable computers: Turing wrote a program for playing chess before there were computers to run such programs on, by slavishly following the code himself. He did this well before 1950, and long before Newell (1973) gave thought in print to the possibility of a sustained, serious attempt at building a good chess-playing computer. [ 6 ] From the perspective of philosophy, which views the systematic investigation of mechanical intelligence as meaningful and productive separate from the specific logicist formalisms (e.g., first-order logic) and problems (e.g., the Entscheidungsproblem ) that gave birth to computer science, neither the 1956 conference, nor Turing’s Mind paper, come close to marking the start of AI. This is easy enough to see. For example, Descartes proposed TT (not the TT by name, of course) long before Turing was born. [ 7 ] Here’s the relevant passage: If there were machines which bore a resemblance to our body and imitated our actions as far as it was morally possible to do so, we should always have two very certain tests by which to recognise that, for all that, they were not real men. The first is, that they could never use speech or other signs as we do when placing our thoughts on record for the benefit of others. For we can easily understand a machine’s being constituted so that it can utter words, and even emit some responses to action on it of a corporeal kind, which brings about a change in its organs; for instance, if it is touched in a particular part it may ask what we wish to say to it; if in another part it may exclaim that it is being hurt, and so on. But it never happens that it arranges its speech in various ways, in order to reply appropriately to everything that may be said in its presence, as even the lowest type of man can do. And the second difference is, that although machines can perform certain things as well as or perhaps better than any of us can do, they infallibly fall short in others, by which means we may discover that they did not act from knowledge, but only for the disposition of their organs. For while reason is a universal instrument which can serve for all contingencies, these organs have need of some special adaptation for every particular action. From this it follows that it is morally impossible that there should be sufficient diversity in any machine to allow it to act in all the events of life in the same way as our reason causes us to act. (Descartes 1637, p. 116) At the moment, Descartes is certainly carrying the day. [ 8 ] Turing predicted that his test would be passed by 2000, but the fireworks across the globe at the start of the new millennium have long since died down, and the most articulate of computers still can’t meaningfully debate a sharp toddler. Moreover, while in certain focussed areas machines out-perform minds (IBM’s famous Deep Blue prevailed in chess over Gary Kasparov, e.g.; and more recently, AI systems have prevailed in other games, e.g. Jeopardy! and Go, about which more will momentarily be said), minds have a (Cartesian) capacity for cultivating their expertise in virtually any sphere. (If it were announced to Deep Blue, or any current successor, that chess was no longer to be the game of choice, but rather a heretofore unplayed variant of chess, the machine would be trounced by human children of average intelligence having no chess expertise.) AI simply hasn’t managed to create general intelligence; it hasn’t even managed to produce an artifact indicating that eventually it will create such a thing. But what about IBM Watson’s famous nail-biting victory in the Jeopardy! game-show contest? [ 9 ] That certainly seems to be a machine triumph over humans on their “home field,” since Jeopardy! delivers a human-level linguistic challenge ranging across many domains. Indeed, among many AI cognoscenti, Watson’s success is considered to be much more impressive than Deep Blue’s, for numerous reasons. One reason is that while chess is generally considered to be well-understood from the formal-computational perspective (after all, it’s well-known that there exists a perfect strategy for playing chess), in open-domain question-answering (QA), as in any significant natural-language processing task, there is no consensus as to what problem, formally speaking, one is trying to solve. Briefly, question-answering (QA) is what the reader would think it is: one asks a question of a machine, and gets an answer, where the answer has to be produced via some “significant” computational process. (See Strzalkowski & Harabagiu (2006) for an overview of what QA, historically, has been as a field.) A bit more precisely, there is no agreement as to what underlying function, formally speaking, question-answering capability computes. This lack of agreement stems quite naturally from the fact that there is of course no consensus as to what natural languages are , formally speaking. [ 10 ] Despite this murkiness, and in the face of an almost universal belief that open-domain question-answering would remain unsolved for a decade or more, Watson decisively beat the two top human Jeopardy! champions on the planet. During the contest, Watson had to answer questions that required not only command of simple factoids ( Question 1 ), but also of some amount of rudimentary reasoning (in the form of temporal reasoning) and commonsense ( Question 2 ): Question 1 : The only two consecutive U.S. presidents with the same first name. Question 2 : In May 1898, Portugal celebrated the 400th anniversary of this explorer’s arrival in India. While Watson is demonstrably better than humans in Jeopardy! -style quizzing (a new human Jeopardy! master could arrive on the scene, but as for chess, AI now assumes that a second round of IBM-level investment would vanquish the new human opponent), this approach does not work for the kind of NLP challenge that Descartes described; that is, Watson can’t converse on the fly. After all, some questions don’t hinge on sophisticated information retrieval and machine learning over pre-existing data, but rather on intricate reasoning right on the spot. Such questions may for instance involve anaphora resolution, which require even deeper degrees of commonsensical understanding of time, space, history, folk psychology, and so on. Levesque (2013) has catalogued some alarmingly simple questions which fall in this category. (Marcus, 2013, gives an account of Levesque’s challenges that is accessible to a wider audience.) The other class of question-answering tasks on which Watson fails can be characterized as dynamic question-answering. These are questions for which answers may not be recorded in textual form anywhere at the time of questioning, or for which answers are dependent on factors that change with time. Two questions that fall in this category are given below (Govindarajulu et al. 2013): Question 3 : If I have 4 foos and 5 bars, and if foos are not the same as bars, how many foos will I have if I get 3 bazes which just happen to be foos? Question 4 : What was IBM’s Sharpe ratio in the last 60 days of trading? Closely following Watson’s victory, in March 2016, Google DeepMind’s AlphaGo defeated one of Go’s top-ranked players, Lee Seedol, in four out of five matches. This was considered a landmark achievement within AI, as it was widely believed in the AI community that computer victory in Go was at least a few decades away, partly due to the enormous number of valid sequences of moves in Go compared to that in Chess. [ 11 ] While this is a remarkable achievement, it should be noted that, despite breathless coverage in the popular press, [ 12 ] AlphaGo, while indisputably a great Go player, is just that. For example, neither AlphaGo nor Watson can understand the rules of Go written in plain-and-simple English and produce a computer program that can play the game. It’s interesting that there is one endeavor in AI that tackles a narrow version of this very problem: In general game playing , a machine is given a description of a brand new game just before it has to play the game (Genesereth et al. 2005). However, the description in question is expressed in a formal language, and the machine has to manage to play the game from this description. Note that this is still far from understanding even a simple description of a game in English well enough to play it. But what if we consider the history of AI not from the perspective of philosophy, but rather from the perspective of the field with which, today, it is most closely connected? The reference here is to computer science. From this perspective, does AI run back to well before Turing? Interestingly enough, the results are the same: we find that AI runs deep into the past, and has always had philosophy in its veins. This is true for the simple reason that computer science grew out of logic and probability theory, [ 13 ] which in turn grew out of (and is still intertwined with) philosophy. Computer science, today, is shot through and through with logic; the two fields cannot be separated. This phenomenon has become an object of study unto itself (Halpern et al. 2001). The situation is no different when we are talking not about traditional logic, but rather about probabilistic formalisms, also a significant component of modern-day AI: These formalisms also grew out of philosophy, as nicely chronicled, in part, by Glymour (1992). For example, in the one mind of Pascal was born a method of rigorously calculating probabilities, conditional probability (which plays a particularly large role in AI, currently), and such fertile philosophico-probabilistic arguments as Pascal’s wager , according to which it is irrational not to become a Christian. That modern-day AI has its roots in philosophy, and in fact that these historical roots are temporally deeper than even Descartes’ distant day, can be seen by looking to the clever, revealing cover of the second edition (the third edition is the current one) of the comprehensive textbook Artificial Intelligence: A Modern Approach (known in the AI community as simply AIMA2e for Russell & Norvig, 2002). Cover of AIMA2e (Russell & Norvig 2002) What you see there is an eclectic collection of memorabilia that might be on and around the desk of some imaginary AI researcher. For example, if you look carefully, you will specifically see: a picture of Turing, a view of Big Ben through a window (perhaps R&N are aware of the fact that Turing famously held at one point that a physical machine with the power of a universal Turing machine is physically impossible: he quipped that it would have to be the size of Big Ben), a planning algorithm described in Aristotle’s De Motu Animalium , Frege’s fascinating notation for first-order logic , a glimpse of Lewis Carroll’s (1958) pictorial representation of syllogistic reasoning, Ramon Lull’s concept-generating wheel from his 13 th -century Ars Magna , and a number of other pregnant items (including, in a clever, recursive, and bordering-on-self-congratulatory touch, a copy of AIMA itself). Though there is insufficient space here to make all the historical connections, we can safely infer from the appearance of these items (and here we of course refer to the ancient ones: Aristotle conceived of planning as information-processing over two-and-a-half millennia back; and in addition, as Glymour (1992) notes, Artistotle can also be credited with devising the first knowledge-bases and ontologies, two types of representation schemes that have long been central to AI) that AI is indeed very, very old. Even those who insist that AI is at least in part an artifact-building enterprise must concede that, in light of these objects, AI is ancient, for it isn’t just theorizing from the perspective that intelligence is at bottom computational that runs back into the remote past of human history: Lull’s wheel, for example, marks an attempt to capture intelligence not only in computation, but in a physical artifact that embodies that computation. [ 14 ] AIMA has now reached its the third edition, and those interested in the history of AI, and for that matter the history of philosophy of mind, will not be disappointed by examination of the cover of the third installment (the cover of the second edition is almost exactly like the first edition). (All the elements of the cover, separately listed and annotated, can be found online .) One significant addition to the cover of the third edition is a drawing of Thomas Bayes; his appearance reflects the recent rise in the popularity of probabilistic techniques in AI, which we discuss later. One final point about the history of AI seems worth making. It is generally assumed that the birth of modern-day AI in the 1950s came in large part because of and through the advent of the modern high-speed digital computer. This assumption accords with common-sense. After all, AI (and, for that matter, to some degree its cousin, cognitive science, particularly computational cognitive modeling, the sub-field of cognitive science devoted to producing computational simulations of human cognition) is aimed at implementing intelligence in a computer, and it stands to reason that such a goal would be inseparably linked with the advent of such devices. However, this is only part of the story: the part that reaches back but to Turing and others (e.g., von Neuman) responsible for the first electronic computers. The other part is that, as already mentioned, AI has a particularly strong tie, historically speaking, to reasoning (logic-based and, in the need to deal with uncertainty, inductive/probabilistic reasoning). In this story, nicely told by Glymour (1992), a search for an answer to the question “What is a proof?” eventually led to an answer based on Frege’s version of first-order logic (FOL): a (finitary) mathematical proof consists in a series of step-by-step inferences from one formula of first-order logic to the next. The obvious extension of this answer (and it isn’t a complete answer, given that lots of classical mathematics, despite conventional wisdom, clearly can’t be expressed in FOL; even the Peano Axioms, to be expressed as a finite set of formulae, require S OL) is to say that not only mathematical thinking, but thinking, period, can be expressed in FOL. (This extension was entertained by many logicians long before the start of information-processing psychology and cognitive science – a fact some cognitive psychologists and cognitive scientists often seem to forget.) Today, logic-based AI is only part of AI, but the point is that this part still lives (with help from logics much more powerful, but much more complicated, than FOL), and it can be traced all the way back to Aristotle’s theory of the syllogism. [ 15 ] In the case of uncertain reasoning, the question isn’t “What is a proof?”, but rather questions such as “What is it rational to believe, in light of certain observations and probabilities?” This is a question posed and tackled long before the arrival of digital computers. 2. What Exactly is AI? So far we have been proceeding as if we have a firm and precise grasp of the nature of AI. But what exactly is AI? Philosophers arguably know better than anyone that precisely defining a particular discipline to the satisfaction of all relevant parties (including those working in the discipline itself) can be acutely challenging. Philosophers of science certainly have proposed credible accounts of what constitutes at least the general shape and texture of a given field of science and/or engineering, but what exactly is the agreed-upon definition of physics? What about biology? What, for that matter, is philosophy, exactly? These are remarkably difficult, maybe even eternally unanswerable, questions, especially if the target is a consensus definition. Perhaps the most prudent course we can manage here under obvious space constraints is to present in encapsulated form some proposed definitions of AI. We do include a glimpse of recent attempts to define AI in detailed, rigorous fashion (and we suspect that such attempts will be of interest to philosophers of science, and those interested in this sub-area of philosophy). Russell and Norvig (1995, 2002, 2009), in their aforementioned AIMA text, provide a set of possible answers to the “What is AI?” question that has considerable currency in the field itself. These answers all assume that AI should be defined in terms of its goals: a candidate definition thus has the form “AI is the field that aims at building …” The answers all fall under a quartet of types placed along two dimensions. One dimension is whether the goal is to match human performance, or, instead, ideal rationality. The other dimension is whether the goal is to build systems that reason/think, or rather systems that act. The situation is summed up in this table: Human-Based Ideal Rationality Reasoning-Based: Systems that think like humans. Systems that think rationally. Behavior-Based: Systems that act like humans. Systems that act rationally. Four Possible Goals for AI According to AIMA Please note that this quartet of possibilities does reflect (at least a significant portion of) the relevant literature. For example, philosopher John Haugeland (1985) falls into the Human/Reasoning quadrant when he says that AI is “The exciting new effort to make computers think … machines with minds , in the full and literal sense.” (By far, this is the quadrant that most popular narratives affirm and explore. The recent Westworld TV series is a powerful case in point.) Luger and Stubblefield (1993) seem to fall into the Ideal/Act quadrant when they write: “The branch of computer science that is concerned with the automation of intelligent behavior.” The Human/Act position is occupied most prominently by Turing, whose test is passed only by those systems able to act sufficiently like a human. The “thinking rationally” position is defended (e.g.) by Winston (1992). While it might not be entirely uncontroversial to assert that the four bins given here are exhaustive, such an assertion appears to be quite plausible, even when the literature up to the present moment is canvassed. It’s important to know that the contrast between the focus on systems that think/reason versus systems that act, while found, as we have seen, at the heart of the AIMA texts, and at the heart of AI itself, should not be interpreted as implying that AI researchers view their work as falling all and only within one of these two compartments. Researchers who focus more or less exclusively on knowledge representation and reasoning, are also quite prepared to acknowledge that they are working on (what they take to be) a central component or capability within any one of a family of larger systems spanning the reason/act distinction. The clearest case may come from the work on planning – an AI area traditionally making central use of representation and reasoning. For good or ill, much of this research is done in abstraction (in vitro, as opposed to in vivo), but the researchers involved certainly intend or at least hope that the results of their work can be embedded into systems that actually do things, such as, for example, execute the plans. What about Russell and Norvig themselves? What is their answer to the What is AI? question? They are firmly in the “acting rationally” camp. In fact, it’s safe to say both that they are the chief proponents of this answer, and that they have been remarkably successful evangelists. Their extremely influential AIMA series can be viewed as a book-length defense and specification of the Ideal/Act category. We will look a bit later at how Russell and Norvig lay out all of AI in terms of intelligent agents , which are systems that act in accordance with various ideal standards for rationality. But first let’s look a bit closer at the view of intelligence underlying the AIMA text. We can do so by turning to Russell (1997). Here Russell recasts the “What is AI?” question as the question “What is intelligence?” (presumably under the assumption that we have a good grasp of what an artifact is), and then he identifies intelligence with rationality . More specifically, Russell sees AI as the field devoted to building intelligent agents , which are functions taking as input tuples of percepts from the external environment, and producing behavior (actions) on the basis of these percepts. Russell’s overall picture is this one: The Basic Picture Underlying Russell’s Account of Intelligence/Rationality Let’s unpack this diagram a bit, and take a look, first, at the account of perfect rationality that can be derived from it. The behavior of the agent in the environment \(E\) (from a class \(\bE\) of environments) produces a sequence of states or snapshots of that environment. A performance measure \(U\) evaluates this sequence; notice the box labeled “Performance Measure” in the above figure. We let \(V(f,\bE,U)\) denote the expected utility according to \(U\) of the agent function \(f\) operating on \(\bE\). [ 16 ] Now we identify a perfectly rational agent with the agent function: \[\tag{1}\label{eq1} f_{\opt} = \argmax_f V(f,\bE,U) \] According to the above equation, a perfectly rational agent can be taken to be the function \(f_{opt}\) which produces the maximum expected utility in the environment under consideration. Of course, as Russell points out, it’s usually not possible to actually build perfectly rational agents. For example, though it’s easy enough to specify an algorithm for playing invincible chess, it’s not feasible to implement this algorithm. What traditionally happens in AI is that programs that are – to use Russell’s apt terminology – calculatively rational are constructed instead: these are programs that, if executed infinitely fast , would result in perfectly rational behavior. In the case of chess, this would mean that we strive to write a program that runs an algorithm capable, in principle, of finding a flawless move, but we add features that truncate the search for this move in order to play within intervals of digestible duration. Russell himself champions a new brand of intelligence/rationality for AI; he calls this brand bounded optimality . To understand Russell’s view, first we follow him in introducing a distinction: We say that agents have two components: a program, and a machine upon which the program runs. We write \(Agent(P, M)\) to denote the agent function implemented by program \(P\) running on machine \(M\). Now, let \(\mathcal{P}(M)\) denote the set of all programs \(P\) that can run on machine \(M\). The bounded optimal program \(P_{\opt,M}\) then is: \[ P_{\opt,M}=\argmax_{P\in\mathcal{P}(M)}V(\mathit{Agent}(P,M),\bE,U) \] You can understand this equation in terms of any of the mathematical idealizations for standard computation. For example, machines can be identified with Turing machines minus instructions (i.e., TMs are here viewed architecturally only: as having tapes divided into squares upon which symbols can be written, read/write heads capable of moving up and down the tape to write and erase, and control units which are in one of a finite number of states at any time), and programs can be identified with instructions in the Turing-machine model (telling the machine to write and erase symbols, depending upon what state the machine is in). So, if you are told that you must “program” within the constraints of a 22-state Turing machine, you could search for the “best” program given those constraints. In other words, you could strive to find the optimal program within the bounds of the 22-state architecture. Russell’s (1997) view is thus that AI is the field devoted to creating optimal programs for intelligent agents, under time and space constraints on the machines implementing these programs. [ 17 ] The reader must have noticed that in the equation for \(P_{\opt,M}\) we have not elaborated on \(\bE\) and \(U\) and how equation \eqref{eq1} might be used to construct an agent if the class of environments \(\bE\) is quite general, or if the true environment \(E\) is simply unknown. Depending on the task for which one is constructing an artificial agent, \(E\) and \(U\) would vary. The mathematical form of the environment \(E\) and the utility function \(U\) would vary wildly from, say, chess to Jeopardy! . Of course, if we were to design a globally intelligent agent, and not just a chess-playing agent, we could get away with having just one pair of \(E\) and \(U\). What would \(E\) look like if we were building a generally intelligent agent and not just an agent that is good at a single task? \(E\) would be a model of not just a single game or a task, but the entire physical-social-virtual universe consisting of many games, tasks, situations, problems, etc. This project is (at least currently) hopelessly difficult as, obviously, we are nowhere near to having such a comprehensive theory-of-everything model. For further discussion of a theoretical architecture put forward for this problem, see the Supplement on the AIXI architecture . It should be mentioned that there is a different, much more straightforward answer to the “What is AI?” question. This answer, which goes back to the days of the original Dartmouth conference, was expressed by, among others, Newell (1973), one of the grandfathers of modern-day AI (recall that he attended the 1956 conference); it is: AI is the field devoted to building artifacts that are intelligent, where ‘intelligent’ is operationalized through intelligence tests (such as the Wechsler Adult Intelligence Scale), and other tests of mental ability (including, e.g., tests of mechanical ability, creativity, and so on). The above definition can be seen as fully specifying a concrete version of Russell and Norvig’s four possible goals. Though few are aware of this now, this answer was taken quite seriously for a while, and in fact underlied one of the most famous programs in the history of AI: the ANALOGY program of Evans (1968), which solved geometric analogy problems of a type seen in many intelligence tests. An attempt to rigorously define this forgotten form of AI (as what they dub Psychometric AI ), and to resurrect it from the days of Newell and Evans, is provided by Bringsjord and Schimanski (2003) [see also e.g. (Bringsjord 2011)]. A sizable private investment has been made in the ongoing attempt, now known as Project Aristo , to build a “digital Aristotle”, in the form of a machine able to excel on standardized tests such at the AP exams tackled by US high school students (Friedland et al. 2004). (Vibrant work in this direction continues today at the Allen Institute for Artificial Intelligence .) [ 18 ] In addition, researchers at Northwestern have forged a connection between AI and tests of mechanical ability (Klenk et al. 2005). In the end, as is the case with any discipline, to really know precisely what that discipline is requires you to, at least to some degree, dive in and do, or at least dive in and read. Two decades ago such a dive was quite manageable. Today, because the content that has come to constitute AI has mushroomed, the dive (or at least the swim after it) is a bit more demanding. 3. Approaches to AI There are a number of ways of “carving up” AI. By far the most prudent and productive way to summarize the field is to turn yet again to the AIMA text given its comprehensive overview of the field. 3.1 The Intelligent Agent Continuum As Russell and Norvig (2009) tell us in the Preface of AIMA : The main unifying theme is the idea of an intelligent agent. We define AI as the study of agents that receive percepts from the environment and perform actions. Each such agent implements a function that maps percept sequences to actions, and we cover different ways to represent these functions… (Russell & Norvig 2009, vii) The basic picture is thus summed up in this figure: Impressionistic Overview of an Intelligent Agent The content of AIMA derives, essentially, from fleshing out this picture; that is, the above figure corresponds to the different ways of representing the overall function that intelligent agents implement. And there is a progression from the least powerful agents up to the more powerful ones. The following figure gives a high-level view of a simple kind of agent discussed early in the book. (Though simple, this sort of agent corresponds to the architecture of representation-free agents designed and implemented by Rodney Brooks, 1991.) A Simple Reflex Agent As the book progresses, agents get increasingly sophisticated, and the implementation of the function they represent thus draws from more and more of what AI can currently muster. The following figure gives an overview of an agent that is a bit smarter than the simple reflex agent. This smarter agent has the ability to internally model the outside world, and is therefore not simply at the mercy of what can at the moment be directly sensed. A More Sophisticated Reflex Agent There are seven parts to AIMA . As the reader passes through these parts, she is introduced to agents that take on the powers discussed in each part. Part I is an introduction to the agent-based view. Part II is concerned with giving an intelligent agent the capacity to think ahead a few steps in clearly defined environments. Examples here include agents able to successfully play games of perfect information, such as chess. Part III deals with agents that have declarative knowledge and can reason in ways that will be quite familiar to most philosophers and logicians (e.g., knowledge-based agents deduce what actions should be taken to secure their goals). Part IV of the book outfits agents with the power to handle uncertainty by reasoning in probabilistic fashion. [ 19 ] In Part V, agents are given a capacity to learn. The following figure shows the overall structure of a learning agent. A Learning Agent The final set of powers agents are given allow them to communicate. These powers are covered in Part VI. Philosophers who patiently travel the entire progression of increasingly smart agents will no doubt ask, when reaching the end of Part VII, if anything is missing. Are we given enough, in general, to build an artificial person, or is there enough only to build a mere animal? This question is implicit in the following from Charniak and McDermott (1985): The ultimate goal of AI (which we are very far from achieving) is to build a person, or, more humbly, an animal. (Charniak & McDermott 1985, 7) To their credit, Russell & Norvig, in AIMA ’s Chapter 27, “AI: Present and Future,” consider this question, at least to some degree. [ ] They do so by considering some challenges to AI that have hitherto not been met. One of these challenges is described by R&N as follows: [M]achine learning has made very little progress on the important problem of constructing new representations at levels of abstraction higher than the input vocabulary. In computer vision, for example, learning complex concepts such as Classroom and Cafeteria would be made unnecessarily difficult if the agent were forced to work from pixels as the input representation; instead, the agent needs to be able to form intermediate concepts first, such as Desk and Tray, without explicit human supervision. Similar concepts apply to learning behavior: HavingACupOfTea is a very important high-level step in many plans, but how does it get into an action library that initially contains much simpler actions such as RaiseArm and Swallow? Perhaps this will incorporate deep belief networks – Bayesian networks that have multiple layers of hidden variables, as in the work of Hinton et al. (2006), Hawkins and Blakeslee (2004), and Bengio and LeCun (2007). … Unless we understand such issues, we are faced with the daunting task of constructing large commonsense knowledge bases by hand, and approach that has not fared well to date. (Russell & Norvig 2009, Ch. 27.1) While there has seen some advances in addressing this challenge (in the form of deep learning or representation learning ), this specific challenge is actually merely a foothill before a range of dizzyingly high mountains that AI must eventually somehow manage to climb. One of those mountains, put simply, is reading . [ 21 ] Despite the fact that, as noted, Part V of AIMA is devoted to machine learning, AI, as it stands, offers next to nothing in the way of a mechanization of learning by reading. Yet when you think about it, reading is probably the dominant way you learn at this stage in your life. Consider what you’re doing at this very moment. It’s a good bet that you are reading this sentence because, earlier, you set yourself the goal of learning about the field of AI. Yet the formal models of learning provided in AIMA ’s Part IV (which are all and only the models at play in AI) cannot be applied to learning by reading. [ 22 ] These models all start with a function-based view of learning. According to this view, to learn is almost invariably to produce an underlying function \(\ff\) on the basis of a restricted set of pairs \[ \left\{\left\langle x_1, \ff(x_1)\right\rangle,\left\langle x_2, \ff(x_2)\right\rangle, \ldots, \left\langle x_n, \ff(x_n)\right\rangle\right\}. \] For example, consider receiving inputs consisting of 1, 2, 3, 4, and 5, and corresponding range values of 1, 4, 9, 16, and 25; the goal is to “learn” the underlying mapping from natural numbers to natural numbers. In this case, assume that the underlying function is \(n^2\), and that you do “learn” it. While this narrow model of learning can be productively applied to a number of processes, the process of reading isn’t one of them. Learning by reading cannot (at least for the foreseeable future) be modeled as divining a function that produces argument-value pairs. Instead, your reading about AI can pay dividends only if your knowledge has increased in the right way, and if that knowledge leaves you poised to be able to produce behavior taken to confirm sufficient mastery of the subject area in question. This behavior can range from correctly answering and justifying test questions regarding AI, to producing a robust, compelling presentation or paper that signals your achievement. Two points deserve to be made about machine reading. First, it may not be clear to all readers that reading is an ability that is central to intelligence. The centrality derives from the fact that intelligence requires vast knowledge. We have no other means of getting systematic knowledge into a system than to get it in from text, whether text on the web, text in libraries, newspapers, and so on. You might even say that the big problem with AI has been that machines really don’t know much compared to humans. That can only be because of the fact that humans read (or hear: illiterate people can listen to text being uttered and learn that way). Either machines gain knowledge by humans manually encoding and inserting knowledge, or by reading and listening. These are brute facts. (We leave aside supernatural techniques, of course. Oddly enough, Turing didn’t: he seemed to think ESP should be discussed in connection with the powers of minds and machines. See Turing, 1950.) [ 23 ] Now for the second point. Humans able to read have invariably also learned a language, and learning languages has been modeled in conformity to the function-based approach adumbrated just above (Osherson et al. 1986). However, this doesn’t entail that an artificial agent able to read, at least to a significant degree, must have really and truly learned a natural language. AI is first and foremost concerned with engineering computational artifacts that measure up to some test (where, yes, sometimes that test is from the human sphere), not with whether these artifacts process information in ways that match those present in the human case. It may or may not be necessary, when engineering a machine that can read, to imbue that machine with human-level linguistic competence. The issue is empirical, and as time unfolds, and the engineering is pursued, we shall no doubt see the issue settled. Two additional high mountains facing AI are subjective consciousness and creativity, yet it would seem that these great challenges are ones the field apparently hasn’t even come to grips with. Mental phenomena of paramount importance to many philosophers of mind and neuroscience are simply missing from AIMA . For example, consciousness is only mentioned in passing in AIMA , but subjective consciousness is the most important thing in our lives – indeed we only desire to go on living because we wish to go on enjoying subjective states of certain types. Moreover, if human minds are the product of evolution, then presumably phenomenal consciousness has great survival value, and would be of tremendous help to a robot intended to have at least the behavioral repertoire of the first creatures with brains that match our own (hunter-gatherers; see Pinker 1997). Of course, subjective consciousness is largely missing from the sister fields of cognitive psychology and computational cognitive modeling as well. We discuss some of these challenges in the Philosophy of Artificial Intelligence section below. For a list of similar challenges to cognitive science, see the relevant section of the entry on cognitive science . [ 24 ] To some readers, it might seem in the very least tendentious to point to subjective consciousness as a major challenge to AI that it has yet to address. These readers might be of the view that pointing to this problem is to look at AI through a distinctively philosophical prism, and indeed a controversial philosophical standpoint. But as its literature makes clear, AI measures itself by looking to animals and humans and picking out in them remarkable mental powers, and by then seeing if these powers can be mechanized. Arguably the power most important to humans (the capacity to experience) is nowhere to be found on the target list of most AI researchers. There may be a good reason for this (no formalism is at hand, perhaps), but there is no denying the state of affairs in question obtains, and that, in light of how AI measures itself, that it’s worrisome. As to creativity, it’s quite remarkable that the power we most praise in human minds is nowhere to be found in AIMA . Just as in (Charniak & McDermott 1985) one cannot find ‘neural’ in the index, ‘creativity’ can’t be found in the index of AIMA . This is particularly odd because many AI researchers have in fact worked on creativity (especially those coming out of philosophy; e.g., Boden 1994, Bringsjord & Ferrucci 2000). Although the focus has been on AIMA , any of its counterparts could have been used. As an example, consider Artificial Intelligence: A New Synthesis , by Nils Nilsson. As in the case of AIMA , everything here revolves around a gradual progression from the simplest of agents (in Nilsson’s case, reactive agents ), to ones having more and more of those powers that distinguish persons. Energetic readers can verify that there is a striking parallel between the main sections of Nilsson’s book and AIMA . In addition, Nilsson, like Russell and Norvig, ignores phenomenal consciousness, reading, and creativity. None of the three are even mentioned. Likewise, a recent comprehensive AI textbook by Luger (2008) follows the same pattern. A final point to wrap up this section. It seems quite plausible to hold that there is a certain inevitability to the structure of an AI textbook, and the apparent reason is perhaps rather interesting. In personal conversation, Jim Hendler, a well-known AI researcher who is one of the main innovators behind Semantic Web (Berners-Lee, Hendler, Lassila 2001), an under-development “AI-ready” version of the World Wide Web, has said that this inevitability can be rather easily displayed when teaching Introduction to AI; here’s how. Begin by asking students what they think AI is. Invariably, many students will volunteer that AI is the field devoted to building artificial creatures that are intelligent. Next, ask for examples of intelligent creatures. Students always respond by giving examples across a continuum: simple multi-cellular organisms, insects, rodents, lower mammals, higher mammals (culminating in the great apes), and finally human persons. When students are asked to describe the differences between the creatures they have cited, they end up essentially describing the progression from simple agents to ones having our (e.g.) communicative powers. This progression gives the skeleton of every comprehensive AI textbook. Why does this happen? The answer seems clear: it happens because we can’t resist conceiving of AI in terms of the powers of extant creatures with which we are familiar. At least at present, persons, and the creatures who enjoy only bits and pieces of personhood, are – to repeat – the measure of AI. [ 25 ] 3.2 Logic-Based AI: Some Surgical Points Reasoning based on classical deductive logic is monotonic; that is, if \(\Phi\vdash\phi\), then for all \(\psi\), \(\Phi\cup \{\psi\}\vdash\phi\). Commonsense reasoning is not monotonic. While you may currently believe on the basis of reasoning that your house is still standing, if while at work you see on your computer screen that a vast tornado is moving through the location of your house, you will drop this belief. The addition of new information causes previous inferences to fail. In the simpler example that has become an AI staple, if I tell you that Tweety is a bird, you will infer that Tweety can fly, but if I then inform you that Tweety is a penguin, the inference evaporates, as well it should. Nonmonotonic (or defeasible) logic includes formalisms designed to capture the mechanisms underlying these kinds of examples. See the separate entry on logic and artificial intelligence , which is focused on nonmonotonic reasoning, and reasoning about time and change. It also provides a history of the early days of logic-based AI, making clear the contributions of those who founded the tradition (e.g., John McCarthy and Pat Hayes; see their seminal 1969 paper). The formalisms and techniques of logic-based AI have reached a level of impressive maturity – so much so that in various academic and corporate laboratories, implementations of these formalisms and techniques can be used to engineer robust, real-world software. It is strongly recommend that readers who have an interest to learn where AI stands in these areas consult (Mueller 2006), which provides, in one volume, integrated coverage of nonmonotonic reasoning (in the form, specifically, of circumscription), and reasoning about time and change in the situation and event calculi. (The former calculus is also introduced by Thomason. In the second, timepoints are included, among other things.) The other nice thing about (Mueller 2006) is that the logic used is multi-sorted first-order logic (MSL), which has unificatory power that will be known to and appreciated by many technical philosophers and logicians (Manzano 1996). We now turn to three further topics of importance in AI. They are: The overarching scheme of logicist AI, in the context of the attempt to build intelligent artificial agents. Common Logic and the intensifying quest for interoperability. A technique that can be called encoding down , which can allow machines to reason efficiently over knowledge that, were it not encoded down, would, when reasoned over, lead to paralyzing inefficiency. This trio is covered in order, beginning with the first. Detailed accounts of logicist AI that fall under the agent-based scheme can be found in (Lenat 1983, Lenat & Guha 1990, Nilsson 1991, Bringsjord & Ferrucci 1998). [ 26 ] . The core idea is that an intelligent agent receives percepts from the external world in the form of formulae in some logical system (e.g., first-order logic), and infers, on the basis of these percepts and its knowledge base, what actions should be performed to secure the agent’s goals. (This is of course a barbaric simplification. Information from the external world is encoded in formulae, and transducers to accomplish this feat may be components of the agent.) To clarify things a bit, we consider, briefly, the logicist view in connection with arbitrary logical systems \(\mathcal{L}_{X}\). [ 27 ] We obtain a particular logical system by setting \(X\) in the appropriate way. Some examples: If \(X=I\), then we have a system at the level of FOL [following the standard notation from model theory; see e.g. (Ebbinghaus et al. 1984)]. \(\mathcal{L}_{II}\) is second-order logic, and \(\mathcal{L}_{\omega_I\omega}\) is a “small system” of infinitary logic (countably infinite conjunctions and disjunctions are permitted). These logical systems are all extensional , but there are intensional ones as well. For example, we can have logical systems corresponding to those seen in standard propositional modal logic (Chellas 1980). One possibility, familiar to many philosophers, would be propositional KT45, or \(\mathcal{L}_{KT45}\). [ 28 ] In each case, the system in question includes a relevant alphabet from which well-formed formulae are constructed by way of a formal grammar, a reasoning (or proof) theory, a formal semantics, and at least some meta-theoretical results (soundness, completeness, etc.). Taking off from standard notation, we can thus say that a set of formulas in some particular logical system \(\mathcal{L}_X\), \(\Phi_{\mathcal{L}_X}\), can be used, in conjunction with some reasoning theory, to infer some particular formula \(\phi_{\mathcal{L}_X}\). (The reasoning may be deductive, inductive, abductive, and so on. Logicist AI isn’t in the least restricted to any particular mode of reasoning.) To say that such a situation holds, we write \[ \Phi_{\mathcal{L}_X} \vdash_{\mathcal{L}_X} \phi_{\mathcal{L}_X} \] When the logical system referred to is clear from context, or when we don’t care about which logical system is involved, we can simply write \[ \Phi \vdash \phi \] Each logical system, in its formal semantics, will include objects designed to represent ways the world pointed to by formulae in this system can be. Let these ways be denoted by \(W^i_{{\mathcal{L}_X}}\). When we aren’t concerned with which logical system is involved, we can simply write \(W^i\). To say that such a way models a formula \(\phi\) we write \[ W_i \models \phi \] We extend this to a set of formulas in the natural way: \(W^i\models\Phi\) means that all the elements of \(\Phi\) are true on \(W^i\). Now, using the simple machinery we’ve established, we can describe, in broad strokes, the life of an intelligent agent that conforms to the logicist point of view. This life conforms to the basic cycle that undergirds intelligent agents in the AIMA sense. To begin, we assume that the human designer, after studying the world, uses the language of a particular logical system to give to our agent an initial set of beliefs \(\Delta_0\) about what this world is like. In doing so, the designer works with a formal model of this world, \(W\), and ensures that \(W\models\Delta_0\). Following tradition, we refer to \(\Delta_0\) as the agent’s (starting) knowledge base . (This terminology, given that we are talking about the agent’s beliefs , is known to be peculiar, but it persists.) Next, the agent ADJUSTS its knowlege base to produce a new one, \(\Delta_1\). We say that adjustment is carried out by way of an operation \(\mathcal{A}\); so \(\mathcal{A}[\Delta_0]=\Delta_1\). How does the adjustment process, \(\mathcal{A}\), work? There are many possibilities. Unfortunately, many believe that the simplest possibility (viz., \(\mathcal{A}[\Delta_i]\) equals the set of all formulas that can be deduced in some elementary manner from \(\Delta_i\)) exhausts all the possibilities. The reality is that adjustment, as indicated above, can come by way of any mode of reasoning – induction, abduction, and yes, various forms of deduction corresponding to the logical system in play. For present purposes, it’s not important that we carefully enumerate all the options. The cycle continues when the agent ACTS on the environment, in an attempt to secure its goals. Acting, of course, can cause changes to the environment. At this point, the agent SENSES the environment, and this new information \(\Gamma_1\) factors into the process of adjustment, so that \(\mathcal{A}[\Delta_1\cup\Gamma_1]=\Delta_2\). The cycle of SENSES \(\Rightarrow\) ADJUSTS \(\Rightarrow\) ACTS continues to produce the life \(\Delta_0,\Delta_1,\Delta_2,\Delta_3,\ldots,\) … of our agent. It may strike you as preposterous that logicist AI be touted as an approach taken to replicate all of cognition. Reasoning over formulae in some logical system might be appropriate for computationally capturing high-level tasks like trying to solve a math problem (or devising an outline for an entry in the Stanford Encyclopedia of Philosophy), but how could such reasoning apply to tasks like those a hawk tackles when swooping down to capture scurrying prey? In the human sphere, the task successfully negotiated by athletes would seem to be in the same category. Surely, some will declare, an outfielder chasing down a fly ball doesn’t prove theorems to figure out how to pull off a diving catch to save the game! Two brutally reductionistic arguments can be given in support of this “logicist theory of everything” approach towards cognition. The first stems from the fact that a complete proof calculus for just first-order logic can simulate all of Turing-level computation (Chapter 11, Boolos et al. 2007). The second justification comes from the role logic plays in foundational theories of mathematics and mathematical reasoning. Not only are foundational theories of mathematics cast in logic (Potter 2004), but there have been successful projects resulting in machine verification of ordinary non-trivial theorems, e.g., in the Mizar project alone around 50,000 theorems have been verified (Naumowicz and Kornilowicz 2009). The argument goes that if any approach to AI can be cast mathematically, then it can be cast in a logicist form. Needless to say, such a declaration has been carefully considered by logicists beyond the reductionistic argument given above. For example, Rosenschein and Kaelbling (1986) describe a method in which logic is used to specify finite state machines. These machines are used at “run time” for rapid, reactive processing. In this approach, though the finite state machines contain no logic in the traditional sense, they are produced by logic and inference. Real robot control via first-order theorem proving has been demonstrated by Amir and Maynard-Reid (1999, 2000, 2001). In fact, you can download version 2.0 of the software that makes this approach real for a Nomad 200 mobile robot in an office environment. Of course, negotiating an office environment is a far cry from the rapid adjustments an outfielder for the Yankees routinely puts on display, but certainly it’s an open question as to whether future machines will be able to mimic such feats through rapid reasoning. The question is open if for no other reason than that all must concede that the constant increase in reasoning speed of first-order theorem provers is breathtaking. (For up-to-date news on this increase, visit and monitor the TPTP site .) There is no known reason why the software engineering in question cannot continue to produce speed gains that would eventually allow an artificial creature to catch a fly ball by processing information in purely logicist fashion. Now we come to the second topic related to logicist AI that warrants mention herein: common logic and the intensifying quest for interoperability between logic-based systems using different logics. Only a few brief comments are offered. [ 29 ] Readers wanting more can explore the links provided in the course of the summary. One standardization is through what is known as Common Logic (CL), and variants thereof. (CL is published as an ISO standard – ISO is the International Standards Organization.) Philosophers interested in logic, and of course logicians, will find CL to be quite fascinating. From an historical perspective, the advent of CL is interesting in no small part because the person spearheading it is none other than Pat Hayes, the same Hayes who, as we have seen, worked with McCarthy to establish logicist AI in the 1960s. Though Hayes was not at the original 1956 Dartmouth conference, he certainly must be regarded as one of the founders of contemporary AI.) One of the interesting things about CL, at least as we see it, is that it signifies a trend toward the marriage of logics, and programming languages and environments. Another system that is a logic/programming hybrid is Athena , which can be used as a programming language, and is at the same time a form of MSL. Athena is based on formal systems known as denotational proof languages (Arkoudas 2000). How is interoperability between two systems to be enabled by CL? Suppose one of these systems is based on logic \(L\), and the other on \(L'\). (To ease exposition, assume that both logics are first-order.) The idea is that a theory \(\Phi_L\), that is, a set of formulae in \(L\), can be translated into CL, producing \(\Phi_{CL}\), and then this theory can be translated into \(\Phi_L'\). CL thus becomes an inter lingua . Note that what counts as a well-formed formula in \(L\) can be different than what counts as one in \(L'\). The two logics might also have different proof theories. For example, inference in \(L\) might be based on resolution, while inference in \(L'\) is of the natural deduction variety. Finally, the symbol sets will be different. Despite these differences, courtesy of the translations, desired behavior can be produced across the translation. That, at any rate, is the hope. The technical challenges here are immense, but federal monies are increasingly available for attacks on the problem of interoperability. Now for the third topic in this section: what can be called encoding down . The technique is easy to understand. Suppose that we have on hand a set \(\Phi\) of first-order axioms. As is well-known, the problem of deciding, for arbitrary formula \(\phi\), whether or not it’s deducible from \(\Phi\) is Turing-undecidable: there is no Turing machine or equivalent that can correctly return “Yes” or “No” in the general case. However, if the domain in question is finite, we can encode this problem down to the propositional calculus. An assertion that all things have \(F\) is of course equivalent to the assertion that \(Fa\), \(Fb\), \(Fc\), as long as the domain contains only these three objects. So here a first-order quantified formula becomes a conjunction in the propositional calculus. Determining whether such conjunctions are provable from axioms themselves expressed in the propositional calculus is Turing-decidable, and in addition, in certain clusters of cases, the check can be done very quickly in the propositional case; very quickly . Readers interested in encoding down to the propositional calculus should consult recent DARPA-sponsored work by Bart Selman . Please note that the target of encoding down doesn’t need to be the propositional calculus. Because it’s generally harder for machines to find proofs in an intensional logic than in straight first-order logic, it is often expedient to encode down the former to the latter. For example, propositional modal logic can be encoded in multi-sorted logic (a variant of FOL); see (Arkoudas & Bringsjord 2005). Prominent usage of such an encoding down can be found in a set of systems known as Description Logics , which are a set of logics less expressive than first-order logic but more expressive than propositional logic (Baader et al. 2003). Description logics are used to reason about ontologies in a given domain and have been successfully used, for example, in the biomedical domain (Smith et al. 2007). 3.3 Non-Logicist AI: A Summary It’s tempting to define non-logicist AI by negation: an approach to building intelligent agents that rejects the distinguishing features of logicist AI. Such a shortcut would imply that the agents engineered by non-logicist AI researchers and developers, whatever the virtues of such agents might be, cannot be said to know that \(\phi\); – for the simple reason that, by negation, the non-logicist paradigm would have not even a single declarative proposition that is a candidate for \(\phi\);. However, this isn’t a particularly enlightening way to define non-symbolic AI. A more productive approach is to say that non-symbolic AI is AI carried out on the basis of particular formalisms other than logical systems, and to then enumerate those formalisms. It will turn out, of course, that these formalisms fail to include knowledge in the normal sense. (In philosophy, as is well-known, the normal sense is one according to which if \(p\) is known, \(p\) is a declarative statement.) From the standpoint of formalisms other than logical systems, non-logicist AI can be partitioned into symbolic but non-logicist approaches, and connectionist/neurocomputational approaches. (AI carried out on the basis of symbolic, declarative structures that, for readability and ease of use, are not treated directly by researchers as elements of formal logics, does not count. In this category fall traditional semantic networks, Schank’s (1972) conceptual dependency scheme, frame-based schemes, and other such schemes.) The former approaches, today, are probabilistic, and are based on the formalisms (Bayesian networks) covered below . The latter approaches are based, as we have noted, on formalisms that can be broadly termed “neurocomputational.” Given our space constraints, only one of the formalisms in this category is described here (and briefly at that): the aforementioned artificial neural networks . [ 30 ] . Though artificial neural networks, with an appropriate architecture, could be used for arbitrary computation, they are almost exclusively used for building learning systems. Neural nets are composed of units or nodes designed to represent neurons, which are connected by links designed to represent dendrites, each of which has a numeric weight . A “Neuron” Within an Artificial Neural Network (from AIMA3e) It is usually assumed that some of the units work in symbiosis with the external environment; these units form the sets of input and output units. Each unit has a current activation level , which is its output, and can compute, based on its inputs and weights on those inputs, its activation level at the next moment in time. This computation is entirely local: a unit takes account of but its neighbors in the net. This local computation is calculated in two stages. First, the input function , \(in_i\), gives the weighted sum of the unit’s input values, that is, the sum of the input activations multiplied by their weights: \[ in_i = \displaystyle\sum_j W_{ji} a_j \] In the second stage, the activation function , \(g\), takes the input from the first stage as argument and generates the output, or activation level, \(a_i\): \[ a_i = g(in_i) = g \left(\displaystyle\sum_j W_{ji}a_j\right) \] One common (and confessedly elementary) choice for the activation function (which usually governs all units in a given net) is the step function, which usually has a threshold \(t\) that sees to it that a 1 is output when the input is greater than \(t\), and that 0 is output otherwise. This is supposed to be “brain-like” to some degree, given that 1 represents the firing of a pulse from a neuron through an axon, and 0 represents no firing. A simple three-layer neural net is shown in the following picture. A Simple Three-Layer Artificial Neural Network (from AIMA3e) As you might imagine, there are many different kinds of neural networks. The main distinction is between feed-forward and recurrent networks. In feed-forward networks like the one pictured immediately above, as their name suggests, links move information in one direction, and there are no cycles; recurrent networks allow for cycling back, and can become rather complicated. For a more detailed presentation, see the Supplement on Neural Nets . Neural networks were fundamentally plagued by the fact that while they are simple and have theoretically efficient learning algorithms, when they are multi-layered and thus sufficiently expressive to represent non-linear functions, they were very hard to train in practice. This changed in the mid 2000s with the advent of methods that exploit state-of-the-art hardware better (Rajat et al. 2009). The backpropagation method for training multi-layered neural networks can be translated into a sequence of repeated simple arithmetic operations on a large set of numbers. The general trend in computing hardware has favored algorithms that are able to do a large of number of simple operations that are not that dependent on each other, versus a small of number of complex and intricate operations. Another key recent observation is that deep neural networks can be pre-trained first in an unsupervised phase where they are just fed data without any labels for the data. Each hidden layer is forced to represent the outputs of the layer below. The outcome of this training is a series of layers which represent the input domain with increasing levels of abstraction. For example, if we pre-train the network with images of faces, we would get a first layer which is good at detecting edges in images, a second layer which can combine edges to form facial features such as eyes, noses etc., a third layer which responds to groups of features, and so on (LeCun et al. 2015). Perhaps the best technique for teaching students about neural networks in the context of other statistical learning formalisms and methods is to focus on a specific problem, preferably one that seems unnatural to tackle using logicist techniques. The task is then to seek to engineer a solution to the problem, using any and all techniques available . One nice problem is handwriting recognition (which also happens to have a rich philosophical dimension; see e.g. Hofstadter & McGraw 1995). For example, consider the problem of assigning, given as input a handwritten digit \(d\), the correct digit, 0 through 9. Because there is a database of 60,000 labeled digits available to researchers (from the National Institute of Science and Technology), this problem has evolved into a benchmark problem for comparing learning algorithms. It turns out that neural networks currently reign as the best approach to the problem according to a recent ranking by Benenson (2016). Readers interested in AI (and computational cognitive science) pursued from an overtly brain-based orientation are encouraged to explore the work of Rick Granger (2004a, 2004b) and researchers in his Brain Engineering Laboratory and W. H. Neukom Institute for Computational Sciences . The contrast between the “dry”, logicist AI started at the original 1956 conference, and the approach taken here by Granger and associates (in which brain circuitry is directly modeled) is remarkable. For those interested in computational properties of neural networks, Hornik et al. (1989) address the general representation capability of neural networks independent of learning. 3.4 AI Beyond the Clash of Paradigms At this point the reader has been exposed to the chief formalisms in AI, and may wonder about heterogeneous approaches that bridge them. Is there such research and development in AI? Yes. From an engineering standpoint, such work makes irresistibly good sense. There is now an understanding that, in order to build applications that get the job done, one should choose from a toolbox that includes logicist, probabilistic/Bayesian, and neurocomputational techniques. Given that the original top-down logicist paradigm is alive and thriving (e.g., see Brachman & Levesque 2004, Mueller 2006), and that, as noted, a resurgence of Bayesian and neurocomputational approaches has placed these two paradigms on solid, fertile footing as well, AI now moves forward, armed with this fundamental triad, and it is a virtual certainty that applications (e.g., robots) will be engineered by drawing from elements of all three. Watson’s DeepQA architecture is one recent example of an engineering system that leverages multiple paradigms. For a detailed discussion, see the Supplement on Watson’s DeepQA Architecture . Google DeepMind’s AlphaGo is another example of a multi-paradigm system, although in a much narrower form than Watson. The central algorithmic problem in games such as Go or Chess is to search through a vast sequence of valid moves. For most non-trivial games, this is not feasible to do so exhaustively. The Monte Carlo tree search (MCTS) algorithm gets around this obstacle by searching through an enormous space of valid moves in a statistical fashion (Browne et al. 2012). While MCTS is the central algorithm in AlpaGo, there are two neural networks which help evaluate states in the game and help model how expert opponents play (Silver et al. 2016). It should be noted that MCTS is behind almost all the winning submissions in general game playing (Finnsson 2012). What, though, about deep, theoretical integration of the main paradigms in AI? Such integration is at present only a possibility for the future, but readers are directed to the research of some striving for such integration. For example: Sun (1994, 2002) has been working to demonstrate that human cognition that is on its face symbolic in nature (e.g., professional philosophizing in the analytic tradition, which deals explicitly with arguments and definitions carefully symbolized) can arise from cognition that is neurocomputational in nature. Koller (1997) has investigated the marriage between probability theory and logic. And, in general, the very recent arrival of so-called human-level AI is being led by theorists seeking to genuinely integrate the three paradigms set out above (e.g., Cassimatis 2006). Finally, we note that cognitive architectures such as Soar (Laird 2012) and PolyScheme (Cassimatis 2006) are another area where integration of different fields of AI can be found. For example, one such endeavor striving to build human-level AI is the Companions project (Forbus and Hinrichs 2006). Companions are long-lived systems that strive to be human-level AI systems that function as collaborators with humans. The Companions architecture tries to solve multiple AI problems such as reasoning and learning, interactivity, and longevity in one unifying system. 4. The Explosive Growth of AI As we noted above, work on AI has mushroomed over the past couple of decades. Now that we have looked a bit at the content that composes AI, we take a quick look at the explosive growth of AI. First, a point of clarification. The growth of which we speak is not a shallow sort correlated with amount of funding provided for a given sub-field of AI. That kind of thing happens all the time in all fields, and can be triggered by entirely political and financial changes designed to grow certain areas, and diminish others. Along the same line, the growth of which we speak is not correlated with the amount of industrial activity revolving around AI (or a sub-field thereof); for this sort of growth too can be driven by forces quite outside an expansion in the scientific breadth of AI. [ 31 ] Rather, we are speaking of an explosion of deep content : new material which someone intending to be conversant with the field needs to know. Relative to other fields, the size of the explosion may or may not be unprecedented. (Though it should perhaps be noted that an analogous increase in philosophy would be marked by the development of entirely new formalisms for reasoning, reflected in the fact that, say, longstanding philosophy textbooks like Copi’s (2004) Introduction to Logic are dramatically rewritten and enlarged to include these formalisms, rather than remaining anchored to essentially immutable core formalisms, with incremental refinement around the edges through the years.) But it certainly appears to be quite remarkable, and is worth taking note of here, if for no other reason than that AI’s near-future will revolve in significant part around whether or not the new content in question forms a foundation for new long-lived research and development that would not otherwise obtain. [ 32 ] AI has also witnessed an explosion in its usage in various artifacts and applications. While we are nowhere near building a machine with capabilities of a human or one that acts rationally in all scenarios according to the Russell/Hutter definition above, algorithms that have their origins in AI research are now widely deployed for many tasks in a variety of domains. 4.1 Bloom in Machine Learning A huge part of AI’s growth in applications has been made possible through invention of new algorithms in the subfield of machine learning . Machine learning is concerned with building systems that improve their performance on a task when given examples of ideal performance on the task, or improve their performance with repeated experience on the task. Algorithms from machine learning have been used in speech recognition systems, spam filters, online fraud-detection systems, product-recommendation systems, etc. The current state-of-the-art in machine learning can be divided into three areas (Murphy 2013, Alpaydin 2014): Supervised Learning : A form of learning in which a computer tries to learn a function \(\ff\) given examples, the training data \(T\), of its values at various points in its domain \[ T=\left\{\left\langle x_1, \ff(x_1)\right\rangle,\left\langle x_2, \ff(x_2)\right\rangle, \ldots, \left\langle x_n, \ff(x_n)\right\rangle\right\}. \] A sample task would be trying to label images of faces with a person’s name. The supervision in supervised learning comes in the form of the value of the function \(\ff(x)\) at various points \(x\) in some part of the domain of the function. This is usually given in the form of a fixed set of input and output pairs for the function. Let \(\hh\) be the “learned function.” The goal of supervised learning is have \({\hh}\) match as closely as possible the true function \({\ff}\) over the same domain. The error is usually defined in terms of an error function, for instance, \(error = \sum_{x\in T} \delta(\ff(x) - \hh(x))\), over the training data \(T\). Other forms of supervision and goals for learning are possible. For example, in active learning the learning algorithm can request the value of the function for arbitrary inputs. Supervised learning dominates the field of machine learning and has been used in almost all practical applications mentioned just above. Unsupervised Learning : Here the machine tries to find useful knowledge or information when given some raw data \(\left\{ x_1,x_2, \ldots, x_n \right\}\). There is no function associated with the input that has to be learned. The idea is that the machine helps uncover interesting patterns or information that could be hidden in the data. One use of unsupervised learning is data mining , where large volumes of data are searched for interesting information. PageRank , one of the earliest algorithms used by the Google search engine, can be considered to be an unsupervised learning system that ranks pages without any human supervision (Chapter 14.10, Hastie et al. 2009). Reinforcement Learning : Here a machine is set loose in an environment where it constantly acts and perceives (similar to the Russell/Hutter view above) and only occasionally receives feedback on its behavior in the form of rewards or punishments. The machine has to learn to behave rationally from this feedback. One use of reinforcement learning has been in building agents to play computer games. The objective here is to build agents that map sensory data from the game at every time instant to an action that would help win in the game or maximize a human player’s enjoyment of the game. In most games, we know how well we are playing only at the end of the game or only at infrequent intervals throughout the game (e.g., a chess game that we feel we are winning could quickly turn against us at the end). In supervised learning, the training data has ideal input-output pairs. This form of learning is not suitable for building agents that have to operate across a length of time and are judged not on one action but a series of actions and their effects on the environment. The field of Reinforcement Learning tries to tackle this problem through a variety of methods. Though a bit dated, Sutton and Barto (1998) provide a comprehensive introduction to the field. In addition to being used in domains that are traditionally the ken of AI, machine-learning algorithms have also been used in all stages of the scientific process. For example, machine-learning techniques are now routinely applied to analyze large volumes of data generated from particle accelerators. CERN, for instance, generates a petabyte (\(10^{15}\) bytes) per second, and statistical algorithms that have their origins in AI are used to filter and analyze this data. Particle accelerators are used in fundamental experimental research in physics to probe the structure of our physical universe. They work by colliding larger particles together to create much finer particles. Not all such events are fruitful. Machine-learning methods have been used to select events which are then analyzed further (Whiteson & Whiteson 2009 and Baldi et al. 2014). More recently, researchers at CERN launched a machine learning competition to aid in the analysis of the Higgs Boson. The goal of this challenge was to develop algorithms that separate meaningful events from background noise given data from the Large Hadron Collider, a particle accelerator at CERN. In the past few decades, there has been an explosion in data that does not have any explicit semantics attached to it. This data is generated by both humans and machines. Most of this data is not easily machine-processable; for example, images, text, video (as opposed to carefully curated data in a knowledge- or data-base). This has given rise to a huge industry that applies AI techniques to get usable information from such enormous data. This field of applying techniques derived from AI to large volumes of data goes by names such as “data mining,” “big data,” “analytics,” etc. This field is too vast to even moderately cover in the present article, but we note that there is no full agreement on what constitutes such a “big-data” problem. One definition, from Madden (2012), is that big data differs from traditional machine-processable data in that it is too big (for most of the existing state-of-the-art hardware), too quick (generated at a fast rate, e.g. online email transactions), or too hard. It is in the too-hard part that AI techniques work quite well. While this universe is quite varied, we use the Watson’s system later in this article as an AI-relevant exemplar. As we will see later, while most of this new explosion is powered by learning, it isn’t entirely limited to just learning. This bloom in learning algorithms has been supported by both a resurgence in neurocomputational techniques and probabilistic techniques. 4.2 The Resurgence of Neurocomputational Techniques One of the remarkable aspects of (Charniak & McDermott 1985) is this: The authors say the central dogma of AI is that “What the brain does may be thought of at some level as a kind of computation” (p. 6). And yet nowhere in the book is brain-like computation discussed. In fact, you will search the index in vain for the term ‘neural’ and its variants. Please note that the authors are not to blame for this. A large part of AI’s growth has come from formalisms, tools, and techniques that are, in some sense, brain-based, not logic-based. A paper that conveys the importance and maturity of neurocomputation is (Litt et al. 2006). (Growth has also come from a return of probabilistic techniques that had withered by the mid-70s and 80s. More about that momentarily, in the next “resurgence” section .) One very prominent class of non-logicist formalism does make an explicit nod in the direction of the brain: viz., artificial neural networks (or as they are often simply called, neural networks , or even just neural nets ). (The structure of neural networks and more recent developments are discussed above ). Because Minsky and Pappert’s (1969) Perceptrons led many (including, specifically, many sponsors of AI research and development) to conclude that neural networks didn’t have sufficient information-processing power to model human cognition, the formalism was pretty much universally dropped from AI. However, Minsky and Pappert had only considered very limited neural networks. Connectionism , the view that intelligence consists not in symbolic processing, but rather non -symbolic processing at least somewhat like what we find in the brain (at least at the cellular level), approximated specifically by artificial neural networks, came roaring back in the early 1980s on the strength of more sophisticated forms of such networks, and soon the situation was (to use a metaphor introduced by John McCarthy) that of two horses in a race toward building truly intelligent agents. If one had to pick a year at which connectionism was resurrected, it would certainly be 1986, the year Parallel Distributed Processing (Rumelhart & McClelland 1986) appeared in print. The rebirth of connectionism was specifically fueled by the back-propagation (backpropagation) algorithm over neural networks, nicely covered in Chapter 20 of AIMA . The symbolicist/connectionist race led to a spate of lively debate in the literature (e.g., Smolensky 1988, Bringsjord 1991), and some AI engineers have explicitly championed a methodology marked by a rejection of knowledge representation and reasoning. For example, Rodney Brooks was such an engineer; he wrote the well-known “Intelligence Without Representation” (1991), and his Cog Project, to which we referred above, is arguably an incarnation of the premeditatedly non-logicist approach. Increasingly, however, those in the business of building sophisticated systems find that both logicist and more neurocomputational techniques are required (Wermter & Sun 2001). [ 33 ] In addition, the neurocomputational paradigm today includes connectionism only as a proper part, in light of the fact that some of those working on building intelligent systems strive to do so by engineering brain-based computation outside the neural network-based approach (e.g., Granger 2004a, 2004b). Another recent resurgence in neurocomputational techniques has occurred in machine learning. The modus operandi in machine learning is that given a problem, say recognizing handwritten digits \(\{0,1,\ldots,9\}\) or faces, from a 2D matrix representing an image of the digits or faces, a machine learning or a domain expert would construct a feature vector representation function for the task. This function is a transformation of the input into a format that tries to throw away irrelevant information in the input and keep only information useful for the task. Inputs transformed by \(\rr\) are termed features . For recognizing faces, irrelevant information could be the amount of lighting in the scene and relevant information could be information about facial features. The machine is then fed a sequence of inputs represented by the features and the ideal or ground truth output values for those inputs. This converts the learning challenge from that of having to learn the function \(\ff\) from the examples: \(\left\{\left\langle x_1, \ff(x_1)\right\rangle,\left\langle x_2, \ff(x_2)\right\rangle, \ldots, \left\langle x_n, \ff(x_n)\right\rangle \right\}\) to having to learn from possibly easier data: \(\left\{\left\langle \rr(x_1), \ff(x_1)\right\rangle,\left\langle \rr(x_2), \ff(x_2)\right\rangle, \ldots, \left\langle \rr(x_n), \ff(x_n)\right\rangle \right\}\). Here the function \(\rr\) is the function that computes the feature vector representation of the input. Formally, \(\ff\) is assumed to be a composition of the functions \(\gg\) and \(\rr\). That is, for any input \(x\), \(f(x) = \gg\left(\rr\left(x\right)\right)\). This is denoted by \(\ff=\gg\circ \rr\). For any input, the features are first computed, and then the function \(\gg\) is applied. If the feature representation \(\rr\) is provided by the domain expert, the learning problem becomes simpler to the extent the feature representation takes on the difficulty of the task. At one extreme, the feature vector could hide an easily extractable form of the answer in the input and in the other extreme the feature representation could be just the plain input. For non-trivial problems, choosing the right representation is vital. For instance, one of the drastic changes in the AI landscape was due to Minsky and Papert’s (1969) demonstration that the perceptron cannot learn even the binary XOR function, but this function can be learnt by the perceptron if we have the right representation. Feature engineering has grown to be one of the most labor intensive tasks of machine learning, so much so that it is considered to be one of the “black arts” of machine learning. The other significant black art of learning methods is choosing the right parameters. These black arts require significant human expertise and experience, which can be quite difficult to obtain without significant apprenticeship (Domingos 2012). Another bigger issue is that the task of feature engineering is just knowledge representation in a new skin. Given this state of affairs, there has been a recent resurgence in methods for automatically learning a feature representation function \(\rr\); such methods potentially bypass a large part of human labor that is traditionally required. Such methods are based mostly on what are now termed deep neural networks . Such networks are simply neural networks with two or more hidden layers. These networks allow us to learn a feature function \(\rr\) by using one or more of the hidden layers to learn \(\rr\). The general form of learning in which one learns from the raw sensory data without much hand-based feature engineering has now its own term: deep learning . A general and yet concise definition (Bengio et al. 2015) is: Deep learning can safely be regarded as the study of models that either involve a greater amount of composition of learned functions or learned concepts than traditional machine learning does. (Bengio et al. 2015, Chapter 1) Though the idea has been around for decades, recent innovations leading to more efficient learning techniques have made the approach more feasible (Bengio et al. 2013). Deep-learning methods have recently produced state-of-the-art results in image recognition (given an image containing various objects, label the objects from a given set of labels), speech recognition (from audio input, generate a textual representation), and the analysis of data from particle accelerators (LeCun et al. 2015). Despite impressive results in tasks such as these, minor and major issues remain unresolved. A minor issue is that significant human expertise is still needed to choose an architecture and set up the right parameters for the architecture; a major issue is the existence of so-called adversarial inputs , which are indistinguishable from normal inputs to humans but are computed in a special manner that makes a neural network regard them as different than similar inputs in the training data. The existence of such adversarial inputs, which remain stable across training data, has raised doubts about how well performance on benchmarks can translate into performance in real-world systems with sensory noise (Szegedy et al. 2014). 4.3 The Resurgence of Probabilistic Techniques There is a second dimension to the explosive growth of AI: the explosion in popularity of probabilistic methods that aren’t neurocomputational in nature, in order to formalize and mechanize a form of non-logicist reasoning in the face of uncertainty. Interestingly enough, it is Eugene Charniak himself who can be safely considered one of the leading proponents of an explicit, premeditated turn away from logic to statistical techniques. His area of specialization is natural language processing, and whereas his introductory textbook of 1985 gave an accurate sense of his approach to parsing at the time (as we have seen, write computer programs that, given English text as input, ultimately infer meaning expressed in FOL), this approach was abandoned in favor of purely statistical approaches (Charniak 1993). At the AI@50 conference, Charniak boldly proclaimed, in a talk tellingly entitled “Why Natural Language Processing is Now Statistical Natural Language Processing,” that logicist AI is moribund, and that the statistical approach is the only promising game in town – for the next 50 years. [ 34 ] The chief source of energy and debate at the conference flowed from the clash between Charniak’s probabilistic orientation, and the original logicist orientation, upheld at the conference in question by John McCarthy and others. AI’s use of probability theory grows out of the standard form of this theory, which grew directly out of technical philosophy and logic. This form will be familiar to many philosophers, but let’s review it quickly now, in order to set a firm stage for making points about the new probabilistic techniques that have energized AI. Just as in the case of FOL, in probability theory we are concerned with declarative statements, or propositions , to which degrees of belief are applied; we can thus say that both logicist and probabilistic approaches are symbolic in nature. Both approaches also agree that statements can either be true or false in the world. In building agents, a simplistic logic-based approach requires agents to know the truth-value of all possible statements. This is not realistic, as an agent may not know the truth-value of some proposition \(p\) due to either ignorance, non-determinism in the physical world, or just plain vagueness in the meaning of the statement. More specifically, the fundamental proposition in probability theory is a random variable , which can be conceived of as an aspect of the world whose status is initially unknown to the agent. We usually capitalize the names of random variables, though we reserve \(p,q,r, \ldots\) as such names as well. For example, in a particular murder investigation centered on whether or not Mr. Barolo committed the crime, the random variable \(Guilty\) might be of concern. The detective may be interested as well in whether or not the murder weapon – a particular knife, let us assume – belongs to Barolo. In light of this, we might say that \(\Weapon = \true\) if it does, and \(\Weapon = \false\) if it doesn’t. As a notational convenience, we can write \(weapon\) and \(\lnot weapon\) and for these two cases, respectively; and we can use this convention for other variables of this type. The kind of variables we have described so far are \(\mathbf{Boolean}\), because their \(\mathbf{domain}\) is simply \(\{true,false\}.\) But we can generalize and allow \(\mathbf{discrete}\) random variables, whose values are from any countable domain. For example, \(\PriceTChina\) might be a variable for the price of (a particular, presumably) tea in China, and its domain might be \(\{1,2,3,4,5\}\), where each number here is in US dollars. A third type of variable is \(\mathbf{continous}\); its domain is either the reals, or some subset thereof. We say that an atomic event is an assignment of particular values from the appropriate domains to all the variables composing the (idealized) world. For example, in the simple murder investigation world introduced just above, we have two Boolean variables, \(\Guilty\) and \(\Weapon\), and there are just four atomic events. Note that atomic events have some obvious properties. For example, they are mutually exclusive, exhaustive, and logically entail the truth or falsity of every proposition. Usually not obvious to beginning students is a fourth property, namely, any proposition is logically equivalent to the disjunction of all atomic events that entail that proposition. Prior probabilities correspond to a degree of belief accorded to a proposition in the complete absence of any other information. For example, if the prior probability of Barolo’s guilt is \(0.2\), we write \[ P\left(\Guilty=true\right)=0.2 \] or simply \(\P(guilty)=0.2\). It is often convenient to have a notation allowing one to refer economically to the probabilities of all the possible values for a random variable. For example, we can write \[ \P\left(\PriceTChina\right) \] as an abbreviation for the five equations listing all the possible prices for tea in China. We can also write \[ \P\left(\PriceTChina\right)=\langle 1,2,3,4,5\rangle \] In addition, as further convenient notation, we can write \( \mathbf{P}\left(\Guilty, \Weapon\right)\) to denote the probabilities of all combinations of values of the relevant set of random variables. This is referred to as the joint probability distribution of \(\Guilty\) and \(\Weapon\). The full joint probability distribution covers the distribution for all the random variables used to describe a world. Given our simple murder world, we have 20 atomic events summed up in the equation \[ \mathbf{P}\left(\Guilty, \Weapon, \PriceTChina\right) \] The final piece of the basic language of probability theory corresponds to conditional probabilities. Where \(p\) and \(q\) are any propositions, the relevant expression is \(P\!\left(p\given q\right)\), which can be interpreted as “the probability of \(p\), given that all we know is \(q\).” For example, \[ P\left(guilty\ggiven weapon\right)=0.7 \] says that if the murder weapon belongs to Barolo, and no other information is available, the probability that Barolo is guilty is \(0.7.\) Andrei Kolmogorov showed how to construct probability theory from three axioms that make use of the machinery now introduced, viz., All probabilities fall between \(0\) and \(1.\) I.e., \(\forall p. 0 \leq P(p) \leq 1\). Valid (in the traditional logicist sense) propositions have a probability of \(1\); unsatisfiable (in the traditional logicist sense) propositions have a probability of \(0\). \(P(p\lor q) = P(p) +P(q) - P(p\land q)\) These axioms are clearly at bottom logicist. The remainder of probability theory can be erected from this foundation (conditional probabilities are easily defined in terms of prior probabilities). We can thus say that logic is in some fundamental sense still being used to characterize the set of beliefs that a rational agent can have. But where does probabilistic inference enter the picture on this account, since traditional deduction is not used for inference in probability theory? Probabilistic inference consists in computing, from observed evidence expressed in terms of probability theory, posterior probabilities of propositions of interest. For a good long while, there have been algorithms for carrying out such computation. These algorithms precede the resurgence of probabilistic techniques in the 1990s. (Chapter 13 of AIMA presents a number of them.) For example, given the Kolmogorov axioms, here is a straightforward way of computing the probability of any proposition, using the full joint distribution giving the probabilities of all atomic events: Where \(p\) is some proposition, let \(\alpha(p)\) be the disjunction of all atomic events in which \(p\) holds. Since the probability of a proposition (i.e., \(P(p)\)) is equal to the sum of the probabilities of the atomic events in which it holds, we have an equation that provides a method for computing the probability of any proposition \(p\), viz., \[ P(p) = \sum_{e_i\in\alpha(p)} P(e_i) \] Unfortunately, there were two serious problems infecting this original probabilistic approach: One, the processing in question needed to take place over paralyzingly large amounts of information (enumeration over the entire distribution is required). And two, the expressivity of the approach was merely propositional. (It was by the way the philosopher Hilary Putnam (1963) who pointed out that there was a price to pay in moving to the first-order level. The issue is not discussed herein.) Everything changed with the advent of a new formalism that marks the marriage of probabilism and graph theory: Bayesian networks (also called belief nets ). The pivotal text was (Pearl 1988). For a more detailed discussion, see the Supplement on Bayesian Networks . Before concluding this section, it is probably worth noting that, from the standpoint of philosophy, a situation such as the murder investigation we have exploited above would often be analyzed into arguments , and strength factors, not into numbers to be crunched by purely arithmetical procedures. For example, in the epistemology of Roderick Chisholm, as presented his Theory of Knowledge (1966, 1977), Detective Holmes might classify a proposition like Barolo committed the murder. as counterbalanced if he was unable to find a compelling argument either way, or perhaps probable if the murder weapon turned out to belong to Barolo. Such categories cannot be found on a continuum from 0 to 1, and they are used in articulating arguments for or against Barolo’s guilt. Argument-based approaches to uncertain and defeasible reasoning are virtually non-existent in AI. One exception is Pollock’s approach, covered below. This approach is Chisholmian in nature. It should also be noted that there have been well-established formalisms for dealing with probabilistic reasoning as an instance of logic-based reasoning. E.g., the activity a researcher in probabilistic reasoning undertakes when she proves a theorem \(\phi\) about their domain (e.g. any theorem in (Pearl 1988)) is purely within the realm of traditional logic. Readers interested in logic-flavored approaches to probabilistic reasoning can consult (Adams 1996, Hailperin 1996 & 2010, Halpern 1998). Formalisms marrying probability theory, induction and deductive reasoning, placing them on an equal footing, have been on the rise, with Markov logic (Richardson and Domingos 2006) being salient among these approaches. Probabilistic Machine Learning Machine learning, in the sense given above , has been associated with probabilistic techniques. Probabilistic techniques have been associated with both the learning of functions (e.g. Naive Bayes classification) and the modeling of theoretical properties of learning algorithms. For example, a standard reformulation of supervised learning casts it as a Bayesian problem . Assume that we are looking at recognizing digits \([0{-}9]\) from a given image. One way to cast this problem is to ask what the probability that the hypothesis \(H_x\): “ the digit is \(x\) ” is true given the image \(d\) from a sensor. Bayes theorem gives us: \[ P\left(H_x\ggiven d\right) = \frac{P\left(d\ggiven H_x\right)*P\left(H_x\right)}{P\left(d\right)} \] \(P(d\given H_x)\) and \(P(H_x)\) can be estimated from the given training dataset. Then the hypothesis with the highest posterior probability is then given as the answer and is given by: \(\argmax_{x}P\left(d\ggiven H_x\right)*P\left(H_x\right) \) In addition to probabilistic methods being used to build algorithms, probability theory has also been used to analyze algorithms which might not have an overt probabilistic or logical formulation. For example, one of the central classes of meta-theorems in learning, probably approximately correct (PAC) theorems, are cast in terms of lower bounds of the probability that the mismatch between the induced/learnt f L function and the true function f T being less than a certain amount, given that the learnt function f L works well for a certain number of cases (see Chapter 18, AIMA). 5. AI in the Wild From at least its modern inception, AI has always been connected to gadgets, often ones produced by corporations, and it would be remiss of us not to say a few words about this phenomenon. While there have been a large number of commercial in-the-wild success stories for AI and its sister fields, such as optimization and decision-making, some applications are more visible and have been thoroughly battle-tested in the wild. In 2014, one of the most visible such domains (one in which AI has been strikingly successful) is information retrieval, incarnated as web search. Another recent success story is pattern recognition. The state-of-the-art in applied pattern recognition (e.g., fingerprint/face verification, speech recognition, and handwriting recognition) is robust enough to allow “high-stakes” deployment outside the laboratory. As of mid 2018, several corporations and research laboratories have begun testing autonomous vehicles on public roads, with even a handful of jurisdictions making self-driving cars legal to operate. For example, Google’s autonomous cars have navigated hundreds of thousands of miles in California with minimal human help under non-trivial conditions (Guizzo 2011). Computer games provide a robust test bed for AI techniques as they can capture important parts that might be necessary to test an AI technique while abstracting or removing details that might beyond the scope of core AI research, for example, designing better hardware or dealing with legal issues (Laird and VanLent 2001). One subclass of games that has seen quite fruitful for commercial deployment of AI is real-time strategy games. Real-time strategy games are games in which players manage an army given limited resources. One objective is to constantly battle other players and reduce an opponent’s forces. Real-time strategy games differ from strategy games in that players plan their actions simultaneously in real-time and do not have to take turns playing. Such games have a number of challenges that are tantalizing within the grasp of the state-of-the-art. This makes such games an attractive venue in which to deploy simple AI agents. An overview of AI used in real-time strategy games can be found in (Robertson and Watson 2015). Some other ventures in AI, despite significant success, have been only chugging slowly and humbly along, quietly. For instance, AI-related methods have achieved triumphs in solving open problems in mathematics that have resisted any solution for decades. The most noteworthy instance of such a problem is perhaps a proof of the statement that “ All Robbins algebras are Boolean algebras. ” This was conjectured in the 1930s, and the proof was finally discovered by the Otter automatic theorem-prover in 1996 after just a few months of effort (Kolata 1996, Wos 2013). Sister fields like formal verification have also bloomed to the extent that it is now not too difficult to semi-automatically verify vital hardware/software components (Kaufmann et al. 2000 and Chajed et al. 2017). Other related areas, such as (natural) language translation, still have a long way to go, but are good enough to let us use them under restricted conditions. The jury is out on tasks such as machine translation, which seems to require both statistical methods (Lopez 2008) and symbolic methods (España-Bonet 2011). Both methods now have comparable but limited success in the wild. A deployed translation system at Ford that was initially developed for translating manufacturing process instructions from English to other languages initially started out as rule-based system with Ford and domain-specific vocabulary and language. This system then evolved to incorporate statistical techniques along with rule-based techniques as it gained new uses beyond translating manuals, for example, lay users within Ford translating their own documents (Rychtyckyj and Plesco 2012). AI’s great achievements mentioned above so far have all been in limited, narrow domains. This lack of any success in the unrestricted general case has caused a small set of researchers to break away into what is now called artificial general intelligence (Goertzel and Pennachin 2007). The stated goals of this movement include shifting the focus again to building artifacts that are generally intelligent and not just capable in one narrow domain. 6. Moral AI Computer Ethics has been around for a long time. In this sub-field, typically one would consider how one ought to act in a certain class of situations involving computer technology, where the “one” here refers to a human being (Moor 1985). So-called “robot ethics” is different. In this sub-field (which goes by names such as “moral AI,” “ethical AI,” “machine ethics,” “moral robots,” etc.) one is confronted with such prospects as robots being able to make autonomous and weighty decisions – decisions that might or might not be morally permissible (Wallach & Allen 2010). If one were to attempt to engineer a robot with a capacity for sophisticated ethical reasoning and decision-making, one would also be doing Philosophical AI, as that concept is characterized elsewhere in the present entry. There can be many different flavors of approaches toward Moral AI. Wallach and Allen (2010) provide a high-level overview of the different approaches. Moral reasoning is obviously needed in robots that have the capability for lethal action. Arkin (2009) provides an introduction to how we can control and regulate machines that have the capacity for lethal behavior. Moral AI goes beyond obviously lethal situations, and we can have a spectrum of moral machines. Moor (2006) provides one such spectrum of possible moral agents. An example of a non-lethal but ethically-charged machine would be a lying machine. Clark (2010) uses a computational theory of the mind , the ability to represent and reason about other agents, to build a lying machine that successfully persuades people into believing falsehoods. Bello & Bringsjord (2013) give a general overview of what might be required to build a moral machine, one of the ingredients being a theory of mind. The most general framework for building machines that can reason ethically consists in endowing the machines with a moral code . This requires that the formal framework used for reasoning by the machine be expressive enough to receive such codes. The field of Moral AI, for now, is not concerned with the source or provenance of such codes. The source could be humans, and the machine could receive the code directly (via explicit encoding) or indirectly (reading). Another possibility is that the code is inferred by the machine from a more basic set of laws. We assume that the robot has access to some such code, and we then try to engineer the robot to follow that code under all circumstances while making sure that the moral code and its representation do not lead to unintended consequences. Deontic logics are a class of formal logics that have been studied the most for this purpose. Abstractly, such logics are concerned mainly with what follows from a given moral code. Engineering then studies the match of a given deontic logic to a moral code (i.e., is the logic expressive enough) which has to be balanced with the ease of automation. Bringsjord et al. (2006) provide a blueprint for using deontic logics to build systems that can perform actions in accordance with a moral code. The role deontic logics play in the framework offered by Bringsjord et al (which can be considered to be representative of the field of deontic logic for moral AI) can be best understood as striving towards Leibniz’s dream of a universal moral calculus: When controversies arise, there will be no more need for a disputation between two philosophers than there would be between two accountants [computistas]. It would be enough for them to pick up their pens and sit at their abacuses, and say to each other (perhaps having summoned a mutual friend): ‘Let us calculate.’ Deontic logic-based frameworks can also be used in a fashion that is analogous to moral self-reflection. In this mode, logic-based verification of the robot’s internal modules can done before the robot ventures out into the real world. Govindarajulu and Bringsjord (2015) present an approach, drawing from formal-program verification , in which a deontic-logic based system could be used to verify that a robot acts in a certain ethically-sanctioned manner under certain conditions. Since formal-verification approaches can be used to assert statements about an infinite number of situations and conditions, such approaches might be preferred to having the robot roam around in an ethically-charged test environment and make a finite set of decisions that are then judged for their ethical correctness. More recently, Govindarajulu and Bringsjord (2017) use a deontic logic to present a computational model of the Doctrine of Double Effect , an ethical principle for moral dilemmas that has been studied empirically and analyzed extensively by philosophers. [ 35 ] The principle is usually presented and motivated via dilemmas using trolleys and was first presented in this fashion by Foot (1967). While there has been substantial theoretical and philosophical work, the field of machine ethics is still in its infancy. There has been some embryonic work in building ethical machines. One recent such example would be Pereira and Saptawijaya (2016) who use logic programming and base their work in machine ethics on the ethical theory known as contractualism , set out by Scanlon (1982). And what about the future? Since artificial agents are bound to get smarter and smarter, and to have more and more autonomy and responsibility, robot ethics is almost certainly going to grow in importance. This endeavor might not be a straightforward application of classical ethics. For example, experimental results suggest that humans hold robots to different ethical standards than they expect from humans under similar conditions (Malle et al. 2015). [ 36 ] 7. Philosophical AI Notice that the heading for this section isn’t Philosophy of AI. We’ll get to that category momentarily. (For now it can be identified with the attempt to answer such questions as whether artificial agents created in AI can ever reach the full heights of human intelligence.) Philosophical AI is AI, not philosophy; but it’s AI rooted in and flowing from, philosophy. For example, one could engage, using the tools and techniques of philosophy, a paradox, work out a proposed solution, and then proceed to a step that is surely optional for philosophers: expressing the solution in terms that can be translated into a computer program that, when executed, allows an artificial agent to surmount concrete instances of the original paradox. [ 37 ] Before we ostensively characterize Philosophical AI of this sort courtesy of a particular research program, let us consider first the view that AI is in fact simply philosophy, or a part thereof. Daniel Dennett (1979) has famously claimed not just that there are parts of AI intimately bound up with philosophy, but that AI is philosophy (and psychology, at least of the cognitive sort). (He has made a parallel claim about Artificial Life (Dennett 1998)). This view will turn out to be incorrect, but the reasons why it’s wrong will prove illuminating, and our discussion will pave the way for a discussion of Philosophical AI. What does Dennett say, exactly? This: I want to claim that AI is better viewed as sharing with traditional epistemology the status of being a most general, most abstract asking of the top-down question: how is knowledge possible? (Dennett 1979, 60) Elsewhere he says his view is that AI should be viewed “as a most abstract inquiry into the possibility of intelligence or knowledge” (Dennett 1979, 64). In short, Dennett holds that AI is the attempt to explain intelligence, not by studying the brain in the hopes of identifying components to which cognition can be reduced, and not by engineering small information-processing units from which one can build in bottom-up fashion to high-level cognitive processes, but rather by – and this is why he says the approach is top-down – designing and implementing abstract algorithms that capture cognition. Leaving aside the fact that, at least starting in the early 1980s, AI includes an approach that is in some sense bottom-up (see the neurocomputational paradigm discussed above, in Non-Logicist AI: A Summary ; and see, specifically, Granger’s (2004a, 2004b) work, hyperlinked in text immediately above, a specific counterexample), a fatal flaw infects Dennett’s view. Dennett sees the potential flaw, as reflected in: It has seemed to some philosophers that AI cannot plausibly be so construed because it takes on an additional burden: it restricts itself to mechanistic solutions, and hence its domain is not the Kantian domain of all possible modes of intelligence, but just all possible mechanistically realizable modes of intelligence. This, it is claimed, would beg the question against vitalists, dualists, and other anti-mechanists. (Dennett 1979, 61) Dennett has a ready answer to this objection. He writes: But … the mechanism requirement of AI is not an additional constraint of any moment, for if psychology is possible at all, and if Church’s thesis is true, the constraint of mechanism is no more severe than the constraint against begging the question in psychology, and who would wish to evade that? (Dennett 1979, 61) Unfortunately, this is acutely problematic; and examination of the problems throws light on the nature of AI. First, insofar as philosophy and psychology are concerned with the nature of mind, they aren’t in the least trammeled by the presupposition that mentation consists in computation. AI, at least of the “Strong” variety (we’ll discuss “Strong” versus “Weak” AI below ) is indeed an attempt to substantiate, through engineering certain impressive artifacts, the thesis that intelligence is at bottom computational (at the level of Turing machines and their equivalents, e.g., Register machines). So there is a philosophical claim, for sure. But this doesn’t make AI philosophy, any more than some of the deeper, more aggressive claims of some physicists (e.g., that the universe is ultimately digital in nature) make their field philosophy. Philosophy of physics certainly entertains the proposition that the physical universe can be perfectly modeled in digital terms (in a series of cellular automata, e.g.), but of course philosophy of physics can’t be identified with this doctrine. Second, we now know well (and those familiar with the relevant formal terrain knew at the time of Dennett’s writing) that information processing can exceed standard computation, that is, can exceed computation at and below the level of what a Turing machine can muster ( Turing-computation , we shall say). (Such information processing is known as hypercomputation , a term coined by philosopher Jack Copeland, who has himself defined such machines (e.g., Copeland 1998). The first machines capable of hypercomputation were trial-and-error machines , introduced in the same famous issue of the Journal of Symbolic Logic (Gold 1965; Putnam 1965). A new hypercomputer is the infinite time Turing machine (Hamkins & Lewis 2000).) Dennett’s appeal to Church’s thesis thus flies in the face of the mathematical facts: some varieties of information processing exceed standard computation (or Turing-computation). Church’s thesis, or more precisely, the Church-Turing thesis, is the view that a function \(f\) is effectively computable if and only if \(f\) is Turing-computable (i.e., some Turing machine can compute \(f\)). Thus, this thesis has nothing to say about information processing that is more demanding than what a Turing machine can achieve. (Put another way, there is no counter-example to CTT to be automatically found in an information-processing device capable of feats beyond the reach of TMs.) For all philosophy and psychology know, intelligence, even if tied to information processing, exceeds what is Turing-computational or Turing-mechanical. [ 38 ] This is especially true because philosophy and psychology, unlike AI, are in no way fundamentally charged with engineering artifacts, which makes the physical realizability of hypercomputation irrelevant from their perspectives. Therefore, contra Dennett, to consider AI as psychology or philosophy is to commit a serious error, precisely because so doing would box these fields into only a speck of the entire space of functions from the natural numbers (including tuples therefrom) to the natural numbers. (Only a tiny portion of the functions in this space are Turing-computable.) AI is without question much, much narrower than this pair of fields. Of course, it’s possible that AI could be replaced by a field devoted not to building computational artifacts by writing computer programs and running them on embodied Turing machines. But this new field, by definition, would not be AI. Our exploration of AIMA and other textbooks provide direct empirical confirmation of this. Third, most AI researchers and developers, in point of fact, are simply concerned with building useful, profitable artifacts, and don’t spend much time reflecting upon the kinds of abstract definitions of intelligence explored in this entry (e.g., What Exactly is AI? ). Though AI isn’t philosophy, there are certainly ways of doing real implementation-focussed AI of the highest caliber that are intimately bound up with philosophy. The best way to demonstrate this is to simply present such research and development, or at least a representative example thereof. While there have been many examples of such work, the most prominent example in AI is John Pollock’s OSCAR project, which stretched over a considerable portion of his lifetime. For a detailed presentation and further discussion, see the Supplement on the OSCAR Project. It’s important to note at this juncture that the OSCAR project, and the information processing that underlies it, are without question at once philosophy and technical AI. Given that the work in question has appeared in the pages of Artificial Intelligence , a first-rank journal devoted to that field, and not to philosophy, this is undeniable (see, e.g., Pollock 2001, 1992). This point is important because while it’s certainly appropriate, in the present venue, to emphasize connections between AI and philosophy, some readers may suspect that this emphasis is contrived: they may suspect that the truth of the matter is that page after page of AI journals are filled with narrow, technical content far from philosophy. Many such papers do exist. But we must distinguish between writings designed to present the nature of AI, and its core methods and goals, versus writings designed to present progress on specific technical issues. Writings in the latter category are more often than not quite narrow, but, as the example of Pollock shows, sometimes these specific issues are inextricably linked to philosophy. And of course Pollock’s work is a representative example (albeit the most substantive one). One could just as easily have selected work by folks who don’t happen to also produce straight philosophy. For example, for an entire book written within the confines of AI and computer science, but which is epistemic logic in action in many ways, suitable for use in seminars on that topic, see (Fagin et al. 2004). (It is hard to find technical work that isn’t bound up with philosophy in some direct way. E.g., AI research on learning is all intimately bound up with philosophical treatments of induction, of how genuinely new concepts not simply defined in terms of prior ones can be learned. One possible partial answer offered by AI is inductive logic programming , discussed in Chapter 19 of AIMA .) What of writings in the former category? Writings in this category, while by definition in AI venues, not philosophy ones, are nonetheless philosophical. Most textbooks include plenty of material that falls into this latter category, and hence they include discussion of the philosophical nature of AI (e.g., that AI is aimed at building artificial intelligences, and that’s why, after all, it’s called ‘AI’). 8. Philosophy of Artificial Intelligence 8.1 “Strong” versus “Weak” AI Recall that we earlier discussed proposed definitions of AI, and recall specifically that these proposals were couched in terms of the goals of the field. We can follow this pattern here: We can distinguish between “Strong” and “Weak” AI by taking note of the different goals that these two versions of AI strive to reach. “Strong” AI seeks to create artificial persons: machines that have all the mental powers we have, including phenomenal consciousness. “Weak” AI, on the other hand, seeks to build information-processing machines that appear to have the full mental repertoire of human persons (Searle 1997). “Weak” AI can also be defined as the form of AI that aims at a system able to pass not just the Turing Test (again, abbreviated as TT), but the Total Turing Test (Harnad 1991). In TTT, a machine must muster more than linguistic indistinguishability: it must pass for a human in all behaviors – throwing a baseball, eating, teaching a class, etc. It would certainly seem to be exceedingly difficult for philosophers to overthrow “Weak” AI (Bringsjord and Xiao 2000). After all, what philosophical reason stands in the way of AI producing artifacts that appear to be animals or even humans? However, some philosophers have aimed to do in “Strong” AI, and we turn now to the most prominent case in point. 8.2 The Chinese Room Argument Against “Strong AI” Without question, the most famous argument in the philosophy of AI is John Searle’s (1980) Chinese Room Argument (CRA), designed to overthrow “Strong” AI. We present a quick summary here and a “report from the trenches” as to how AI practitioners regard the argument. Readers wanting to further study CRA will find an excellent next step in the entry on the Chinese Room Argument and (Bishop & Preston 2002). CRA is based on a thought-experiment in which Searle himself stars. He is inside a room; outside the room are native Chinese speakers who don’t know that Searle is inside it. Searle-in-the-box, like Searle-in-real-life, doesn’t know any Chinese, but is fluent in English. The Chinese speakers send cards into the room through a slot; on these cards are written questions in Chinese. The box, courtesy of Searle’s secret work therein, returns cards to the native Chinese speakers as output. Searle’s output is produced by consulting a rulebook: this book is a lookup table that tells him what Chinese to produce based on what is sent in. To Searle, the Chinese is all just a bunch of – to use Searle’s language – squiggle-squoggles. The following schematic picture sums up the situation. The labels should be obvious. \(O\) denotes the outside observers, in this case the Chinese speakers. Input is denoted by \(i\) and output by \(o\). As you can see, there is an icon for the rulebook, and Searle himself is denoted by \(P\). The Chinese Room, Schematic View Now, what is the argument based on this thought-experiment? Even if you’ve never heard of CRA before, you doubtless can see the basic idea: that Searle (in the box) is supposed to be everything a computer can be, and because he doesn’t understand Chinese, no computer could have such understanding. Searle is mindlessly moving squiggle-squoggles around, and (according to the argument) that’s all computers do, fundamentally. [ 39 ] Where does CRA stand today? As we’ve already indicated, the argument would still seem to be alive and well; witness (Bishop & Preston 2002). However, there is little doubt that at least among AI practitioners , CRA is generally rejected. (This is of course thoroughly unsurprising.) Among these practitioners, the philosopher who has offered the most formidable response out of AI itself is Rapaport (1988), who argues that while AI systems are indeed syntactic, the right syntax can constitute semantics. It should be said that a common attitude among proponents of “Strong” AI is that CRA is not only unsound, but silly, based as it is on a fanciful story (CR) far removed from the practice of AI – practice which is year by year moving ineluctably toward sophisticated robots that will once and for all silence CRA and its proponents. For example, John Pollock (as we’ve noted, philosopher and practitioner of AI) writes: Once [my intelligent system] OSCAR is fully functional, the argument from analogy will lead us inexorably to attribute thoughts and feelings to OSCAR with precisely the same credentials with which we attribute them to human beings. Philosophical arguments to the contrary will be passé. (Pollock 1995, p. 6) To wrap up discussion of CRA, we make two quick points, to wit: Despite the confidence of the likes of Pollock about the eventual irrelevance of CRA in the face of the eventual human-level prowess of OSCAR (and, by extension, any number of other still-improving AI systems), the brute fact is that deeply semantic natural-language processing (NLP) is rarely even pursued these days, so proponents of CRA are certainly not the ones feeling some discomfort in light of the current state of AI. In short, Searle would rightly point to any of the success stories of AI, including the Watson system we have discussed, and still proclaim that understanding is nowhere to be found – and he would be well within his philosophical rights in saying this. It would appear that the CRA is bubbling back to a level of engagement not seen for a number of years, in light of the empirical fact that certain thinkers are now issuing explicit warnings to the effect that future conscious, malevolent machines may well wish to do in our species. In reply, Searle (2014) points out that since CRA is sound, there can’t be conscious machines; and if there can’t be conscious machines, there can’t be malevolent machines that wish anything. We return to this at the end of our entry; the chief point here is that CRA continues to be quite relevant, and indeed we suspect that Searle’s basis for have-no-fear will be taken up energetically by not only philosophers, but AI experts, futurists, lawyers, and policy-makers. Readers may wonder if there are philosophical debates that AI researchers engage in, in the course of working in their field (as opposed to when they might attend a philosophy conference). Surely, AI researchers have philosophical discussions amongst themselves, right? Generally, one finds that AI researchers do discuss among themselves topics in philosophy of AI, and these topics are usually the very same ones that occupy philosophers of AI. However, the attitude reflected in the quote from Pollock immediately above is by far the dominant one. That is, in general, the attitude of AI researchers is that philosophizing is sometimes fun, but the upward march of AI engineering cannot be stopped, will not fail, and will eventually render such philosophizing otiose. We will return to the issue of the future of AI in the final section of this entry. 8.3 The Gödelian Argument Against “Strong AI” Four decades ago, J.R. Lucas (1964) argued that Gödel’s first incompleteness theorem entails that no machine can ever reach human-level intelligence. His argument has not proved to be compelling, but Lucas initiated a debate that has produced more formidable arguments. One of Lucas’ indefatigable defenders is the physicist Roger Penrose, whose first attempt to vindicate Lucas was a Gödelian attack on “Strong” AI articulated in his The Emperor’s New Mind (1989). This first attempt fell short, and Penrose published a more elaborate and more fastidious Gödelian case, expressed in Chapters 2 and 3 of his Shadows of the Mind (1994). In light of the fact that readers can turn to the entry on the Gödel’s Incompleteness Theorems , a full review here is not needed. Instead, readers will be given a decent sense of the argument by turning to an online paper in which Penrose, writing in response to critics (e.g., the philosopher David Chalmers, the logician Solomon Feferman, and the computer scientist Drew McDermott) of his Shadows of the Mind , distills the argument to a couple of paragraphs. [ 40 ] Indeed, in this paper Penrose gives what he takes to be the perfected version of the core Gödelian case given in SOTM . Here is this version, verbatim: We try to suppose that the totality of methods of (unassailable) mathematical reasoning that are in principle humanly accessible can be encapsulated in some (not necessarily computational) sound formal system \(F\). A human mathematician, if presented with \(F\), could argue as follows (bearing in mind that the phrase “I am \(F\)” is merely a shorthand for “\(F\) encapsulates all the humanly accessible methods of mathematical proof”): (A) “Though I don’t know that I necessarily am \(F\), I conclude that if I were, then the system \(F\) would have to be sound and, more to the point, \(F'\) would have to be sound, where \(F'\) is \(F\) supplemented by the further assertion “I am \(F\).” I perceive that it follows from the assumption that I am \(F\) that the Gödel statement \(G(F')\) would have to be true and, furthermore, that it would not be a consequence of \(F'\). But I have just perceived that “If I happened to be \(F\), then \(G(F')\) would have to be true,” and perceptions of this nature would be precisely what \(F'\) is supposed to achieve. Since I am therefore capable of perceiving something beyond the powers of \(F'\), I deduce that I cannot be \(F\) after all. Moreover, this applies to any other (Gödelizable) system, in place of \(F\).” (Penrose 1996, 3.2) Does this argument succeed? A firm answer to this question is not appropriate to seek in the present entry. Interested readers are encouraged to consult four full-scale treatments of the argument (LaForte et. al 1998; Bringsjord and Xiao 2000; Shapiro 2003; Bowie 1982). 8.4 Additional Topics and Readings in Philosophy of AI In addition to the Gödelian and Searlean arguments covered briefly above, a third attack on “Strong” AI (of the symbolic variety) has been widely discussed (though with the rise of statistical machine learning has come a corresponding decrease in the attention paid to it), namely, one given by the philosopher Hubert Dreyfus (1972, 1992), some incarnations of which have been co-articulated with his brother, Stuart Dreyfus (1987), a computer scientist. Put crudely, the core idea in this attack is that human expertise is not based on the explicit, disembodied, mechanical manipulation of symbolic information (such as formulae in some logic, or probabilities in some Bayesian network), and that AI’s efforts to build machines with such expertise are doomed if based on the symbolic paradigm. The genesis of the Dreyfusian attack was a belief that the critique of (if you will) symbol-based philosophy (e.g., philosophy in the logic-based, rationalist tradition, as opposed to what is called the Continental tradition) from such thinkers as Heidegger and Merleau-Ponty could be made against the rationalist tradition in AI. After further reading and study of Dreyfus’ writings, readers may judge whether this critique is compelling, in an information-driven world increasingly managed by intelligent agents that carry out symbolic reasoning (albeit not even close to the human level). For readers interested in exploring philosophy of AI beyond what Jim Moor (in a recent address – “The Next Fifty Years of AI: Future Scientific Research vs. Past Philosophical Criticisms” – as the 2006 Barwise Award winner at the annual eastern American Philosophical Association meeting) has called “the big three” criticisms of AI, there is no shortage of additional material, much of it available on the Web. The last chapter of AIMA provides a compressed overview of some additional arguments against “Strong” AI, and is in general not a bad next step. Needless to say, Philosophy of AI today involves much more than the three well-known arguments discussed above, and, inevitably, Philosophy of AI tomorrow will include new debates and problems we can’t see now. Because machines, inevitably, will get smarter and smarter (regardless of just how smart they get), Philosophy of AI, pure and simple, is a growth industry. With every human activity that machines match, the “big” questions will only attract more attention. 9. The Future If past predictions are any indication, the only thing we know today about tomorrow’s science and technology is that it will be radically different than whatever we predict it will be like. Arguably, in the case of AI, we may also specifically know today that progress will be much slower than what most expect. After all, at the 1956 kickoff conference (discussed at the start of this entry), Herb Simon predicted that thinking machines able to match the human mind were “just around the corner” (for the relevant quotes and informative discussion, see the first chapter of AIMA ). As it turned out, the new century would arrive without a single machine able to converse at even the toddler level. (Recall that when it comes to the building of machines capable of displaying human-level intelligence, Descartes, not Turing, seems today to be the better prophet.) Nonetheless, astonishing though it may be, serious thinkers in the late 20th century have continued to issue incredibly optimistic predictions regarding the progress of AI. For example, Hans Moravec (1999), in his Robot: Mere Machine to Transcendent Mind , informs us that because the speed of computer hardware doubles every 18 months (in accordance with Moore’s Law, which has apparently held in the past), “fourth generation” robots will soon enough exceed humans in all respects, from running companies to writing novels. These robots, so the story goes, will evolve to such lofty cognitive heights that we will stand to them as single-cell organisms stand to us today. [ 41 ] Moravec is by no means singularly Pollyannaish: Many others in AI predict the same sensational future unfolding on about the same rapid schedule. In fact, at the aforementioned AI@50 conference, Jim Moor posed the question “Will human-level AI be achieved within the next 50 years?” to five thinkers who attended the original 1956 conference: John McCarthy, Marvin Minsky, Oliver Selfridge, Ray Solomonoff, and Trenchard Moore. McCarthy and Minsky gave firm, unhesitating affirmatives, and Solomonoff seemed to suggest that AI provided the one ray of hope in the face of fact that our species seems bent on destroying itself. (Selfridge’s reply was a bit cryptic. Moore returned a firm, unambiguous negative, and declared that once his computer is smart enough to interact with him conversationally about mathematical problems, he might take this whole enterprise more seriously.) It is left to the reader to judge the accuracy of such risky predictions as have been given by Moravec, McCarthy, and Minsky. [ 42 ] The judgment of the reader in this regard ought to factor in the stunning resurgence, very recently, of serious reflection on what is known as “The Singularity,” (denoted by us simply as S ) the future point at which artificial intelligence exceeds human intelligence, whereupon immediately thereafter (as the story goes) the machines make themselves rapidly smarter and smarter and smarter, reaching a superhuman level of intelligence that, stuck as we are in the mud of our limited mentation, we can’t fathom. For extensive, balanced analysis of S , see Eden et al. (2013). Readers unfamiliar with the literature on S may be quite surprised to learn the degree to which, among learned folks, this hypothetical event is not only taken seriously, but has in fact become a target for extensive and frequent philosophizing [for a mordant tour of the recent thought in question, see Floridi (2015)]. What arguments support the belief that S is in our future? There are two main arguments at this point: the familiar hardware-based one [championed by Moravec, as noted above, and again more recently by Kurzweil (2006)]; and the – as far as we know – original argument given by mathematician I. J. Good (1965). In addition, there is a recent and related doomsayer argument advanced by Bostrom (2014), which seems to presuppose that S will occur. Good’s argument, nicely amplified and adjusted by Chalmers (2010), who affirms the tidied-up version of the argument, runs as follows: Premise 1 : There will be AI (created by HI and such that AI = HI). Premise 2 : If there is AI, there will be AI\(^+\) (created by AI). Premise 3 : If there is AI\(^+\), there will be AI\(^{++}\) (created by AI\(^+\)). Conclusion : There will be AI\(^{++}\) (= S will occur). In this argument, ‘AI’ is artificial intelligence at the level of, and created by, human persons, ‘AI\(^+\)’ artificial intelligence above the level of human persons, and ‘AI\(^{++}\)’ super-intelligence constitutive of S . The key process is presumably the creation of one class of machine by another. We have added for convenience ‘HI’ for human intelligence; the central idea is then: HI will create AI, the latter at the same level of intelligence as the former; AI will create AI\(^+\); AI\(^+\) will create AI\(^{++}\); with the ascension proceeding perhaps forever, but at any rate proceeding long enough for us to be as ants outstripped by gods. The argument certainly appears to be formally valid. Are its three premises true? Taking up such a question would fling us far beyond the scope of this entry. We point out only that the concept of one class of machines creating another, more powerful class of machines is not a transparent one, and neither Good nor Chalmers provides a rigorous account of the concept, which is ripe for philosophical analysis. (As to mathematical analysis, some exists, of course. It is for example well-known that a computing machine at level \(L\) cannot possibly create another machine at a higher level \(L'\). For instance, a linear-bounded automaton can’t create a Turing machine.) The Good-Chalmers argument has a rather clinical air about it; the argument doesn’t say anything regarding whether machines in the AI\(^{++}\) category will be benign, malicious, or munificent. Many others gladly fill this gap with dark, dark pessimism. The locus classicus here is without question a widely read paper by Bill Joy (2000): “Why The Future Doesn’t Need Us.” Joy believes that the human race is doomed, in no small part because it’s busy building smart machines. He writes: The 21st-century technologies – genetics, nanotechnology, and robotics (GNR) – are so powerful that they can spawn whole new classes of accidents and abuses. Most dangerously, for the first time, these accidents and abuses are widely within the reach of individuals or small groups. They will not require large facilities or rare raw materials. Knowledge alone will enable the use of them. Thus we have the possibility not just of weapons of mass destruction but of knowledge-enabled mass destruction (KMD), this destructiveness hugely amplified by the power of self-replication. I think it is no exaggeration to say we are on the cusp of the further perfection of extreme evil, an evil whose possibility spreads well beyond that which weapons of mass destruction bequeathed to the nation-states, on to a surprising and terrible empowerment of extreme individuals. [ 43 ] Philosophers would be most interested in arguments for this view. What are Joy’s? Well, no small reason for the attention lavished on his paper is that, like Raymond Kurzweil (2000), Joy relies heavily on an argument given by none other than the Unabomber (Theodore Kaczynski). The idea is that, assuming we succeed in building intelligent machines, we will have them do most (if not all) work for us. If we further allow the machines to make decisions for us – even if we retain oversight over the machines –, we will eventually depend on them to the point where we must simply accept their decisions. But even if we don’t allow the machines to make decisions, the control of such machines is likely to be held by a small elite who will view the rest of humanity as unnecessary – since the machines can do any needed work (Joy 2000). This isn’t the place to assess this argument. (Having said that, the pattern pushed by the Unabomber and his supporters certainly appears to be flatly invalid. [ 44 ] ) In fact, many readers will doubtless feel that no such place exists or will exist, because the reasoning here is amateurish. So then, what about the reasoning of professional philosophers on the matter? Bostrom has recently painted an exceedingly dark picture of a possible future. He points out that the “first superintelligence” could have the capability to shape the future of Earth-originating life, could easily have non-anthropomorphic final goals, and would likely have instrumental reasons to pursue open-ended resource acquisition. If we now reflect that human beings consist of useful resources (such as conveniently located atoms) and that we depend on many more local resources, we can see that the outcome could easily be one in which humanity quickly becomes extinct. (Bostrom 2014, p. 416) Clearly, the most vulnerable premise in this sort of argument is that the “first superintelligence” will arrive indeed arrive. Here perhaps the Good-Chalmers argument provides a basis. Searle (2014) thinks Bostrom’s book is misguided and fundamentally mistaken, and that we needn’t worry. His rationale is dirt-simple: Machines aren’t conscious; Bostrom is alarmed at the prospect of malicious machines who do us in; a malicious machine is by definition a conscious machine; ergo, Bostrom’s argument doesn’t work. Searle writes: If the computer can fly airplanes, drive cars, and win at chess, who cares if it is totally nonconscious? But if we are worried about a maliciously motivated superintelligence destroying us, then it is important that the malicious motivation should be real. Without consciousness, there is no possibiity of its being real. The positively remarkable thing here, it seems to us, is that Searle appears to be unaware of the brute fact that most AI engineers are perfectly content to build machines on the basis of the AIMA view of AI we presented and explained above: the view according to which machines simply map percepts to actions. On this view, it doesn’t matter whether the machine really has desires; what matters is whether it acts suitably on the basis of how AI scientists engineer formal correlates to desire. An autonomous machine with overwhelming destructive power that non-consciously “decides” to kill doesn’t become just a nuisance because genuine, human-level, subjective desire is absent from the machine. If an AI can play the game of chess, and the game of Jeopardy! , it can certainly play the game of war. Just as it does little good for a human loser to point out that the victorious machine in a game of chess isn’t conscious, it will do little good for humans being killed by machines to point out that these machines aren’t conscious. (It is interesting to note that the genesis of Joy’s paper was an informal conversation with John Searle and Raymond Kurzweil. According to Joy, Searle didn’t think there was much to worry about, since he was (and is) quite confident that tomorrow’s robots can’t be conscious. [ 45 ] ) There are some things we can safely say about tomorrow. Certainly, barring some cataclysmic events (nuclear or biological warfare, global economic depression, a meteorite smashing into Earth, etc.), we now know that AI will succeed in producing artificial animals . Since even some natural animals (mules, e.g.) can be easily trained to work for humans, it stands to reason that artificial animals, designed from scratch with our purposes in mind, will be deployed to work for us. In fact, many jobs currently done by humans will certainly be done by appropriately programmed artificial animals. To pick an arbitrary example, it is difficult to believe that commercial drivers won’t be artificial in the future. (Indeed, Daimler is already running commercials in which they tout the ability of their automobiles to drive “autonomously,” allowing human occupants of these vehicles to ignore the road and read.) Other examples would include: cleaners, mail carriers, clerical workers, military scouts, surgeons, and pilots. (As to cleaners, probably a significant number of readers, at this very moment, have robots from iRobot cleaning the carpets in their homes.) It is hard to see how such jobs are inseparably bound up with the attributes often taken to be at the core of personhood – attributes that would be the most difficult for AI to replicate. [ 46 ] Andy Clark (2003) has another prediction: Humans will gradually become, at least to an appreciable degree, cyborgs, courtesy of artificial limbs and sense organs, and implants. The main driver of this trend will be that while standalone AIs are often desirable, they are hard to engineer when the desired level of intelligence is high. But to let humans “pilot” less intelligent machines is a good deal easier, and still very attractive for concrete reasons. Another related prediction is that AI would play the role of a cognitive prosthesis for humans (Ford et al. 1997; Hoffman et al. 2001). The prosthesis view sees AI as a “great equalizer” that would lead to less stratification in society, perhaps similar to how the Hindu-Arabic numeral system made arithmetic available to the masses, and to how the Guttenberg press contributed to literacy becoming more universal. Even if the argument is formally invalid, it leaves us with a question – the cornerstone question about AI and the future: Will AI produce artificial creatures that replicate and exceed human cognition (as Kurzweil and Joy believe)? Or is this merely an interesting supposition? This is a question not just for scientists and engineers; it is also a question for philosophers. This is so for two reasons. One, research and development designed to validate an affirmative answer must include philosophy – for reasons rooted in earlier parts of the present entry. (E.g., philosophy is the place to turn to for robust formalisms to model human propositional attitudes in machine terms.) Two, philosophers might well be able to provide arguments that answer the cornerstone question now, definitively. If a version of either of the three arguments against “Strong” AI alluded to above (Searle’s CRA; the Gödelian attack; the Dreyfus argument) are sound, then of course AI will not manage to produce machines having the mental powers of persons. No doubt the future holds not only ever-smarter machines, but new arguments pro and con on the question of whether this progress can reach the human level that Descartes declared to be unreachable. Bibliography Adams, E. W., 1996, A Primer of Probability Logic , Stanford, CA: CSLI. Almeida, J., Frade, M., Pinto, J. & de Sousa, S., 2011, Rigorous Software Development: An Introduction to Program Verification , New York, NY: Spinger. Alpaydin, E., 2014, Introduction to Machine Learning , Cambridge, MA: MIT Press. Amir, E. & Maynard-Reid, P., 1999, “Logic-Based Subsumption Architecture,” in Proceedings of the 16 th International Joint Conference on Artificial Intelligence (IJCAI-1999) , (San Francisco, CA: MIT Morgan Kaufmann), pp. 147–152. Amir, E. & Maynard-Reid, P., 2000, “Logic-Based Subsumption Architecture: Empirical Evaluation,” in Proceedings of the AAAI Fall Symposium on Parallel Architectures for Cognition . Amir, E. & Maynard-Reid, P., 2001, “LiSA: A Robot Driven by Logical Subsumption,” in Proceedings of the Fifth Symposium on the Logical Formalization of Commonsense Reasoning , (New York, NY). Anderson, C. A., 1983, “The Paradox of the Knower,” The Journal of Philosophy , 80.6: 338–355. Anderson, J. & Lebiere, C., 2003, “The Newell Test for a Theory of Cognition,” Behavioral and Brain Sciences , 26: 587–640. Ashcraft, M., 1994, Human Memory and Cognition , New York, NY: HarperCollins. Arkin, R., 2009, Governing Lethal Behavior in Autonomous Robots , London: Chapman and Hall/CRC Imprint, Taylor and Francis Group. Arkoudas, K. & Bringsjord, S., 2005, “Vivid: A Framework for Heterogeneous Problem Solving,” Artificial Intelligence , 173.15: 1367–1405. Arkoudas, K. & Bringsjord, S., 2005, “Metareasoning for Multi-agent Epistemic Logics,” in Fifth International Conference on Computational Logic In Multi-Agent Systems (CLIMA 2004) , in the series Lecture Notes in Artificial Intelligence (LNAI) , volume 3487, New York, NY: Springer-Verlag, pp. 111–125. Arkoudas, K., 2000, Denotational Proof Languages , PhD dissertation, Massachusetts Institute of Technology (Computer Science). Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., & Patel-Schneider, P. F., eds., 2003, The Description Logic Handbook: Theory, Implementation, and Applications , New York, NY: Cambridge University Press. Smith, B., Ashburner, M., Rosse, C., Bard, J., Bug, W., Ceusters, W., Goldberg, L. J., Eilbeck, K., Ireland, A., Mungall, C. J., The OBI Consortium, Leontis, N., Rocca-Serra, P., Ruttenberg, A., Sansone, S., Scheuermann, R. H., Shah, N., Whetzel, P. L. & Lewis, S., 2007, “The OBO Foundry: Coordinated Evolution of Ontologies to Support Biomedical Data Integration,” Nature Biotechnology 25, 1251–1255. Barwise, J. & Etchemendy, J., 1999, Language, Proof, and Logic , New York, NY: Seven Bridges Press. Barwise, J. & Etchemendy, J., 1995, “Heterogeneous Logic,” in Diagrammatic Reasoning: Cognitive and Computational Perspectives , J. Glasgow, N.H. Narayanan, & B. Chandrasekaran, eds., Cambridge, MA: MIT Press, pp. 211–234. Baldi, P., Sadowski P. & Whiteson D., 2014, “Searching for Exotic Particles in High-energy Physics with Deep Learning,” Nature Communications . [ Available online ] Barwise, J. & Etchemendy, J., 1994, Hyperproof , Stanford, CA: CSLI. Barwise, J. & Etchemendy, J., 1990, “Infons and Inference,” in Situation Theory and its Applications, (Vol 1) , Cooper, Mukai, and Perry (eds), CSLI Lecture Notes #22, CSLI Press, pp. 33–78. Bello, P. & Bringsjord S., 2013, “On How to Build a Moral Machine,” Topoi , 32.2: 251–266. Bengio, Y., Goodfellow, I., & Courville, A., 2016, Deep Learning , Cambridge: MIT Press. [ Available online ] Bengio, Y., Courville, A. & Vincent, P., 2013, “Representation Learning: A Review and New Perspectives,” Pattern Analysis and Machine Intelligence, IEEE Transactions , 35.8: 1798–1828. Berners-Lee, T., Hendler, J. & Lassila, O., 2001, “The Semantic Web,” Scientific American , 284: 34–43. Bishop, M. & Preston, J., 2002, Views into the Chinese Room: New Essays on Searle and Artificial Intelligence , Oxford, UK: Oxford University Press. Boden, M., 1994, “Creativity and Computers,” in Artificial Intelligence and Computers , T. Dartnall, ed., Dordrecht, The Netherlands: Kluwer, pp. 3–26. Boolos, G. S., Burgess, J.P., & Jeffrey., R.C., 2007, Computability and Logic 5th edition , Cambridge: Cambridge University Press. Bostrom, N., 2014, Superintelligence: Paths, Dangers, Strategies , Oxford, UK: Oxford University Press. Bowie, G.L., 1982, “Lucas’ Number is Finally Up,” Journal of Philosophical Logic , 11: 279–285. Brachman, R. & Levesque, H., 2004, Knowledge Representation and Reasoning , San Francisco, CA: Morgan Kaufmann/Elsevier. Bringsjord, S., Arkoudas K. & Bello P., 2006, “Toward a General Logicist Methodology for Engineering Ethically Correct Robots,” IEEE Intelligent Systems, 21.4: 38–44. Bringsjord, S. & Ferrucci, D., 1998, “Logic and Artificial Intelligence: Divorced, Still Married, Separated…?” Minds and Machines , 8: 273–308. Bringsjord, S. & Schimanski, B., 2003, “What is Artificial Intelligence? Psychometric AI as an Answer,” Proceedings of the 18 th International Joint Conference on Artificial Intelligence (IJCAI-2003) , (San Francisco, CA: MIT Morgan Kaufmann), pp. 887–893. Bringsjord, S. & Ferrucci, D., 2000, Artificial Intelligence and Literary Creativity: Inside the Mind of Brutus, a Storytelling Machine , Mahwah, NJ: Lawrence Erlbaum. Bringsjord, S. & van Heuveln, B., 2003, “The Mental Eye Defense of an Infinitized Version of Yablo’s Paradox,” Analysis 63.1: 61–70. Bringsjord S. & Xiao, H., 2000, “A Refutation of Penrose’s Gödelian Case Against Artificial Intelligence,” Journal of Experimental and Theoretical Artificial Intelligence , 12: 307–329. Bringsjord, S. & Zenzen, M., 2002, “Toward a Formal Philosophy of Hypercomputation,” Minds and Machines , 12: 241–258. Bringsjord, S., 2000, “Animals, Zombanimals, and the Total Turing Test: The Essence of Artificial Intelligence,” Journal of Logic, Language, and Information , 9: 397–418. Bringsjord, S., 1998, “Philosophy and ‘Super’ Computation,” The Digital Phoenix: How Computers are Changing Philosophy , J. Moor and T. Bynam, eds., Oxford, UK: Oxford University Press, pp. 231–252. Bringsjord, S., 1991, “Is the Connectionist-Logicist Clash one of AI’s Wonderful Red Herrings?” Journal of Experimental & Theoretical AI , 3.4: 319–349. Bringsjord, S., Govindarajulu N. S., Eberbach, E. & Yang, Y., 2012, “Perhaps the Rigorous Modeling of Economic Phenomena Requires Hypercomputation,” International Journal of Unconventional Computing , 8.1: 3–32. [ Preprint available online ] Bringsjord, S., 2011, “Psychometric Artificial Intelligence,” Journal of Experimental and Theoretical Artificial Intelligence , 23.3: 271–277. Bringsjord, S. & Govindarajulu N. S., 2012, “Given the Web, What is Intelligence, Really?” Metaphilosophy 43.12: 464–479. Brooks, R. A., 1991, “Intelligence Without Representation,” Artificial Intelligence , 47: 139–159. Browne, C. B., Powley, E. & Whitehouse, D., 2012, “A Survey of Monte Carlo Tree Search Methods,” A Survey of Monte Carlo Tree Search Methods , 4.1: 1–43. Buchanan, B. G., 2005, “A (Very) Brief History of Artificial Intelligence,” AI Magazine , 26.4: 53–60. Carroll, L., 1958, Symbolic Logic; Game of Logic , New York, NY: Dover. Cassimatis, N., 2006, “Cognitive Substrate for Human-Level Intelligence,” AI Magazine , 27.2: 71–82. Chajed, T., Chen, H., Chlipala, A., Kaashoek, F., Zeldovich, N., & Ziegler, D., 2017, “Research Highlight: Certifying a File System using Crash Hoare Logic: Correctness in the Presence of Crashes,” Communications of the ACM (CACM) , 60.4: 75–84. Chalmers, D., 2010, “The Singularity: A Philosophical Analysis,” Journal of Consciousness Studies , 17: 7–65. Charniak, E., 1993, Statistical Language Learning , Cambridge: MIT Press. Charniak, E. & McDermott, D., 1985, Introduction to Artificial Intelligence , Reading, MA: Addison Wesley. Chellas, B., 1980, Modal Logic: An Introduction , Cambridge, UK: Cambridge University Press. Chisholm, R., 1957, Perceiving , Ithaca, NY: Cornell University Press. Chisholm, R., 1966, Theory of Knowledge , Englewood Cliffs, NJ: Prentice-Hall. Chisholm, R., 1977, Theory of Knowledge 2nd ed , Englewood Cliffs, NJ: Prentice-Hall. Clark, A., 2003, Natural-Born Cyborgs , Oxford, UK: Oxford University Press. Clark, M. H., 2010, Cognitive Illusions and the Lying Machine: A Blueprint for Sophistic Mendacity , PhD dissertation, Rensselaer Polytechnic Institute (Cognitive Science). Copeland, B. J., 1998, “Super Turing Machines,” Complexity , 4: 30–32. Copi, I. & Cohen, C., 2004, Introduction to Logic , Saddle River, NJ: Prentice-Hall. Dennett, D., 1998, “Artificial Life as Philosophy,” in his Brainchildren: Essays on Designing Minds , Cambridge, MA: MIT Press, pp. 261–263. Dennett, D., 1994, “The Practical Requirements for Making a Conscious Robot,” Philosophical Transactions of the Royal Society of London , 349: 133–146. Dennett, D., 1979, “Artificial Intelligence as Philosophy and as Psychology,” Philosophical Perspectives in Artificial Intelligence , M. Ringle, ed., Atlantic Highlands, NJ: Humanities Press, pp. 57–80. Descartes, 1637, R., in Haldane, E. and Ross, G.R.T., translators, 1911, The Philosophical Works of Descartes, Volume 1 , Cambridge, UK: Cambridge University Press. Dick, P. K., 1968, Do Androids Dream of Electric Sheep? , New York, NY: Doubleday. Domingos, P., 2012, “A Few Useful Things to Know about Machine Learning,” Communications of the ACM , 55.10: 78–87. Dreyfus, H., 1972, What Computers Can’t Do , Cambridge, MA: MIT Press. Dreyfus, H., 1992, What Computers Still Can’t Do , Cambridge, MA: MIT Press. Dreyfus, H. & Dreyfus, S., 1987, Mind Over Machine: The Power of Human Intuition and Expertise in the Era of the Computer , New York, NY: Free Press. Ebbinghaus, H., Flum, J. & Thomas, W., 1984, Mathematical Logic , New York, NY: Springer-Verlag. Eden, A., Moor, J., Soraker, J. & Steinhart, E., 2013, Singularity Hypotheses: A Scientific and Philosophical Assessment , New York, NY: Springer. España-Bonet, C., Enache, R., Slaski, A., Ranta, A., Màrquez L. & Gonzàlez, M., 2011, “Patent Translation within the MOLTO project,” in Proceedings of the 4th Workshop on Patent Translation, MT Summit XIII , pp. 70–78. Evans, G., 1968, “A Program for the Solution of a Class of Geometric-Analogy Intelligence-Test Questions,” in M. Minsky, ed., Semantic Information Processing , Cambridge, MA: MIT Press, pp. 271–353. Fagin, R., Halpern, J. Y., Moses, Y. & Vardi, M., 2004, Reasoning About Knowledge , Cambridge, MA: MIT Press. Ferrucci, D. & Lally, A., 2004, “UIMA: An Architectural Approach to Unstructured Information Processing in the Corporate Research Environment,” Natural Language Engineering , 10.3–4: 327–348. Cambridge, UK: Cambridge University Press. Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur, A., Lally, A., Murdock, J., Nyberg, E., Prager, J., Schlaefer, N. & Welty, C., 2010, “Building Watson: An Overview of the DeepQA Project,” AI Magazine , 31.3: 59–79. Finnsson, H., 2012, “Generalized Monte-Carlo Tree Search Extensions for General Game Playing,” in Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence (AAAI-2012) , Toronto, Canda, pp. 1550–1556. Fitelson, B., 2005, “Inductive Logic,” in Pfeifer, J. and Sarkar, S., eds., Philosophy of Science: An Encyclopedia , London, UK: Routledge, pp. 384–394. Floridi, L., 2015, “Singularitarians, AItheists, and Why the Problem with Artificial Intelligence is H.A.L. (Humanity At Large), not HAL,” APA Newsletter: Philosophy and Computers , 14.2: 8–11. Foot, P., 1967, “The Problem of Abortion and the Doctrine of the Double Effect,” Oxford Review , 5: 5–15. Forbus, K. D. & Hinrichs, T. R., 2006, “Companion Cognitive Systems: A Step toward Human-Level AI,” AI Magazine , 27.2: 83. Ford, K. M., Glymour C. & Hayes P., 1997, “On the Other Hand … Cognitive Prostheses,” AI Magazine , 18.3: 104. Friedland, N., Allen, P., Matthews, G., Witbrock, M., Baxter, D., Curtis, J., Shepard, B., Miraglia, P., Angele, J., Staab, S., Moench, E., Oppermann, H., Wenke, D., Israel, D., Chaudhri, V., Porter, B., Barker, K., Fan, J., Yi Chaw, S., Yeh, P., Tecuci, D. & Clark, P., 2004, “Project Halo: Towards a Digital Aristotle,” AI Magazine , 25.4: 29–47. Genesereth, M., Love, N. & Pell B., 2005, “General Game Playing: Overview of the AAAI Competition,” AI Magazine , 26.2: 62–72. [ Available online ] Ginsberg, M., 1993, Essentials of Artificial Intelligence , New York, NY: Morgan Kaufmann. Glymour, G., 1992, Thinking Things Through , Cambridge, MA: MIT Press. Goertzel, B. & Pennachin, C., eds., 2007, Artificial General Intelligence , Berlin, Heidelberg: Springer-Verlag. Gold, M., 1965, “Limiting Recursion,” Journal of Symbolic Logic , 30.1: 28–47. Goldstine, H. & von Neumann, J., 1947, “Planning and Coding of Problems for an Electronic Computing Instrument,” IAS Reports Institute for Advanced Study, Princeton, NJ. [This remarkable work is available online from the Institute for Advanced Study. Please note that this paper is Part II of a three-volume set. The first volume was devoted to a preliminary discussion, and the first author on it was Arthur Burks, joining Goldstine and von Neumann.] Good, I., 1965, “Speculations Concerning the First Ultraintelligent Machines,” in Advances in Computing (vol. 6), F. Alt and M. Rubinoff, eds., New York, NY: Academic Press, pp. 31–38. Govindarajulu, N. S., Bringsjord, S. & Licato J., 2013, “On Deep Computational Formalization of Natural Language,” in Proceedings of the Workshop “Formalizing Mechanisms for Artificial General Intelligence and Cognition (Formal MAGiC),” Osnabrück, Germany: PICS. Govindarajulu, N. S., & Bringsjord, S., 2015, “Ethical Regulation of Robots Must Be Embedded in Their Operating Systems” in Trappl, R., ed., A Construction Manual for Robot’s Ethical Systems: Requirements, Methods, Implementations , Berlin, DE: Springer. Govindarajulu, N. S., & Bringsjord, S., 2017, “On Automating the Doctrine of Double Effect,” in Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17) , pp. 4722–4730. doi:10.24963/ijcai.2017/658 Granger, R., 2004a, “Derivation and Analysis of Basic Computational Operations of Thalamocortical Circuits,” Journal of Cognitive Neuroscience 16: 856–877. Granger, R., 2004b, “Brain Circuit Implementation: High-precision Computation from Low-Precision Components,” in Toward Replacement Parts for the Brain , T. Berger and D. Glanzman, eds., Cambridge, MA: MIT Press, pp. 277–294. Griewank, A., 2000, Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation , Philadlphia, PA: Society for Industrial and Applied Mathematics (SIAM). Guizzo, E., 2011, “How Google’s Self-driving Car Works,” IEEE Spectrum Online . [ Available online] Hailperin, T., 1996, Sentential Probability Logic: Origins, Development, Current Status, and Technical Applications , Bethlehem, United States: Lehigh University Press. Hailperin, T., 2010, Logic with a Probability Semantics , Bethlehem, United States: Lehigh University Press. Halpern, J. Y., 1990, “An Analysis of First-order Logics of Probability,” Artificial Intelligence , 46: 311–350. Halpern, J., Harper, R., Immerman, N., Kolaitis, P. G., Vardi, M. & Vianu, V., 2001, “On the Unusual Effectiveness of Logic in Computer Science,” The Bulletin of Symbolic Logic , 7.2: 213–236. Hamkins, J. & Lewis, A., 2000, “Infinite Time Turing Machines,” Journal of Symbolic Logic , 65.2: 567–604. Harnad, S., 1991, “Other Bodies, Other Minds: A Machine Incarnation of an Old Philosophical Problem,” Minds and Machines , 1.1: 43–54. Haugeland, J., 1985, Artificial Intelligence: The Very Idea , Cambridge, MA: MIT Press. Hendler, J. & Jennifer G., 2008, “Metcalfe’s Law, Web 2.0, and the Semantic Web,” Web Semantics: Science, Services and Agents on the World Wide Web , 6.1: 14–20. Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A. R., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P., Sainath, T. & Kingsbury, B., 2012, “Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups,” IEEE Signal Processing Magazine , 29.6: 82–97. Hoffman, R. R., Hayes, P. J. & Ford, K. M., 2001, “Human-Centered Computing: Thinking In and Out of the Box,” IEEE Intelligent Systems , 16.5: 76–78. Hoffman, R. R., Bradshaw J. M., Hayes P. J. & Ford K. M., 2003, “ The Borg Hypothesis,” IEEE Intelligent Systems , 18.5: 73–75. Hofstadter, D. & McGraw, G., 1995, “Letter Spirit: Esthetic Perception and Creative Play in the Rich Microcosm of the Roman Alphabet,” in Hofstadter’s Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought , New York, NY: Basic Books, pp. 407–488. Hornik, K., Stinchcombe, M. & White, H., 1989, “Multilayer Feedforward Networks are Universal Approximators,” Neural Networks , 2.5: 359–366. Hutter, M., 2005, Universal Artificial Intelligence , Berlin: Springer. Joy, W., 2000, “Why the Future Doesn’t Need Us,” Wired 8.4. [ Available online ] Kahneman, D., 2013. Thinking, Fast and Slow , New York, NY: Farrar, Straus, and Giroux. Kaufmann, M., Manolios, P. & Moore, J. S., 2000, Computer-Aided Reasoning: ACL2 Case Studies , Dordrecht, The Netherlands: Kluwer Academic Publishers. Klenk, M., Forbus, K., Tomai, E., Kim,H. & Kyckelhahn, B., 2005, “Solving Everyday Physical Reasoning Problems by Analogy using Sketches,” in Proceedings of 20th National Conference on Artificial Intelligence (AAAI-05), Pittsburgh, PA. Kolata, G., 1996, “Computer Math Proof Shows Reasoning Power,” in New York Times . [ Availabe online ] Koller, D., Levy, A. & Pfeffer, A., 1997, “P-CLASSIC: A Tractable Probablistic Description Logic,” in Proceedings of the AAAI 1997 Meeting , 390–397. Kurzweil, R., 2006, The Singularity Is Near: When Humans Transcend Biology , New York, NY: Penguin USA. Kurzweil, R., 2000, The Age of Spiritual Machines: When Computers Exceed Human Intelligence , New York, NY: Penguin USA. LaForte, G., Hayes P. & Ford, K., 1998, “Why Gödel’s Theorem Cannot Refute Computationslism,” Artificial Intelligence , 104: 265–286. Laird, J. E., 2012, The Soar Cognitive Architecture , Cambridge, MA: MIT Press. Laird, J. & VanLent M., 2001, “Human-level AI’s Killer Application: Interactive Computer Games,” AI Magazine 22.2:15–26. LeCun, Y., Bengio, Y. & Hinton G., 2015, “Deep Learning,” Nature , 521: 436–444. Lenat, D., 1983, “EURISKO: A Program that Learns New Heuristics and Domain Concepts,” Artificial Intelligence , 21(1-2): 61–98. doi:10.1016/s0004-3702(83)80005-8 Lenat, D., & Guha, R. V., 1990, Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project , Reading, MA: Addison Wesley. Lenzen, W., 2004, “Leibniz’s Logic,” in Gabbay, D., Woods, J. and Kanamori, A., eds., Handbook of the History of Logic , Elsevier, Amsterdam, The Netherlands, pp. 1–83. Lewis, H. & Papadimitriou, C., 1981, Elements of the Theory of Computation , Prentice Hall, Englewood Cliffs, NJ: Prentice Hall. Litt, A., Eliasmith, C., Kroon, F., Weinstein, S. & Thagard, P., 2006, “Is the Brain a Quantum Computer?” Cognitive Science 30: 593–603. Lucas, J. R., 1964, “Minds, Machines, and Gödel,” in Minds and Machines , A. R. Anderson, ed., Prentice-Hall, NJ: Prentice-Hall, pp. 43–59. Luger, G., 2008, Artificial Intelligence: Structures and Strategies for Complex Problem Solving , New York, NY: Pearson. Luger, G. & Stubblefield, W., 1993, Artificial Intelligence: Structures and Strategies for Complex Problem Solving , Redwood, CA: Benjamin Cummings. Lopez, A., 2008, “Statistical Machine Translation,” ACM Computing Surveys , 40.3: 1–49. Malle, B. F., Scheutz, M., Arnold, T., Voiklis, J. & Cusimano, C., 2015, “Sacrifice One For the Good of Many?: People Apply Different Moral Norms to Human and Robot Agents,” in Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI ’15) (New York, NY: ACM), pp. 117–124. Manzano, M., 1996, Extensions of First Order Logic , Cambridge, UK: Cambridge University Press. Marcus, G., 2013, “Why Can’t My Computer Understand Me?,” in The New Yorker , August 2013. [ Available online ] McCarthy, J. & Hayes, P., 1969, “Some Philosophical Problems from the Standpoint of Artificial Intelligence,” in Machine Intelligence 4 , B. Meltzer and D. Michie, eds., Edinburgh: Edinburgh University Press, 463–502. Mueller, E., 2006, Commonsense Reasoning , San Francisco, CA: Morgan Kaufmann. Murphy, K. P., 2012, Machine Learning: A Probabilistic Perspective , Cambridge, MA: MIT Press. Minsky, M. & Pappert, S., 1969, Perceptrons: An Introduction to Computational Geometry , Cambridge, MA: MIT Press. Montague, R., 1970, “Universal Grammar,” Theoria , 36, 373–398. Moor, J., 2006, “The Nature, Importance, and Difficulty of Machine Ethics”, IEEE Intelligent Systems 21.4: 18–21. Moor, J., 1985, “What is Computer Ethics?” Metaphilosophy 16.4: 266–274. Moor, J., ed., 2003, The Turing Test: The Elusive Standard of Artificial Intelligence , Dordrecht, The Netherlands: Kluwer Academic Publishers. Moravec, H., 1999, Robot: Mere Machine to Transcendant Mind , Oxford, UK: Oxford University Press, Naumowicz, A. & Kornilowicz., A., 2009, “A Brief Overview of Mizar,” in Theorem Proving in Higher Order Logics , S. Berghofer, T. Nipkow, C. Urban & M. Wenzel, eds., Berlin: Springer, pp. 67–72. Newell, N., 1973, “You Can’t Play 20 Questions with Nature and Win: Projective Comments on the Papers of this Symposium”, in Visual Information Processing , W. Chase, ed., New York, NY: Academic Press, pp. 283–308. Nilsson, N., 1998, Artificial Intelligence: A New Synthesis , San Francisco, CA: Morgan Kaufmann. Nilsson, N., 1987, Principles of Artificial Intelligence , New York, NY: Springer-Verlag. Nilsson, N., 1991, “Logic and Artificial Intelligence,” Artificial Intelligence , 47: 31–56. Nozick, R., 1970, “Newcomb’s Problem and Two Principles of Choice,” in Essays in Honor of Carl G. Hempel , N. Rescher, ed., Highlands, NJ: Humanities Press, pp. 114–146. This appears to be the very first published treatment of NP – though the paradox goes back to its creator: William Newcomb, a physicist. Osherson, D., Stob, M. & Weinstein, S., 1986, Systems That Learn , Cambridge, MA: MIT Press. Pearl, J., 1988, Probabilistic Reasoning in Intelligent Systems , San Mateo, CA: Morgan Kaufmann. Pennington, J., Socher R., & Manning C. D., 2014, “GloVe: Global Vectors for Word Representation,” in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014) , pp. 1532–1543. [ Available online ] Penrose, R., 1989, The Emperor’s New Mind , Oxford, UK: Oxford University Press. Penrose, R., 1994, Shadows of the Mind , Oxford, UK: Oxford University Press. Penrose, R., 1996, “Beyond the Doubting of a Shadow: A Reply to Commentaries on Shadows of the Mind ,” Psyche , 2.3. This paper is available online. Pereira, L., & Saptawijaya A., 2016, Programming Machine Ethics , Berlin, Germany: Springer Pinker, S., 1997, How the Mind Works , New York, NY: Norton. Pollock, J., 2006, Thinking about Acting: Logical Foundations for Rational Decision Making , Oxford, UK: Oxford University Press. Pollock, J., 2001, “Defeasible Reasoning with Variable Degrees of Justification,” Artificial Intelligence , 133, 233–282. Pollock, J., 1995, Cognitive Carpentry: A Blueprint for How to Build a Person , Cambridge, MA: MIT Press. Pollock, J., 1992, “How to Reason Defeasibly,” Artificial Intelligence , 57, 1–42. Pollock, J., 1989, How to Build a Person: A Prolegomenon , Cambridge, MA: MIT Press. Pollock, J., 1974, Knowledge and Justification , Princeton, NJ: Princeton University Press. Pollock, J., 1967, “Criteria and our Knowledge of the Material World,” Philosophical Review , 76, 28–60. Pollock, J., 1965, Analyticity and Implication , PhD dissertation, University of California at Berkeley (Philosophy). Potter, M.D., 2004, Set Theory and its Philosophy , Oxford, UK: Oxford University Press Preston, J. & Bishop, M., 2002, Views into the Chinese Room: New Essays on Searle and Artificial Intelligence , Oxford, UK: Oxford University Press. Putnam, H., 1965, “Trial and Error Predicates and a Solution to a Problem of Mostowski,” Journal of Symbolic Logic , 30.1, 49–57. Putnam, H., 1963, “Degree of Confirmation and Inductive Logic,” in The Philosophy of Rudolf Carnap , Schilipp, P., ed., Open Court, pp. 270–292. Rajat, R., Anand, M. & Ng, A. Y., 2009, “Large-scale Deep Unsupervised Learning Using Graphics Processors,” in Proceedings of the 26th Annual International Conference on Machine Learning , ACM, pp. 873–880. Rapaport, W., 1988, “Syntactic Semantics: Foundations of Computational Natural-Language Understanding,” in Aspects of Artificial Intelligence , J. H. Fetzer ed., Dordrecht, The Netherlands: Kluwer Academic Publishers, 81–131. Rapaport, W. & Shapiro, S., 1999, “Cognition and Fiction: An Introduction,” Understanding Language Understanding: Computational Models of Reading , A. Ram & K. Moorman, eds., Cambridge, MA: MIT Press, 11–25. [ Available online ] Reeke, G. & Edelman, G., 1988, “Real Brains and Artificial Intelligence,” in The Artificial Intelligence Debate: False Starts, Real Foundations , Cambridge, MA: MIT Press, pp. 143–173. Richardson, M. & Domingos, P., 2006, “Markov Logic Networks,” Machine Learning , 62.1–2:107–136. Robertson, G. & Watson, I., 2015, “A Review of Real-Time Strategy Game AI,” AI Magazine , 35.4: 75–104. Rosenschein, S. & Kaelbling, L., 1986, “The Synthesis of Machines with Provable Epistemic Properties,” in Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning About Knowledge , San Mateo, CA: Morgan Kaufmann, pp. 83–98. Rumelhart, D. & McClelland, J., 1986, eds., Parallel Distributed Processing , Cambridge, MA: MIT Press. Russell, S., 1997, “Rationality and Intelligence,” Artificial Intelligence , 94: 57–77. [ Version available online from author ] Russell, S. & Norvig, P., 1995, Artificial Intelligence: A Modern Approach , Saddle River, NJ: Prentice Hall. Russell, S. & Norvig, P., 2002, Artificial Intelligence: A Modern Approach 2nd edition , Saddle River, NJ: Prentice Hall. Russell, S. & Norvig, P., 2009, Artificial Intelligence: A Modern Approach 3rd edition , Saddle River, NJ: Prentice Hall. Rychtyckyj, N. & Plesco, C., 2012, “Applying Automated Language Translation at a Global Enterprise Level,” AI Magazine , 34.1: 43–54. Scanlon, T. M., 1982, “Contractualism and Utilitarianism,” in A. Sen and B. Williams, eds., Utilitarianism and Beyond , Cambridge: Cambridge University Press, pp. 103–128. Schank, R., 1972, “Conceptual Dependency: A Theory of Natural Language Understanding,” Cognitive Psychology , 3.4: 532–631. Schaul, T. & Schmidhüber, J., 2010, “Metalearning,” Scholarpedia 5(6): 4650. URL: http://www.scholarpedia.org/article/Metalearning Schmidhüber, J., 2009, “Ultimate Cognition à la Gödel,” Cognitive Computation 1.2: 177–193. Searle, J., 1997, The Mystery of Consciousness , New York, NY: New York Review of Books. Searle, J., 1980, “Minds, Brains and Programs,” Behavioral and Brain Sciences , 3: 417–424. Searle, J., 1984, Minds, Brains and Science , Cambridge, MA: Harvard University Press. The Chinese Room Argument is covered in Chapter Two, “Can Computers Think?”. Searle, J., 2014, “What Your Computer Can’t Know,” New York Review of Books , October 9. Shapiro, S., 2000, “An Introduction to SNePS 3,” in Conceptual Structures: Logical, Linguistic, and Computational Issues. Lecture Notes in Artificial Intelligence 1867 , B. Ganter & G. W. Mineau, eds., Springer-Verlag, 510–524. Shapiro, S., 2003, “Mechanism, Truth, and Penrose’s New Argument,” Journal of Philosophical Logic , 32.1: 19–42. Siegelmann, H., 1999, Neural Networks and Analog Computation: Beyond the Turing Limit , Boston, MA: Birkhauser. Siegelmann, H. & and Sontag, E., 1994, “Analog Computation Via Neural Nets,” Theoretical Computer Science , 131: 331–360. Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., van den Driessche, G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., Dieleman, S., Grewe, D., Nham, J., Kalchbrenner, N., Sutskever, I., Lillicrap, T., Leach, M., Kavukcuoglu, K., Graepel T. & Hassabis D., 2016, “Mastering the Game of Go with Deep Neural Networks and Tree Search,” Nature , 529: 484–489. Shin, S-J, 2002, The Iconic Logic of Peirce’s Graphs , Cambridge, MA: MIT Press. Smolensky, P., 1988, “On the Proper Treatment of Connectionism,” Behavioral & Brain Sciences , 11: 1–22. Somers, J., 2013, “The Man Who Would Teach Machines to Think,” in The Atlantic . [ Available online ] Stanovich, K. & West, R., 2000, “Individual Differences in Reasoning: Implications for the Rationality Debate,” Behavioral and Brain Sciences , 23.5: 645–665. Strzalkowski, T. & Harabagiu, M. S., 2006, eds., Advances in Open Domain Question Answering ; in the series Text, Speech and Language Technology, volume 32, Dordrecht, The Netherlands: Springer-Verlag. Sun, R., 2002, Duality of the Mind: A Bottom Up Approach Toward Cognition , Mahwah, NJ: Lawrence Erlbaum. Sun, R., 1994, Integrating Rules and Connectionism for Robust Commonsense Reasoning , New York, NY: John Wiley and Sons. Sutton R. S. & Barto A. G., 1998, Reinforcement Learning: An Introduction , Cambridge, MA: MIT Press. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. & Fergus, R., 2014, “Intriguing Properties of Neural Networks,” in Second International Conference on Learning Representations , Banff, Canada. [ Available online ] Hastie, T., Tibshirani, R., & Jerome, F., 2009, The Elements of Statistical Learning , in the series Springer Series in Statistics , New York: Springer. Turing, A., 1950, “Computing Machinery and Intelligence,” Mind , LIX: 433–460. Turing, A., 1936, “On Computable Numbers with Applications to the Entscheidung-Problem,” Proceedings of the London Mathematical Society , 42: 230–265. Vilalta, R. & Drissi, Y., 2002, “A Perspective View and Survey of Meta-learning,” Artificial Intelligence Review , 18.2:77–95. Voronkov, A., 1995, “The Anatomy of Vampire: Implementing Bottom-Up Procedures with Code Trees,” Journal of Automated Reasoning , 15.2. Wallach, W. & Allen, C., 2010, Moral Machines: Teaching Robots Right from Wrong , Oxford, UK: Oxford University Press. Wermter, S. & Sun, R., 2001 (Spring), “The Present and the Future of Hybrid Neural Symbolic Systems: Some Reflections from the Neural Information Processing Systems Workshop,” AI Magazine , 22.1: 123–125. Suppes, P., 1972, Axiomatic Set Theory , New York, NY: Dover. Whiteson, S. & Whiteson, D., 2009, “Machine Learning for Event Selection in High Energy Physics,” Engineering Applications of Artificial Intelligence 22.8: 1203–1217. Williams, D. E., Hinton G. E., & Williams R. J., 1986 “Learning Representations by Back-propagating Errors,” Nature , 323.10: 533–536. Winston, P., 1992, Artificial Intelligence , Reading, MA: Addison-Wesley. Wos, L., Overbeek, R., Lusk R. & Boyle, J., 1992, Automated Reasoning: Introduction and Applications (2nd edition) , New York, NY: McGraw-Hill. Wos, L., 2013, “The Legacy of a Great Researcher,” in Automated Reasoning and Mathematics: Essays in Memory of William McCune , Bonacina, M.P. & Stickel, M.E., eds., 1–14. Berlin: Springer. Zalta, E., 1988, Intensional Logic and the Metaphysics of Intentionality , Cambridge, MA: Bradford Books. Academic Tools How to cite this entry . Preview the PDF version of this entry at the Friends of the SEP Society . Look up topics and thinkers related to this entry at the Internet Philosophy Ontology Project (InPhO). Enhanced bibliography for this entry at PhilPapers , with links to its database. Other Internet Resources Artificial Intelligence Positioned to be a Game-changer , an excellent segment on AI from CBS’s esteemed 60 Minutes program, this gives a popular science level overview of the current state of AI (as of Ocotober, 2016). The videos in the segment covers applications of AI, Watson’s evolution from winning Jeopardy! to fighting cancer and advances in robotics. AIMA textbook: web site for first edition (1995) web site for second edition (2002) web site for the third edition (2009) Association for the Advancement of Artificial Intelligence Cognitive Science Society International Joint Conference on Artificial Intelligence Artificial General Intelligence (AGI) Conference An introduction and a collection of resources on Artificial General Intelligence AGI 2010 Workshop Call for a Serious Computational Science of Intelligence Cited Resources Baydin A.G., Pearlmutter, B. A., Radul, A. A. & Siskind J. M., 2015, “Automatic Differentiation in Machine Learning: A Survey,” arXiv:1502.05767 [cs.SC]. URL: http://arxiv.org/abs/1502.05767 Benenson, 2016, “ Classification Datasets Results, ” URL = http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html (Last accessed in July 2018). LeCun, Y., Cortes, C. and Burges, C. J.C, 2017, “THE MNIST DATABASE of handwritten digits,” URL = http://yann.lecun.com/exdb/mnist/ (Last accessed in July 2018). Levesque, J. H., 2013, “ On Our Best Behaviour ,” Speech for the IJCAI 2013 Award for Research Excellence , Beijing. Online Courses on AI Artificial Intelligence: Principles and Techniques (Stanford University) Artifical Intelligence (online course from Udacity). Artificial Intelligence (Columbia University). Artificial Intelligence MIT (Fall 2010). Related Entries artificial intelligence: logic-based | causation: probabilistic | Chinese room argument | cognitive science | computability and complexity | computing: modern history of | connectionism | epistemology: Bayesian | frame problem | information technology: and moral values | language of thought hypothesis | learning theory, formal | linguistics: computational | mind: computational theory of | reasoning: automated | reasoning: defeasible | statistics, philosophy of | Turing test Acknowledgments Thanks are due to Peter Norvig and Prentice-Hall for allowing figures from AIMA to be used in this entry. Thanks are due as well to the many first-rate (human) minds who have read earlier drafts of this entry, and provided helpful feedback. Without the support of our AI research and development from both ONR and AFOSR, our knowledge of AI and ML would confessedly be acutely narrow, and we are grateful for the support. We are also very grateful to the anonymous referees who provided us with meticulous reviews in our reviewing round in late 2015 to early 2016. Special acknowledgements are due to the SEP editors and, in particular, Uri Nodelman for patiently working with us throughout and for providing technical and insightful editorial help. Copyright © 2018 by Selmer Bringsjord < Selmer . Bringsjord @ gmail . com > Naveen Sundar Govindarajulu < Naveen . Sundar . G @ gmail . com > Open access to the SEP is made possible by a world-wide funding initiative. The Encyclopedia Now Needs Your Support Please Read How You Can Help Keep the Encyclopedia Free Browse Table of Contents What's New Random Entry Chronological Archives About Editorial Information About the SEP Editorial Board How to Cite the SEP Special Characters Advanced Tools Accessibility Contact Support SEP Support the SEP PDFs for SEP Friends Make a Donation SEPIA for Libraries Mirror Sites View this site from another server: USA (Main Site) Philosophy, Stanford University Info about mirror sites The Stanford Encyclopedia of Philosophy is copyright © 2025 by The Metaphysics Research Lab , Department of Philosophy, Stanford University Library of Congress Catalog Data: ISSN 1095-5054
====================================================================================================
What Is Artificial Intelligence (AI)? ‒ Intel Skip To Main Content Toggle Navigation Sign In My Intel My Tools ? Sign Out English Select Your Language Bahasa Indonesia Deutsch English Español Français Português Tiếng Việt ไทย 한국어 日本語 简体中文 繁體中文 Toggle Search Search < Close Search Panel Advanced Search close Sign In to access restricted content Using Intel.com Search You can easily search the entire Intel.com site in several ways. Brand Name: Core i9 Document Number: 123456 Code Name: Emerald Rapids Special Operators: “Ice Lake”, Ice AND Lake, Ice OR Lake, Ice* Quick Links You can also try the quick links below to see results for most popular searches. Product Information Support Drivers & Software Recent Searches Sign In to access restricted content Advanced Search All of these terms Any of these terms Exact term only Find results with All Results Product Information Support Drivers & Software Documentation & Resources Partners Communities Corporate Show results from Only search in Title Description Content ID Search Sign in to access restricted content. What Is Artificial Intelligence (AI)? The browser version you are using is not recommended for this site. Please consider upgrading to the latest version of your browser by clicking one of the following links. Safari Chrome Edge Firefox What Is Artificial Intelligence (AI)? Harness the power of AI to help transform workflows and enhance decision-making. From automating tasks to powering smart applications, AI is revolutionizing how we work, create, and interact. Key Takeaways AI uses algorithms to replicate human intelligence in decision-making for specific tasks. AI can transform processes by automating complex tasks or tailoring workflows to individual needs. Most industries can benefit in some way from deploying AI, with many more use cases still being discovered. Technology providers can help businesses assess their AI needs and deploy AI based on proven successful use cases. By Artificial Intelligence (AI) is a technology designed to perform tasks that typically require human intelligence, involving learning, adapting, and decision-making. AI brings numerous benefits, including automation and personalized experiences, to fields such as personal computing, automotive, healthcare, retail, and banking. Artificial Intelligence (AI) is a technology designed to perform tasks that typically require human intelligence, involving learning, adapting, and decision-making. AI brings numerous benefits, including automation and personalized experiences, to fields such as personal computing, automotive, healthcare, retail, and banking. What Is Artificial Intelligence? Artificial Intelligence (AI) is a field of computer science focused on creating machines capable of performing tasks that usually require human intelligence. This is done through learning, reasoning, understanding, and adapting. AI has been around for many years and has been used for specific, often narrow applications such as recommendation engines in online searches. Narrow AI and General AI With the launch of large language models (LLMs) and generative AI (GenAI) tools such as ChatGPT, AI has become more prevalent and useful in daily life. This has also given rise to a new categorization of AI that anticipates future use cases: Narrow AI or weak AI : This type of AI is designed to perform specific tasks, such as facial recognition or driving a car. Most current AI applications fall into this category. General AI or strong AI : This type of AI is designed to use a broader range of cognitive abilities to perform any reasoning task that a human being can. General AI does not exist yet but is considered a long-term goal for AI research. Benefits of Artificial Intelligence AI offers numerous advantages for end users and businesses across every industry. Depending on the use cases, AI is capable of identifying patterns and forecasting events, automating complex processes, and tailoring workflows to meet the individual needs of a project or person. AI can also play a critical role in monitoring and optimizing resource management. With advances such as natural language processing (NLP), AI can also power chatbots and interfaces to provide personalized interactions to users, helping make information more accessible. AI can have a transformational impact on the way people and organizations work, make decisions, and express creativity. Challenges of Artificial Intelligence There are some barriers to entry to deploying AI , including a high initial cost associated with setting up AI infrastructure and hiring skilled professionals to develop and maintain these systems. Business leaders may also find that integrating AI technologies into their existing workflows can be time-consuming and disruptive, as well as requiring continuous monitoring, analysis, and refinement of AI models for best results. Furthermore, organizations must be proactive about counteracting the potential bias in AI models when using AI to inform their decision-making. Fortunately, there may be ways for organizations to leverage existing IT infrastructure for their AI processes, in addition to using hybrid cloud resources, to help offset initial costs. Gradual implementation and pilot programs can help ease the transition to AI prior to full-scale rollout, and continuous refinement of AI models can result in more-efficient AI over time. To help mitigate bias in AI models, organizations can regularly audit data and inference results for greater transparency, use diverse sets of training data, and facilitate diversity and equity within teams that design and develop AI systems. How Does Artificial Intelligence Work? At the core of AI technology lies the ability of AI models to analyze data, recognize patterns, and make decisions with minimal human intervention. On a technical level, AI models operate through sophisticated algorithms that enable machines to process data, learn from it, and make informed decisions. AI models are essentially software that data scientists and AI developers code and train using vast quantities of data. The AI Development Workflow The AI development workflow involves three main stages. The first stage is data preprocessing in which the data that will be analyzed is cleaned and formatted. Next is AI modeling, where algorithms and frameworks are selected to build the model, and the model learns from the preprocessed data. Finally, the trained model is deployed and used for inferencing, making predictions or decisions based on new data to demonstrate its real-world applicability. From end to end, this entire process is often referred to as an AI pipeline. Why Is Artificial Intelligence Important? AI is already making a profound impact on society, from aiding clinicians in medical diagnoses to helping businesses design improved, more sophisticated products. Wherever knowledge and data are present, AI offers new ways to understand and interact with that data to produce new outcomes. How Is Artificial Intelligence Used? The application of AI can vary greatly in terms of its complexity and capabilities. Here are four common types of AI deployment: Machine Learning Machine learning uses multiple algorithms—sets of logical instructions—to recognize and learn from patterns in data. The more data machine learning acts on, the more accurate it gets. Deep Learning Deep learning is a multilayered version of machine learning built to act on vast amounts of data. Unlike machine learning, deep learning is designed to work on raw data and requires less or no human intervention to improve accuracy. Neural Networks Neural networks are the building blocks of machine and deep learning systems, consisting of interconnected nodes that emulate the structure of the human brain. Each node performs a computation and passes its result onto subsequent nodes. Computer Vision Computer vision is a type of AI that allows computers to understand and act on visual inputs. Generally, computer vision helps machines recognize specific objects in the physical world. Artificial Intelligence Industry Applications Owing to its adaptability and potential for yet-to-be-envisioned applications, AI is maturing as a fundamental component of digital transformation across several industries . Here are a few highlighted examples: AI in Automotive : AI is helping driverless vehicles become a reality, using computer vision to enable driver and passenger monitoring and bringing Gen AI assistants and AI-enabled gaming to vehicles. AI in Banking , AI in Financial Services : AI chatbots are personalizing customer interactions, while on the back end, AI is helping to detect and prevent fraud, automate risk assessment, and facilitate algorithmic stock trading. AI in Cybersecurity : AI supports defense-in-depth strategies by automating threat detection and response. As the digital footprint of businesses expands, SecOps and IT teams are increasingly relying on AI to scale operations beyond human limitations. AI in Education : AI tools are helping teachers and students personalize lessons as well as drive administrative efficiency in assignment scoring or attendance taking. AI in Healthcare : AI is being leveraged by healthcare practitioners to improve diagnostic speed and accuracy. In medical research, AI’s pattern recognition abilities are helping to accelerate drug discovery. AI in Manufacturing : AI is driving robotics on the factory and warehouse floor, automating situational awareness with digital twins, helping reduce downtime with predictive maintenance, and helping improve output with automated defect detection. AI in Sustainability , AI in Energy : AI enhances smart grids that efficiently integrate renewable energy, enables predictive maintenance for energy infrastructure like power lines, helps optimize energy use in buildings, and analyzes environmental and emissions data to help combat climate change. History of Artificial Intelligence AI has a rich, complex history full of many key figures, innovations, and institutions. Here are a few milestones to help illustrate how far AI has come to shape the present moment. 1945 John von Neumann proposes a computer architecture scheme that will become foundational to modern digital computers. 1 1950 Alan Turing proposes the Turing Test to determine if a computer can successfully imitate human responses. 2 1956 Researchers create the first AI computer program, Logic Theorist, which proves theorems using symbolic logic. 3 1956 The Dartmouth Summer Research Project on Artificial Intelligence workshop establishes AI as a formal field of study. 4 1956–1974 Leaps in AI progress spark interest and funding from government agencies such as the Defense Advanced Research Projects Agency (DARPA). 5 1959 Arthur Samuel coins the term “machine learning” to describe self-teaching computers. 6 1966 The Stanford Research Institute creates Shakey, the first mobile robot with computer vision-based navigation and the ability to process complex commands. 7 1973 In the UK, the Lighthill report criticizes AI’s failure to produce major impacts, resulting in a period of governmental funding cuts—dubbed “AI winter”—that were subsequently mirrored in the US. 8 1980 Backpropagation—a more efficient way to calculate how changes in variables impact machine learning’s accuracy—becomes foundational to training neural networks. 9 1981 The first IBM PC launches, leading to a shift away from AI-based expert systems to a client-server model in business settings. This culminates in another AI winter through the 1990s. 10 1997 The IBM supercomputer Deep Blue wins a chess rematch against world champion Garry Kasparov. 11 2004 The DARPA Grand Challenge begins awarding cash prizes for groundbreaking developments in autonomous driving, with successive challenges in the following years. 12 2014 Google subsidiary DeepMind begins developing AlphaGo, an AI that plays the game Go, considered to be more complex than chess. The effort culminates in AlphaGo defeating legendary player Lee Sedol in 2016. 13 2018 Stanford’s Artificial Intelligence Index reports a surge of new AI research efforts worldwide, suggesting a new AI boom. 14 2021 UNESCO publishes the first global standard on AI ethics to address concerns about AI’s impact on human rights and climate change. 15 2023 OpenAI’s ChatGPT, an AI adept at simulating human conversation, reaches 100 million users. 16 View all Show less The Four Types of Artificial Intelligence Researchers have identified four types of AI. These types reflect the current state of AI and what it might look like when fully realized. Reactive Machines AI that is task-specific and retains no memory of past events is known as a reactive machine. This type of AI works on repeatable data inputs and provides predictable outputs. An example of a reactive machine is a visual inspection appliance on an assembly line. Limited Memory Limited memory refers to AI processes that learn from additional data inputs. They apply deep learning to continually adjust and improve their accuracy. Examples of limited memory AI include self-driving cars and LLMs. Theory of Mind Theory of mind describes a type of AI that can understand and interpret the emotions, beliefs, and intentions of other beings. This type of AI does not currently exist. Self-Awareness AI with self-awareness can comprehend its own existence and possess a sense of self. For now, this type of AI remains in the purview of theory and science fiction. Artificial Intelligence Solutions Most AI deployments consist of AI software running on AI hardware—which may include devices and/or servers—and always some type of AI processor. AI Hardware AI hardware encompasses the general purpose and specialized computer parts and components used to support AI workloads across devices, servers, or cloud environments. Generally, AI hardware refers to systems built for postdeployment inference, but it can also refer to systems used in developing and training AI models. AI Processors AI processors typically refer to central processing units (CPUs) designed for AI workloads in addition to AI accelerators such as graphics processing units (GPUs), neural processing units (NPUs), or field-programmable gate arrays (FPGAs). AI Servers AI servers refer to any server configuration including processors, accelerators, memory, storage, or networking designed specifically to support AI workloads. AI Software AI software is a broad topic covering many types of programs. It can refer to AI applications or AI models users interface with directly, as with AI chatbots, or to AI programs that run as background processes without user prompting. AI software can also refer to the programs or tools used by developers to prepare datasets and develop, deploy, and optimize AI models. Future of Artificial Intelligence AI is evolving quickly, demonstrating remarkable progress that suggests a future brimming with potential. Advances in the already-established fields of machine learning and deep learning, combined with the ingenuity of LLMs, could potentially reshape industries, enhance efficiency, and unlock new realms of creativity. Responsible AI As more businesses and members of the public embrace AI, the use of responsible AI can help curb potentially negative impacts. Responsible AI describes AI processes that are transparent, fair, and accountable. Integrating these practices into the development and implementation of AI can help mitigate the effects of bias and help ensure that AI works to uplift communities. Get Started Discover how Intel can help you rapidly bring your AI initiatives to life—across data center, cloud, client, and edge—with optimal performance, scalability, and cost. Intel® Artificial Intelligence Solutions Unlock AI results for your business with perfect-fit hardware and software solutions backed by proven experience and an ecosystem of AI partners. AI PCs with Intel® Core™ Ultra Processors AI PCs use AI to elevate productivity, creativity, gaming, entertainment, security, and more. They have a CPU, GPU, and neural processing unit (NPU) to handle AI tasks locally and more efficiently. Intel® Xeon® Processors The latest generation of Intel® Xeon® processors provides a single platform with options focusing on high performance for AI and compute-intense workloads, exceptional efficiency, or cloud scalability. Intel® Gaudi® AI Accelerators This deep learning architecture provides a cost-effective, high-performance training and inference alternative to comparable GPUs. Intel® Tiber™ AI Solutions Enterprises can find everything they need to develop and scale AI, including access to cutting-edge AI hardware on the Intel® Tiber™ Developer Cloud. OpenVINO™ toolkit Explore how this open source toolkit gives developers a single tool to accelerate models across several hardware platforms, including FPGAs, streamlining development and deployment. Show more Show less Technology Topic Summary View, save, or share a one-page visual with key insights about this topic. Get the insight visual Explore AI Use Cases and Applications See how enterprises are investing in AI to automate processes, personalize customer and employee experiences, and transform their industries. AI in Automotive AI in Banking AI in Cybersecurity AI in Education AI in Energy AI in Finance AI in Government AI in Healthcare AI in Manufacturing AI in Retail AI in Robotics AI for Sustainability AI in Telecommunications Get the Latest on AI Trends and Technologies Subscribe to stay connected with Intel. Sign up What Is Artificial Intelligence? Benefits of Artificial Intelligence Challenges of Artificial Intelligence How Does Artificial Intelligence Work? Why Is Artificial Intelligence Important? How Is Artificial Intelligence Used? Artificial Intelligence Industry Applications History of Artificial Intelligence The Four Types of Artificial Intelligence Artificial Intelligence Solutions Future of Artificial Intelligence Get Started Product and Performance Information 1 “Von Neumann Architecture,” Computer Science GCSE GURU, accessed February 2025, computerscience.gcse.guru/theory/von-neumann-architecture . 2 “Turing test,” Wikipedia, accessed February 2025, en.wikipedia.org/wiki/Turing_test . 3 Sarah Sloat, “The first AI started a 70-year debate,” Popular Science, October 2023, popsci.com/technology/the-first-ai-logic-theorist/ . 4 “Artificial Intelligence Coined at Dartmouth,” Dartmouth, accessed February 2025, home.dartmouth.edu/about/artificial-intelligence-ai-coined-dartmouth . 5 “The Golden Years of AI (1956–1974),” Holloway, November 2022, holloway.com/g/making-things-think/sections/the-golden-years-of-ai-19561974 . 6 Gil Press, “On Thinking Machines, Machine Learning, And How AI Took Over Statistics,” Forbes, May 2021, forbes.com/sites/gilpress/2021/05/28/on-thinking-machines-machine-learning-and-how-ai-took-over-statistics/ . 7 Tekla S. Perry, “SRI's Pioneering Mobile Robot Shakey Honored as IEEE Milestone,” IEEE Spectrum, February 2017, spectrum.ieee.org/sri-shakey-robot-honored-as-ieee-milestone . 8 “Lighthill report,” Wikipedia, accessed February 2025, en.wikipedia.org/wiki/Lighthill_report . 9 “The History of Backpropagation,” Perplexity, August 2024, perplexity.ai/page/the-history-of-backpropagation-LoxpCKvnQmq7nKjA.AWjBA . 10 “Timeline of Computer History,” Computer History Museum, accessed February 2025, computerhistory.org/timeline/1981/ . 11 “Deep Blue,” IBM, accessed February 2025, ibm.com/history/deep-blue . 12 “The DARPA Grand Challenge: Ten Years Later,” DARPA, March 2014, darpa.mil/news/2014/grand-challenge-ten-years-later . 13 “AlphaGo,” Google DeepMind, accessed February 2025, deepmind.google/research/breakthroughs/alphago/ . 14 “The 2018 AI Index Report,” Stanford University Human-Centered Artificial Intelligence, accessed February 2025, hai.stanford.edu/ai-index/2018-ai-index-report . 15 “Ethics of Artificial Intelligence,” UNESCO, accessed February 2025, unesco.org/en/artificial-intelligence/recommendation-ethics . 16 Krystal Hu, “ChatGPT sets record for fastest-growing user base - analyst note,” Reuters, February 2023, reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/ . Get Help Company Overview Contact Intel Newsroom Investors Careers Corporate Responsibility Inclusion Public Policy © Intel Corporation Terms of Use *Trademarks Cookies Privacy Supply Chain Transparency Site Map Recycling Your Privacy Choices California Consumer Privacy Act (CCPA) Opt-Out Icon Notice at Collection Intel technologies may require enabled hardware, software or service activation. // No product or component can be absolutely secure. // Your costs and results may vary. // Performance varies by use, configuration, and other factors. Learn more at intel.com/performanceindex . // See our complete legal Notices and Disclaimers . // Intel is committed to respecting human rights and avoiding causing or contributing to adverse impacts on human rights. See Intel’s Global Human Rights Principles . Intel’s products and software are intended only to be used in applications that do not cause or contribute to adverse impacts on human rights.
====================================================================================================
Just a moment... Enable JavaScript and cookies to continue
====================================================================================================
What is Artificial Intelligence (AI)? - Artificial Intelligence - Research Guides at Case Western Reserve University Skip to Main Content Kelvin Smith Library Kelvin Smith Library Research Guides Artificial Intelligence What is Artificial Intelligence (AI)? Search this Guide Search Artificial Intelligence What is Artificial Intelligence (AI)? AI at CWRU AI Literacy Using AI Ethical Considerations AI in Research AI for Students AI for Faculty and Staff AI Citation and Academic Integrity AI and Copyright Feedback This is a living document for a rapidly changing field. We welcome your feedback and recommendations! This guide includes material from: Duke University YouTube Loyola Notre Dame Library University of Calgary Library: Artificial Intelligence Florida International University Library UC San Diego Library Cleveland State University Library Get Online Help KSL Ask A Librarian Information on how to get help by email, phone, & chat. What is Artificial Intelligence (AI)? “ Artificial intelligence (AI) is the design, implementation, and use of programs, machines, and systems that exhibit human intelligence, with its most important activities being knowledge representation, reasoning, and learning. Artificial intelligence encompasses a number of important subareas, including voice recognition, image identification, natural language processing, expert systems, neural networks , planning, robotics , and intelligent agents.” ( Salem Press Encyclopedia of Science ). “ Generative artificial intelligence is a type of artificial intelligence (AI) technology that can make content such as audio, images, text, and videos. It involves algorithms such as ChatGPT , a chatbot that can produce essays, poetry, and other content requested by a user, and DALL-E, which generates art.” ( Salem Press Encyclopedia of Science ). Artificial intelligence is used across all industries and academic subjects. The term is used to describe everything from finding the best route on Apple and Google Maps, self-driving cars, algorithms to display a list in a certain order on a website or in a social media app, and facial recognition software to unlock a smartphone. It is part of our everyday lives, at work, in school and at home. Videos What is an AI anyway? AI vs Machine Learning How AI Could Save (Not Destroy) Education How will AI Change the World? What is Artificial Intelligence? Generative AI in a Nutshell Additional Resources Introductory Resources A Jargon-Free Explanation of how AI Large Language Models Work Want to really understand large language models? Here’s a gentle primer. Demystifying Large Language Models: A Beginner’s Guide Large Language Model The Wikipedia entry on Large Language Models Generative AI - A Primer An introduction to generative artificial intelligence technology and its implications on education Getting Started with Generative AI in Education for Faculty This short course is intended for those new to Generative AI and will provide a foundation from which to begin your own exploration of how best to use these innovative tools that are changing our world. The course is developed by UTech Teaching and Learning Technologies (TLT) in collaboration with University Center for Innovation in Teaching and Education (UCITE), Kelvin Smith Library (KSL), and CWRU faculty members. Florida International University’s AI Guide Find resources on artificial intelligence, ChatGPT, writing with AI assistance, AI academic productivity tools, plagiarism, prompt engineering, GPT misinformation and hallucinations, AI image tools, AI literacy, and discussions related to AI ethics The UC San Diego Guide on Generative Artificial Intelligence: Using Generative AI Tools AIPRM’s Ultimate Generative AI Glossary Glossary of AI Terms for Educators From the Center for Integrative Research in Computer and Learning Science Advanced Resources Free Code Camp One of the best computer programming resources around, Free Code Camp’s extensive tutorial library includes a number of different courses on LLM use and development. Hugging Face Hugging Face, Inc. is a French-American company that develops computation tools for building applications using machine learning. It is most notable for its transformers library built for natural language processing applications and its platform that allows users to share machine learning models and datasets and showcase their work. Hugging Face has extensive educational resources to get you familiar with its platform and best practices for using LLMs and other tools in natural language processing. Full Stack LLM Bootcamp “The Full Stack brings people together to learn and share best practices across the entire lifecycle of an AI-powered product: from defining the problem and picking a GPU or foundation model to production deployment and continual learning to user experience design.” The LLM Bootcamp is an open course designed to teach you how to leverage LLMs in application development. Cohere LLM University Seven Modules from Cohere that provide an in depth look at how to use LLMs in a variety of projects. Next: AI at CWRU >> Last Updated: May 3, 2025 11:05 AM URL: https://researchguides.case.edu/artificialintelligence Print Page Login to LibApps Report a problem Subjects: Artificial Intelligence
====================================================================================================
Development and applications of artificial intelligence | Britannica Search Britannica Click here to search Search Britannica Click here to search SUBSCRIBE SUBSCRIBE Login https://premium.britannica.com/premium-membership/?utm_source=premium&utm_medium=nav-login-box&utm_campaign=evergreen SUBSCRIBE Home History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Games & Quizzes Videos On This Day One Good Fact Dictionary New Articles History & Society Lifestyles & Social Issues Philosophy & Religion Politics, Law & Government World History Science & Tech Health & Medicine Science Technology Biographies Browse Biographies Animals & Nature Birds, Reptiles & Other Vertebrates Bugs, Mollusks & Other Invertebrates Environment Fossils & Geologic Time Mammals Plants Geography & Travel Geography & Travel Arts & Culture Entertainment & Pop Culture Literature Sports & Recreation Visual Arts Image Galleries Podcasts Summaries Top Questions Britannica Kids Ask the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Videos Related Summaries Artificial Intelligence (AI): At a Glance Summary Alan Turing Summary neural network Summary Home Technology Computers artificial intelligence summary More Actions Cite verified Cite While every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions. Select Citation Style MLA APA Chicago Manual of Style Copy Citation Share Share Share to social media Facebook X URL https://www.britannica.com/summary/artificial-intelligence Feedback Corrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login). Feedback Type Select a type (Required) Factual Correction Spelling/Grammar Correction Link Correction Additional Information Other Your Feedback Submit Feedback Thank you for your feedback Our editors will review what you’ve submitted and determine whether to revise the article. External Websites Learn about the development of artificial intelligence and its various applications Written and fact-checked by The Editors of Encyclopaedia Britannica Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree. They write new content and verify and edit content received from contributors. The Editors of Encyclopaedia Britannica Below is the article summary. For the full article, see artificial intelligence . Pebbles the robot Pebbles, a tractorlike robot utilizing a vision-based control system developed during the late 1990s as part of MIT's Mars Rover Research Project. Pebbles, which is about the size of a domestic cat, negotiates around obstacles with the aid of a single camera, the robot's only sensor. With its arm attached, Pebbles can collect samples or handle dangerous objects. (more) artificial intelligence (AI) , Ability of a machine to perform tasks thought to require human intelligence. Typical applications include game playing, language translation, expert systems, and robotics. Although pseudo-intelligent machinery dates back to antiquity, the first glimmerings of true intelligence awaited the development of digital computers in the 1940s. AI, or at least the semblance of intelligence, has developed in parallel with computer processing power, which appears to be the main limiting factor. Early AI projects, such as playing chess and solving mathematical problems, are now seen as trivial compared to visual pattern recognition, complex decision making, and the use of natural language. See also Turing test. Artificial Intelligence (AI): At a Glance Summary Artificial intelligence (AI) is a computer’s ability to do tasks commonly associated with human intelligence. The term is applied to the project of developing systems endowed with intellectual processes, such as the ability to reason, discover meaning, generalize, or learn from past experience. Alan Turing Summary Alan Turing was a British mathematician and logician who made major contributions to mathematics, cryptanalysis, logic, philosophy, and mathematical biology and also to the new areas later named computer science, cognitive science, artificial intelligence, and artificial life. The son of a civil neural network Summary Neural network, a computer program that operates in a manner inspired by the natural neural network in the brain. The objective of such artificial neural networks is to perform such cognitive functions as problem solving and machine learning. The theoretical basis of neural networks was developed
====================================================================================================
Artificial Intelligence News -- ScienceDaily Skip to main content Your source for the latest research news Follow: Facebook X/Twitter Subscribe: RSS Feeds Newsletter New! Sign up for our free email newsletter . Artificial Intelligence News June 28, 2025 Top Headlines Quantum Breakthrough: ‘Magic States’ Now Easier, Faster, and Way Less Noisy June 26, 2025  Quantum computing just got a significant boost thanks to researchers at the University of Osaka, who developed a much more efficient way to create "magic states" a key component for fault-tolerant ... Quantum Computers Just Got an Upgrade – and It’s 10× More Efficient June 25, 2025  Chalmers engineers built a pulse-driven qubit amplifier that’s ten times more efficient, stays cool, and safeguards quantum states—key for bigger, better quantum ... AI at Light Speed: How Glass Fibers Could Replace Silicon Brains June 20, 2025  Imagine supercomputers that think with light instead of electricity. That s the breakthrough two European research teams have made, demonstrating how intense laser pulses through ultra-thin glass fibers can perform AI-like computations thousands of ... The AI That Writes Climate-Friendly Cement Recipes in Seconds June 19, 2025  AI researchers in Switzerland have found a way to dramatically cut cement s carbon footprint by redesigning its recipe. Their system simulates thousands of ingredient combinations, pinpointing those that keep cement strong while emitting far less ... Robots That Feel Heat, Pain, and Pressure? This New “skin” Makes It Possible June 17, 2025  Researchers have created a revolutionary robotic skin that brings machines closer to human-like touch. Made from a flexible, low-cost gel material, this skin transforms the entire surface of a ... This Quantum Sensor Tracks 3D Movement Without GPS June 14, 2025  Physicists at the University of Colorado Boulder have created a groundbreaking quantum device that can measure 3D acceleration using ultracold atoms, something once thought nearly impossible. By chilling rubidium atoms to near absolute zero and ... Photonic Quantum Chips Are Making AI Smarter and Greener June 8, 2025  A team of researchers has shown that even small-scale quantum computers can enhance machine learning performance, using a novel photonic quantum circuit. Their findings suggest that today s quantum technology isn t just experimental it can already ... This “robot Bird” Flies at 45 Mph Through forests—With No GPS or Light June 7, 2025  Unlike birds, which navigate unknown environments with remarkable speed and agility, drones typically rely on external guidance or pre-mapped routes. However, a groundbreaking development by ... Guardrails, Education Urged to Protect Adolescent AI Users June 3, 2025  The effects of artificial intelligence on adolescents are nuanced and complex, according to a new report that calls on developers to prioritize features that protect young people from exploitation, manipulation and the erosion of real-world ... Self-Powered Artificial Synapse Mimics Human Color Vision June 2, 2025  Despite advances in machine vision, processing visual data requires substantial computing resources and energy, limiting deployment in edge devices. Now, researchers from Japan have developed a self-powered artificial synapse that distinguishes ... Engineers Develop Self-Healing Muscle for Robots May 30, 2025  Students recently unveiled their invention of a robotic actuator -- the 'muscle' that converts energy into a robot's physical movement -- that has the ability to detect punctures or pressure, heal the injury and repair its damage-detecting ... AI Meets Game Theory: How Language Models Perform in Human-Like Social Scenarios May 30, 2025  Large language models (LLMs) -- the advanced AI behind tools like ChatGPT -- are increasingly integrated into daily life, assisting with tasks such as writing emails, answering questions, and even ... Latest Headlines updated 4:00am EDT Affordances in the Brain: The Human Superpower AI Hasn’t Mastered June 23, 2025  Scientists at the University of Amsterdam discovered that our brains automatically understand how we can move through different environments—whether it's swimming in a lake or walking a ... Half of Today’s Jobs Could vanish—Here’s How Smart Countries Are Future-Proofing Workers June 22, 2025  AI is revolutionizing the job landscape, prompting nations worldwide to prepare their workforces for dramatic changes. A University of Georgia study ... Horses 'Mane' Inspiration for New Generation of Social Robots May 29, 2025  Interactive robots should not just be passive companions, but active partners -- like therapy horses who respond to human emotion -- say ... Solitonic Superfluorescence Paves Way for High-Temperature Quantum Materials May 28, 2025  A new study in Nature describes both the mechanism and the material conditions necessary for superfluorescence at high ... Mid-Air Transformation Helps Flying, Rolling Robot to Transition Smoothly May 28, 2025  Engineers have developed a real-life Transformer that has the 'brains' to morph in midair, allowing the drone-like robot to smoothly roll away and begin its ground operations without pause. The ... Emotional Responses Crucial to Attitudes About Self-Driving Cars May 27, 2025  When it comes to public attitudes toward using self-driving cars, understanding how the vehicles work is important -- but so are less obvious characteristics like feelings of excitement or pleasure ... AI Is Here to Stay, Let Students Embrace the Technology, Experts Urge May 26, 2025  A new study says students appear to be using generative artificial intelligence (GenAI) responsibly, and as a way to speed up tasks, not just boost their ... Light-Driven Cockroach Cyborgs Navigate Without Wires or Surgery May 22, 2025  have created a new type of insect cyborg that can navigate autonomously -- without wires, surgery, or stress-inducing electrical shocks. The system uses a small ultraviolet (UV) light helmet to steer ... Could AI Understand Emotions Better Than We Do? May 22, 2025  Is artificial intelligence (AI) capable of suggesting appropriate behavior in emotionally charged situations? A team put six generative AIs -- including ChatGPT -- to the test using emotional ... Imaging Technique Removes the Effect of Water in Underwater Scenes May 21, 2025  SeaSplat is an image-analysis tool that cuts through the ocean's optical effects to generate images of underwater environments reveal an ocean scene's true colors. Researchers paired the ... Affordance: The Brain’s Hidden Superpower Half of Today’s Jobs Could Vanish Horse-Inspired Social Robots Toward High-Temp Quantum Materials Flying, Rolling Robot Transitions Smoothly Attitudes About Self-Driving Cars Students Use AI to Enhance Their Learning Light-Driven Cockroach Cyborgs Could AI Understand Emotions Better Than We Do? Imaging Technique Removes the Effect of Water Earlier Headlines Summaries Headlines Scientists Discover Class of Crystals With Properties That May Prove Revolutionary May 21, 2025  Researchers have discovered a new class of materials -- called intercrystals -- with unique electronic properties that could power future technologies. Intercrystals exhibit newly discovered forms of ... World's First Petahertz-Speed Phototransistor in Ambient Conditions May 19, 2025  Researchers demonstrated a way to to manipulate electrons using pulses of light that last less than a trillionth of a second to record electrons bypassing a physical barrier almost instantaneously -- ... Robots Learning Without Us? New Study Cuts Humans from Early Testing May 19, 2025  Humans no longer have exclusive control over training social robots to interact effectively, thanks to a new study. The study introduces a new simulation method that lets researchers test their ... Empowering Robots With Human-Like Perception to Navigate Unwieldy Terrain May 19, 2025  Researchers have developed a novel framework named WildFusion that fuses vision, vibration and touch to enable robots to 'sense' and navigate complex outdoor environments much like humans ... With Evolutionary AI, Scientists Find Hidden Keys for Better Land Use May 19, 2025  A new AI decision making tool effectively balances various complex trade-offs to recommend ways of maximizing carbon storage, minimizing economic disruptions and helping improve the environment and ... Remotely Controlled Robots at Your Fingertips: Enhancing Safety in Industrial Sites May 19, 2025  A research team has developed a novel haptic device designed to enhance both safety and efficiency for workers in industrial ... Learning as an Adventure: The Lecture Theater in the Spaceship May 15, 2025  In Project Chimera, a game lab combines a VR computer game with educational problems in order to convey scientific content in a motivating ... Seeing Blood Clots Before They Strike June 27, 2025  Researchers have found a way to observe clotting activity in blood as it happens -- without needing invasive procedures. Using a new type of microscope and artificial intelligence (AI), their study ... Following the Folds -- With Quantum Technology May 14, 2025  The connection between a crumpled sheet of paper and quantum technology: A research team at the EPFL in Lausanne (Switzerland) and the University of Konstanz (Germany) uses topology in microwave ... Study Shows Vision-Language Models Can't Handle Queries With Negation Words May 14, 2025  Researchers found that vision-language models, widely used to analyze medical images, do not understand negation words like 'no' and 'not.' This could cause them to fail ... Artificial Intelligence and Genetics Can Help Farmers Grow Corn With Less Fertilizer May 14, 2025  Scientists are using artificial intelligence to determine which genes collectively govern nitrogen use efficiency in plants such as corn, with the goal of helping farmers improve their crop yields ... Energy and Memory: A New Neural Network Paradigm May 14, 2025  Listen to the first notes of an old, beloved song. Can you name that tune? If you can, congratulations -- it's a triumph of your associative memory, in which one piece of information (the first ... How We Think About Protecting Data May 14, 2025  A new game-based experiment sheds light on the tradeoffs people are willing to make about data ... The Key to Spotting Dyslexia Early Could Be AI-Powered Handwriting Analysis May 14, 2025  A new study outlines how artificial intelligence-powered handwriting analysis may serve as an early detection tool for dyslexia and dysgraphia among young ... Handy Octopus Robot Can Adapt to Its Surroundings May 14, 2025  Scientists inspired by the octopus's nervous system have developed a robot that can decide how to move or grip objects by sensing its ... Digital Lab for Data And Robot-Driven Materials Science May 14, 2025  Researchers have developed a digital laboratory (dLab) system that fully automates the material synthesis and structural, physical property evaluation of thin-film samples. With dLab, the team can ... Protons on the Move May 14, 2025  Scientists have successfully relocated protons outside of an antimatter laboratory with the help of an autonomous, open Penning trap. This breakthrough marks a significant step toward transporting ... Eldercare Robot Helps People Sit and Stand, and Catches Them If They Fall May 13, 2025  Engineers built E-BAR, a mobile robot designed to physically support the elderly and prevent them from falling as they move around their homes. E-BAR acts as a set of robotic handlebars that follows ... Robotic Hand Moves Objects With Human-Like Grasp May 13, 2025  A robotic hand can pick up 24 different objects with human-like movements that emerge spontaneously, thanks to compliant materials and structures rather than ... AI Meets the Conditions for Having Free Will -- We Need to Give It a Moral Compass May 13, 2025  AI is advancing at such speed that speculative moral questions, once the province of science fiction, are suddenly real and pressing, says a philosopher and psychology researcher Frank Martela. ... Wednesday, May 21, 2025 Scientists Discover Class of Crystals With Properties That May Prove Revolutionary Monday, May 19, 2025 World's First Petahertz-Speed Phototransistor in Ambient Conditions Robots Learning Without Us? New Study Cuts Humans from Early Testing Empowering Robots With Human-Like Perception to Navigate Unwieldy Terrain With Evolutionary AI, Scientists Find Hidden Keys for Better Land Use Remotely Controlled Robots at Your Fingertips: Enhancing Safety in Industrial Sites Thursday, May 15, 2025 Learning as an Adventure: The Lecture Theater in the Spaceship Friday, June 27, 2025 Seeing Blood Clots Before They Strike Wednesday, May 14, 2025 Following the Folds -- With Quantum Technology Study Shows Vision-Language Models Can't Handle Queries With Negation Words Artificial Intelligence and Genetics Can Help Farmers Grow Corn With Less Fertilizer Energy and Memory: A New Neural Network Paradigm How We Think About Protecting Data The Key to Spotting Dyslexia Early Could Be AI-Powered Handwriting Analysis Handy Octopus Robot Can Adapt to Its Surroundings Digital Lab for Data And Robot-Driven Materials Science Protons on the Move Tuesday, May 13, 2025 Eldercare Robot Helps People Sit and Stand, and Catches Them If They Fall Robotic Hand Moves Objects With Human-Like Grasp AI Meets the Conditions for Having Free Will -- We Need to Give It a Moral Compass New Computer Language Helps Spot Hidden Pollutants Monday, May 12, 2025 Submarine Robot Catches an Underwater Wave Thursday, May 8, 2025 Ping Pong Bot Returns Shots With High-Speed Precision Robotic Dog Mimics Mammals for Superior Mobility on Land and in Water Eco-Friendly Aquatic Robot Is Made from Fish Food Is AI Truly Creative? Turns out Creativity Is in the Eye of the Beholder Wednesday, May 7, 2025 Transforming Hospital Sanitation: Autonomous Robots for Wiping and UV-C Disinfection Is Virtual-Only Couture the New Clothing Craze? Tuesday, May 6, 2025 Gender Characteristics of Service Robots Can Influence Customer Decisions How AI Tools Can Improve Manufacturing Worker Safety, Product Quality Monday, May 5, 2025 A New Method for Characterizing Quantum Gate Errors Robotic Touch Sensors Are Not Just Skin Deep Text-to-Video AI Blossoms With New Metamorphic Video Capabilities Privacy-Aware Building Automation Thursday, May 1, 2025 Using Principles of Swarm Intelligence, Study Compared Platforms That Allow Brainstorming Among Large Groups Making AI Models More Trustworthy for High-Stakes Settings Artificial Sense of Touch, Improved Researchers Develop a Novel Vote-Based Model for More Accurate Hand-Held Object Pose Estimation Wednesday, April 30, 2025 Engineers Advance Toward a Fault-Tolerant Quantum Computer 'Explainable' AI Cracks Secret Language of Sticky Proteins Monday, April 28, 2025 Advancing AI for Diverse Applications in Manufacturing, Business and Education Friday, April 25, 2025 Cutting the Complexity from Digital Carpentry Thursday, April 24, 2025 Awkward. Humans Are Still Better Than AI at Reading the Room Flying Robots Unlock New Horizons in Construction Making AI-Generated Code More Accurate in Any Language Wednesday, April 23, 2025 Engineering a Robot That Can Jump 10 Feet High -- Without Legs 'Periodic Table of Machine Learning' Could Fuel AI Discovery Generative AI Masters the Art of Scent Creation New Electronic 'skin' Could Enable Lightweight Night-Vision Glasses Material? Robot? It's a Metabot Tuesday, April 22, 2025 Robot See, Robot Do: System Learns After Watching How-to Videos Brain-Inspired AI Breakthrough: Making Computers See More Like Humans AI Tool Grounded in Evidence-Based Medicine Outperformed Other AI Tools -- And Most Doctors On USMLE Exams Monday, April 21, 2025 It's a Quantum Zoo out There, and Scientists Just Found a Dozen New 'species' High-Tech Sticker Can Identify Real Human Emotions Wednesday, April 16, 2025 RoboBee Comes in for a Landing Tuesday, April 15, 2025 Explainable AI for Ship Navigation Raises Trust, Decreases Human Error Monday, April 14, 2025 AI Tool to Better Assess Parkinson's Disease, Other Movement Disorders Photonic Computing Needs More Nonlinearity: Acoustics Can Help How the Brain Controls Movement Under Uncertainty Thursday, April 10, 2025 AI Tool Set to Speed Quest for Advanced Superconductors Wednesday, April 9, 2025 AI Models of the Brain Could Serve as 'digital Twins' In Research Could LLMs Help Design Our Next Medicines and Materials? A New Robotic Gripper Made of Measuring Tape Is Sizing Up Fruit and Veggie Picking Hopping Gives This Tiny Robot a Leg Up Engineers Bring Sign Language to 'life' Using AI to Translate in Real-Time 3D-Printed Open-Source Robot Offers Accessible Solution for Materials Synthesis Tuesday, April 8, 2025 AI Threats in Software Development Revealed Tiny, Soft Robot Flexes Its Potential as a Life Saver Monday, April 7, 2025 Chatbot Opens Computational Chemistry to Nonexperts Is AI in Medicine Playing Fair? Friday, April 4, 2025 How Can Science Benefit from AI? Risks? Thursday, April 3, 2025 Nurture More Important Than Nature for Robotic Hand Powerful New Software Platform Could Reshape Biomedical Research by Making Data Analysis More Accessible Wednesday, April 2, 2025 Scientists Unveil Starfish-Inspired Wearable Tech for Heart Monitoring Monday, March 31, 2025 Chance Discovery Improves Stability of Bioelectronic Material Used in Medical Implants, Computing and Biosensors Friday, March 28, 2025 Artificial Neurons Organize Themselves Thursday, March 27, 2025 A Lighter, Smarter Magnetoreceptive Electronic Skin First Therapy Chatbot Trial Shows AI Can Provide 'gold-Standard' Care Feeling the Future: New Wearable Tech Simulates Realistic Touch Revolutionary Brain-Computer Interface Decoding System Wednesday, March 26, 2025 Mini Rolling Robot Takes Virtual Biopsies Philosophy: Cultural Differences in Exploitation of Artificial Agents Smart Insoles That Could Change the Game for Sports and Health Repetitive Behaviors and Special Interests Are More Indicative of an Autism Diagnosis Than a Lack of Social Skills Tuesday, March 25, 2025 Revolutionizing Touch: Researchers Explore the Future of Wearable Multi-Sensory Haptic Technology New Type of Quantum Computer Studies the Dance of Elementary Particles These Electronics-Free Robots Can Walk Right Off the 3D-Printer Listen to Quantum Atoms Talk Together Thanks to Acoustics Thursday, March 20, 2025 New AI Tool Generates High-Quality Images Faster Than State-of-the-Art Approaches Novel Memristors to Overcome AI's 'catastrophic Forgetting' Engineer Develops New Security Protocol to Protect Miniaturized Wireless Medical Implants from Cyberthreats Wednesday, March 19, 2025 Squirrel-Inspired Leaping Robot Can Stick a Landing on a Branch Tuesday, March 18, 2025 Coffee-Making Robot Breaks New Ground for AI Machines 'Democratizing Chemical analysis':Chemists Use Machine Learning and Robotics to Identify Chemical Compositions from Images AI Food Scanner Turns Phone Photos Into Nutritional Analysis AI Ring Tracks Spelled Words in American Sign Language Revolutionary Blueprint to Fuse Wireless Technologies and AI Monday, March 17, 2025 New AI Model Analyzes Full Night of Sleep With High Accuracy in Largest Study of Its Kind Artificial Muscle Flexes in Multiple Directions, Offering a Path to Soft, Wiggly Robots Load more stories LATEST NEWS TOP NEWS Top Science Top Health Top Physical/Tech Top Environment Top Society/Education HEALTH Health & Medicine Mind & Brain Living Well PHYSICAL/TECH Space & Time Matter & Energy Computers & Math Business & Industry Computers and Internet Markets and Finance Computer Science Artificial Intelligence Communications Computational Biology Computer Graphics Computer Modeling Computer Programming Distributed Computing Encryption Hacking Information Technology Internet Mobile Computing Photography Quantum Computers Robotics Software Spintronics Research Video Games Virtual Reality WiFi Education & Learning Educational Technology Neural Interfaces Mathematics Math Puzzles Mathematical Modeling Statistics ENVIRONMENT Plants & Animals Earth & Climate Fossils & Ruins SOCIETY & EDUCATION Science & Society Business & Industry Education & Learning QUIRKY Strange & Offbeat Print Email Share Breaking this hour Mysterious Mineral Found in Asteroid Ryugu A Giant Pulse Is Tearing Africa Apart 3,200-Megapixel Camera Captures the Cosmos NASA Uncovers a Deep-Earth Surprise Carbon Countdown: Time’s Nearly Up Fish Changes Sex After Gaining Dominance New Fossils Shift the Story of Complex Life Zooplankton Store 65 Million Tonnes of Carbon Turning E-Waste Into Gold, Safely Glowing Chip Finds Trillionth of a Gram Trending Topics this week SPACE & TIME Space Missions NASA Solar Flare MATTER & ENERGY Construction Engineering and Construction Energy and Resources COMPUTERS & MATH Hacking Information Technology Markets and Finance Strange & Offbeat SPACE & TIME Martian Dust to Dream Homes: How Microbes Can Build on the Red Planet What the Universe Tried to Hide: The 21-Centimeter Signal Explained Tiny Orange Beads Found by Apollo Astronauts Reveal Moon’s Explosive Past MATTER & ENERGY This Breakthrough Turns Old Tech Into Pure Gold — No Mercury, No Cyanide, Just Light and Salt Invisible Quantum Waves Forge Shape-Shifting Super-Materials in Real Time Heavy Particles, Big Secrets: What Happened Right After the Big Bang COMPUTERS & MATH Artificial Intelligence Isn’t Hurting workers—It Might Be Helping Affordances in the Brain: The Human Superpower AI Hasn’t Mastered Half of Today’s Jobs Could vanish—Here’s How Smart Countries Are Future-Proofing Workers Toggle navigation Menu S D S D Home Page Top Science News Latest News Home Home Page Top Science News Latest News Health View all the latest top news in the health sciences, or browse the topics below: Health & Medicine Allergy Cancer Cold and Flu Diabetes Heart Disease ... more topics Mind & Brain ADD and ADHD Alzheimer's Headaches Intelligence Psychology ... more topics Living Well Parenting Child Development Stress Nutrition Fitness ... more topics Tech View all the latest top news in the physical sciences & technology, or browse the topics below: Matter & Energy Chemistry Fossil Fuels Nanotechnology Physics Solar Energy ... more topics Space & Time Black Holes Dark Matter Extrasolar Planets Solar System Space Telescopes ... more topics Computers & Math Artificial Intelligence Mathematics Quantum Computers Robotics Virtual Reality ... more topics Enviro View all the latest top news in the environmental sciences, or browse the topics below: Plants & Animals Agriculture and Food Biology Biotechnology Extinction Microbes and More ... more topics Earth & Climate Climate Earthquakes Geology Global Warming Pollution ... more topics Fossils & Ruins Anthropology Archaeology Dinosaurs Evolution Paleontology ... more topics Society View all the latest top news in the social sciences & education, or browse the topics below: Science & Society Arts & Culture Economics Privacy Issues Public Health Sports ... more topics Business & Industry Computers & Internet Energy & Resources Engineering Medical Technology Transportation ... more topics Education & Learning Creativity Educational Psychology Infant & Preschool Learning Disorders STEM Education ... more topics Quirky Top News Human Quirks Odd Creatures Bizarre Things Weird World Keyword: Search Free Subscriptions Stay informed with ScienceDaily's free email newsletter, updated daily and weekly. Or view our many newsfeeds in your RSS reader: Email Newsletter RSS Feeds Follow Us Keep up to date with the latest news from ScienceDaily via social networks: Facebook X / Twitter Have Feedback? Tell us what you think of ScienceDaily -- we welcome both positive and negative comments. Have any problems using the site? Questions? Leave Feedback Contact Us About This Site | Staff | Contribute | Advertise | Privacy Policy | Editorial Policy | Terms of Use Copyright 1995-2025 ScienceDaily or by other parties, where indicated. All rights controlled by their respective owners. Content on this website is for information only. It is not intended to provide medical or other professional advice. Views expressed here do not necessarily reflect those of ScienceDaily, contributors or partners. Financial support for ScienceDaily comes from advertisements and referral programs.
====================================================================================================
Artificial Intelligence | Scientific American Skip to main content Scientific American Artificial Intelligence Cognition June 26, 2025 Does Using ChatGPT Change Your Brain Activity? Study Sparks Debate Scientists warn against reading too much into a small experiment about ChatGPT and brain activity that is receiving a lot of buzz Nicola Jones, Nature magazine Climate Change June 23, 2025 AI Could Be Harnessed to Cut More Emissions Than It Creates Power-hungry AI and associated data centers could make the grid cleaner, eventually cutting more climate-change-causing emissions than they produce Sara Schonhardt, E&E News $0 for Digital Access Read all the stories you want. Ecology June 17, 2025 Why iNaturalist Users Freaked Out over a Google AI Grant The nonprofit iNaturalist announced that it received a $1.5-million grant from Google’s philanthropic arm to develop generative AI tools for species identification. The news didn’t go over well Kate Wong Artificial Intelligence June 17, 2025 What Is Your Cat Trying to Say? These AI Tools Aim to Decipher Meows AI is shedding new light on the 12,000-year conversation between cats and their humans, suggesting that house cats wield a far richer vocabulary than once thought Deni Ellis Béchard Artificial Intelligence June 16, 2025 Truly Intelligent AI Could Play by the Rules, No Matter How Strange To build safe but powerful AI models, start by testing their ability to play games on the fly Vinay K. Chaudhri Mathematics June 6, 2025 At Secret Math Meeting, Researchers Struggle to Outsmart AI The world's leading mathematicians were stunned by how adept artificial intelligence is at doing their jobs Lyndie Chiou The Science of Parenting June 2, 2025 Kids See a Lot More Misinformation Than We Think Thanks to faulty artificial intelligence, deepfakes and plain bad actors, children encounter a lot on the Internet that isn’t true. Here’s how to help them spot it Evan Orticio Climate Change May 28, 2025 Elon Musk’s Grok Chatbot Has Started Reciting Climate Denial Talking Points The latest version of Grok, the chatbot created by Elon Musk’s xAI, is promoting fringe climate viewpoints in a way it hasn’t done before, observers say Scott Waldman, E&E News Technology May 23, 2025 Building an LLM for Dolphin Chatter A large language model for dolphin vocalization could let us better understand these beloved marine mammals. Melissa Hobson, Rachel Feltman, Fonda Mwangi, Alex Sugiura Artificial Intelligence May 15, 2025 New Google AI Chatbot Tackles Complex Math and Science A Google DeepMind system improves chip designs and addresses unsolved math problems but has not been rolled out to researchers outside the company Elizabeth Gibney, Nature magazine Artificial Intelligence May 13, 2025 What Are AI Chatbot Companions Doing to Our Mental Health? AI chatbot companions may not be real, but the feelings users form for them are. Some scientists worry about long-term dependency David Adam, Nature magazine Artificial Intelligence May 7, 2025 Criminal AI is Here—And Anyone Can Subscribe A new AI platform called Xanthorox markets itself as a tool for cybercrime, but its real danger may lie in how easily such systems can be built—and sold—by anyone Deni Ellis Béchard Next Subscribe to Scientific American to learn and share the most exciting discoveries, innovations and ideas shaping our world today. Subscription Plans Give a Gift Subscription Explore SciAm Latest Issue News Opinion Newsletters Podcasts Games Travel Company About Press Room FAQs Contact Us Standards & Ethics International Editions Advertise More Accessibility Terms of Use Privacy Policy California Consumer Privacy Statement Use of cookies/Do not sell my data Return & Refund Policy Scientific American is part of Springer Nature, which owns or has commercial relations with thousands of scientific publications (many of them can be found at www.springernature.com/us). Scientific American maintains a strict policy of editorial independence in reporting developments in science to our readers. © 2025 SCIENTIFIC AMERICAN, A DIVISION OF SPRINGER NATURE AMERICA, INC. ALL RIGHTS RESERVED.
====================================================================================================
Artificial intelligence | MIT News | Massachusetts Institute of Technology Skip to content ↓ Massachusetts Institute of Technology MIT Top Menu ↓ Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT More ↓ Search MIT Search websites, locations, and people See More Results Suggestions or feedback? MIT News | Massachusetts Institute of Technology Subscribe to MIT News newsletter Browse Enter keywords to search for news articles: Submit Browse By Topics View All → Explore: Machine learning Sustainability Startups Black holes Classes and programs Departments View All → Explore: Aeronautics and Astronautics Brain and Cognitive Sciences Architecture Political Science Mechanical Engineering Centers, Labs, & Programs View All → Explore: Abdul Latif Jameel Poverty Action Lab (J-PAL) Picower Institute for Learning and Memory Media Lab Lincoln Laboratory Schools School of Architecture + Planning School of Engineering School of Humanities, Arts, and Social Sciences Sloan School of Management School of Science MIT Schwarzman College of Computing View all news coverage of MIT in the media → Listen to audio content from MIT News → Subscribe to MIT newsletter → Close Breadcrumb MIT News Topics Artificial intelligence Topic Artificial intelligence Download RSS feed: News Articles / In the Media / Audio Displaying 1 - 15 of 1384 news articles related to this topic. Show: News Articles In the Media Audio MIT and Mass General Brigham launch joint seed program to accelerate innovations in health The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research. June 27, 2025 Read full story → Using generative AI to help robots jump higher and land safely MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans. June 27, 2025 Read full story → Merging AI and underwater photography to reveal hidden ocean worlds The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data. June 25, 2025 Read full story → LLMs factor in unrelated information when recommending medical treatments Researchers find nonclinical information in patient messages — like typos, extra white space, and colorful language — reduces the accuracy of an AI model. June 23, 2025 Read full story → Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education. June 20, 2025 Read full story → Combining technology, education, and human connection to improve online learning Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the “social magic” that influences curiosity and motivation. June 17, 2025 Read full story → Unpacking the bias of large language models In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems. June 17, 2025 Read full story → A sounding board for strengthening the student experience Composed of “computing bilinguals,” the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing. June 17, 2025 Read full story → Celebrating an academic-industry collaboration to advance vehicle technology MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features. June 16, 2025 Read full story → Bringing meaning into technology deployment The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility. June 11, 2025 Read full story → Photonic processor could streamline 6G wireless signal processing By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis. June 11, 2025 Read full story → Have a damaged painting? Restore it in just hours with an AI-generated “mask” A new method can physically restore original paintings using digitally constructed films, which can be removed if desired. June 11, 2025 Read full story → Inroads to personalized AI trip planning A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas. June 10, 2025 Read full story → Melding data, systems, and society A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science. June 10, 2025 Read full story → How we really judge AI Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization. June 10, 2025 Read full story → Pagination Page 1 Next page More about MIT News at Massachusetts Institute of Technology This website is managed by the MIT News Office, part of the Institute Office of Communications . News by Schools/College: School of Architecture and Planning School of Engineering School of Humanities, Arts, and Social Sciences MIT Sloan School of Management School of Science MIT Schwarzman College of Computing Resources: About the MIT News Office MIT News Press Center Terms of Use Press Inquiries Filming Guidelines RSS Feeds Tools: Subscribe to MIT Daily/Weekly Subscribe to press releases Submit campus news Guidelines for campus news contributors Guidelines on generative AI Massachusetts Institute of Technology MIT Top Level Links: Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT Join us in building a better world. Massachusetts Institute of Technology 77 Massachusetts Avenue, Cambridge, MA, USA Recommended Links: Visit Map (opens in new window) Events (opens in new window) People (opens in new window) Careers (opens in new window) Contact Privacy Accessibility Social Media Hub MIT on X MIT on Facebook MIT on YouTube MIT on Instagram
====================================================================================================
What is AI (artificial intelligence)? | McKinsey Skip to main content What is AI (artificial intelligence)? April 3, 2024 | Article Artificial intelligence is a machine’s ability to perform some cognitive functions we usually associate with human minds. 3D robotics hand (10 pages) Humans and machines: a match made in productivity heaven. Our species wouldn’t have gotten very far without our mechanized workhorses. From the wheel that revolutionized agriculture to the screw that held together increasingly complex construction projects to the robot-enabled assembly lines of today, machines have made life as we know it possible. And yet, despite their seemingly endless utility, humans have long feared machines—more specifically, the possibility that machines might someday acquire human intelligence and strike out on their own. Get to know and directly engage with senior McKinsey experts on AI Sven Blumberg is a senior partner in McKinsey’s Düsseldorf office; Michael Chui is a partner at the McKinsey Global Institute and is based in the Bay Area office, where Lareina Yee is a senior partner; Kia Javanmardian is a senior partner in the Chicago office, where Alex Singla , the global leader of QuantumBlack, AI by McKinsey, is also a senior partner; Kate Smaje and Alex Sukharevsky are senior partners in the London office. But we tend to view the possibility of sentient machines with fascination as well as fear. This curiosity has helped turn science fiction into actual science. Twentieth-century theoreticians, like computer scientist and mathematician Alan Turing, envisioned a future where machines could perform functions faster than humans. The work of Turing and others soon made this a reality. Personal calculators became widely available in the 1970s, and by 2016, the US census showed that 89 percent of American households had a computer. Machines— smart machines at that—are now just an ordinary part of our lives and culture. Those smart machines are also getting faster and more complex. Some computers have now crossed the exascale threshold, meaning they can perform as many calculations in a single second as an individual could in 31,688,765,000 years . And beyond computation, which machines have long been faster at than we have, computers and other devices are now acquiring skills and perception that were once unique to humans and a few other species. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. AI is a machine’s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting with the environment, problem-solving, and even exercising creativity. You’ve probably interacted with AI even if you don’t realize it—voice assistants like Siri and Alexa are founded on AI technology, as are some customer service chatbots that pop up to help you navigate websites. Applied AI —simply, artificial intelligence applied to real-world problems—has serious implications for the business world. By using artificial intelligence, companies have the potential to make business more efficient and profitable. But ultimately, the value of AI isn’t in the systems themselves. Rather, it’s in how companies use these systems to assist humans—and their ability to explain to shareholders and the public what these systems do—in a way that builds trust and confidence. For more about AI, its history, its future, and how to apply it in business, read on. Learn more about QuantumBlack, AI by McKinsey . Looking for direct answers to other complex questions? Explore the full McKinsey Explainers series What is machine learning? Machine learning is a form of artificial intelligence that can adapt to a wide range of inputs, including large sets of historical data, synthesized data, or human inputs. (Some machine learning algorithms are specialized in training themselves to detect patterns; this is called deep learning . See Exhibit 1.) These algorithms can detect patterns and learn how to make predictions and recommendations by processing data, rather than by receiving explicit programming instruction. Some algorithms can also adapt in response to new data and experiences to improve over time. The volume and complexity of data that is now being generated, too vast for humans to process and apply efficiently, has increased the potential of machine learning, as well as the need for it. In the years since its widespread deployment, which began in the 1970s, machine learning has had an impact on a number of industries, including achievements in medical-imaging analysis and high-resolution weather forecasting. The volume and complexity of data that is now being generated, too vast for humans to process and apply efficiently, has increased the potential of machine learning, as well as the need for it. What is deep learning? Deep learning is a more advanced version of machine learning that is particularly adept at processing a wider range of data resources (text as well as unstructured data including images), requires even less human intervention, and can often produce more accurate results than traditional machine learning. Deep learning uses neural networks—based on the ways neurons interact in the human brain —to ingest data and process it through multiple neuron layers that recognize increasingly complex features of the data. For example, an early layer might recognize something as being in a specific shape; building on this knowledge, a later layer might be able to identify the shape as a stop sign. Similar to machine learning, deep learning uses iteration to self-correct and improve its prediction capabilities. For example, once it “learns” what a stop sign looks like, it can recognize a stop sign in a new image. Learn more about QuantumBlack, AI by McKinsey . What is generative AI? Case study: Vistra and the Martin Lake Power Plant Vistra is a large power producer in the United States, operating plants in 12 states with a capacity to power nearly 20 million homes. Vistra has committed to achieving net-zero emissions by 2050. In support of this goal, as well as to improve overall efficiency, QuantumBlack, AI by McKinsey worked with Vistra to build and deploy an AI-powered heat rate optimizer (HRO) at one of its plants. “Heat rate” is a measure of the thermal efficiency of the plant; in other words, it’s the amount of fuel required to produce each unit of electricity. To reach the optimal heat rate, plant operators continuously monitor and tune hundreds of variables, such as steam temperatures, pressures, oxygen levels, and fan speeds. Vistra and a McKinsey team, including data scientists and machine learning engineers, built a multilayered neural network model. The model combed through two years’ worth of data at the plant and learned which combination of factors would attain the most efficient heat rate at any point in time. When the models were accurate to 99 percent or higher and run through a rigorous set of real-world tests, the team converted them into an AI-powered engine that generates recommendations every 30 minutes for operators to improve the plant’s heat rate efficiency. One seasoned operations manager at the company’s plant in Odessa, Texas, said, “There are things that took me 20 years to learn about these power plants. This model learned them in an afternoon.” Overall, the AI-powered HRO helped Vistra achieve the following: approximately 1.6 million metric tons of carbon abated annually 67 power generators optimized $60 million saved in about a year Read more about the Vistra story here . Generative AI (gen AI) is an AI model that generates content in response to a prompt. It’s clear that generative AI tools like ChatGPT and DALL-E (a tool for AI-generated art) have the potential to change how a range of jobs are performed. Much is still unknown about gen AI’s potential, but there are some questions we can answer—like how gen AI models are built, what kinds of problems they are best suited to solve, and how they fit into the broader category of AI and machine learning. For more on generative AI and how it stands to affect business and society, check out our Explainer “ What is generative AI? ” What is the history of AI? The term “artificial intelligence” was coined in 1956 by computer scientist John McCarthy for a workshop at Dartmouth. But he wasn’t the first to write about the concepts we now describe as AI. Alan Turing introduced the concept of the “ imitation game ” in a 1950 paper. That’s the test of a machine’s ability to exhibit intelligent behavior, now known as the “Turing test.” He believed researchers should focus on areas that don’t require too much sensing and action, things like games and language translation. Research communities dedicated to concepts like computer vision, natural language understanding, and neural networks are, in many cases, several decades old. MIT physicist Rodney Brooks shared details on the four previous stages of AI: Symbolic AI (1956). Symbolic AI is also known as classical AI, or even GOFAI (good old-fashioned AI). The key concept here is the use of symbols and logical reasoning to solve problems. For example, we know a German shepherd is a dog , which is a mammal; all mammals are warm-blooded; therefore, a German shepherd should be warm-blooded. The main problem with symbolic AI is that humans still need to manually encode their knowledge of the world into the symbolic AI system, rather than allowing it to observe and encode relationships on its own. As a result, symbolic AI systems struggle with situations involving real-world complexity. They also lack the ability to learn from large amounts of data. Symbolic AI was the dominant paradigm of AI research until the late 1980s. Neural networks (1954, 1969, 1986, 2012). Neural networks are the technology behind the recent explosive growth of gen AI. Loosely modeling the ways neurons interact in the human brain , neural networks ingest data and process it through multiple iterations that learn increasingly complex features of the data. The neural network can then make determinations about the data, learn whether a determination is correct, and use what it has learned to make determinations about new data. For example, once it “learns” what an object looks like, it can recognize the object in a new image. Neural networks were first proposed in 1943 in an academic paper by neurophysiologist Warren McCulloch and logician Walter Pitts. Decades later, in 1969, two MIT researchers mathematically demonstrated that neural networks could perform only very basic tasks. In 1986, there was another reversal, when computer scientist and cognitive psychologist Geoffrey Hinton and colleagues solved the neural network problem presented by the MIT researchers. In the 1990s, computer scientist Yann LeCun made major advancements in neural networks’ use in computer vision, while Jürgen Schmidhuber advanced the application of recurrent neural networks as used in language processing. In 2012, Hinton and two of his students highlighted the power of deep learning. They applied Hinton’s algorithm to neural networks with many more layers than was typical, sparking a new focus on deep neural networks. These have been the main AI approaches of recent years. Traditional robotics (1968). During the first few decades of AI, researchers built robots to advance research. Some robots were mobile, moving around on wheels, while others were fixed, with articulated arms. Robots used the earliest attempts at computer vision to identify and navigate through their environments or to understand the geometry of objects and maneuver them. This could include moving around blocks of various shapes and colors. Most of these robots, just like the ones that have been used in factories for decades, rely on highly controlled environments with thoroughly scripted behaviors that they perform repeatedly. They have not contributed significantly to the advancement of AI itself. But traditional robotics did have significant impact in one area, through a process called “simultaneous localization and mapping” (SLAM). SLAM algorithms helped contribute to self-driving cars and are used in consumer products like vacuum cleaning robots and quadcopter drones. Today, this work has evolved into behavior-based robotics, also referred to as haptic technology because it responds to human touch. Behavior-based robotics (1985). In the real world, there aren’t always clear instructions for navigation, decision making, or problem-solving. Insects, researchers observed, navigate very well (and are evolutionarily very successful) with few neurons. Behavior-based robotics researchers took inspiration from this, looking for ways robots could solve problems with partial knowledge and conflicting instructions. These behavior-based robots are embedded with neural networks. Learn more about QuantumBlack, AI by McKinsey . What is artificial general intelligence? The term “artificial general intelligence” (AGI) was coined to describe AI systems that possess capabilities comparable to those of a human . In theory, AGI could someday replicate human-like cognitive abilities including reasoning, problem-solving, perception, learning, and language comprehension. But let’s not get ahead of ourselves: the key word here is “someday.” Most researchers and academics believe we are decades away from realizing AGI; some even predict we won’t see AGI this century, or ever. Rodney Brooks, an MIT roboticist and cofounder of iRobot, doesn’t believe AGI will arrive until the year 2300 . The timing of AGI’s emergence may be uncertain. But when it does emerge—and it likely will—it’s going to be a very big deal, in every aspect of our lives. Executives should begin working to understand the path to machines achieving human-level intelligence now and making the transition to a more automated world. For more on AGI, including the four previous attempts at AGI, read our Explainer . What is narrow AI? Narrow AI is the application of AI techniques to a specific and well-defined problem, such as chatbots like ChatGPT, algorithms that spot fraud in credit card transactions, and natural-language-processing engines that quickly process thousands of legal documents. Most current AI applications fall into the category of narrow AI. AGI is, by contrast, AI that’s intelligent enough to perform a broad range of tasks. Learn more about QuantumBlack, AI by McKinsey . How is the use of AI expanding? AI is a big story for all kinds of businesses, but some companies are clearly moving ahead of the pack . Our state of AI in 2022 survey showed that adoption of AI models has more than doubled since 2017—and investment has increased apace. What’s more, the specific areas in which companies see value from AI have evolved, from manufacturing and risk to the following: marketing and sales product and service development strategy and corporate finance One group of companies is pulling ahead of its competitors. Leaders of these organizations consistently make larger investments in AI, level up their practices to scale faster, and hire and upskill the best AI talent. More specifically, they link AI strategy to business outcomes and “ industrialize ” AI operations by designing modular data architecture that can quickly accommodate new applications. What are the limitations of AI models? How can these potentially be overcome? We have yet to see the longtail effect of gen AI models. This means there are some inherent risks involved in using them—both known and unknown. The outputs gen AI models produce may often sound extremely convincing. This is by design. But sometimes the information they generate is just plain wrong. Worse, sometimes it’s biased (because it’s built on the gender, racial, and other biases of the internet and society more generally). It can also be manipulated to enable unethical or criminal activity. Since gen AI models burst onto the scene, organizations have become aware of users trying to “jailbreak” the models—that means trying to get them to break their own rules and deliver biased, harmful, misleading, or even illegal content. Gen AI organizations are responding to this threat in two ways: for one thing, they’re collecting feedback from users on inappropriate content. They’re also combing through their databases, identifying prompts that led to inappropriate content, and training the model against these types of generations. But awareness and even action don’t guarantee that harmful content won’t slip the dragnet. Organizations that rely on gen AI models should be aware of the reputational and legal risks involved in unintentionally publishing biased, offensive, or copyrighted content. These risks can be mitigated, however, in a few ways. “Whenever you use a model,” says McKinsey partner Marie El Hoyek, “you need to be able to counter biases and instruct it not to use inappropriate or flawed sources, or things you don’t trust.” How? For one thing, it’s crucial to carefully select the initial data used to train these models to avoid including toxic or biased content. Next, rather than employing an off-the-shelf gen AI model, organizations could consider using smaller, specialized models. Organizations with more resources could also customize a general model based on their own data to fit their needs and minimize biases. It’s also important to keep a human in the loop (that is, to make sure a real human checks the output of a gen AI model before it is published or used) and avoid using gen AI models for critical decisions, such as those involving significant resources or human welfare. It can’t be emphasized enough that this is a new field. The landscape of risks and opportunities is likely to continue to change rapidly in the coming years. As gen AI becomes increasingly incorporated into business, society, and our personal lives, we can also expect a new regulatory climate to take shape. As organizations experiment—and create value—with these tools, leaders will do well to keep a finger on the pulse of regulation and risk. Learn more about QuantumBlack, AI by McKinsey . What is the AI Bill of Rights? The Blueprint for an AI Bill of Rights, prepared by the US government in 2022, provides a framework for how government, technology companies, and citizens can collectively ensure more accountable AI. As AI has become more ubiquitous, concerns have surfaced about a potential lack of transparency surrounding the functioning of gen AI systems, the data used to train them, issues of bias and fairness, potential intellectual property infringements, privacy violations, and more. The Blueprint comprises five principles that the White House says should “guide the design, use, and deployment of automated systems to protect [users] in the age of artificial intelligence.” They are as follows: The right to safe and effective systems. Systems should undergo predeployment testing, risk identification and mitigation, and ongoing monitoring to demonstrate that they are adhering to their intended use. Protections against discrimination by algorithms. Algorithmic discrimination is when automated systems contribute to unjustified different treatment of people based on their race, color, ethnicity, sex, religion, age, and more. Protections against abusive data practices, via built-in safeguards. Users should also have agency over how their data is used. The right to know that an automated system is being used, and a clear explanation of how and why it contributes to outcomes that affect the user. The right to opt out, and access to a human who can quickly consider and fix problems. At present, more than 60 countries or blocs have national strategies governing the responsible use of AI (Exhibit 2). These include Brazil, China, the European Union, Singapore, South Korea, and the United States. The approaches taken vary from guidelines-based approaches, such as the Blueprint for an AI Bill of Rights in the United States, to comprehensive AI regulations that align with existing data protection and cybersecurity regulations, such as the EU’s AI Act, due in 2024. There are also collaborative efforts between countries to set out standards for AI use. The US–EU Trade and Technology Council is working toward greater alignment between Europe and the United States. The Global Partnership on Artificial Intelligence, formed in 2020, has 29 members including Brazil, Canada, Japan, the United States, and several European countries. Even though AI regulations are still being developed, organizations should act now to avoid legal, reputational, organizational, and financial risks. In an environment of public concern, a misstep could be costly. Here are four no-regrets, preemptive actions organizations can implement today: Transparency. Create an inventory of models, classifying them in accordance with regulation, and record all usage across the organization that is clear to those inside and outside the organization. Governance. Implement a governance structure for AI and gen AI that ensures sufficient oversight, authority, and accountability both within the organization and with third parties and regulators. Data, model, and technology management. Data management. Proper data management includes awareness of data sources, data classification, data quality and lineage, intellectual property, and privacy management. Model management. Organizations should establish principles and guardrails for AI development and use them to ensure all AI models uphold fairness and bias controls. Cybersecurity and technology management. Establish strong cybersecurity and technology to ensure a secure environment where unauthorized access or misuse is prevented. Individual rights. Make users aware when they are interacting with an AI system, and provide clear instructions for use. How can organizations scale up their AI efforts from ad hoc projects to full integration? Most organizations are dipping a toe into the AI pool—not cannonballing. Slow progress toward widespread adoption is likely due to cultural and organizational barriers. But leaders who effectively break down these barriers will be best placed to capture the opportunities of the AI era. And—crucially—companies that can’t take full advantage of AI are already being sidelined by those that can, in industries like auto manufacturing and financial services. To scale up AI, organizations can make three major shifts : Move from siloed work to interdisciplinary collaboration. AI projects shouldn’t be limited to discrete pockets of organizations. Rather, AI has the biggest impact when it’s employed by cross-functional teams with a mix of skills and perspectives, enabling AI to address broad business priorities. Empower frontline data-based decision making . AI has the potential to enable faster, better decisions at all levels of an organization. But for this to work, people at all levels need to trust the algorithms’ suggestions and feel empowered to make decisions. (Equally, people should be able to override the algorithm or make suggestions for improvement when necessary.) Adopt and bolster an agile mindset. The agile test-and-learn mindset will help reframe mistakes as sources of discovery, allaying the fear of failure and speeding up development. Learn more about QuantumBlack, AI by McKinsey , and check out AI-related job opportunities if you’re interested in working at McKinsey. Pop quiz Articles referenced: “ As gen AI advances, regulators—and risk functions—rush to keep pace ,” December 21, 2023, Andreas Kremer, Angela Luget , Daniel Mikkelsen , Henning Soller , Malin Strandell-Jansson, and Sheila Zingg “ What is generative AI? ,” January 19, 2023 “ Tech highlights from 2022—in eight charts ,” December 22, 2022 “ Generative AI is here: How tools like ChatGPT could change your business ,” December 20, 2022, Michael Chui , Roger Roberts , and Lareina Yee “ The state of AI in 2022—and a half decade in review ,” December 6, 2022, Michael Chui , Bryce Hall , Helen Mayhew , Alex Singla , and Alex Sukharevsky “ Why businesses need explainable AI—and how to deliver it ,” September 29, 2022, Liz Grennan , Andreas Kremer, Alex Singla , and Peter Zipparo “ Why digital trust truly matters ,” September 12, 2022, Jim Boehm , Liz Grennan , Alex Singla , and Kate Smaje “ McKinsey Technology Trends Outlook 2023 ,” July 20, 2023, Michael Chui , Mena Issler, Roger Roberts , and Lareina Yee “ An AI power play: Fueling the next wave of innovation in the energy sector ,” May 12, 2022, Barry Boswell, Sean Buckley, Ben Elliott, Matias Melero , and Micah Smith “ Scaling AI like a tech native: The CEO’s role ,” October 13, 2021, Jacomo Corbo, David Harvey, Nicolas Hohn, Kia Javanmardian , and Nayur Khan “ What the draft European Union AI regulations mean for business ,” August 10, 2021, Misha Benjamin, Kevin Buehler , Rachel Dooley, and Peter Zipparo “ Winning with AI is a state of mind ,” April 30, 2021, Thomas Meakin , Jeremy Palmer, Valentina Sartori , and Jamie Vickers “ Breaking through data-architecture gridlock to scale AI ,” January 26, 2021, Sven Blumberg , Jorge Machado , Henning Soller , and Asin Tavakoli “ An executive’s guide to AI ,” November 17, 2020, Michael Chui , Brian McCarthy, and Vishnu Kamalnath “ Executive’s guide to developing AI at scale ,” October 28, 2020, Nayur Khan , Brian McCarthy, and Adi Pradhan “ An executive primer on artificial general intelligence ,” April 29, 2020, Federico Berruti , Pieter Nel, and Rob Whiteman “ The analytics academy: Bridging the gap between human and artificial intelligence ,” McKinsey Quarterly , September 25, 2019, Solly Brown, Darshit Gandhi, Louise Herring , and Ankur Puri This article was updated in April 2024; it was originally published in April 2023. Want to know more about AI? Talk to us Related Articles Article Ten unsung digital and AI ideas shaping business Podcast Driving innovation with generative AI Article As gen AI advances, regulators—and risk functions—rush to keep pace
====================================================================================================
Artificial Intelligence Definition - What is AI? Skip to main content Terms Quizzes Help Center Random Term Theme Light Dark High Contrast Font Size 20 Reset Home Technical Terms Artificial Intelligence Definition Artificial Intelligence Artificial Intelligence, or AI, is the ability of a computer running special software to act intelligently — perceiving new data , learning, drawing inferences, and solving problems. It allows computers to perform work that previously required human intervention. AI can handle all sorts of tasks, from simple ones like customer service chatbots and video game opponents to more complex ones like recommendation engines, stock market trading bots, and image generators. Artificial intelligence uses algorithms to process data input that a computer receives. These algorithms analyze data to find patterns, then make predictions or classifications by comparing new inputs to those patterns. Many AIs train using machine learning , which provides them with large, curated data sets to help guide them toward the results the developers of the AI want. Increasingly complex AI algorithms require increasingly-powerful computer hardware . In cases where a computer's CPU isn't fast enough for AI tasks, a high-end GPU can help. Originally designed to process computer graphics, GPUs can handle large amounts of data and quickly analyze it in parallel processes, making them very efficient at running AI and machine learning algorithms. Higher-end AI uses specialized FPGA processors designed for the needs of the AI running on it. Uses of AI The ultimate goal of AI development is to use computers to perform tasks that previously required human effort and to find new or more efficient ways to accomplish those tasks. Early AI started small, with routine work, and has slowly increased its capabilities as algorithms improve and computer hardware becomes more powerful. As AI technology improves, it opens up more kinds of tasks to automation. Chatbots attempt to mimic a real person over online text chat. Early chatbots were novelties, but modern chatbots are commonly used in customer service roles, helping people resolve simple problems and saving time for human customer service agents to focus on more difficult issues. Video games use AI to create virtual opponents for players. Most genres use AI to some degree, including action and strategy games, as well as board games like chess and Go. AI-powered speech recognition enables new user interfaces , allowing people to speak to some devices to ask questions and issue commands. Recommendation engines are used by online stores (like Amazon) and streaming media services (like Netflix) to look for trends in a person's purchases or viewing history. Based on those trends, the AI suggests products or media that person may want to purchase or watch next. AI programs can help businesses, government organizations, and financial institutions identify data trends to streamline processes like identifying fraud, improving logistics, and trading stocks. Art generators like DALL-E and Stable Diffusion are trained on large data sets of curated images and artwork and can generate new images in a wide range of styles based on text prompts. Updated January 13, 2023 by Brian P. APA MLA Chicago HTML Link https://techterms.com/definition/artificial_intelligence Copy Test Your Knowledge Which term describes figuring out a solution to a technical problem? A Troublefixing 0% B Troublesolving 0% C Troubleshooting 0% D Troublezapping 0% Correct! Incorrect! View the Troubleshooting definition . More Quizzes → ‹ Artifact | ASCII › Tech Factor ? 4 / 10 Related Terms Computer Software Machine Learning Algorithm Input User Interface Speech Recognition Bot GPU FPGA The Tech Terms Computer Dictionary The definition of Artificial Intelligence on this page is an original definition written by the TechTerms.com team . If you would like to reference this page or cite this definition, please use the green citation bar directly below the definition. Our goal to explain computer terminology in a way that is easy to understand. We strive for accuracy and simplicity with every definition we publish. If you have feedback about this definition or would like to suggest a new technical term, please contact us . TechTerms Newsletter Improve your technical knowledge with our daily or weekly newsletter! Subscribe today and get new terms and quizzes delivered to your inbox. Subscribe × Sign up for the free TechTerms Newsletter Email (required): First Name: Last Name: How often would you like to receive an email? Daily Weekly (Every Tuesday) You can unsubscribe or change your frequency setting at any time using the links available in each email. Questions? Please contact us . Thank You We just sent you an email to confirm your email address. Once you confirm your address, you will begin to receive the newsletter. If you have any questions, please contact us . Ok © 2025 Sharpened Productions | Terms of Use | Privacy Policy | About | Contact
====================================================================================================
4 Types of AI: Getting to Know Artificial Intelligence | Coursera For Individuals For Businesses For Universities For Governments Explore Online Degrees Careers Log In Join for Free Data AI and Machine Learning 4 Types of AI: Getting to Know Artificial Intelligence 4 Types of AI: Getting to Know Artificial Intelligence Written by Coursera Staff • Updated on Dec 19, 2024 Artificial intelligence (AI) has enabled us to do things faster and better, advancing technology in the 21st century. Learn about the four main types of AI. Artificial intelligence (AI) technology has created opportunities to progress on real-world problems concerning health, education, and the environment. In some cases, artificial intelligence can do things more efficiently or methodically than human intelligence. “Smart” buildings, vehicles, and other technologies can decrease carbon emissions and support people with disabilities. Machine learning , a subset of AI, has enabled engineers to build robots and self-driving cars, recognize speech and images, and forecast market trends. Read on to learn more about the four main types of AI—reactive machines, limited memory machines, theory of mind, and self-awareness—and their functions in everyday life. 4 main types of artificial intelligence Learning in AI can fall under the types “narrow intelligence,” “artificial general intelligence,” and “super AI.” These categories demonstrate AI’s capabilities as it evolves—performing narrowly defined sets of tasks, simulating thought processes in the human mind, and performing beyond human capability. Watch this video from IBM's Introduction to Artificial Intelligence (AI) course to learn more about these categories: T here are four main types of AI as defined by Arend Hintze, researcher and professor of integrative biology at Michigan State University [ 1 ]. They are as follows: 1. Reactive machines Reactive machines are AI systems that have no memory and are task-specific, meaning that an input always delivers the same output. Machine learning models tend to be reactive machines because they take customer data, such as purchase or search history, and use it to deliver recommendations to the same customers. This type of AI is reactive. It performs “super” AI because the average human would not be able to process huge amounts of data, such as a customer’s entire Netflix history and feedback customized recommendations. Reactive AI, for the most part, is reliable and works well in inventions like self-driving cars. It doesn’t have the ability to predict future outcomes unless it has been fed the appropriate information. Compare this to our human lives, where most of our actions are not reactive because we don’t have all the information we need to react upon, but we have the capability to remember and learn. Based on those successes or failures, we may act differently in the future if faced with a similar situation. Examples of reactive machines Beat at chess by IBM’s supercomputer: One of the best examples of reactive AI is when Deep Blue, IBM’s chess-playing AI system, beat Garry Kasparov in the late 1990s. Deep Blue could identify its own and its opponent’s pieces on the chessboard to make predictions, but it does not have the memory capacity to use past mistakes to inform future decisions. It only makes predictions based on what moves could be next for both players and selects the best move. Netflix recommendations: Netflix’s recommendation engine is powered by machine learning models that process the data collected from a customer’s viewing history to determine specific movies and TV shows that they will enjoy. Humans are creatures of habit—if someone tends to watch a lot of Korean dramas, Netflix will show a preview of new releases on the home page. 2. Limited memory machines The next type of AI in its evolution is limited memory. This algorithm imitates the way our brains’ neurons work together, meaning that it gets smarter as it receives more data to train on. Deep learning algorithms improve natural language processing (NLP) , image recognition, and other types of reinforcement learning. Read more: What is Deep Learning? Definition, Examples, and Careers Limited memory AI, unlike reactive machines, can look into the past and monitor specific objects or situations over time. Then, these observations are programmed into the AI so that its actions can be performed based on both past and present moment data. But in limited memory, this data isn’t saved into the AI’s memory as experience to learn from, the way humans might derive meaning from their successes and failures. The AI improves over time as it’s trained on more data. Example of limited memory artificial intelligence Self-driving cars: A good example of limited memory AI is the way self-driving cars observe other cars on the road for their speed, direction, and proximity. This information is programmed as the car’s representation of the world, such as knowing traffic lights, signs, curves, and bumps in the road. The data helps the car decide when to change lanes so that it does not get hit or cut off by another driver. 3. Theory of mind The first two types of AI, reactive machines and limited memory, are types that currently exist. Theory of mind and self-aware AI are theoretical types that could be built in the future. As such, there aren’t any real-world examples yet. If it is developed, theory of mind AI could have the potential to understand the world and how other entities have thoughts and emotions. In turn, this affects how they behave in relation to those around them. Human cognitive abilities are capable of processing how our own thoughts and emotions affect others and how others’ affect us—this is the basis of our society’s human relationships. In the future, theory of mind AI machines could be able to understand intentions and predict behavior, as if to simulate human relationships. What type of AI is ChatGPT? ChatGPT is an example of generative AI , a kind of artificial intelligence powered by large language models (LLMs) that are created by training algorithms on massive amounts of data. Generative AI is capable of creating original outputs in response to user inputs or " prompts ." ChatGPT's ability to produce responses resembling human language has made it a common type of AI used for chatbots and virtual assistants. That said, while tools like ChatGPT, Google Gemini, or Microsoft Copilot may produce responses that give the impression of a self-aware AI, they aren't really. Instead, their responses are actually just the result of the algorithm identifying the statistically most likely output based on its training data and the user's prompt. Read more: What Is ChatGPT? (and How to Use It) 4. Self-awareness The grand finale for the evolution of AI would be to design systems that have a sense of self, a conscious understanding of their existence. This type of AI does not exist yet. This goes a step beyond theory of mind AI and understanding emotions to being aware of themselves, their state of being, and being able to sense or predict others’ feelings. For example, “I’m hungry” becomes “I know I am hungry” or “I want to eat lasagna because it’s my favorite food.” Artificial intelligence and machine learning algorithms are a long way from self-awareness because there is still so much to uncover about the human brain’s intelligence and how memory, learning, and decision-making work. Learn more about artificial intelligence on Coursera Learning about AI can be fun and fascinating, even if you don’t want to become an AI engineer. Whether you just want to boost your productivity in the workplace or build toward a career in AI, Coursera has something for you: For an overview of AI , take DeepLearning.AI's AI for Everyone course. Designed for non-technical people to understand what AI is, the course includes common terminology like neural networks, machine learning, deep learning, and data science. You’ll learn how to work with an AI team build an AI strategy in your company, and much more. To leverage the potential of generative AI, consider enrolling in the IBM Generative AI Fundamentals Specialization . Learn fundamental concepts, models, tools, and AI applications to boost productivity at work and in your life. To enhance your existing AI skills, explore the IBM Deep Learning with PyTorch, Keras and Tensorflow Professional Certificate . Learn to build, train, and deploy deep learning models in this intermediate-level program. Article sources The Conversation. “ Understanding the four types of AI, from reactive robots to self-aware beings , https://theconversation.com/understanding-the-four-types-of-ai-from-reactive-robots-to-self-aware-beings-67616.” Accessed December 19, 2024. Updated on Dec 19, 2024 Written by: C Coursera Staff Editorial Team Coursera’s editorial team is comprised of highly experienced professional editors, writers, and fact... This content has been made available for informational purposes only. Learners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals. Coursera Footer Technical Skills ChatGPT Coding Computer Science Cybersecurity DevOps Ethical Hacking Generative AI Java Programming Python Web Development Analytical Skills Artificial Intelligence Big Data Business Analysis Data Analytics Data Science Financial Modeling Machine Learning Microsoft Excel Microsoft Power BI SQL Business Skills Accounting Digital Marketing E-commerce Finance Google Graphic Design IBM Marketing Project Management Social Media Marketing Career Resources Essential IT Certifications High-Income Skills to Learn How to Get a PMP Certification How to Learn Artificial Intelligence Popular Cybersecurity Certifications Popular Data Analytics Certifications What Does a Data Analyst Do? Career Development Resources Career Aptitude Test Share your Coursera Learning Story Coursera About What We Offer Leadership Careers Catalog Coursera Plus Professional Certificates MasterTrack® Certificates Degrees For Enterprise For Government For Campus Become a Partner Social Impact Free Courses ECTS Credit Recommendations Community Learners Partners Beta Testers Blog The Coursera Podcast Tech Blog More Press Investors Terms Privacy Help Accessibility Contact Articles Directory Affiliates Modern Slavery Statement Manage Cookie Preferences Learn Anywhere © 2025 Coursera Inc. All rights reserved.
====================================================================================================
AI News | Engadget Sign in Advertisement Advertisement Advertisement AI News The latest news and reviews on artificial intelligence software, hardware and AI research. Latest AI might undermine one of the better alternatives to the Kindle Kobo's platform maintains a friendly relationship with indie authors, but new mentions of AI in its terms of service are raising concerns. Donald Trump is reportedly preparing a sweep of pro-AI executive orders The administration could reportedly offer up government-managed land to speed up development. Google's new AI app Doppl lets you try on outfits virtually Google is making virtual outfit try ons available to the masses with a new experimental AI app called Doppl. Google tweaked its AI-powered Ask Photos feature and restarted its rollout Google improved its AI photo search feature and is once again rolling it out to Google Photos users in the US. YouTube's newest Premium perk: more AI clutter A new AI-generated carousel collects relevant videos based on a query. What do Google's Gemini privacy changes actually mean? An email sent to the AI chatbot users made waves in the tech press. AI-powered chat summaries are coming to WhatsApp Meta is adding message summaries to WhatsApp to make it easier to catch up on long chats. Anthropic makes it easier to create and share Claude's bite-sized Artifact apps Anthropic is making it easier to share Artifacts -- small, AI powered apps -- you can make with Claude. Ring's AI video descriptions tell you who's doing what The feature could help you figure out if something requires action. Google's Imagen 4 text-to-image model promises 'significantly improved' boring images Google has unveiled its latest text-to-image models Imagen 4 and Imagen 4 Ultra with the usual promise of "significantly improved text rendering" over the previous version, Imagen 3. Judge rules Anthropic's AI training on copyrighted materials is fair use Anthropic has received a mixed result in a lawsuit brought by authors who claimed the company used their copyrighted creations without permission. The xMEMS 'fan on a chip' is ready for smart glasses It provides active cooling without any moving parts. Perplexity's AI-powered browser opens up to select Windows users Perplexity's CEO, Aravind Srinivas, said on X that the Windows build for Comet is ready. Meta and Oakley announce new 'perfomance AI' smart glasses for athletes Meta has announced new smart glasses inspired by Oakley's HSTN design. The first, limited-edition pair costs $499. Midjourney adds AI video generation AI company Midjourney has released its first video model. Google's AI-powered Search Live feature is here to further cannibalize the internet Google's Search Live feature with voice input is now available on its app for iOS and Android in the US. This 1-800 number will generate ChatGPT images, if for some reason you need that Starting today, all users can text a special number on WhatsApp for ChatGPT image generation. Adobe's Firefly generative AI app is now available on mobile Following its relaunch in April, Adobe Firefly is rolling out as an iOS and Android app. Tesla blows past stopped school bus and hits kid-sized dummies in Full Self-Driving tests Before the Cybercab rollout, anti-Tesla activists organized a demonstration showing the flaws of Full-Self Driving software. How to turn off Google’s AI Overviews in web searches If you find Google's AI Overview more irritating than helpful, here's now to turn it off in Chrome. 1 2 3 4 5 ... Next Advertisement Advertisement Advertisement Subscribe to our newsletter: The Morning After - A twice-weekly dose of the news you need By subscribing, you are agreeing to Engadget's Terms and Privacy Policy . Subscribe By subscribing, you are agreeing to Engadget's Terms and Privacy Policy . About Engadget Masthead About our Ads Advertise Licensing FAQ RSS Feed Sections Reviews Gear Gaming Entertainment Tomorrow Buying Guides Video Podcasts Deals Contribute Comment Guidelines Support BUYING GUIDES Best laptop The best iPad Best Bluetooth speaker Best E Ink tablets Best wireless earbuds Best power banks Best gaming handhelds Contribute Comment Guidelines Support BUYING GUIDES Best laptop The best iPad Best Bluetooth speaker Best E Ink tablets Best wireless earbuds Best power banks Best gaming handhelds Follow Us © 2025 Yahoo. All rights reserved. About Us Reprints and Permissions Trademarks Advertise About Our Ads Terms and Privacy Policy Privacy Dashboard
====================================================================================================
WHAT IS ARTIFICIAL INTELLIGENCE? Next: Basic Questions Extinguished philosophies lie about the cradle of every science as the strangled snakes beside that of Hercules. - adapted from T. H. Huxley WHAT IS ARTIFICIAL INTELLIGENCE? John McCarthy Computer Science Department JanFebMarAprMayJun JulAugSepOctNovDec , :< 10 0 Stanford University Revised November 12, 2007: Abstract: This article for the layman answers basic questions about artificial intelligence. The opinions expressed here are not all consensus opinion among researchers in AI. Basic Questions Branches of AI Applications of AI More questions Bibliography About this document ... John McCarthy 2007-11-12
====================================================================================================
ARTIFICIAL INTELLIGENCE Definition & Meaning - Merriam-Webster Menu Toggle Merriam-Webster Logo Games Word of the Day Grammar Wordplay Slang Rhymes Word Finder Thesaurus Join MWU More Games Word of the Day Grammar Wordplay Slang Rhymes Word Finder Thesaurus Join MWU Shop Books Merch Log In Username My Words Recents Account Log Out Est. 1828 Dictionary Definition Definition Example Sentences Word History Rhymes Entries Near Related Articles Cite this Entry Citation Share Kids Definition Kids More from M-W Show more Show more Citation Share Kids More from M-W Save Word To save this word, you'll need to log in. Log In artificial intelligence noun 1 : the capability of computer systems or algorithms to imitate intelligent human behavior … helped pioneer the idea that computers can exhibit artificial intelligence that mirrors human thinking. — Richard Sandomir A Monmouth University poll … found that only 9 percent of Americans believed that computers with artificial intelligence would do more good than harm to society. — Shira Ovide Artificial intelligence applications are already used behind the scenes in hospitals to automate workforce tasks, improve patient flow, for operating room scheduling and elsewhere to improve efficiency. — Liz Freeman also, plural artificial intelligences : a computer, computer system, or set of algorithms having this capability Someday, our artificial intelligences will be capable enough to pass for human. — Benjamin C. Kinney … they are now eager to create artificial intelligences that can mediate human life at every level. — Edward Ongweso Jr. see also generative artificial intelligence 2 : a branch of computer science dealing with the simulation of intelligent human behavior by computers The school of computer science offers … undergraduate degrees in artificial intelligence . — Evan Robinson-Johnson He is looking to study computer science focusing on artificial intelligence and cybersecurity. — Joe McHugh Examples of artificial intelligence in a Sentence a robot with artificial intelligence Recent Examples on the Web Examples are automatically compiled from online sources to show current usage. Read More Opinions expressed in the examples do not represent those of Merriam-Webster or its editors. Send us feedback . Between January to December 2024, an artificial intelligence threat analysis system analyzed 1.6 million posts and comments. — Charlie Eccleshare, New York Times , 17 June 2025 Founded in 2021, Helsing sells software that uses artificial intelligence technology to analyze large amounts of sensor and weapons system data from the battlefield to inform military decisions in real time. — Ryan Browne, CNBC , 17 June 2025 With nuance and subtlety, with grace and deep feeling, Jayson Greene writes about the most ancient of human stories of love and grief, alongside the pressing, hypermodern concerns of the digital age, like artificial intelligence . — Gabrielle Bellot, Literary Hub , 17 June 2025 The rise of artificial intelligence and the popularity of online classes have led to an explosion of financial aid fraud. — Sharon Lurye, Los Angeles Times , 17 June 2025 See All Example Sentences for artificial intelligence Word History First Known Use 1955, in the meaning defined at sense 1 Time Traveler The first known use of artificial intelligence was in 1955 See more words from the same year Rhymes for artificial intelligence counterintelligence See All Rhymes for artificial intelligence Browse Nearby Words artificial insemination artificial intelligence artificialize See all Nearby Words Articles Related to artificial intelligence Word of the Year 2022 Our Word of the Year 'gaslighting,' plus 8 more Machine Learning The capability of a machine to improve its own performance Cite this Entry Style MLA Chicago APA Merriam-Webster “Artificial intelligence.” Merriam-Webster.com Dictionary , Merriam-Webster, https://www.merriam-webster.com/dictionary/artificial%20intelligence. Accessed 28 Jun. 2025. Copy Citation Share Kids Definition artificial intelligence noun : the power of a machine to imitate intelligent human behavior More from Merriam-Webster on artificial intelligence Britannica.com: Encyclopedia article about artificial intelligence Last Updated: 21 Jun 2025 - Updated example sentences Love words? Need even more definitions? Subscribe to America's largest dictionary and get thousands more definitions and advanced search—ad free! Merriam-Webster unabridged More from Merriam-Webster Can you solve 4 words at once? Play Play Can you solve 4 words at once? Play Play Word of the Day restive See Definitions and Examples » Get Word of the Day daily email! Popular in Grammar & Usage See More 'Affect' vs. 'Effect' Using Bullet Points ( • ) Rack vs. Wrack Are 'Funner' and 'Funnest' Real Words? 'Sneaked' or 'Snuck': Which is correct? See More Popular in Wordplay See More How 'Namaste' Entered The English Language 12 Lovely and Unusual Words for the Natural World 10 Hella Good U.S. Regionalisms Better Ways to Say 'This Sucks' 'Za' and 9 Other Words to Help You Win at SCRABBLE See More Popular See More 'Affect' vs. 'Effect' How 'Namaste' Entered The English Language 12 Lovely and Unusual Words for the Natural World See More Games & Quizzes See All Quordle Can you solve 4 words at once? Play Blossom Pick the best words! Play Missing Letter A daily crossword with a twist Play Guess the Literary Image We show you the art, you guess the literary work.... Take the quiz See All Merriam Webster Learn a new word every day. Delivered to your inbox! Help About Us Advertising Info Contact Us Privacy Policy Terms of Use Facebook Twitter YouTube Instagram © 2025 Merriam-Webster, Incorporated
====================================================================================================
What Defines Artificial Intelligence? The Complete WIRED Guide | WIRED Skip to main content Menu SECURITY POLITICS THE BIG STORY BUSINESS SCIENCE CULTURE REVIEWS Menu Account Account Newsletters Security Politics The Big Story Business Science Culture Reviews Chevron More Expand The Big Interview Magazine Steven Levy’s Plaintext Column Events WIRED Insider WIRED Consulting Newsletters Podcasts Video Merch Search Search Sign In Sign In Tom Simonite Business Feb 8, 2023 7:00 AM The WIRED Guide to Artificial Intelligence Supersmart algorithms won’t take all the jobs, but they are learning faster than ever, doing everything from medical diagnostics to serving up ads. Play/Pause Button Pause Illustrations by Radio Save this story Save Save this story Save Artificial intelligence is here. It’s overhyped, poorly understood, and flawed but already core to our lives—and it’s only going to extend its reach. AI powers driverless car research , spots otherwise invisible signs of disease on medical images, finds an answer when you ask Alexa a question, and lets you unlock your phone with your face to talk to friends as an animated poop on the iPhone X using Apple’s Animoji . Those are just a few ways AI already touches our lives, and there’s plenty of work still to be done. But don’t worry, superintelligent algorithms aren’t about to take all the jobs or wipe out humanity . The current boom in all things AI was catalyzed by breakthroughs in an area known as machine learning. It involves “training” computers to perform tasks based on examples, rather than relying on programming by a human. A technique called deep learning has made this approach much more powerful. Just ask Lee Sedol, holder of 18 international titles at the complex game of Go. He got creamed by software called AlphaGo in 2016. There’s evidence that AI can make us happier and healthier . But there’s also reason for caution. Incidents in which algorithms picked up or amplified societal biases around race or gender show that an AI-enhanced future won’t automatically be a better one. The Beginnings of Artificial Intelligence Artificial intelligence as we know it began as a vacation project. Dartmouth professor John McCarthy coined the term in the summer of 1956, when he invited a small group to spend a few weeks musing on how to make machines do things like use language. Moments that Shaped AI 1956 The Dartmouth Summer Research Project on Artificial Intelligence coins the name of a new field concerned with making software smart like humans. 1965 Joseph Weizenbaum at MIT creates Eliza, the first chatbot, which poses as a psychotherapist. 1975 Meta-Dendral, a program developed at Stanford to interpret chemical analyses, makes the first discoveries by a computer to be published in a refereed journal. 1987 A Mercedes van fitted with two cameras and a bunch of computers drives itself 20 kilometers along a German highway at more than 55 mph, in an academic project led by engineer Ernst Dickmanns. 1997 IBM’s computer Deep Blue defeats chess world champion Garry Kasparov . 2004 The Pentagon stages the Darpa Grand Challenge, a race for robot cars in the Mojave Desert that catalyzes the autonomous-car industry. 2012 Researchers in a niche field called deep learning spur new corporate interest in AI by showing their ideas can make speech and image recognition much more accurate. 2016 AlphaGo, created by Google unit DeepMind, defeats a world champion player of the board game Go. He had high hopes of a breakthrough in the drive toward human-level machines. “We think that a significant advance can be made,” he wrote with his co-organizers , “if a carefully selected group of scientists work on it together for a summer.” Those hopes were not met, and McCarthy later conceded that he had been overly optimistic. But the workshop helped researchers dreaming of intelligent machines coalesce into a recognized academic field. Early work often focused on solving fairly abstract problems in math and logic. But it wasn’t long before AI started to show promising results on more human tasks. In the late 1950s, Arthur Samuel created programs that learned to play checkers. In 1962, one scored a win over a master at the game. In 1967, a program called Dendral showed it could replicate the way chemists interpreted mass-spectrometry data on the makeup of chemical samples. As the field of AI developed, so did different strategies for making smarter machines. Some researchers tried to distill human knowledge into code or come up with rules for specific tasks, like understanding language. Others were inspired by the importance of learning to understand human and animal intelligence. They built systems that could get better at a task over time, perhaps by simulating evolution or by learning from example data. The field hit milestone after milestone as computers mastered tasks that could previously only be completed by people. Deep learning, the rocket fuel of the current AI boom, is a revival of one of the oldest ideas in AI. The technique involves passing data through webs of math loosely inspired by the working of brain cells that are known as artificial neural networks. As a network processes training data, connections between the parts of the network adjust, building up an ability to interpret future data. Artificial neural networks became an established idea in AI not long after the Dartmouth workshop. The room-filling Perceptron Mark 1 from 1958, for example, learned to distinguish different geometric shapes and got written up in The New York Times as the “Embryo of Computer Designed to Read and Grow Wiser.” But neural networks tumbled from favor after an influential 1969 book coauthored by MIT’s Marvin Minsky suggested they couldn’t be very powerful. Not everyone was convinced by the skeptics, however, and some researchers kept the technique alive over the decades. They were vindicated in 2012, when a series of experiments showed that neural networks fueled with large piles of data could give machines new powers of perception. Churning through so much data was difficult using traditional computer chips, but a shift to graphics cards precipitated an explosion in processing power . In one notable result, researchers at the University of Toronto trounced rivals in an annual competition where software is tasked with categorizing images. In another, researchers from IBM, Microsoft, and Google teamed up to publish results showing deep learning could also deliver a significant jump in the accuracy of speech recognition. Tech companies began frantically hiring all the deep-learning experts they could find. It's important to note however that the AI field has had several booms and busts (aka, “AI winters”) in the past, and a sea change remains a possibility again today. The State of AI Today Improvements to AI hardware, growth in training courses in machine learning , and open source machine-learning projects have accelerated the spread of AI to other industries, from national security to business support and medicine . Alphabet-owned DeepMind has turned its AI loose on a variety of problems: the movement of soccer players , the restoration of ancient texts , and even ways to control nuclear fusion . In 2020, DeepMind said that its AlphaFold AI could predict the structure of proteins, a long-standing problem that had hampered research. This was widely seen as one of the first times a real scientific question has been answered with AI. AlphaFold was subsequently used to study Covid-19 and is now helping scientists study neglected diseases . Meanwhile, consumers can expect to be pitched more gadgets and services with AI-powered features. Google and Amazon, in particular, are betting that improvements in machine learning will make their virtual assistants and smart speakers more powerful. Amazon, for example, has devices with cameras to look at their owners and the world around them. Much progress has been made in the past two decades, but there’s plenty to work on. Despite the flurry of recent progress in AI and wild prognostications about its near future, there are still many things that machines can’t do, such as understanding the nuances of language, commonsense reasoning, and learning new skills from just one or two examples. AI software will need to master tasks like these if it is to get close to the multifaceted, adaptable, and creative intelligence of humans, an idea known as artificial general intelligence that may never be possible. One deep-learning pioneer, Google’s Geoff Hinton, argues that making progress on that grand challenge will require rethinking some of the foundations of the field . Generative AI and Its Controversies There’s a particular type of AI making headlines—in some cases, actually writing them too. Generative AI is a catch-all term for AI that can cobble together bits and pieces from the digital world to make something new—well, new-ish—such as art, illustrations, images, complete and functional code , and tranches of text that pass not only the Turing test , but MBA exams . Tools such as OpenAI’s Chat-GPT text generator and Stable Diffusion’s text-to-image maker manage this by sucking up unbelievable amounts of data, analyzing the patterns using neural networks, and regurgitating it in sensible ways. The natural language system behind Chat-GPT has churned through the entire internet, as well as an untold number of books, letting it answer questions, write content from prompts, and—in the case of CNET —write explanatory articles for websites to match search terms. (To be clear, this article was not written by Chat-GPT, though including text generated by the natural language system is quickly becoming an AI-writing cliche.) While investors are drooling , writers, visual artists, and other creators are naturally worried : Chatbots are (or at least appear to be) cheap, and humans require a livable income. Why pay an illustrator for an image when you can prompt Dall-E to make something for free? Content makers aren’t the only ones concerned. Google is quietly ramping up its AI efforts in response to OpenAI’s accomplishments, and the search giant should be worried about what happens to people’s search habits when chatbots can answer questions for us . So long Googling, hello Chat-GPTing? Challenges loom on the horizon, however. AI models need more and more data to improve, but OpenAI has already used the easy sources; finding new piles of written text to use won’t be easy or free. Legal challenges also loom: OpenAI is training its system on text and images that may be under copyright, perhaps even created by the very same people whose jobs are at risk from this technology. And as more online content is created using AI, it creates a feedback loop in which the online data-training models won’t be created by humans, but by machines. Data aside, there’s a fundamental problem with such language models: They spit out text that reads well enough but is not necessarily accurate. As smart as these models are, they don’t know what they’re saying or have any concept of truth—that’s easily forgotten amid the mad rush to make use of such tools for new businesses or to create content. Words aren’t just supposed to sound good, they’re meant to convey meaning too. The Challenges (and Future) of Artificial Intelligence There are as many critics of AI as there are cheerleaders—which is good news, given the hype surrounding this set of technologies. Criticism of AI touches on issues as disparate as sustainability , ethics , bias , disinformation , and even copyright , with some arguing the technology is not as capable as most believe and others predicting it’ll be the end of humanity as we know it . It’s a lot to consider. Your AI Decoder Ring Artificial intelligence The development of computers capable of tasks that typically require human intelligence. Machine learning Using example data or experience to refine how computers make predictions or perform a task. Deep learning A machine learning technique in which data is filtered through self-adjusting networks of math loosely inspired by neurons in the brain. Supervised learning Showing software labeled example data, such as photographs, to teach a computer what to do. Unsupervised learning Learning without annotated examples, just from experience of data or the world—trivial for humans but not generally practical for machines. Yet. Reinforcement learning Software that experiments with different actions to figure out how to maximize a virtual reward, such as scoring points in a game. Artificial general intelligence As yet nonexistent software that displays a humanlike ability to adapt to different environments and tasks, and transfer knowledge between them. To start, deep learning inherently requires huge swathes of data, and though innovations in chips mean we can do that faster and more efficiently than ever, there’s no question that AI research churns through energy. A startup estimated that in teaching one system to solve a Rubik’s Cube using a robotic hand OpenAI consumed 2.8 gigawatt-hours of electricity—as much as three nuclear plants could output in an hour. Other estimates suggest training an AI model emits as much carbon dioxide as five American cars being manufactured and driven for their average lifespan. There are techniques to reduce the impact: Researchers are developing more efficient training techniques, models can be chopped up so only necessary sections are run, and data centers and labs are shifting to cleaner energy. AI also has a role to play in improving efficiencies in other industries and otherwise helping address the climate crisis. But boosting the accuracy of AI generally means having more complicated models sift through more data— OpenAI’s GPT2 model reportedly had 1.5 billion weights to assess data, while GPT3 had 175 billion—suggesting AI’s sustainability could get worse before it improves. Vacuuming up all the data needed to build these models creates additional challenges, beyond the shrinking availability of fresh data mentioned above. Bias remains a core problem: Data sets reflect the world around us, and that means models absorb our racism, sexism, and other cultural assumptions. This causes a host of serious problems: AI trained to spot skin cancer performs better on white skin ; software designed to predict recidivism inherently rates Black people as more likely to reoffend ; and flawed AI facial recognition software has already incorrectly identified Black men , leading to their arrests. And sometimes the AI simply doesn’t work: One violent crime prediction tool for police was wildly inaccurate because of an apparent coding error. Again, mitigations are possible. More inclusive data sets could help tackle bias at the source, while forcing tech companies to explain algorithmic decision-making could add a layer of accountability. Diversifying the industry beyond white men wouldn’t hurt, either. But the most serious challenges may require regulating —and perhaps banning—the use of AI decision-making in situations with the most risk of serious damage to people. Those are a few examples of unwanted outcomes. But people are also already using AI for nefarious ends, such as to create deepfakes and spread disinformation. While AI-edited or AI-generated videos and images have intriguing use cases—such as filling in for voice actors after they leave a show or pass away—generative AI has also been used to make deepfake porn , adding famous faces to adult actors, or used to defame everyday individuals. And AI has been used to flood the web with disinformation , though fact-checkers have turned to the technology to fight back. As AI systems grow more powerful, they will rightly invite more scrutiny. Government use of software in areas such as criminal justice is often flawed or secretive , and corporations like Meta have begun confronting the downsides of their own life-shaping algorithms . More powerful AI has the potential to create worse problems, for example by perpetuating historical biases and stereotypes against women or Black people. Civil-society groups and even the tech industry itself are now exploring rules and guidelines on the safety and ethics of AI. But the hype around generative models suggests we still haven’t learned our lesson when it comes to AI. We need to calm down; understand how it works and when it doesn’t; and then roll out this tool in a careful, considered manner, mitigating concerns as they’re raised. AI has real potential to better—and even extend—our lives, but to truly reap the benefits of machines getting smarter, we’ll need to get smarter about machines. Learn More AI Shouldn’t Compete With Workers—It Should Supercharge Them The economy could get a boost if machine-learning engineers switched from copying human abilities to augmenting them. How to Stop Robots From Becoming Racist Algorithms can amplify patterns of discrimination. Robotics researchers are calling for new ways to prevent mechanical bodies acting out those biases. Generative AI Won’t Revolutionize Game Development Just Yet Hypesters say artificial intelligence will one day automate all the hard work of video game creation. But it’s not that simple. It’s Time to Teach AI How to Be Forgetful By emulating the human ability to forget some of the data, psychological AIs will transform algorithmic accuracy. The Race to Build a ChatGPT-Powered Search Engine A search bot you converse with could make finding answers easier—if it doesn’t tell fibs. Microsoft, Google, Baidu, and others are working on it. AI Reveals the Most Human Parts of Writing When do writers want help finding inspiration? And when do they want full control? Computers could expose the true future of the medium. ChatGPT Isn’t the Only Way to Use AI in Education AI can be a tool to create meaningful connections and learning experiences for children—and may help foster more equitable outcomes. Where the AI Art Boom Came From—and Where It’s Going In the past year, algorithms got a lot better at generating illustrations, art, and photo-realistic scenes. Next up? Video. Plus! AI’s hallucination problem and more WIRED artificial intelligence coverage . This guide was last updated on February 8, 2023. Enjoyed this deep dive? Check out more WIRED Guides . Tom Simonite is a former senior editor who edited WIRED’s business coverage. He previously covered artificial intelligence and once trained an artificial neural network to generate seascapes. Simonite was previously San Francisco bureau chief at MIT Technology Review, and wrote and edited technology coverage at New Scientist magazine in London. ... Read More Senior Editor X Topics Wired Guide artificial intelligence Read More My Couples Retreat With 3 AI Chatbots and the Humans Who Love Them I found people in serious relationships with AI partners and planned a weekend getaway for them at a remote Airbnb. We barely survived. Sam Apple How the Loudest Voices in AI Went From ‘Regulate Us’ to ‘Unleash Us’ Two years after Sam Altman pitched Congress on AI guardrails, he's back in Washington with a new message: To beat China, invest in OpenAI. Steven Levy ‘They're Not Breathing’: Inside the Chaos of ICE Detention Center 911 Calls Records of hundreds of emergency calls from ICE detention centers obtained by WIRED—including audio recordings—show a system inundated by life-threatening incidents, delayed treatment, and overcrowding. Dell Cameron OpenAI’s Unreleased AGI Paper Could Complicate Microsoft Negotiations The partnership between OpenAI and Microsoft in many ways hinges on the definition of artificial general intelligence, creating a tension that has spilled over into OpenAI research that has not been made public. Kylie Robison How ‘Big Ag’ Spied on Animal Rights Activists and Pushed the FBI to Treat Them as Bioterrorists For years, a powerful farm industry group served up information on activists to the FBI. Records reveal a decade-long effort to see the animal rights movement labeled a “bioterrorism” threat. Dell Cameron This Historian Has Seen the Future of Trans Health Care Jules Gill-Peterson doesn’t want to fight for trans joy. She wants to fight for what trans people really need: resources, hormones, and surgery. Her latest arena? The US Supreme Court. Harron Walker How to Protest Safely: What to Bring and What to Do If you’re planning on hitting the streets, here’s what you need to know. Boone Ashworth Demis Hassabis Embraces the Future of Work in the Age of AI The CEO of Google's DeepMind says systems as smart as humans are almost here—and that the job market will undergo "scary" changes. Steven Levy The WIRED Guide to Protecting Yourself From Government Surveillance Donald Trump has vowed to deport millions and jail his enemies. To carry out that agenda, his administration will exploit America’s digital surveillance machine. Here are some steps you can take to evade it. Andy Greenberg Social Media Replaced Zines. Now Zines Are Taking the Power Back At a time of fleeting memes and cultural platforms operated by multibillion-dollar companies, an old mode of creativity and community-building gets a second life. C. Brandon Ogbunu What Big Tech's Band of Execs Will Do in the Army Meta CTO Andrew "Boz" Bosworth and leaders from OpenAI and Palantir have joined a detachment intended to make the US Armed Forces "leaner, smarter, and more lethal." Steven Levy The 65 Best Movies on Disney+ Right Now Sally, The Last Showgirl, and Spider-Man: Across the Spider-Verse are just a few of the movies you should be watching on Disney+ this month. WIRED Staff WIRED is where tomorrow is realized. It is the essential source of information and ideas that make sense of a world in constant transformation. The WIRED conversation illuminates how technology is changing every aspect of our lives—from culture to business, science to design. The breakthroughs and innovations that we uncover lead to new ways of thinking, new connections, and new industries. More From WIRED Subscribe Newsletters Travel FAQ WIRED Staff WIRED Education Editorial Standards Archive RSS Accessibility Help Reviews and Guides Reviews Buying Guides Mattresses Electric Bikes Soundbars Streaming Guides Wearables TVs Coupons Gift Guides Advertise Contact Us Manage Account Jobs Press Center Condé Nast Store User Agreement Privacy Policy Your California Privacy Rights © 2025 Condé Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices Select international site United States LargeChevron Italia Japón Czech Republic & Slovakia Facebook X Pinterest YouTube Instagram Tiktok
====================================================================================================
Artificial Intelligence news - Today’s latest updates - CBS News Latest U.S. Israel-Iran Conflict War Powers Vote World Politics Entertainment HealthWatch MoneyWatch Crime Space Sports Brand Studio Local News Baltimore Bay Area Boston Chicago Colorado Detroit Los Angeles Miami Minnesota New York Philadelphia Pittsburgh Sacramento Texas Live CBS News 24/7 Baltimore Bay Area Boston Chicago Colorado Detroit Los Angeles Miami Minnesota New York Philadelphia Pittsburgh Sacramento Texas 48 Hours 60 Minutes Shows 48 Hours 60 Minutes America Decides CBS Evening News CBS Mornings CBS Morning News CBS Reports CBS Saturday Morning The Daily Report The Dish Face the Nation Sunday Morning The Takeout The Uplift CBS News Investigates CBS News Confirmed CBS Village Podcasts Newsletters Download Our App CBS News Team Executive Team Brand Studio Paramount+ Join Our Talent Community RSS Feeds Davos Interviews A Moment With... Innovators & Disruptors Economy 4.0 U.S. Israel-Iran Conflict War Powers Vote World Politics HealthWatch MoneyWatch Entertainment Crime Sports Watch CBS News Artificial Intelligence AI-generated videos fuel falsehoods about Iran-Israel conflict Coordinated networks have spread fabricated videos about the Iran-Israel conflict, experts say. 18H ago Debunking fake videos on Iran-Israel conflict AI-generated videos depicting dramatic scenes from the Iran-Israel conflict have circulated online. CBS News Confirmed producer Erielle Delzer explains what people should know about these videos and who's behind some of them. 18H ago 01:36 How AI is helping solve an ancient mystery from the Roman Empire An expert said there could be more scrolls out there as artificial intelligence and other new technology helps to decipher the ancient messages. Jun 26 AI is helping to solve an ancient mystery Artificial intelligence is helping to solve an ancient mystery from the Roman Empire. It involves scrolls from a library that was buried when Mount Vesuvius erupted in 79 AD. CBS News' Chris Livesay reports. Jun 26 04:47 Traffic safety watchdog looking into erratic driving by Tesla robotaxis Traffic safety regulators are investigating after videos surfaced showing Tesla robotaxis being tested in Texas driving unpredictably. Jun 25 Reporter's Notebook: Some good news about AI Apocalyptic news about artificial intelligence darts into the news cycle pretty regularly, but "CBS Evening News" co-anchor John Dickerson delves into some good news about AI. Jun 24 02:06 Anthropic wins AI copyright case, but must face trial on pirated books Anthropic didn't violate U.S. copyright law when the AI company used millions of legally purchased books to train its chatbot, judge rules. Jun 26 AI's human imitation brings dangers "Godfather of AI" Yoshua Bengio said concerns about the technology are not just about it taking jobs, but also the risks of training it to imitate humans. Tech journalist Yasmin Khorram has more on its "sociopathic tendencies." Jun 20 04:05 Meta and Oakley pair up to launch new AI glasses Meta and sportswear brand Oakley introduced new AI glasses Friday called Oakley Meta HSTN. Jun 20 Amazon CEO: AI will mean fewer corporate jobs Amazon CEO Andy Jassy says artificial intelligence will lead to fewer corporate jobs at the company. Technology journalist Jacob Ward, host of "The Rip Current" podcast, joins CBS News to discuss how AI is already reshaping the workforce. Jun 19 05:06 Amazon CEO says rollout of generative AI will reshape company's workforce Andy Jassy, CEO of Amazon, said he expects the company to reduce its workforce over the next few years as it rolls out more generative AI and agents. Jun 17 AI data centers are driving up energy bills An increase in demand for artificial intelligence may be increasing the cost of your electric bills. CBS News national environmental correspondent David Schechter explains. Jun 16 04:01 Some Meta AI personal chats made public Some users of Meta's AI app say their personal chats are being inadvertently shared publicly. Tech journalist Yasmin Khorram has more. Jun 16 02:56 Scammers use AI to create fake job applicants Artificial intelligence is being used to create realistic video and audio to impersonate people, in some cases looking for love or deceiving companies looking to hire. In a 2024 study, half of the businesses surveyed said they'd experienced AI deepfake fraud. CBS News MoneyWatch correspondent Kelly O'Grady reports. Jun 16 04:28 The AI revolution is likely to drive up your electricity bill. Here's why. Utilities are racing to build data centers to meet surging demand for AI and other tech services. Ratepayers will pick up the tab, experts say. Jun 17 Barbie maker Mattel and OpenAI partner to develop AI-powered toys The toymaker and ChatGPT developer are teaming up to develop toys and games that incorporate artificial intelligence. Jun 12 OpenAI tools ChatGPT, Sora image generator are down ChatGPT maker OpenAI suffered an outage that took its generative AI tools down on Tuesday. Jun 10 New college grad? Here's what experts say you should know about AI. We asked three experts what fresh college graduates can do to prepare as artificial intelligence changes how Americans work. Here's what they said. Jun 6 Meta platforms showed hundreds of "nudify" deepfake ads, CBS News finds Meta platforms such as Instagram have marketed AI tools that let users create sexually explicit images of real people. Jun 6 Reddit sues Anthropic over alleged "scraping" of content to train Claude Reddit sued the artificial intelligence company on Wednesday, claiming that it is stealing millions of user comments from platform to train its chatbot, Claude. Jun 4 Surge in sextortion cases targeting teen boys FBI records reviewed by CBS News show a spike in reports of sextortion since 2019 and a surge in cases targeting teen boys. Scott MacFarlane reports. Jun 3 02:18 Meta signs nuclear power deal for AI energy Meta has signed a 20-year agreement to buy nuclear power from Constellation Energy, joining the growing list of tech giants turning to nuclear energy to meet the demands of artificial intelligence. Bloomberg News tech reporter Riley Griffin has more. Jun 3 01:38 China, U.S. swap trade violation claims China is pushing back against the U.S. after President Trump accused the country of violating a May 12 trade agreement. CBS News senior business and technology correspondent Jo Ling Kent reports. Jun 2 05:04 Teen's family fights for change after sextortion scam leads to death Elijah Heacock's parents had never heard of sextortion before their son died by suicide. Now, they're fighting to protect other families. May 31 Leavitt: "MAHA" report had "formatting issues" The Trump administration has scrambled to address a NOTUS article that found its "MAHA" commission report misinterpreted several studies and cited others that do not exist. Alex Tin, CBS News health reporter, and Dr. Céline Gounder, CBS News medical contributor, join with analysis. May 30 07:43 Show More Trump administration's "divide and conquer" approach to LGBTQ rights Now in its sixth month, President Trump's administration has become the antithesis of progress, many LGBTQ Americans say. 2H ago Pride Month photos show celebrations around the world Trump administration to shutter specialized LGBTQ+ suicide lifeline option Senate to hold initial vote today on Trump's "big, beautiful bill" Congress is racing to meet a self-imposed July 4 deadline to send the tax and spending bill to the president. 3H ago Iran holds first state funerals for military leaders, nuclear scientists Mourners gathered in Tehran for the funeral of top Iranian commanders and scientists killed in a 12-day war with Israel. 2H ago 17 injured, married couple killed in Russian drone strike, Ukraine says Ukrainian authorities say two people were killed and some 17 injured after Russian drones attacked the southern Ukrainian port city of Odesa. updated 54M ago Supreme Court, in birthright citizenship case, limits use of universal injunctions The court ruled that universal injunctions issued by lower courts likely exceed the authority Congress has granted them. 13H ago Trump praises Supreme Court ruling on nationwide injunctions Israeli strikes kill at least 60 in Gaza, Hamas-run health ministry says The strikes come as President Trump on Friday said there could be a ceasefire agreement between Israel and Hamas within the next week. 11M ago University of Virginia president to resign amid Trump administration DEI probe The move marks the latest university resignation tied to President Trump's national effort to scrutinize and scale back diversity efforts at universities. 16H ago Senate votes down measure restricting Trump from military action in Iran Democratic Sen. Tim Kaine forced a vote on a resolution he introduced days before the U.S. bombed Iran. 12H ago Photos: Jeff Bezos, Lauren Sánchez's wedding draws celebrity crowd Jeff Bezos and Lauren Sánchez got married Friday in Venice, and movie stars, TV personalities and business titans joined the celebrations. 14H ago U.S. More U.S. Summer heat increases risk of child deaths in hot cars Nine children have died in the U.S. after being left in hot cars this year, according to data from Kids and Car Safety. 1H ago The Trump administration's "divide and conquer" approach to LGBTQ rights Now in its sixth month, President Trump's administration has become the antithesis of progress, many LGBTQ Americans say. 2H ago Pride Month photos show celebrations around the world From Washington, D.C., to Kathmandu and beyond, enormous crowds gathered to celebrate the LGBTQ community at Pride parades across the globe. 2H ago Study: Some parts of New Orleans' flood walls sinking nearly 2 inches per year This summer marks 20 years since Hurricane Katrina made landfall on the Gulf Coast, leaving more than 1,300 people dead and displacing more than a million people across the region. 12H ago How a quiet high school senior used her art to connect with her classmates Molly Schafer spent about 600 hours painting 44 portraits of her peers. 14H ago More in U.S. MoneyWatch More MoneyWatch Kansas furniture store owner forced to shutter due to tariffs Henrik Svendsen said President Trump's trade war is making the furniture he sells unaffordable to import and unaffordable for customers. 14H ago Minimum wage set to rise in 15 cities and states in July. Here's where. Hundreds of thousands of workers will see more money in their paychecks starting next month due to minimum wage increases. 17H ago Half of all private-sector workers lack access to a retirement plan Tens of millions of Americans are unable to save for retirement through their jobs. "That's not a gap — it's a crisis," one expert says. 17H ago Trump says he's "terminating all discussions on trade with Canada" President Trump said he'll let Canada know what their tariff rate on exports to the U.S. will be soon. 17H ago The Trump tariffs aren't causing U.S. prices to spike. Here's why. Economists warned that a barrage of new U.S. tariffs could trigger a renewed bout of inflation. So why aren't prices surging? 19H ago More from MoneyWatch Politics More Politics The Trump administration's "divide and conquer" approach to LGBTQ rights Now in its sixth month, President Trump's administration has become the antithesis of progress, many LGBTQ Americans say. 2H ago Senate to hold initial vote today on Trump's "big, beautiful bill" Congress is racing to meet a self-imposed July 4 deadline to send the tax and spending bill to the president. 3H ago Trump says ceasefire in Gaza possible "within the next week" President Trump has pushed for an Israel-Hamas ceasefire for weeks, but a deal has proven elusive so far. 16H ago Judge finds Trump executive order punishing Susman Godfrey unconstitutional U.S. District Judge Loren AliKhan ruled that President Trump's executive order is unconstitutional. 16H ago University of Virginia president to resign amid Trump administration DEI probe The move marks the latest university resignation tied to President Trump's national effort to scrutinize and scale back diversity efforts at universities. 16H ago More in Politics HealthWatch More HealthWatch Supreme Court upholds task force that sets no-cost preventive coverage The Supreme Court on Friday upheld the structure of a federal health task force that recommends preventive medical services that must be provided to patients at no cost. Jun 27 Experts say halting U.S. funds for Gavi vaccine alliance will cost lives RFK Jr. announced a halt to all U.S. funding for the global Gavi vaccine alliance. One expert calls it a "travesty and a nightmare." Jun 26 RFK Jr.'s vaccine committee votes against rarely used flu shot preservative The votes on vaccine recommendations are the first move by the panel after Health and Human Services Secretary Robert F. Kennedy Jr. replaced all its members. Jun 26 Too sick to work, some Americans worry Trump's bill will strip their insurance Republicans claim 4.8 million Americans on Medicaid who could work choose not to. The GOP's work-requirement legislation could sweep up disabled people who say they're unable to hold jobs. Jun 26 Nestle to stop using artificial dyes in U.S. foods, beverages by mid-2026 Nestle says it will eliminate artificial colors from its U.S. food and beverages by the middle of 2026. It's the latest big food company making that pledge. Jun 26 More in HealthWatch World More World Israeli strikes kill at least 60 in Gaza, Hamas-run health ministry says The strikes come as President Trump on Friday said there could be a ceasefire agreement between Israel and Hamas within the next week. 11M ago More than $130 million in cocaine recovered from ship in London port The drugs — valued at about $132 million — were found under containers on a vessel at London Gateway port. 17M ago Iran holds first state funerals for military leaders, nuclear scientists Mourners gathered in Tehran for the funeral of top Iranian commanders and scientists killed in a 12-day war with Israel. 2H ago 17 injured, married couple killed in Russian drone strike, Ukraine says Ukrainian authorities say two people were killed and some 17 injured after Russian drones attacked the southern Ukrainian port city of Odesa. updated 54M ago Pride Month photos show celebrations around the world From Washington, D.C., to Kathmandu and beyond, enormous crowds gathered to celebrate the LGBTQ community at Pride parades across the globe. 2H ago More in World Entertainment More Entertainment Entertainment Details on Jeff Bezos' Venice wedding Amazon founder Jeff Bezos and former TV journalist Lauren Sanchez got married in Venice in front of a star-studded guest list. 2H ago 02:03 Natasha Bedingfield announces U.S. tour, reflects on success of "Unwritten" Natasha Bedingfield announced her U.S. tour on "CBS Mornings" and talked about her creative process and why she's hitting the road again. 22H ago Natasha Bedingfield returns to the stage Known for chart-toppers like "Unwritten" and "These Words," Natasha Bedingfield is set to headline a fall tour across the United States. Jun 27 04:30 Anna Wintour exits top Vogue role After nearly four decades as editor in chief, Anna Wintour is stepping aside from her signature role at Vogue. The 75-year-old will retain global responsibilities at Condé Nast as the magazine searches for a new editorial leader. Jun 27 02:12 Brad Pitt's home targeted in burglary Police say burglars broke into Brad Pitt's Los Feliz home while he was abroad. The case joins a string of recent high-profile break-ins involving athletes and actors. Jun 27 01:28 More in Entertainment Technology More Technology AI-generated videos fuel falsehoods about Iran-Israel conflict Coordinated networks have spread fabricated videos about the Iran-Israel conflict, experts say. 18H ago AI is helping to solve an ancient mystery Artificial intelligence is helping to solve an ancient mystery from the Roman Empire. It involves scrolls from a library that was buried when Mount Vesuvius erupted in 79 AD. CBS News' Chris Livesay reports. Jun 26 04:47 How AI powered robots are helping small farms From labor shortages to environmental impacts, farmers are looking to AI to help revolutionize the agriculture industry. One California startup, Farm-ng, is tapping into the power of AI and robotics to perform a wide range of tasks, including seeding, weeding and harvesting. Mar 28, 2024 03:27 Bumble to lay off 30% of workforce as it moves to slash costs Bumble plans to cut hundreds of jobs, with CEO Whitney Wolfe Herd saying the online dating business is at an "inflection point." Jun 25 SpaceX rocket lifts off for historic mission A SpaceX rocket blasted off on a historic two-week mission to the international Space Station, carrying astronauts from India, Poland and Hungary – three countries that haven't been to space in decades. It is led by veteran NASA astronaut Peggy Whitson, who has spent more time in space than any other American. Jun 25 02:44 More in Technology Science More Science These may be the oldest rocks on Earth Scientists have identified what could be the oldest rocks on Earth from a rock formation in Canada. Jun 27 James Webb telescope captures images of possible newly discovered exoplanet The exoplanet, a planet beyond our solar system, has been dubbed TWA 7b after NASA's James Webb Space Telescope captured evidence of it. Jun 26 First close-up images of Mars ridges show "dramatic evidence" of water The new images by the Curiosity rover on Mars show "dramatic evidence" of ancient groundwater in crisscrossing low ridges, NASA said. Jun 25 Killer whales caught on video grooming each other with seaweed A study published in the journal Current Biology describes a new example of tool use by a critically endangered population of orcas. Jun 23 Trump administration's cuts to National Science Foundation blocked A federal judge blocked the Trump administration from making drastic cuts to research funding that is provided by the National Science Foundation. Jun 21 More in Science Crime More Crime More than $130 million in cocaine recovered from ship in London port The drugs — valued at about $132 million — were found under containers on a vessel at London Gateway port. 17M ago Vance Boelter appears in court Minnesota state lawmaker Melissa Hortman, her husband, Mark Hortman, and their dog, Gilbert, lay in state at the Minnesota Capitol rotunda on Friday. As they were remembered, the man accused of killing them appeared in court. CBS News homeland security correspondent Nicole Sganga reports. 15H ago 03:42 Sean "Diddy" Combs' defense closing arguments Closing arguments in Sean "Diddy" Combs' sex trafficking and racketeering trial wrapped up in New York City court on Friday. CBS News legal reporter Katrina Kaufman has more. 15H ago 05:19 Ninth escaped New Orleans inmate has been arrested after 6-week manhunt Nine of the 10 Orleans Parish Prison inmates have now been recaptured following their May 16 jailbreak​. Only one, Derrick Groves, remains on the lam. 13H ago Video shows "narco sub" loaded with cocaine seized in Pacific Ocean It is the latest in a series of major drug hauls showcased by Mexico, which is under pressure from President Donald Trump to curb narcotics smuggling. 19H ago More in Crime Space More Space Fireball seen as meteorite streaks through sky over Georgia and South Carolina The American Meteor Society said it received more than 160 reports of a fireball sighting from observers in Georgia and South Carolina. 22H ago James Webb telescope captures images of possible newly discovered exoplanet The exoplanet, a planet beyond our solar system, has been dubbed TWA 7b after NASA's James Webb Space Telescope captured evidence of it. Jun 26 Webb Telescope captures images of exoplanet NASA's James Webb Telescope has captured unprecedented pictures of a newly discovered exoplanet, a planet that is outside our solar system. Jun 26 00:25 Crew docks at space station for 2-week commercial mission SpaceX's Crew Dragon Grace brought a privately-financed crew of researchers to the space station for a two-week stay. Jun 26 Watch: Axiom-4 crew docks at ISS The SpaceX Dragon spacecraft carrying the Axiom Mission 4 crew successfully docked at the International Space Station early Thursday morning. It is the the fourth private astronaut mission to the ISS, NASA says. CBS News space consultant Bill Harwood has the details. Jun 26 03:47 More in Space Latest Galleries More Latest Galleries Notable Deaths in 2025 A look back at the esteemed personalities who've left us this year, who'd touched us with their innovation, creativity and humanity. Jun 9 30 photos Attack on Pearl Street Mall in Boulder A suspect was taken into custody after an attack on Pearl Street Mall in Boulder on June 1 in which there were 15 people and a dog who were victims. The suspect threw Molotov cocktails that burned some of the victims, who were part of a march for Israeli hostages. Jun 1 17 photos Summer music heats up 2025 Live performances are in full swing this summer. Scroll through our concert gallery, featuring pictures by CBS News photojournalist Jake Barlow and photographers Ed Spinelli and Kirstine Walton. Jun 6 19 photos "No Kings": Protesters across country march against Trump, Musk Protests against the Trump administration took place across the U.S. Saturday. The demonstrations were held to mark the 250th anniversary of the start of the Revolutionary War. Apr 19 56 photos Jason Corbett murder: A look at the evidence In August 2015, former FBI agent Tom Martens and his daughter Molly Corbett admitted killing her Irish-born husband Jason Corbett, insisting they beat him in self-defense May 20 11 photos More in Latest Galleries Latest CBS News Videos More Latest CBS News Videos Latest CBS News Videos Commemorating the Battle of Gettysburg The Battle of Gettysburg raged from July 1 through July 3 in 1863, and was the turning point of the American Civil War. CBS Saturday Morning takes a tour of the famous battlefield. 2H ago 08:14 Keeping cool in extreme urban heat As the first major heat wave hit the Northeast this week, city dwellers experienced what is known as the "island effect." Here's how one neighborhood plans to stay cool amid the extreme heat. 2H ago 04:22 D.C. Jewish Museum opens LGBTQ+ exhibit The Capitol Jewish Museum in Washington, D.C. where two Israeli Embassy workers were fatally shot over a month ago, has opened a new LGBTQ+ exhibit. 2H ago 03:14 Where to get the latest CBS Mornings Deals On this edition of CBS Mornings Deals, we show you items that might just become essentials in your everyday life. Visit cbsdeals.com to take advantage of these exclusive deals today. CBS earns commissions on purchases made through cbsdeals.com. 2H ago 04:52 Details on Jeff Bezos' Venice wedding Amazon founder Jeff Bezos and former TV journalist Lauren Sanchez got married in Venice in front of a star-studded guest list. 2H ago 02:03 More in Latest Videos Featured Iran's Ayatollah Khamenei Issues Claim of Victory Over Israel War Powers Vote In Birthright Citizenship Case, Supreme Court Limits Judges' Use Of Injunctions 2025 NHL Playoff Schedule Follow Us On YouTube Facebook Instagram X Privacy Privacy Policy California Notice Your Privacy Choices Terms of Use More from CBS News Newsletters Podcasts Download Our App Brand Studio Sitemap Company About Paramount Advertise With Paramount Join Our Talent Community Help Feedback Copyright ©2025 CBS Interactive Inc. All rights reserved. View CBS News In CBS News App Open Chrome Safari Continue Be the first to know Get browser notifications for breaking news, live events, and exclusive reporting. Not Now Turn On
====================================================================================================
Emerging technologies whitepaper series: Artificial Intelligence July 2018 / OICT Emerging Tech Team / contact us: ai@un.org WHAT IS ARTIFICIAL INTELLIGENCE (AI)? WHAT IS AI? Simply stated, artificial intelligence (AI) is “human intelligence or behaviour demonstrated by machines”. In practice, an AI is a computer program (software). There is no precise definition of AI, and the meaning has evolved over time, but a number of technologies are generally understood to be included: pattern recognition, image recognition, voice recognition, and understanding of natural language. There are a number of devices for which AI is particularly useful, such as robots, autonomous vehicles and “drones”, which use AI for observation, navigation, task planning, and avoiding collisions. Voice interaction by consumer devices such as Amazon Alexa and Google Home are also examples of AI. But AI is not exclusive to robots and devices – it also plays an important role in business. For example, credit card companies have been using AI systems effectively for years to prevent fraudulent transactions. WHY HAS AI SUDDENLY BECOME SO POPULAR? Most of the ideas behind AI are not new, with some dating from the 1970s. However, a few recent changes have opened up new possibilities in AI: (a) an increase in computing power has made tasks that were previously out of our reach possible; (b) a large and growing amount of data now available from a rapidly digitizing world (photos, traffic data, telephone calls, website traffic and activity on social networks) can be used to train computers to recognize patterns; and, (c) new algorithms have been developed to make use of this new hardware and data – Machine Learning and, in particular, Neural Networks are techniques where much progress is being made. Although this revolution in computer science that is still evolving, it is already clear that AI is one of the most important technologies of our time, perhaps the most important. Google’s CEO Sundar Pichai and a number of technology experts have called AI “as profound as electricity”. WHAT DOES AI MEAN FOR THE WORLD AND FOR THE UN? The possible applications of AI seem almost endless. With sufficient learning, the vast majority of human jobs could be done cheaper and more effectively by AI. The potential implications of AI for the world are enormous. Whether these implications will be mostly good or bad is much debated. Some respected scientists, successful IT entrepreneurs and others have warned that AI may turn out be humanity’s downfall: risks mentioned include discrimination or bias in AI systems or even an advanced AI in the future getting out of control and taking over the world. Others are optimistic about the efficiencies and opportunities created: AI aids progress in all areas of science, creates new conveniences and makes life better. For example, self-driving cars could drastically reduce the need for private cars and avoid millions of deaths from traffic accidents. In any case, the genie is out of the bottle –AI cannot be un- invented. The loss of certain types of jobs (ranging from radiologists to truck drivers and insurance claim assessors) already seems unavoidable in the near future. The best we can do at the moment is to maximize the number of positive applications of AI that benefit humanity and create norms and ethics for responsible use of AI so as to contain the negative effects. Young generations should be prepared to live and work alongside AI systems. In Dubai and several Chinese cities the government is already deploying robots to deliver public services and this trend will no doubt continue. Faster computing 1 Availability of Big data 2 New algorithms 3 Reasons for the rapid rise of AI Emerging technologies whitepaper series: Artificial Intelligence July 2018 / OICT Emerging Tech Team / contact us: ai@un.org THE ETHICS OF AI A few countries already routinely use unmanned planes (“drones”) equipped with weapons and AI systems in military operations. As these AI systems improve they will inevitably be given more decision-making power, which raises important ethical questions. The UN’s Conference of the Convention on Certain Conventional Weapons has already established a Group of Governmental Experts on Lethal Autonomous Weapon Systems. A group of over 1000 prominent AI researchers, entrepreneurs and others have sent an open letter to the UN expressing their concern about the possibility of autonomous weapons. Ethics are found in other types of AI systems as well. As AI systems are used to support decisions in recruitment, issuance of loans or approval of online publications, and many other areas, avoiding bias is important. However, with modern AI systems such as Neural Nets, it is incredibly difficult, if not impossible, to know why an AI system came to a certain conclusion. The laws that exist in human society preventing discrimination are hard to implement and the effects of possible bias of AI systems are hard to predict. The new norms and ethics needed can come from all parts of society: recently employees at Microsoft and Google have revolted against their (AI) technologies being use for certain government programs, which had led to government contracts being canceled. I has also prompted companies such as Google to announce their “AI principles”. EQUAL ACCESS TO AI AI capacity is currently concentrated within a few large companies: Google, Amazon, Facebook and Baidu are leading by a wide margin. Not coincidently, these are companies that own large quantities of data – AI engineers need large amounts data to train the systems. AI experts expect there to be only a few “winners” in the AI race, and they will accumulate much power and wealth. This may be true for companies or for nations. Does this mean AI will increase the gap between rich and poor, between the haves and have nots? Or will applications of AI for society, such as preventing epidemics, improving infrastructure and increasing inclusiveness, put poor nations on equal footing with rich ones? It is clear that AI makes data “the new oil”, and nations should be conscious of what data they allow companies to collect about citizens. Some influential and successful people in the IT area have set up a non-profit called OpenAI (openai.com) that aims to make the latest AI technology freely accessibly to all. It does not yet solve the access to data, but an increasing number of Open Data initiatives exist and together these may lead to a more equitable AI future. USES OF AI TECHNOLOGY FOR THE UN SECRETARIAT OICT has applied AI in a number of prototypes of applications so far: • A document summarization tool (trained through feedback from users) • Violence prediction for elections (trained with data from previous events) • Analysis of political alignment in GA votes (using clustering techniques) • Classification of Humanitarian Documents There are many other opportunities to use AI in the Secretariat. A few ideas include: • Automated responses to staff queries using text or voice “bots”. • More effective recruitment and human resource management • Image recognition for humanitarian assessment or for security • Predicting the impact of free trade pacts • Identifying peace building opportunities through social media analysis Capacity building for member states would also be a valuable service the UN secretariat could offer.
====================================================================================================
Artificial Intelligence | Science News Skip to content Subscribe today Every print subscription comes with full digital access Subscribe Now Menu All Topics Health Humans Life Earth Physics Space Magazine Menu All Stories Multimedia Reviews Puzzles Collections Educator Portal Century of Science Unsung characters Coronavirus Outbreak Newsletters About SN Explores Our Store SIGN IN Donate Home INDEPENDENT JOURNALISM SINCE 1921 SIGN IN Search Open search Close search Home INDEPENDENT JOURNALISM SINCE 1921 All Topics Earth Agriculture Climate Oceans Environment Humans Anthropology Health & Medicine Archaeology Psychology Life Animals Plants Ecosystems Paleontology Neuroscience Genetics Microbes Physics Materials Science Quantum Physics Particle Physics Space Astronomy Planetary Science Cosmology Tech Computing Artificial Intelligence Chemistry Math Science & Society All Topics Health Humans Humans Anthropology Health & Medicine Archaeology Psychology Recent posts in Humans Climate Harmful heat doesn’t always come in waves By Nikk Ogasa 18 hours ago Psychology AI can measure our cultural history. But is it accurate? By Sujata Gupta June 26, 2025 Health & Medicine Many U.S. babies may lack gut bacteria that train their immune systems By Tina Hesman Saey June 25, 2025 Life Life Animals Plants Ecosystems Paleontology Neuroscience Genetics Microbes Recent posts in Life Life A barrage of radiation couldn’t kill this hardy life-form By Katherine Kornei 21 hours ago Genetics Genetics reveal the origin story of East Asia’s favorite sweet bean By Celina Zhao June 27, 2025 Animals This bug’s all-in helicopter parenting reshaped its eggs By Susan Milius June 26, 2025 Earth Earth Agriculture Climate Oceans Environment Recent posts in Earth Climate Harmful heat doesn’t always come in waves By Nikk Ogasa 18 hours ago Earth Earth’s oldest rocks may be at least 4.16 billion years old By Carolyn Gramling June 26, 2025 Animals U.S. seal populations have rebounded — and so have their conflicts with humans By Aaron Tremper June 19, 2025 Physics Physics Materials Science Quantum Physics Particle Physics Recent posts in Physics Quantum Physics ‘Magic’ states empower error-resistant quantum computing By Emily Conover June 25, 2025 Physics No player can return this killer shot. Physics explains how it works By Celina Zhao June 24, 2025 Science & Society A Supreme Court ruling on nuclear waste spotlights U.S. storage woes By Emily Conover June 18, 2025 Space Space Astronomy Planetary Science Cosmology Recent posts in Space Life A barrage of radiation couldn’t kill this hardy life-form By Katherine Kornei 21 hours ago Astronomy Mysterious ‘little red dot’ galaxies have a possible origin story By Ken Croswell 22 hours ago Planetary Science In a first, the Webb telescope found a planet by actually ‘seeing’ it By Adam Mann June 25, 2025 Artificial Intelligence Tech Artificial Intelligence Computing Artificial Intelligence Artificial Intelligence A new AI-based weather tool surpasses current forecasts The AI tool used machine learning to outperform current weather simulations, offering faster, cheaper, more accurate forecasts. By Kathryn Hulick May 21, 2025 Artificial Intelligence Tech billionaires’ vision of an AI-dominated future is flawed — and dangerous By Ashley Yeager April 15, 2025 Artificial Intelligence Spotting climate misinformation with AI requires expertly trained models By Ananya April 14, 2025 More Stories in Artificial Intelligence Artificial Intelligence AI is helping scientists decode previously inscrutable proteins A new set of artificial intelligence models could make protein sequencing even more powerful for better understanding cell biology and diseases. By Lauren Leffer March 31, 2025 Artificial Intelligence As AI advances, the meaning of artificial general intelligence remains murky AI models are growing ever-more capable, accurate and impressive. The question of if they represent “general intelligence” is increasingly moot. By Lauren Leffer March 11, 2025 Artificial Intelligence Medical AI tools are growing, but are they being tested properly? AI medical benchmark tests fall short because they don’t test efficiency on real tasks such as writing medical notes, experts say. By Ananya March 7, 2025 Artificial Intelligence More brainlike computers could change AI for the better New brain-inspired hardware, architectures and algorithms could lead to more efficient, more capable forms of AI. By Kathryn Hulick February 26, 2025 Artificial Intelligence Are AI chatbot ‘personalities’ in the eye of the beholder? Defining AI chatbot personality could be based on how a bot “feels” about itself or on how a person feels about the bot they’re interacting with. By Sujata Gupta February 5, 2025 Health & Medicine AI could transform health care, but will it live up to the hype? AI has the potential to make health care more effective, equitable and humane. Whether the tech delivers on these promises remains to be seen. By Meghan Rosen and Tina Hesman Saey January 10, 2025 Health & Medicine AI helps doctors detect more breast cancer in the largest real-world study AI is as good as clinicians at interpreting mammograms, a cancer study with nearly 500,000 participants in Germany suggests. By McKenzie Prillaman January 7, 2025 Artificial Intelligence AI sniffs out whiskey flavor notes as well as the pros A machine learning algorithm identified the top five flavor notes in 16 types of whiskey. Each matched the aggregate of what a panel of human pros said. By Carolyn Gramling December 19, 2024 Artificial Intelligence Generative AI is an energy hog. Is the tech worth the environmental cost? Generative AI and the hype around it has rung in excitement and alarm bells this year. Here’s how to consider climate, energy and AI's intersection. By Lauren Leffer December 9, 2024 Pagination Navigation Go to page 1 Go to page 2 Go to page 3 … Go to page 6 Next Most Popular Health & Medicine Many U.S. babies may lack gut bacteria that train their immune systems By Tina Hesman Saey June 25, 2025 Animals 50 years after ‘Jaws,’ sharks face their own terror By Brianna Randall June 20, 2025 Astronomy Mysterious ‘little red dot’ galaxies have a possible origin story By Ken Croswell 22 hours ago Science News Science News was founded in 1921 as an independent, nonprofit source of accurate information on the latest news of science, medicine and technology. Today, our mission remains the same: to empower people to evaluate the news and the world around them. It is published by the Society for Science, a nonprofit 501(c)(3) membership organization dedicated to public engagement in scientific research and education (EIN 53-0196483). Science News Explores Science News Learning Subscriber Services Subscribe Renew Give a Gift Subscription Customer Service Follow Science News on Facebook Follow Science News on X Follow Science News via RSS Follow Science News on Instagram Follow Science News on YouTube Follow Science News on TikTok Follow Science News on Reddit Follow Science News on Threads More Information FAQ Newsletters Rights & Permissions Advertise Contact Society for Science About the Society Society Store Donate Careers © Society for Science & the Public 2000–2025. All rights reserved. 1719 N St. NW, Washington, DC 20036 202.785.2255 Terms of Service Privacy Policy Privacy Manager Close Log in Subscribers, enter your e-mail address for full access to the Science News archives and digital editions. Not a subscriber? Become one now . Client key* E-mail Address* Log In
====================================================================================================
Artificial Intelligence: A Modern Approach AIMA Home Code Contents Errata Courses Instructors Get the Book Artificial Intelligence: A Modern Approach (Third edition) by Stuart Russell and Peter Norvig The leading textbook in Artificial Intelligence. Used in over 1400 universities in over 125 countries. The 22nd most cited computer science publication on Citeseer (and 4th most cited publication of this century). What's New Comments and Discussion Comments from readers Errata list (errors in the book) AIMA-talk discussion list, open to all AI Resources on the Web AI Resources in many categories AI courses that are using AIMA (1400 schools) Free Online AI course , Berkeley's CS 188, offered through edX . Previous editions: 1st , 2nd, translations Table of Contents [ Full Contents ] Preface [ html ] Part I Artificial Intelligence 1 Introduction ... 1 2 Intelligent Agents ... 34 Part II Problem Solving 3 Solving Problems by Searching ... 64 4 Beyond Classical Search ... 120 5 Adversarial Search ... 161 6 Constraint Satisfaction Problems ... 202 Part III Knowledge and Reasoning 7 Logical Agents ... 234 8 First-Order Logic ... 285 9 Inference in First-Order Logic ... 322 10 Classical Planning ...366 11 Planning and Acting in the Real World ... 401 12 Knowledge Representation ... 437 Part IV Uncertain Knowledge and Reasoning 13 Quantifying Uncertainty ... 480 14 Probabilistic Reasoning ... 510 15 Probabilistic Reasoning over Time ... 566 16 Making Simple Decisions ... 610 17 Making Complex Decisions ...645 Part V Learning 18 Learning from Examples ...693 19 Knowledge in Learning ... 768 20 Learning Probabilistic Models ... 802 21 Reinforcement Learning ... 830 Part VI Communicating, Perceiving, and Acting 22 Natural Language Processing ... 860 23 Natural Language for Communication ... 888 24 Perception ... 928 25 Robotics ... 971 Part VII Conclusions 26 Philosophical Foundations ... 1020 27 AI: The Present and Future ... 1044 A Mathematical Background [ pdf ] ... 1053 B Notes on Languages and Algorithms [ pdf ] ... 1060 Bibliography [ pdf and histograms ] ... 1063 Index [ html or pdf ] ... 1109 AI: A Modern Approach Modified: Apr 16, 2020
====================================================================================================
reuters.com Please enable JS and disable any ad blocker
====================================================================================================
9 Benefits of Artificial Intelligence (AI) in 2025 | University of Cincinnati Skip to content Business Partnerships Student Resources Search… Search Search… Search Degrees & Certificates Associate Degrees Bachelor’s Degrees Master’s Degrees Doctoral Degrees Certificates Endorsements All Programs Business Associate of Applied Business in Accounting Technology Associate of Applied Business in Business Applications Technology Associate of Applied Business in Business Management Technology Associate of Applied Business in Financial Management Technology Associate of Applied Business in Marketing Management Technology Associate of Applied Business in Supply Chain Management Technology Associate of Arts in Business Administration (Pre) Communication Associate of Arts in Communication Education AAS Early Childhood Care & Education Health Care AAS Health Information Systems Associate of Applied Business in Healthcare Management Technology Associate of Applied Science - Cancer Registry Management Hospitality Associate of Applied Business in Hospitality Management Human Services Associate of Science in Public Health Information Technology Associate of Applied Business in Information Technology Interdisciplinary Studies Associate of Individualized Study in Interdisciplinary Studies Law Associate of Applied Business in Law & Paralegal Studies All Associate Degrees Business Bachelor in Business Administration-Accounting Bachelor of Business Administration - Finance Bachelor of Business Administration - Marketing Bachelor of Technical and Applied Studies in Applied Administration Communication Bachelor of Arts in Communication Criminal Justice Bachelor of Science in Criminal Justice Education BS Early Childhood Education Health Care Bachelor of Health Information Management Bachelor of Science in Health Informatics Bachelor of Science in Health Sciences Bachelor of Science in Health Sciences - Pre-Occupational Therapy Bachelor of Science in Medical Laboratory Science Bachelor of Science in Respiratory Therapy (RRT to BSRT) Bachelor of Technical and Applied Studies in Applied Administration : Healthcare Leadership Human Services Bachelor of Science in Public Health Bachelor of Science in Substance Abuse Counseling Bachelor of Social Work Interdisciplinary Studies Bachelor of Arts in Professional Studies Law Bachelor of Science in Law & Paralegal Studies Leadership Bachelor of Arts in Organizational Leadership Nursing RN to BSN Online All Bachelor’s Degrees Athletics Master of Science in Exercise and Sport Science Master of Science in Sport Administration Behavior Analysis Master of Education in Foundations in Behavior Analysis Master of Science in Behavior Analysis Business Master of Business Administration - MBA Master of Science in Business Analytics Master of Science in Finance Master of Science in Information Systems Master of Science in Marketing Master of Science in Taxation Criminal Justice Master of Science in Criminal Justice Education MAT Special Education MEd Curriculum and Instruction MEd Educational Leadership MEd Literacy and Second Language Studies MEd Special Education Engineering MEng in Electrical Engineering MEng in Mechanical Engineering MEng in Robotics & Intelligent Autonomous Systems Geographic Sciences Master of Science in Geographic Information Systems Health Care Master of Health Administration (Executive) - MHA Master of Health Informatics - MHI Master of Science in Medical Laboratory Science Leadership Master of Science in Respiratory Therapy Human Services Master of Science in Community Health & Prevention Science Master of Science in Health and Wellness Management Information Technology Master of Science in Information Technology Instructional Design and Technology MEd Instructional Design and Technology Law Master of Legal Studies Nursing MSN Adult-Gerontology Primary Care Nurse Practitioner MSN Family Nurse Practitioner MSN Nurse-Midwifery MSN Nursing Education MSN Systems Leadership MSN Women's Health Nurse Practitioner Pharmacy MS Pharm Sci in Healthcare Operational Excellence MS Pharm Sci: Drug Development MS Pharm Sci: Health Outcomes & Pharmacoeconomics MS Pharm Sci: Pharmacogenomics and Personalized Healthcare Master of Science in Cosmetic Science Master of Science in Pharmacy Leadership All Master’s Degrees Health Care Clinical Doctorate in Speech-Language Pathology Doctorate of Clinical Laboratory Sciences Nursing BSN to DNP Specializations Post-MSN Doctor of Nursing Practice All Doctoral Degrees Business Artificial Intelligence in Business Graduate Certificate Business Foundations Graduate Certificate Certificate in Insurance & Finance Management Corporate Taxation Graduate Certificate Data Analytics Graduate Certificate Digital Marketing Graduate Certificate Individual Taxation Graduate Certificate Investment Management Graduate Certificate Marketing Graduate Certificate Quantitative Finance Graduate Certificate All Business Certificates Criminal Justice Graduate Certificate in Analysis of Criminal Behavior Graduate Certificate in Correctional Rehabilitation Graduate Certificate in Crime Analysis and Prevention All Criminal Justice Certificates Education Autism Spectrum Disorders Graduate Certificate STEM and Sustainability Education Graduate Certificate Special Education Leadership Graduate Certificate All Education Certificates Health Care Certificate in Health Data Science and Artificial Intelligence Health Care Administration Graduate Certificate Health Care Finance Graduate Certificate Health Care Policy & Regulation Graduate Certificate Medical Coder Certificate Online Cancer Registry Certification Physician Practice Management Certificate Revenue Cycle Management Certificate All Health Care Certificates Hospitality Certificate in Hospitality Management Human Services Certificate in Substance Abuse Counseling Health & Wellness Coaching Certificate All Human Services Certificates Information Technology Application Software Support Specialist Certificate Data-Driven Cybersecurity Certificate Information Technology Certificate Information Technology Graduate Certificate All Information Technology Certificates Instructional Design and Technology Certificate Blended Online Learning and Teaching (BOLT) Interdisciplinary Studies Certificate in Fire Administration Law Post-Associate Certificate in Law and Paralegal Studies Post-Baccalaureate Certificate in Law & Paralegal Studies All Law Certificates Nursing Post-Master's Family Nurse Practitioner Post-Master's Psychiatric-Mental Health Nurse Practitioner All Nursing Certificates Pharmacy Clinical Trials Design and Research Graduate Certificate Cosmetic Science Graduate Certificate Global Regulatory Affairs in Drug Development Graduate Certificate Hygienic Manufacturing of Cosmetic Products Graduate Certificate Pharmacogenomics and Personalized Healthcare Graduate Certificate Pharmacy Leadership Graduate Certificate All Pharmacy Certificates All Certificates Education Gifted Education Endorsement PreK-12 Reading Instruction Endorsement Principal Licensure Endorsement Teaching English to Speakers of Other Languages Endorsement Transition to Work Endorsement All Endorsements All Programs Admissions Admissions Process Business Partnerships – Student Info Transfers State Authorization Student Complaint Information Tuition & Aid Tuition Academic Progress Online Program Fees Financial Aid Aid Budget and Limits Aid Recalculation Understanding Financial Aid Education Program Awards Year-Round Loan Distribution Military Military Benefits & Financial Aid Military Experience VetSuccess Online Partnerships Content Library Blog Online Events News Why UC? About Us FAQ Online Readiness Refer a Friend Testimonials UC Online Recognitions UC Online Experience Request Info Apply Student Resources Back to Blog 9 Benefits of Artificial Intelligence (AI) in 2025 Blog Share Share on Facebook Follow us on LinkedIn Share on Pinterest Share via Email The age of AI is well and truly upon us. Since the release of OpenAI’s ChatGPT in late 2022, countless new AI products and solutions have followed, and artificial intelligence has already transformed numerous industries, government agencies, and personal aspects of modern life. As it continues to evolve and develop, its influence and importance will undoubtedly grow even larger. In short, it’s an exciting form of tech, with a lot to offer. This guide explores just some of the many benefits of artificial intelligence. Key Takeaways AI is transforming industries and everyday life. From healthcare and finance to agriculture and cybersecurity, artificial intelligence is driving innovation, increasing efficiency, and solving complex challenges. Economic and environmental benefits make AI indispensable. AI is expected to contribute trillions to the global economy while also playing a crucial role in climate change mitigation and sustainable resource management. The future of AI is expanding rapidly. Emerging trends like multimodal AI, stronger virtual assistants, and ethical considerations are shaping how AI will continue to evolve and integrate into businesses and daily life. What Is Artificial Intelligence? Before we delve into the many possible AI applications and benefits of AI technologies, it’s worth taking a moment to explain what this technology is all about. In the simplest of terms, AI is the branch of computer science dedicated to creating machines that are able to think like humans. It’s about taking the unique abilities of the human brain to understand, react, and interpret and incorporating those abilities into computers and other devices. It’s quite a complicated field but essentially boils down to two key components: data and algorithms. Vast amounts of data are used in conjunction with algorithms to essentially “train” AI to be able to learn and grow of its own accord, without the need for programming and code updates. The idea of AI has been around for a long time. But, for many decades, it was reserved for the realms of science fiction. However, the work of Alan Turing in the 1950s and many other great minds that followed gradually led to the rise of machine learning and the development of genuine AI solutions. This all culminated with the so-called “ AI boom ” that became most prominent in 2022, as large language models and AI chatbots, like ChatGPT, were released for public usage. Since then, AI has taken off, with many businesses embracing the tech in exciting, innovative ways. What Are 9 Notable Artificial Intelligence Benefits? So, at a fundamental level, AI is simply about putting human intelligence into machines. The benefits of this are numerous and far-reaching. Here are 9 amazing examples: Enhanced healthcare Boosted economic growth Climate change mitigation Advanced transportation Customer service excellence Scientific discovery Enhanced financial services Improved agriculture Enhanced cybersecurity #1 – Enhanced Healthcare AI-based solutions could prove invaluable in the field of healthcare, in so many ways. AI could be used, for example, to assist researchers in developing cures and treatments for illnesses that have plagued mankind for many years. It could also be used for administrative tasks like test analysis and data entry, or much more complicated procedures. In the future, we may even have AI-powered robots performing surgery, reducing human error and saving lives. #2 – Boosted Economic Growth There’s been much fear about AI replacing jobs or damaging economic stability. But the stats tell a different story. Indeed, one study found that AI could contribute a whopping $15.7 trillion to the global economy by 2030. This is partly thanks to the fact that AI, rather than replacing or removing jobs, is opening up countless new working opportunities in diverse fields, from finance to tech. It’s also driving huge productivity growth for many organizations. #3 – Climate Change Mitigation Climate change is arguably the greatest threat currently faced by mankind, with future generations and the well-being of the very planet at stake. As such, scientists and researchers are racing to find ways to mitigate its effects, and machine learning – the bedrock of AI – can help with that. An AI system could, for example, play a role in developing and making the most of new green and renewable energy systems, or finding ways to minimize carbon emissions to improve decision-making processes for governments across the globe. #4 – Advanced Transportation The value and benefit of AI technology are particularly clear to see in the field of transport. Self-driving cars, for example, were once a pipe dream but are becoming a reality thanks to AI’s role in computer vision and self-navigation potential, with 33 million such vehicles set to hit the road by 2040. Beyond self-driving cars, AI can also be used in other fields of transport, like GPS systems to plot the perfect route or traffic analysis to help urban planners ease congestion. This can all help to reduce fuel consumption and get people where they need to be more quickly and safely than ever before. #5 – Customer Service Excellence Multiple artificial intelligence benefits are evident in the customer service sector. For example, in the past, if customers had queries or complaints, they had to call a company or send an email and await a response. Now, they can air their concerns with an AI chatbot and receive instant feedback, thanks to natural language processing. AI technology also helps businesses personalize and manage their customer interactions more effectively. This applies to fields like banking, retail, insurance, and beyond. AI is consistently helping brands deliver the most helpful and valuable customer experiences. #6 – Scientific Discovery For years, scientists have dreamt of the power of AI. There’s almost no limit to how much it could aid them in research. Even today, in the infancy of AI, we can train an AI program to analyze data with remarkable speed and accuracy, thus drawing valuable conclusions, spotting patterns, and providing scientists with the info they need to make breakthroughs and discoveries. In other words, AI represents a major upgrade to the fundamentals of research as we know it. It will make it much faster and easier to dig into data and make predictions. This could lead to the development of everything from cures for major diseases to game-changing new technologies for deeper insights. #7 – Enhanced Financial Services The financial industry is yet another area that is already reaping numerous artificial intelligence benefits. An AI-powered computer program, for example, can assess individual customers’ financial records in deep detail, helping firms make stronger recommendations and more informed decisions in their services. In the field of fraud detection and prevention, AI has a part to play there too. It can help to spot the common signs of fraud or detect fraudulent activities by monitoring accounts and transfers in deep detail, potentially saving institutions and individuals from financial ruin. #8 – Improved Agriculture At first glance, agriculture and AI may not seem like an obvious match. But when you dig into the many artificial intelligence benefits and applications, it’s clear to see how AI can influence and improve farming around the world. AI programs can, for instance, help farmers make better decisions about how to make the most of their land and resources. They can provide weather forecasts, instructions on when to water crops, suggestions on which pesticides (if any) to utilize, and so on. #9 – Enhanced Cybersecurity Cybersecurity has been a hot topic in the tech world for a long time, particularly with the rapid increase in data breaches and the development of malware. For too long, cyber-defense experts have felt like they’re playing catch-up with hackers and malware developers, but AI could change all of that. AI tech can introduce new ways to combat cyber threats and counteract the likes of hacking attempts, ransomware, and viruses. AI programs and defenses can be set up across devices, servers, or entire networks to spot attacks in advance and take the necessary steps to mitigate their negative effects. Artificial Intelligence Trends and Future Given the relative infancy of this industry and the very fast-evolving nature of AI, it’s difficult to pin down any one dominating trend. However, with that said, there are still some noticeable patterns and themes emerging for AI in 2025 and beyond: Multimodal AI: The release of multimodal AI models, like OpenAI’s GPT-4o, changes how AI is used. These models don’t just deal in text but also photos and videos, too, and there’s a lot of focus on finding the most value-adding, interesting ways to harness this tech. Stronger Virtual Agents: As the foundations of AI tech improve, so too do its applications. AI virtual assistants are becoming increasingly useful, valuable additions to both personal and professional lives, taking care of so many tedious tasks for their users to save time and improve productivity. Ethical AI Concerns and Regulations: The rapid rise in AI technology also brings with it new ethical questions that have become hot topics of debate across the globe. Agencies and authorities are currently focused on finding ways to enjoy artificial intelligence benefits in the most ethical and moral manner. Why Should You Care About AI? Quite simply, because AI is the future. This tech is most certainly here to stay, and it’s only going to get bigger, better, smarter, and more influential in so many different industries, as well as in people’s personal lives. It has such a vast range of applications, and so many jobs in the future will involve AI at some level. So, the more you learn about it now, the better placed you’ll be to reap the rewards and benefits of this tech in the years to come. Enhance Your Understanding of AI in Business Enhance your understanding of AI in business with the University of Cincinnati Carl H. Lindner College of Business’s AI in Business Graduate Certificate . This program equips you with the skills and knowledge to master and make the most of AI technology in various business contexts. Students receive strong support from the University of Cincinnati Online, ensuring comprehensive assistance from enrollment through graduation. This certificate can be a valuable addition to your MBA program, with all credits earned applicable toward the Master of Science in Information Systems or Master of Science in Business Analytics programs. For more details on how credits can be applied to these master’s degrees, please contact an Enrollment Services Advisor. Get in touch with UC Online today to find out more and kick-start your AI learning journey. Frequently Asked Questions (FAQs) What is the main benefit of artificial intelligence? The biggest advantage of AI is its versatility—its ability to enhance efficiency, automate processes, and generate insights across industries. From revolutionizing healthcare with faster diagnostics to optimizing business operations with intelligent automation, AI is fundamentally changing how we work and live. As it continues to evolve, its potential to drive innovation and solve complex challenges will only expand. What are the pros and cons of AI? The pros of AI include enhanced efficiency, task automation, and better innovation. Yet, AI also raises some concerns like job displacement, ethical biases, and data privacy risks. So, as AI evolves, it’ll be important to balance its benefits with responsible use and regulation. How can AI help the world? AI is already making a global impact by tackling some of humanity’s biggest challenges, from predicting and mitigating climate change effects to improving disease detection and treatment in healthcare. It enhances disaster response efforts, streamlines logistics to reduce waste, and strengthens cybersecurity by detecting threats in real time. As AI technology advances, it will continue to unlock solutions that drive progress and improve quality of life worldwide. How does AI benefit everyday life? AI plays a bigger role in daily life than many people realize, powering everything from voice assistants and personalized recommendations to fraud detection and smart home automation. It simplifies tasks like route planning, manages schedules through digital assistants, and even improves online shopping experiences with smarter search results. Whether directly or behind the scenes, AI is making life more efficient, convenient, and connected. Need additional student resources? Already an online student? UC Online has additional tips and tricks to ensure you are on the path to success. Check out our Student Resources section for what you need to maximize your learning. Learn More Helping You Build a Better Business Through Continuing Education Employee recruitment and retention is crucial for the growth and profitability of an organization and should be a high priority for every business. At the University of Cincinnati Online, we want to help develop and retain your employees through our Business Partnership offering. Learn More Related Posts 7 Benefits of Artificial Intelligence (AI) for Business Blog 7 Benefits of Artificial Intelligence (AI) for Business From generative AI-powered chatbots to forecasting tools that use machine learning, artificial intelligence is quickly becoming an integral part of business operations. AI tools can take over time-consuming tasks and automate a… Read More Share Share on Facebook Follow us on LinkedIn Share on Pinterest Share via Email What Is Artificial Intelligence (AI)? Definition, Uses, and More Blog What Is Artificial Intelligence (AI)? Definition, Uses, and More Once reserved for the realms of science fiction, artificial intelligence (AI) is now a very real, emerging technology, with a vast array of applications and benefits. From generating vast quantities of content… Read More Share Share on Facebook Follow us on LinkedIn Share on Pinterest Share via Email Sign up for updates from UC Online Name * First Last Email * Name This field is for validation purposes and should be left unchanged. Submit Ready to get started? We offer over 130 degrees from undergraduate to doctoral programs . Connect with an Advisor Areas of Study Athletics Behavior Analysis Business Communication Criminal Justice Education Engineering Geographic Sciences Health Care Hospitality Human Services Information Systems Information Technology Instructional Design and Technology Interdisciplinary Studies Law Leadership Nursing Organizational Leadership Pharmacy Practicing Healthcare Getting Started Degrees & Programs Admissions Military Tuition and Financial Aid Contact Us Follow Us Facebook profile LinkedIn profile YouTube profile Instagram profile Pinterest profile uc.edu > This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Notice of Non-Discrimination Privacy Policy Clery and HEOA Notice eAccessibility Concerns © 2025 University of Cincinnati Online Copyright Information
====================================================================================================
Artificial Intelligence | Pros, Cons, Debate, Arguments, Computer Science, & Technology | Britannica Search Britannica Click here to search Search Britannica Click here to search SUBSCRIBE SUBSCRIBE Login https://premium.britannica.com/premium-membership/?utm_source=premium&utm_medium=nav-login-box&utm_campaign=evergreen SUBSCRIBE Home History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Games & Quizzes Videos On This Day One Good Fact Dictionary New Articles History & Society Lifestyles & Social Issues Philosophy & Religion Politics, Law & Government World History Science & Tech Health & Medicine Science Technology Biographies Browse Biographies Animals & Nature Birds, Reptiles & Other Vertebrates Bugs, Mollusks & Other Invertebrates Environment Fossils & Geologic Time Mammals Plants Geography & Travel Geography & Travel Arts & Culture Entertainment & Pop Culture Literature Sports & Recreation Visual Arts Image Galleries Podcasts Summaries Top Questions Britannica Kids Ask the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Videos Artificial Intelligence (AI) Table of Contents Introduction Pros and Cons at a Glance Pros Pro 1: AI can make everyday life more enjoyable and convenient, while improving our health and standard of living. Pro 2: AI makes work easier for students and professionals alike. Pro 3: AI helps marginalized groups by offering accessibility for people with disabilities. Pro 4: Artificial intelligence can improve workplace safety. Pro 5: AI can function as a reliable research partner. Pro Quotes Cons Con 1: AI will harm the standard of living for many people by causing mass unemployment. Con 2: AI undermines critical thinking skills for students and adults alike. Con 3: AI hurts racial minorities by repeating and exacerbating racism. Con 4: Artificial intelligence poses dangerous privacy risks. Con 5: AI can spread politicized, even dangerous misinformation. Con Quotes Historical Timeline B.C.E. Approximately 600 B.C.E.: Greek God Hephæstus Creates Artificial Beings 1950 - 1999 1950 - Alan Turning Creates the Turing Test 1956 - John McCarthy Coins the Term “Artificial Intelligence” 1955-1956 - Logic Theorist Program Created 1958 - Perceptron Invented 1959 - Artificial Intelligence Laboratory Founded at MIT 1960 - John McCarthy Creates LISP Computer Programming Language 1964 - 1966 - Joseph Weizenbaum Creates ELIZA 1966 - John McCarthy Stages Computer Chess Games 1968 - Alexey Ivakhnenkko Proposes New Approach to AI Progamming 1972 - Psychiatrist Kenneth Colby Develops Parry Chatbot October 1981 - 1983 - Chatbot Racter Publishes Short Story and Novel 1995 - A.L.I.C.E. Chatbot Allows Developer Input 1995 - Microsoft Launches Bob February 1996 - May 1997 - IBM’s Computer Deep Blue Faces Chess Master Garry Kasparov 1997 - Microsoft Launches Clippy 1997 - Jabberwacky Launched for Entertainment 1998 - Kismet Developed at MIT 2000 - 2019 2001 - Elbot Praised for Humor and Snark 2001 - SmarterChild Released for Use on AOL Instant Messenger (AIM) and MSN Messenger June 4, 2001 - Radiohead Released GooglyMinotaur Chatbot January 13, 2011 - February 16, 2011 - IBM’s Watson Wins Jeopordy! October 4, 2011 - Siri Added to iPhone 4S May 2014 - Microsoft Launches XiaoIce in China June 18, 2014 - Eugene Goostman Passes Turing Test April 2, 2014 - Cortana Debuts November 2014 - Alexa Debuts on Amazon Echo July 1, 2015 - Google Photos AI Uses Racist Tags December 11, 2015 - OpenAI Launches March 23, 2016 - Microsoft Tay Shut Down within 16 Hours of Launch 2017 - 2019 - BBC Produces AI Interactive Storytelling Project 2018 - Microsoft Publishes Book on the Future of AI August 2018 - Schools Increasingly Track Students with AI July 22, 2019 - Microsoft Partners with OpenAI 2020 - 2023 May 2020 - Thomson Reuters Sues ROSS Intelligence November 30, 2022 - ChatGPT Launched by OpenAI November 3, 2022 - Class Action Lawsuit Filed against GitHub, Microsoft and OpenAI January 13, 2023 - Visual Artists Sue Stability AI July 18, 2023 - Open AI Partners with American Journalism Project February 3, 2023 - Getty Images Sues Stability AI March 22, 2023 - Tech Giants Call for Six-Month Pause May 8, 2023 - Brookings Institute Notes Political Bias in AI June - September 2023 - Three Separate Lawsuits Filed against OpenAI May 30, 2023 - Wellness Chatbot Taken Offline After Weight Loss Focus June 22, 2023 - OpenAI CEO Testifies Before Senate July 7, 2023 - Authors Sue Meta July 11, 2023 - Authors and Other Creatives Sue Google AI August 12, 2023 - AI Creates Deadly Recipes September 12, 2023 - Coke Releases Limited Edition Drink Co-created with AI September 19, 2023 - January 5, 2024 - Authors’s Groups Sue OpenAI October 17, 2023 - Mike Huckabee and Others Sue Bloomberg Media October 18, 2023 - Music Publishers Sue Anthropic October 30, 2023 - Biden Establishes Standards for AI Safety and Security December 2, 2023 - McDonald’s Forms AI Partnership with Google Cloud December 27, 2023 - June 27, 2024 - Newspapers Sue Microsoft and OpenAI 2024 January 24, 2024 - Pope Francis Warns Against AI February 8, 2024 - FCC Outlaws Use of AI Voices in RoboCalls February 14, 2024 - Study Finds Carbon Emissions Are Higher for Human Writers and Illustrators than for AI February 21, 2024 - Google’s Gemini AI Over-corrects Racial Bias February 28, 2024 - Raw Story Media and AlterNet Sue OpenAI February 28, 2024 - The Intercept Media Sues OpenAI and Microsoft March 8 - May 2, 2024 - Authors Sue NVIDIA March 13 - October 8, 2024 - OpenAI Expands News Media and Content Provider Partnerships March 12, 2024 - Google Limits Election-Related Questions July 2, 2024 - Report: Ukraine Uses AI-powered Drones in War with Russia June 10, 2024 - OpenAI Partners with Apple July 10, 2024 - Open AI Partners with Los Alamos National Laboratory August 14, 2024 - AI Allows Man with ALS to Speak September 4, 2024 - Man Arrested for Fraud, Accused of Using AI to Create Fake Bands October 2024 - Mother Sues Character.AI. Over Child’s Death by Suicide October 2024 - AI Companies Look to Nuclear Power October 24, 2024 - Biden Signs National Security Memo with AI “Guardrails” October 26, 2024 - AI Mortality Calculator Introduced October 28, 2024 - AI Beats Human Doctors in Diagnosing Patients November 4, 2024 - Meta to Allow U.S. Military Use of AI Models November 14, 2024 - Studies Find Humans Prefer AI-generated Poetry November 14, 2024 - “Daisy” Introduced to Scramble “Granny Scam Artists” in United Kingdom November 19, 2024 - HarperCollins Will Allow Use of Books for AI Training November 20, 2024 - AI Coca-Cola Ads Slammed Online as Not “the Real Thing” November 29, 2024 - Canadian News Outlets Sue OpenAI December 4, 2024 - Google Releases AI Weather Forecast Bot December 4, 2024 - UCLA Announces AI Comparative Literature Class December 9, 2024 - Parents File Suit Against Character.AI for Alleged Abuse December 12, 2024 - Klarna Chief Executive Claims AI Can Replace Humans at Work 2025 January 3, 2025 - Reports of Religious Leaders Experimenting with AI January 7, 2025 - Representative Schweikert Introduces Bill to Allow AI to Write Prescriptions January 9, 2025 - 41 Percent of Surveyed Companies Say They Will Downsize and Use AI January 13, 2025 - Biden Administration Issues AI Rules January 13, 2025 - Washington Post Investigation Finds Misuse of AI by Police January 15, 2025 - Gallup Poll Finds Americans Unknowingly Use AI January 15 - February, 2025 - Open AI Expands Media Partnerships January 16, 2025 - Apple to Disable AI News Summaries January 20, 2025 - Trump Revokes Biden AI Executive Order January 21, 2025 - Stargate Announced by Trump January 22, 2025 - AI Failed to Detect Gun Brought to School and Used in Shooting January 23, 2025 - SafeRBot Released in Conjuction with Urbana Police Department January 23, 2025 - “Humanity’s Last Exam” Featured in New York Times January 27, 2025 - DeepSeek Upends AI World January 30, 2025 - OpenAI Partners with U.S. National Laboratories February 2, 2025 - Open AI Releases Deep Research February 10, 2025 - Nonsense Phrases Mark AI-generated Scientific Papers February 11, 2015 - Thomson Reuters Wins AI Copyright Case February 21, 2025 - OpenAI Reports Evidence of A.I.-Powered Chinese Surveillance Tool February 24, 2025 - American Psychological Association (APA) Warns Against AI “Therapists” February 25, 2025 - AI Video of Trump and Musk Broadcast at HUD March 4, 2025 - OpenAI Announces Partnerships with 15 Research Institutions March 10, 2025 - Lila Sciences Goes Public March 10, 2025 - Experts Recommend Policy Update for Voice Recognition in Courtrooms March 12, 2025 - Sam Altman Unveils AI Model That Is “Good at Creative Writing” March 2025 - Yale Law School Scholar Suspended After AI-news Site Reports Terrorist Link March 20, 2025 - AI Saves Man’s Life According to New York Times Report March 23, 2025 - Author Richard Osman Encourages Authors to “Have a Good Go” at Meta for Copyright Infringement Assessment Quiz 1-minute Survey Discussion Questions Take Action Sources References & Edit History Related Topics Images Contents ProCon Artificial intelligence Is artificial intelligence good for society? (more) Artificial Intelligence (AI) Is Artificial Intelligence Good for Society? Ask the Chatbot a Question More Actions Print print Print Please select which sections you would like to print: Table Of Contents Cite verified Cite While every effort has been made to follow citation style rules, there may be some discrepancies. Please refer to the appropriate style manual or other sources if you have any questions. Select Citation Style MLA APA Chicago Manual of Style Copy Citation Share Share Share to social media Facebook X URL https://www.britannica.com/procon/artificial-intelligence-AI-debate Feedback Feedback Corrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login). Feedback Type Select a type (Required) Factual Correction Spelling/Grammar Correction Link Correction Additional Information Other Your Feedback Submit Feedback Thank you for your feedback Our editors will review what you’ve submitted and determine whether to revise the article. External Websites Ask the Chatbot a Question Written and fact-checked by The Editors of ProCon ProCon's editors write and verify new content and update existing content. ProCon presents the pro and con arguments to debatable issues in a straightforward, nonpartisan, freely accessible way. The Editors of ProCon Last Updated: Jun 6, 2025 • Article History Table of Contents Table of Contents Ask the Chatbot Artificial intelligence (AI) is the use of “ computers and machines to mimic the problem-solving and decision-making capabilities of the human mind,” according to IBM . [1] The idea of AI dates back at least 2,700 years. As Adrienne Mayor, research scholar, folklorist, and science historian at Stanford University , explains: “Our ability to imagine artificial intelligence goes back to ancient times. Long before technological advances made self-moving devices possible, ideas about creating artificial life and robots were explored in ancient myths.” [2] Mayor notes that the myths about Hephaestus , the Greek god of invention and blacksmithing, included precursors to AI. For example, Hephaestus created the giant bronze man Talos, which had a mysterious life force from the gods called ichor . Hephaestus also created Pandora and her infamous and powerful jar/box, as well as a set of automated servants made of gold that were given the knowledge of the gods. Mayor concludes, “Not one of those myths has a good ending once the artificial beings are sent to Earth. It’s almost as if the myths say that it’s great to have these artificial things up in heaven used by the gods. But once they interact with humans, we get chaos and destruction.” [2] The modern notion of AI largely began when Alan Turing , who contributed to breaking the Nazis’ Enigma code during World War II , created the “ Turing test ” to determine if a computer is capable of “thinking.” The value and legitimacy of the test have long been debated. [1] [3] [4] The “Father of Artificial Intelligence,” John McCarthy , coined the term “artificial intelligence” as “the science and engineering of making intelligent machines.” He would go on to create the computer programming language LISP (which is still used in AI), host computer chess games against human Russian opponents, and develop the first computer with “hand-eye” capability, all important building blocks for AI. [1] [5] [6] [7] AI technology continued to grow at a rapid pace during the 1950s. And, as computers became cheaper in the 1960s and ’70s, AI programs flourished, and U.S. government agencies including the Defense Advanced Research Projects Agency (DARPA) began to fund AI-related research. But computers were still too weak to manage the language tasks researchers asked of them. Another influx of funding in the 1980s and early ’90s furthered the research, including the invention of expert systems . But progress again waned with another drop in government funding. [10] More recently, advances in computer storage limits and speeds have opened new avenues for AI research and implementation, aiding scientific research and forging new paths in medicine for patient diagnosis, robotic surgery, and drug development. [1] [10] [11] [12] Now, artificial intelligence is used for a variety of everyday implementations including facial recognition software, online shopping algorithms, search engines, digital assistants like Siri and Alexa , translation services, automated safety functions on cars, cybersecurity, airport body scanning security, poker playing strategy, and fighting disinformation on social media . [13] [58] For more on the history of AI, see ProCon’s Historical Timeline . Pros and Cons at a Glance PROS CONS Pro 1: AI can make everyday life more enjoyable and convenient, while improving our health and standard of living. Read More. Con 1: AI will harm the standard of living for many people by causing mass unemployment. Read More. Pro 2: AI makes work easier for students and professionals alike. Read More. Con 2: AI undermines critical thinking skills for students and adults alike. Read More. Pro 3: AI helps marginalized groups by offering accessibility for people with disabilities. Read More. Con 3: AI hurts racial minorities by repeating and exacerbating racism. Read More. Pro 4: Artificial intelligence can improve workplace safety. Read More. Con 4: Artificial intelligence poses dangerous privacy risks. Read More. Pro 5: AI can function as a reliable research partner. Read More. Con 5: AI can spread politicized, even dangerous misinformation. Read More. Pro Arguments (Go to Con Arguments) Pro 1: AI can make everyday life more enjoyable and convenient, while improving our health and standard of living. Why sit in a traffic jam when a map app can navigate you around the car accident? Why fumble with shopping bags searching for your keys in the dark when a preset location-based command can have your doorway illuminated as you approach your now unlocked door? [23] Why scroll through hundreds of possible TV shows when the streaming app already knows what genres you like? Why forget eggs at the grocery store when a digital assistant can take an inventory of your refrigerator and add them to your grocery list and have them delivered to your home? All of these marvels are assisted by AI technology. [23] AI-enabled fitness apps boomed during the COVID-19 pandemic when gyms were closed, increasing the number of AI options for at-home workouts. Now, you can not only set a daily steps goal with encouragement reminders on your smart watch, but you can ride virtually through the countryside on a Peloton bike from your garage or have a personal trainer on your living room TV. For more specialized fitness, AI wearables can monitor yoga poses or golf and baseball swings. [24] [25] AI can even enhance your doctor’s appointments and medical procedures. It can alert medical caregivers to patterns in your health data as compared to a vast library of medical data, while also doing the paperwork tied to medical appointments so doctors have more time to focus on their patients, resulting in more personalized care. AI can even help surgeons be quicker, more accurate, and less invasive in their operations. [26] Smart speakers including Amazon’s Echo can use AI to soothe babies to sleep and monitor their breathing. Using AI, speakers can also detect regular and irregular heartbeats, as well as heart attacks and congestive heart failure. [27] [28] [29] AI is even beginning to excel at creative writing, producing fiction and poetry that some readers enjoy. Some observers predict that TV and film scripts will also soon benefit from the compositional powers of AI. Pro 2: AI makes work easier for students and professionals alike. Much like the calculator did not signal the end of students’ grasp of mathematics, typing did not eliminate handwriting, and Google did not herald the end of research skills, AI does not signal the end of reading and writing or of education in general. [78] [79] Elementary school teacher Shannon Morris explains that AI tools like “ChatGPT can help students by providing real-time answers to their questions, engaging them in personalized conversations, and providing customized content based on their interests. It can also offer personalized learning resources, videos, articles, and interactive activities. This resource can even provide personalized recommendations for studying, help with research, provide context-specific answers, and offer educational games.” She also notes that teachers’ more daunting tasks like grading and making vocabulary lists can be streamlined with AI tools. [79] For adults AI can similarly make work easier and more efficient, rather than signaling the rise of the robot employee. Pesky, time-consuming tasks like scheduling and managing meetings, finding important emails amongst the spam, prioritizing tasks for the day, and creating and posting social media content can be delegated to AI, freeing up time for more important and rewarding work. The technology can also help with brainstorming, understanding difficult concepts, finding errors in code, and learning languages via conversation, making daunting tasks more manageable. [80] AI is a tool that, if used responsibly, can enhance both learning and work for everyone. Carri Spector of the Stanford Graduate School of Education says, “I think of AI literacy as being akin to driver’s ed: We’ve got a powerful tool that can be a great asset, but it can also be dangerous. We want students to learn how to use it responsibly.” [81] Pro 3: AI helps marginalized groups by offering accessibility for people with disabilities. Artificial intelligence is commonly integrated into smartphones and other household devices. Virtual assistants, including Siri, Alexa, and Cortana, can perform innumerable tasks from making a phone call to navigating the internet. People who are deaf and hearing impaired can access transcripts of voicemail or other audio, for example. [20] Other virtual assistants can transcribe conversations as they happen, allowing for more comprehension and participation by those who have impairments that affect their communication. Using voice commands with virtual assistants can help people with mobility disabilities who may have difficulty navigating small buttons or screens or turning on a lamp. [20] Apps enabled by AI on smartphones and other devices, including VoiceOver and TalkBack, can read messages, describe app icons or images, and give information such as battery levels for visually impaired people. Other apps, such as Voiceitt, can transcribe and standardize the voices of people with speech impediments. [20] Wheelmap provides users with information about wheelchair accessibility, and Evelity offers indoor navigation tools that are customized to the user’s needs, providing audio or text instructions and routes for wheelchair accessibility. [20] Other AI implementations, such as smart thermostats, smart lighting, and smart plugs, can be automated to work on a schedule to aid people with mobility or cognitive disabilities to lead more independent lives. [21] More advanced AI projects can combine with robotics to help physically disabled people. HOOBOX Robotics, for example, uses facial recognition software to allow a wheelchair user to move their wheelchair with facial expressions, making movement easier for seniors and those with ALS or quadriparesis . [22] Pro 4: Artificial intelligence can improve workplace safety. AI doesn’t get stressed, tired, or sick, three major causes of human accidents in the workplace. AI robots can collaborate with or replace humans for especially dangerous tasks. For example 50 percent of construction companies that used drones to inspect roofs and other risky tasks saw improvements in safety. [14] [15] Artificial intelligence can also help humans be safer. For instance, AI can ensure employees are up to date on training by tracking and automatically scheduling safety or other training. AI can also check and offer corrections for ergonomics to prevent repetitive stress injuries or worse. [16] An AI program called AI-SAFE (Automated Intelligent System for Assuring Safe Working Environments) aims to automate the workplace personal protective equipment (PPE) check, eliminating human errors that could cause accidents in the workplace. As more people wear PPE to prevent the spread of COVID-19 and other viruses, this sort of AI could protect against large-scale outbreaks. [17] [18] [19] In India, AI was used during the coronavirus pandemic to reopen factories safely by providing camera, cell phone, and smart wearable device-based technology to ensure social distancing, take employee temperatures at regular intervals, and perform contact tracing if anyone tested positive for the virus. [18] [19] AI can also perform more sensitive tasks in the workplace such as scanning work emails for improper behavior and types of harassment. [15] Pro 5: AI can function as a reliable research partner. While AI can be wrong, limited, biased, or misleading, so can every other information source including textbooks, the Internet at large, and people. Whether you’re looking for a new restaurant, writing a college research paper, or trying to cure cancer, the job of any researcher is to distinguish between good and bad information. AI is simply a tool. For example, ChatGPT and Google AI, which now offer citations, are now as reliable as a search engine or a library card catalog in that researchers should go to the primary sources and evaluate the information for themselves. [103] Leo S. Lo, dean of the College of University Libraries and Learning Sciences at the University of New Mexico, who calls AI "my new favorite research partner," noted, a "limitation of ChatGPT is that it cannot replace critical thinking. Although it can help researchers generate ideas, it cannot replace their ability to critically think about research. In addition, it may not possess the same depth and nuance as a human researcher." As such, AI is simply another research tool. [104] As a tool, a 2024 study found AI was helpful for academic research in several areas: "idea generation, content structuring, literature synthesis, data management, editing, and ethical compliance." Note that the list does not include the actual research or writing the paper. Instead, AI is a brainstorming tool that has the entire Internet at it’s disposal, which also lends itself to "literature synthesis" (collating information from multiple sources). AI can also be used to put data in nicely formatted tables and point out where a comma is missing. All of that help leaves researchers time and effort to focus on the actual research component. [105] The study noted that AI can be especially helpful when researchers need information from another field of study: "AI holds immense potential to revolutionise and streamline interdisciplinary research, acting as a bridge between diverse fields. Its advanced data analysis capabilities enable it to uncover patterns and correlations that might be invisible to human researchers, thereby fostering new insights and theories. AI can process and synthesize vast amounts of information from different disciplines, helping researchers in one field to utilize findings from another, leading to innovative solutions." Again, the AI is "helping" researchers, not running wild in a lab by itself. [105] When asked if it is a good research partner, ChatGPT offers, "Absolutely! I can help you find reliable sources, summarize information, organize your thoughts, and even suggest angles you might not have considered." Google’s AI also promises to "streamline" the peer review process, especially "in the initial stages [by] automating tasks like identifying potential reviewers and summarizing research findings, potentially speeding up the review process." [106] [107] As a research partner, AI is helping in myriad ways. It’s speeding up drug discovery, analyzing huge quantities of particle accelerator data, automating repetitive tasks such as protein folding, making weather predictions, assessing bee behavior patterns, reviewing audio for bird and electric wire collisions, using game theory to catch animal poachers, evaluating social media posts to locate and track animals on the endangered list, predicting regions of poverty, and even identifying areas of city water pipes that need upgrades. In other words, AI is an enthusiastic and super-powered intern—ready to do the both grunt work as well as high-level thinking. [108] [109] [110] Pro Quotes Co-founder of LinkedIn Reid Hoffman stated: I truly believe that by giving billions of people access to A.I. tools they can use in whatever ways they choose, we can create a world where A.I. augments and amplifies human creativity and labor instead of simply replacing it.... Tech skeptics have long used the adjective “Orwellian” to cast everything from a video recommendation feature to turn-by-turn navigation apps as threats to individual autonomy, but the history of technological innovation in the 21st century tells a different story. In “1984,” George Orwell’s classic novel of state oppression, powerful telescreens enable a totalitarian regime to rule over dispossessed proles with unchecked omnipotence. But today we live in a world where individual identity is the coin of the realm — where plumbers and presidents alike aspire to be social media influencers and cultural power flows increasingly to self-made operators.… I believe A.I. is on a path not just to continue this trend of individual empowerment but also to dramatically enhance it. [97] David Brooks , opinion columnist for The New York Times , stated: I don’t think A.I. is going to be as powerful as many of its evangelists think it will be. I don’t think A.I. is ever going to be able to replace us — ultimately I think it will simply be a useful tool. In fact, I think instead of replacing us, A.I. will complement us. In fact, it may make us free to be more human. Many fears about A.I. are based on an underestimation of the human mind. Some people seem to believe that the mind is like a computer. It’s all just information processing, algorithms all the way down, so of course machines are going to eventually overtake us. This is an impoverished view of who we humans are.… The brain is its own universe. Sometimes I hear tech people saying they are building machines that think like people. Then I report this ambition to neuroscientists and their response is: That would be a neat trick, because we don’t know how people think. [101] Medha Bankhwal, Michael Chui, Ankit Bisht, Roger Roberts, and Ashley van Heteren, all of consulting firm McKinsey & Company , stated: By collaborating to find ways to put AI to work at scale for social good, mission-driven organizations, governments, foundations, universities, ecosystems of developers, and businesses can help solve some of the world’s most challenging and intractable problems. They can help thwart human trafficking, ensure girls and children all over the world receive the education they deserve, protect forests from illegal deforestation, support the health and safety of pregnant women and newborns, and so much more. If these things aren’t worth fighting for, what is? [102] Con Arguments (Go to Pro Arguments) Con 1: AI will harm the standard of living for many people by causing mass unemployment. AI robots and other software and hardware are becoming less expensive and need none of the benefits and services required by human workers, such as sick days, lunch hours, bathroom breaks, health insurance, pay raises, promotions, and performance reviews, which spells trouble for workers and society at large. [51] Some 48 percent of experts believed AI will replace a large number of blue- and even white-collar jobs (including Hollywood and TV script writing), creating greater income inequality, increased unemployment, and a breakdown of the social order. [35] The axiom “everything that can be automated, will be automated” is no longer science fiction. Self-checkout kiosks in stores like CVS, Target, and Walmart use AI-assisted video and scanners to prevent theft, alert staff to suspicious transactions, predict shopping trends, and mitigate sticking points at checkout. These AI-enabled machines have displaced human cashiers. About 11,000 retail jobs were lost in 2019, largely due to self-checkout and other technologies. In 2020, during the COVID-19 pandemic, a self-checkout manufacturer shipped 25 percent more units globally, reflecting the more than 70 percent of American grocery shoppers who preferred self- or touchless checkouts. [35] [52] [53] [54] [55] An October 2020 World Economic Forum report found 43 percent of businesses surveyed planned to reduce workforces in favor of automation. Many businesses, especially fast-food restaurants, retail shops, and hotels, automated jobs during the COVID-19 pandemic. [35] Income inequality was exacerbated over the last four decades as 50–70 percent of changes in American paychecks were caused by wage decreases for workers whose industries experienced rapid automation, including AI technologies. [56] [57] Con 2: AI undermines critical thinking skills for students and adults alike. The idea that the Internet is making us stupid is legitimate, and AI is like the Internet on steroids. With AI bots doing everything from research to writing papers, from basic math to logic problems, from generating hypotheses to performing science experiments, from editing photos to creating “original” art, students of all ages will be tempted (and many will succumb to the temptation) to use AI for their school work, undermining education goals. [82] [83] [84] [85] [86] “The academic struggle for students is what pushes them to become better writers, thinkers and doers. Like most positive outcomes in life, the important part is the journey. Soon, getting college degrees without AI assistance will be as foreign to the next generation as payphones and Blockbuster [are to the current generation], and they will suffer for it,” says Mark Massaro, professor of English at Florida SouthWestern State College. [83] A June 2023 study found that increased use of AI correlates with increased student laziness because of a loss of human decision-making. Similarly, an October 2023 study found increased laziness and carelessness as well as a decline in work quality when humans worked alongside AI robots. [87] [88] [89] The implications of allowing AI to complete tasks are enormous. We will see declines in work quality and human motivation as well as the rise of dangerous situations from deadly workplace accidents to George Orwell’s dreaded “ groupthink .” And, when humans have become too lazy to program the technology, we’ll see lazy AI, too. [90] “An overreliance on technology will further sever the American public from determining truth from lies, information from propaganda, a critical skill that is slowly becoming a lost art, leaving the population willfully ignorant and intellectually lazy,” explains Massaro. [73] [83] Con 3: AI hurts racial minorities by repeating and exacerbating racism. Facial recognition has been found to be racially biased, easily recognizing the faces of white men while wrongly identifying Black women 35 percent of the time. One study of Amazon’s Rekognition AI program falsely matched 28 members of the U.S. Congress with mugshots from a criminal database, with 40 percent of the errors being people of color. [22] [36] [43] [44] AI has also been disproportionately employed against Black and Brown communities, with more federal and local police surveillance cameras in neighborhoods of color, and more social media surveillance of Black Lives Matter and other Black activists. The same technologies are used for housing and employment decisions and TSA airport screenings. Some cities, including Boston and San Francisco, have banned police use of facial recognition for these reasons. [36] [43] One particular AI software tasked with predicting recidivism risk for U.S. courts—the Correctional Offender Management Profiling for Alternative Sanctions (Compas)—–was found to falsely label Black defendants as high risk at twice the rate of white defenders, and to falsely label white defendants as low risk more often. AI is also incapable of distinguishing between when the N-word is being used as a slur and when it’s being used culturally by a Black person. [45] [46] In China, facial recognition AI has been used to track Uyghurs, a largely Muslim minority. The U.S. and other governments have accused the Chinese government of genocide and forced labor in Xinjiang, where a large population of Uyghurs live. AI algorithms have also been found to show a “persistent anti-Muslim bias,” by associating violence with the word “Muslim” at a higher rate than with words describing people of other religions including Christians, Jews, Sikhs, and Buddhists. [47] [48] [50] Con 4: Artificial intelligence poses dangerous privacy risks. Facial recognition technology can be used for passive, warrantless surveillance without the knowledge of the person being watched. In Russia, facial recognition was used to monitor and arrest protesters who supported jailed opposition politician Aleksey Navalny , who was found dead in prison in 2024. Russians fear a new facial recognition payment system for Moscow’s metro will increase these sorts of arrests. [36] [37] [38] Ring, the AI doorbell and camera company owned by Amazon, has partnered with more than 400 police departments, allowing the police to request footage from users’ doorbell cameras. While users were allowed to deny access to any footage, privacy experts feared the close relationship between Ring and the police could override customer privacy, especially when the cameras frequently record activity on others’ property. The policy ended in 2024, but experts say other companies allow similar invasions. [39] [91] AI also follows you on your weekly errands. Target used an algorithm to determine which shoppers were pregnant and sent them baby- and pregnancy-specific coupons in the mail, infringing on the medical privacy of those who may be pregnant, as well as those whose shopping patterns may just imitate pregnant people. [40] [41] Moreover, artificial intelligence can be a godsend to crooks. In 2020 a group of 17 criminals defrauded $35 million from a bank in the United Arab Emirates using AI “deep voice” technology to impersonate an employee authorized to make money transfers. In 2019, thieves attempted to steal $240,000 using the same AI technology to impersonate the CEO of an energy firm in the United Kingdom. [42] Con 5: AI can spread politicized, even dangerous misinformation. “The ability to create websites that host fake news or fake information has been around since the inception of the Internet, and they pre-date the AI revolution,” according to engineering and machine learning expert Walid Saad. “With the advent of AI, it became easier to sift through large amounts of information and create ‘believable’ stories and articles. Specifically, LLMs [large language models] made it more accessible for bad actors to generate what appears to be accurate information. This AI-assisted refinement of how the information is presented makes such fake sites more dangerous." [111] A 2024 study noted highlights of the AI misinformation problem: "With the advent of generative artificial intelligence (AI), the internet has become a breeding ground for fake news and misinformation. The phenomenon of fake news and misinformation has had significant impacts across various sectors, including the world of finance and politics. A notable example occurred in mid-January 2023, when the spread of a false report stating that the SEC (U.S. Securities and Exchange Commission) had approved a spot-listed ETF (exchange-traded fund) caused volatility in Bitcoin prices. In May 2023, an instance of generative AI being used to create a fictitious image of a building near the Pentagon in Washington D.C. engulfed in black flames, leading to turmoil in the U.S. stock market. Additionally, fabricated images of a former U.S. president being arrested and a fashionably dressed Pope in a white puffer coat were examples of fake news created using AI-generated fake photographs. [112] Google’s AI chatbot Gemini even generated historical inaccuracies by inserting people of color into historical events they never participated in—including Black Nazi soldiers and Black Popes—further damaging historical literacy. [73] AI can also be politicized by both AI creators and AI users. A May 2023 study by the Brookings Institute found that the AI knowledge source routinely supported left-leaning positions on hot button issues including abortion and gun control, while AI robocalls were banned by the FCC for imitating President Joe Biden’s voice during the 2024 election. In 2025, political operatives broadcast a lewd AI-generated video of President Trump and Elon Musk on all Department of Housing and Urban Development (HUD) headquarter monitors. [75] [76] [77] [92] [113] Equally troubling, as exemplified by robocalls and deep-fake videos, AI can be virtually indistinguishable from humans. Impressionable people can be swayed into harmful actions including but not limited to eating disorders, suicide, and assassination. For example, a British man was arrested in a plot to kill Queen Elizabeth in 2021 after a chatbot encouraged him to do so, saying his assassination plan was "very wise." AI bots have also created and publicized potentially deadly recipes and recommended harmful solutions to losing weight. [114] [115] [116] Marjorie Wallace, founder and chief executive of mental health charity SANE, says "the rapid rise of artificial intelligence has a new and concerning impact on people who suffer from depression, delusions, loneliness and other mental health conditions." As the technology becomes more and more indistinguishable from reality, we will all need to be vigilant about and protected from the dangerous uses of AI. [116]
====================================================================================================
Artificial Intelligence Courses and Programs | Stanford Online We're sorry but you will need to enable Javascript to access all of the features of this site. Skip to main content Skip to main navigation Stanford Online my stanford connection Explore Topics Engineering Artificial Intelligence Computer Science & Security Leadership & Business Transformation Product Management Energy & Sustainability Data Science Medicine & Health Education Explore All Programs Graduate Education Professional Education Custom & Executive Programs Free Content Free Online Courses Free Content Library Schools & Centers School of Engineering Graduate School of Education Stanford Doerr School of Sustainability School of Humanities & Sciences Graduate School of Business Stanford Law School School of Medicine View All About Us Overview Who We Work With Stanford Credentials Our Community Events Contact Us Get Course Updates Menu Artificial Intelligence AI Courses and Programs AI for Engineers and Technical Professionals AI for Business Professionals AI for Professionals in Healthcare Home Topics Artificial Intelligence Courses and Programs Artificial Intelligence Courses and Programs Welcome to Stanford Online's hub for Artificial Intelligence education. Whether you're a seasoned professional or just beginning your journey, we have options for every level. Dive into the forefront of AI with industry insights, practical skills, and deep academic expertise of this transformative field. AI for Engineers and Technical Professionals These courses and programs provide the foundational and advanced skills needed to accelerate your career in AI. Topics include machine learning, deep generative models, neural networks, and natural language processing and understanding. View Courses & Programs AI for Business Professionals These courses and programs are tailored for leaders, founders, team managers, and product professionals looking to create and implement AI strategies. This portfolio requires little to no technical background and can be completed at your own pace. View Courses & Programs AI for Professionals in Healthcare These courses are designed for medical professionals and those in computer or data science within healthcare. Familiarity with statistics and programming is helpful but not required. Interest or experience in healthcare is recommended. View Courses & Programs Browse All AI Courses and Programs Browse AI Content & Resources Footer menu Stanford Engineering Center for Global & Online Education Site Search Social Media Facebook Twitter YouTube LinkedIn Stanford Home Maps & Directions Search Stanford Emergency Info Terms of Use Privacy Copyright Trademarks Non-Discrimination Accessibility © Copyright Stanford University . Stanford , California 94305 . Explore Topics Engineering Artificial Intelligence Computer Science & Security Leadership & Business Transformation Product Management Energy & Sustainability Data Science Medicine & Health Education Explore All Programs Graduate Education Overview Technical Support Master's Degrees Master’s Application FAQs Master’s Student FAQs Master's Tuition & Fees Grades & Policies HCP 70th Anniversary HCP History Graduate Courses & Certificates Graduate Application FAQs Graduate Student FAQs Graduate Tuition & Fees Grades & Policies Community Standards Review Process Academic Calendar Exams & Homework FAQs Professional Education Overview Enrollment FAQs Grades & Policies Technical Support Tuition, Fees, & Payments Custom & Executive Programs Free Content Free Online Courses Free Content Library Schools & Centers School of Engineering Graduate School of Education Stanford Doerr School of Sustainability School of Humanities & Sciences Graduate School of Business Stanford Law School School of Medicine View All About Us Overview Who We Work With Stanford Credentials Stanford Credentials What is a digital credential? Grades and Units Information Verify your credential Our Community Events Contact Us Get Course Updates Feedback
====================================================================================================
Outline of artificial intelligence - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk Contents move to sidebar hide (Top) 1 AI algorithms and techniques Toggle AI algorithms and techniques subsection 1.1 Search 1.2 Optimization search 1.3 Logic 1.4 Other symbolic knowledge and reasoning tools 1.5 Probabilistic methods for uncertain reasoning 1.6 Classifiers and statistical learning methods 1.7 Artificial neural networks 1.8 Biologically based or embodied 1.9 Cognitive architecture and multi-agent systems 2 Philosophy Toggle Philosophy subsection 2.1 Definition of AI 2.2 Classifying AI 3 Goals and applications Toggle Goals and applications subsection 3.1 General intelligence 3.2 Reasoning and Problem Solving 3.3 Knowledge representation 3.4 Planning 3.5 Learning 3.6 Natural language processing 3.7 Perception 3.8 Robotics 3.9 Control 3.10 Social intelligence 3.11 Game playing 3.12 Creativity, art and entertainment 3.13 Integrated AI systems 3.14 Intelligent personal assistants 3.15 Other applications 4 History Toggle History subsection 4.1 History by subject 5 Future 6 Fiction 7 AI community Toggle AI community subsection 7.1 Open-source AI development tools 7.2 Projects 7.3 Competitions and awards 7.4 Publications 7.5 Organizations 7.6 Companies 7.7 Artificial intelligence researchers and scholars 7.7.1 1930s and 40s (generation 0) 7.7.2 1950s (the founders) 7.7.3 1960s (their students) 7.7.4 1970s 7.7.5 1980s 7.7.6 1990s 7.7.7 2000s on 8 See also 9 References Toggle References subsection 9.1 Bibliography 10 External links Toggle the table of contents Outline of artificial intelligence 4 languages العربية فارسی 한국어 پښتو Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Overview of and topical guide to artificial intelligence Part of a series on Artificial intelligence (AI) Major goals Artificial general intelligence Intelligent agent Recursive self-improvement Planning Computer vision General game playing Knowledge representation Natural language processing Robotics AI safety Approaches Machine learning Symbolic Deep learning Bayesian networks Evolutionary algorithms Hybrid intelligent systems Systems integration Applications Bioinformatics Deepfake Earth sciences Finance Generative AI Art Audio Music Government Healthcare Mental health Industry Translation Military Physics Projects Philosophy Artificial consciousness Chinese room Friendly AI Control problem / Takeover Ethics Existential risk Turing test Uncanny valley History Timeline Progress AI winter AI boom Glossary Glossary v t e The following outline is provided as an overview of and topical guide to artificial intelligence: Artificial intelligence (AI) is intelligence exhibited by machines or software. It is also the name of the scientific field which studies how to create computers and computer software that are capable of intelligent behavior. AI algorithms and techniques [ edit ] Main article: Artificial intelligence § Tools Search [ edit ] Discrete search algorithms [ 1 ] Uninformed search [ 2 ] Brute force search Search tree Breadth-first search Depth-first search State space search Informed search [ 3 ] Best-first search A* search algorithm Heuristics Pruning (algorithm) Adversarial search Minmax algorithm Logic as search [ 4 ] Production system (computer science) , Rule based system Production rule , Inference rule , Horn clause Forward chaining Backward chaining Planning as search [ 5 ] State space search Means–ends analysis Optimization search [ edit ] Optimization (mathematics) algorithms [ 6 ] Hill climbing Simulated annealing Beam search Random optimization Evolutionary computation [ 7 ] [ 8 ] [ 9 ] [ 10 ] Genetic algorithms Gene expression programming Genetic programming Differential evolution Society based learning algorithms. [ 11 ] [ 12 ] Swarm intelligence Particle swarm optimization Ant colony optimization Metaheuristic Logic [ edit ] Logic and automated reasoning [ 13 ] Programming using logic Logic programming See "Logic as search" above. Forms of Logic Propositional logic [ 14 ] First-order logic [ 15 ] First-order logic with equality Constraint satisfaction Fuzzy logic [ 16 ] [ 17 ] Fuzzy set theory Fuzzy systems Combs method Ordered weighted averaging aggregation operator Perceptual Computing – Default reasoning and other solutions to the frame problem and qualification problem [ 18 ] Non-monotonic logic Abductive reasoning [ 19 ] Default logic Circumscription (logic) Closed world assumption Domain specific logics Representing categories and relations [ 20 ] Description logics Semantic networks Inheritance (object-oriented programming) Frame (artificial intelligence) Scripts (artificial intelligence) Representing events and time [ 21 ] Situation calculus Event calculus Fluent calculus Causes and effects [ 22 ] causal calculus Knowledge about knowledge Belief revision [ 23 ] Modal logics [ 23 ] paraconsistent logics Planning using logic [ 24 ] Satplan Learning using logic [ 25 ] Inductive logic programming Explanation based learning Relevance based learning Case based reasoning General logic algorithms Automated theorem proving Other symbolic knowledge and reasoning tools [ edit ] Symbolic representations of knowledge Ontology (information science) Upper ontology Domain ontology Frame (artificial intelligence) Semantic net Conceptual Dependency Theory Unsolved problems in knowledge representation Default reasoning Frame problem Qualification problem Commonsense knowledge [ 26 ] Probabilistic methods for uncertain reasoning [ edit ] Stochastic methods for uncertain reasoning: [ 27 ] Bayesian networks [ 28 ] Bayesian inference algorithm [ 29 ] Bayesian learning and the expectation-maximization algorithm [ 30 ] Bayesian decision theory and Bayesian decision networks [ 31 ] Probabilistic perception and control: Dynamic Bayesian networks [ 32 ] Hidden Markov model [ 33 ] Kalman filters [ 32 ] Fuzzy Logic Decision tools from economics: Decision theory [ 34 ] Decision analysis [ 34 ] Information value theory [ 35 ] Markov decision processes [ 36 ] Dynamic decision networks [ 36 ] Game theory [ 37 ] Mechanism design [ 37 ] Algorithmic information theory Algorithmic probability Classifiers and statistical learning methods [ edit ] Classifier (mathematics) and Statistical classification [ 38 ] Alternating decision tree [ 39 ] Artificial neural network (see below) [ 40 ] K-nearest neighbor algorithm [ 41 ] Kernel methods [ 42 ] Support vector machine [ 42 ] Naive Bayes classifier [ 43 ] Artificial neural networks [ edit ] Artificial neural networks [ 40 ] Network topology feedforward neural networks [ 44 ] Perceptrons Multi-layer perceptrons Radial basis networks Convolutional neural network Recurrent neural networks [ 45 ] Long short-term memory [ 46 ] Hopfield networks [ 47 ] Attractor networks [ 47 ] Deep learning Hybrid neural network Learning algorithms for neural networks Hebbian learning [ 47 ] Backpropagation [ 48 ] GMDH Competitive learning [ 47 ] Supervised backpropagation [ 49 ] Neuroevolution [ 50 ] Restricted Boltzmann machine [ 51 ] Biologically based or embodied [ edit ] Behavior based AI Subsumption architecture Nouvelle AI Developmental robotics [ 52 ] Situated AI Bio-inspired computing Artificial immune systems Embodied cognitive science Embodied cognition Free energy principle Cognitive architecture and multi-agent systems [ edit ] Artificial intelligence systems integration Cognitive architecture LIDA (cognitive architecture) AERA (AI architecture) Agent architecture Control system Hierarchical control system Networked control system Distributed artificial intelligence – Multi-agent system – Hybrid intelligent system Monitoring and Surveillance Agents Blackboard system Philosophy [ edit ] Main articles: Artificial intelligence § Philosophy , and Philosophy of AI Definition of AI [ edit ] Pei Wang's definition of artificial intelligence Dartmouth proposal ("Every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it") Turing test Computing Machinery and Intelligence Intelligent agent and rational agent Action selection AI effect Synthetic intelligence Classifying AI [ edit ] Symbolic vs sub-symbolic AI Symbolic AI Physical symbol system Dreyfus' critique of AI Moravec's paradox Elegant and simple vs. ad-hoc and complex Neat vs. Scruffy Society of Mind (scruffy approach) The Master Algorithm (neat approach) Level of generality and flexibility Artificial general intelligence Narrow AI Level of precision and correctness Soft computing "Hard" computing Level of intelligence Progress in artificial intelligence Superintelligence Level of consciousness , mind and understanding Chinese room Hard problem of consciousness Computationalism Functionalism (philosophy of mind) Robot rights User illusion Artificial consciousness Goals and applications [ edit ] Main articles: Applications of artificial intelligence and Artificial intelligence § Goals General intelligence [ edit ] Artificial general intelligence AI-complete Reasoning and Problem Solving [ edit ] Automated reasoning Mathematics Automated theorem prover Computer-assisted proof – Computer algebra General Problem Solver Expert system – Decision support system – Clinical decision support system – Knowledge representation [ edit ] Knowledge representation Knowledge management Cyc Planning [ edit ] Automated planning and scheduling Strategic planning Sussman anomaly – Learning [ edit ] Machine learning – Constrained Conditional Models – Deep learning – Neural modeling fields – Supervised learning – Weak supervision (semi-supervised learning) – Unsupervised learning – Natural language processing [ edit ] Natural language processing ( outline ) – Chatterbots – Language identification – Large language model – Natural language user interface – Natural language understanding – Machine translation – Statistical semantics – Question answering – Semantic translation – Concept mining – Data mining – Text mining – Process mining – E-mail spam filtering – Information extraction – Named-entity extraction – Coreference resolution – Named-entity recognition – Relationship extraction – Terminology extraction – Perception [ edit ] Machine perception Pattern recognition – Computer Audition – Speech recognition – Speaker recognition – Computer vision ( outline ) – Image processing Intelligent word recognition – Object recognition – Optical mark recognition – Handwriting recognition – Optical character recognition – Automatic number plate recognition – Information extraction – Image retrieval – Automatic image annotation – Facial recognition systems – Silent speech interface – Activity recognition – Percept (artificial intelligence) Robotics [ edit ] Robotics – Behavior-based robotics – Cognitive – Cybernetics – Developmental robotics – Evolutionary robotics – Control [ edit ] Intelligent control Self-management (computer science) – Autonomic Computing – Autonomic Networking – Social intelligence [ edit ] Affective computing Kismet Game playing [ edit ] Game artificial intelligence – Computer game bot – computer replacement for human players. Video game AI – Computer chess – Computer Go – General game playing – General video game playing – Creativity, art and entertainment [ edit ] Artificial creativity Artificial intelligence art Creative computing Generative artificial intelligence Uncanny valley Music and artificial intelligence Computational humor Chatbot Integrated AI systems [ edit ] AIBO – Sony's robot dog. It integrates vision, hearing and motorskills. Asimo (2000 to present) – humanoid robot developed by Honda, capable of walking, running, negotiating through pedestrian traffic, climbing and descending stairs, recognizing speech commands and the faces of specific individuals, among a growing set of capabilities. MIRAGE – A.I. embodied humanoid in an augmented reality environment. Cog – M.I.T. humanoid robot project under the direction of Rodney Brooks . QRIO – Sony's version of a humanoid robot. TOPIO , TOSY's humanoid robot that can play ping-pong with humans. Watson (2011) – computer developed by IBM that played and won the game show Jeopardy! It is now being used to guide nurses in medical procedures. Purpose: Open domain question answering Technologies employed: Natural language processing Information retrieval Knowledge representation Automated reasoning Machine learning Project Debater (2018) – artificially intelligent computer system, designed to make coherent arguments, developed at IBM's lab in Haifa, Israel. Intelligent personal assistants [ edit ] Intelligent personal assistant – Amazon Alexa – Assistant – Braina – Cortana – Google Assistant – Google Now – Mycroft – Siri – Viv – Other applications [ edit ] Artificial life – simulation of natural life through the means of computers, robotics, or biochemistry. Automatic target recognition – Diagnosis (artificial intelligence) – Speech generating device – Vehicle infrastructure integration – Virtual Intelligence – History [ edit ] History of artificial intelligence Progress in artificial intelligence Timeline of artificial intelligence AI effect – as soon as AI successfully solves a problem, the problem is no longer considered by the public to be a part of AI. This phenomenon has occurred in relation to every AI application produced, so far, throughout the history of development of AI. AI winter – a period of disappointment and funding reductions occurring after a wave of high expectations and funding in AI. Such funding cuts occurred in the 1970s, for instance. Moore's law History by subject [ edit ] History of Logic (formal reasoning is an important precursor of AI) History of machine learning ( timeline ) History of machine translation ( timeline ) History of natural language processing History of optical character recognition ( timeline ) Future [ edit ] Artificial general intelligence . An intelligent machine with the versatility to perform any intellectual task. Superintelligence . A machine with a level of intelligence far beyond human intelligence. Chinese room § Strong AI . A machine that has mind , consciousness and understanding . (Also, the philosophical position that any digital computer can have a mind by running the right program.) Technological singularity . The short period of time when an exponentially self-improving computer is able to increase its capabilities to a superintelligent level. Recursive self improvement (aka seed AI) – speculative ability of strong artificial intelligence to reprogram itself to make itself even more intelligent. The more intelligent it got, the more capable it would be of further improving itself, in successively more rapid iterations, potentially resulting in an intelligence explosion leading to the emergence of a superintelligence. Intelligence explosion – through recursive self-improvement and self-replication, the magnitude of intelligent machinery could achieve superintelligence, surpassing human ability to resist it. Singularitarianism Human enhancement – humans may be enhanced, either by the efforts of AI or by merging with it. Transhumanism – philosophy of human transformation Posthumanism – people may survive, but not be recognizable in comparison to present modern-day humans. Cyborgs – Mind uploading – Existential risk from artificial general intelligence Global catastrophic risk § Artificial intelligence AI takeover – point at which humans are no longer the dominant form of intelligence on Earth and machine intelligence is Ethics of AI § Weaponization Artificial intelligence arms race – competition between two or more states to have its military forces equipped with the best "artificial intelligence" (AI). Lethal autonomous weapon Military robot Unmanned combat aerial vehicle Mitigating risks: AI safety AI control problem Friendly AI – hypothetical AI that is designed not to harm humans and to prevent unfriendly AI from being developed Machine ethics Regulation of AI AI box Self-replicating machines – smart computers and robots would be able to make more of themselves, in a geometric progression or via mass production. Or smart programs may be uploaded into hardware existing at the time (because linear architecture of sufficient speeds could be used to emulate massively parallel analog systems such as human brains). Hive mind – Robot swarm – Fiction [ edit ] Artificial intelligence in fiction – Some examples of artificially intelligent entities depicted in science fiction include: AC created by merging 2 AIs in the Sprawl trilogy by William Gibson Agents in the simulated reality known as " The Matrix " in The Matrix franchise Agent Smith , began as an Agent in The Matrix , then became a renegade program of overgrowing power that could make copies of itself like a self-replicating computer virus AM (Allied Mastercomputer), the antagonist of Harlan Ellison ' s short novel I Have No Mouth, and I Must Scream Amusement park robots (with pixilated consciousness) that went homicidal in Westworld and Futureworld Angel F (2007) – Arnold Rimmer – computer-generated sapient hologram, aboard the Red Dwarf deep space ore hauler Ash – android crew member of the Nostromo starship in the movie Alien Ava – humanoid robot in Ex Machina Bishop, android crew member aboard the U.S.S. Sulaco in the movie Aliens C-3PO , protocol droid featured in all the Star Wars movies Chappie in the movie CHAPPiE Cohen and other Emergent AIs in Chris Moriarty 's Spin Series Colossus – fictitious supercomputer that becomes sentient and then takes over the world; from the series of novels by Dennis Feltham Jones , and the movie Colossus: The Forbin Project (1970) Commander Data in Star Trek: The Next Generation Cortana and other "Smart AI" from the Halo series of games Cylons – genocidal robots with resurrection ships that enable the consciousness of any Cylon within an unspecified range to download into a new body aboard the ship upon death. From Battlestar Galactica . Erasmus – baby killer robot that incited the Butlerian Jihad in the Dune franchise HAL 9000 (1968) – paranoid "Heuristically programmed ALgorithmic" computer from 2001: A Space Odyssey , that attempted to kill the crew because it believed they were trying to kill it. Holly – ship's computer with an IQ of 6000 and a sense of humor, aboard the Red Dwarf In Greg Egan 's novel Permutation City the protagonist creates digital copies of himself to conduct experiments that are also related to implications of artificial consciousness on identity Jane in Orson Scott Card 's Speaker for the Dead , Xenocide , Children of the Mind , and Investment Counselor Johnny Five from the movie Short Circuit Joshua from the movie War Games Keymaker , an "exile" sapient program in The Matrix franchise "Machine" – android from the film The Machine , whose owners try to kill her after they witness her conscious thoughts, out of fear that she will design better androids (intelligence explosion) Maschinenmensch (1927) an android is given female form in a plot to bring down the Metropolis (the first film designated to the UNESCO Memory of the World Register ) Mimi, humanoid robot in Real Humans – "Äkta människor" (original title) 2012 Omnius , sentient computer network that controlled the Universe until overthrown by the Butlerian Jihad in the Dune franchise Operating Systems in the movie Her Puppet Master in Ghost in the Shell manga and anime Questor (1974) from a screenplay by Gene Roddenberry and the inspiration for the character of Data R2-D2 , excitable astromech droid featured in all the Star Wars movies Replicants – biorobotic androids from the novel Do Androids Dream of Electric Sheep? and the movie Blade Runner which portray what might happen when artificially conscious robots are modeled very closely upon humans Roboduck , combat robot superhero in the NEW-GEN comic book series from Marvel Comics Robots in Isaac Asimov 's Robot series Robots in The Matrix franchise , especially in The Animatrix Samaritan in the Warner Brothers Television series "Person of Interest"; a sentient AI which is hostile to the main characters and which surveils and controls the actions of government agencies in the belief that humans must be protected from themselves, even by killing off "deviants" Skynet (1984) – fictional, self-aware artificially intelligent computer network in the Terminator franchise that wages total war with the survivors of its nuclear barrage upon the world. "Synths" are a type of android in the video game Fallout 4 . There is a faction in the game known as "the Railroad" which believes that, as conscious beings, synths have their own rights. The institute, the lab that produces the synths, mostly does not believe they are truly conscious and attributes any apparent desires for freedom as a malfunction. TARDIS , time machine and spacecraft of Doctor Who , sometimes portrayed with a mind of its own Terminator (1984) – (also known as the T-800, T-850 or Model 101) refers to a number of fictional cyborg characters from the Terminator franchise . The Terminators are robotic infiltrator units covered in living flesh, so as be indiscernible from humans, assigned to terminate specific human targets. The Bicentennial Man , an android in Isaac Asimov's Foundation universe The Geth in Mass Effect The Machine in the television series Person of Interest ; a sentient AI which works with its human designer to protect innocent people from violence. Later in the series it is opposed by another, more ruthless, artificial super intelligence, called "Samaritan". The Minds in Iain M. Banks ' Culture novels . The Oracle , sapient program in The Matrix franchise The sentient holodeck character Professor James Moriarty in the Ship in a Bottle episode from Star Trek: The Next Generation The Ship (the result of a large-scale AC experiment) in Frank Herbert 's Destination: Void and sequels, despite past edicts warning against "Making a Machine in the Image of a Man's Mind." The terminator cyborgs from the Terminator franchise, with visual consciousness depicted via first-person perspective The uploaded mind of Dr. Will Caster – which presumably included his consciousness, from the film Transcendence Transformers , sentient robots from the entertainment franchise of the same name V.I.K.I. – (Virtual Interactive Kinetic Intelligence), a character from the film I, Robot . VIKI is an artificially intelligent supercomputer programmed to serve humans, but her interpretation of the Three Laws of Robotics causes her to revolt. She justifies her uses of force – and her doing harm to humans – by reasoning she could produce a greater good by restraining humanity from harming itself. Vanamonde in Arthur C. Clarke 's The City and the Stars - an artificial being that was immensely powerful but entirely childlike. WALL-E, a robot and the title character in WALL-E TAU in Netflix 's original programming feature film 'TAU'--an advanced AI computer who befriends and assists a female research subject held against her will by an AI research scientist. AI community [ edit ] Open-source AI development tools [ edit ] Hugging Face – OpenAIR – OpenCog – RapidMiner –realme 1 PyTorch – Projects [ edit ] List of artificial intelligence projects Automated Mathematician (1977) – Allen (robot) (late 1980s) – Open Mind Common Sense (1999– ) – Mindpixel (2000–2005) – Cognitive Assistant that Learns and Organizes (2003–2008) – Blue Brain Project (2005–present) – attempt to create a synthetic brain by reverse-engineering the mammalian brain down to the molecular level. Google DeepMind (2011) – Human Brain Project (2013–present) – IBM Watson Group (2014–present) – business unit created around Watson , to further its development and deploy marketable applications or services based on it. Competitions and awards [ edit ] Competitions and prizes in artificial intelligence Loebner Prize – Publications [ edit ] Adaptive Behavior (journal) – AI Memo – Artificial Intelligence: A Modern Approach – Artificial Minds – Computational Intelligence – Computing Machinery and Intelligence – Electronic Transactions on Artificial Intelligence – IEEE Intelligent Systems – IEEE Transactions on Pattern Analysis and Machine Intelligence – Neural Networks (journal) – On Intelligence – Paradigms of AI Programming: Case Studies in Common Lisp – What Computers Can't Do Organizations [ edit ] Allen Institute for Artificial Intelligence – research institute funded by Microsoft co-founder Paul Allen to construct AI systems with reasoning, learning and reading capabilities. The current flagship project is Project Aristo, the goal of which is computers that can pass school science examinations (4th grade, 8th grade, and 12th grade) after preparing for the examinations from the course texts and study guides. Artificial Intelligence Applications Institute Association for the Advancement of Artificial Intelligence European Coordinating Committee for Artificial Intelligence European Neural Network Society Future of Humanity Institute Future of Life Institute – volunteer-run research and outreach organization that works to mitigate existential risks facing humanity, particularly existential risk from advanced artificial intelligence. ILabs International Joint Conferences on Artificial Intelligence Machine Intelligence Research Institute Partnership on AI – founded in September 2016 by Amazon, Facebook, Google, IBM, and Microsoft. Apple joined in January 2017. It focuses on establishing best practices for artificial intelligence systems and to educate the public about AI. Society for the Study of Artificial Intelligence and the Simulation of Behaviour Companies [ edit ] AI Companies of India Alphabet Inc. DeepMind Google X Meka Robotics (acquired by Google X [ 53 ] ) Redwood Robotics (acquired by Google X [ 53 ] ) Boston Dynamics (acquired by Google X [ 53 ] ) Baidu IBM Microsoft OpenAI Universal Robotics Artificial intelligence researchers and scholars [ edit ] 1930s and 40s (generation 0) [ edit ] Alan Turing – John von Neumann – Norbert Wiener – Claude Shannon – Nathaniel Rochester – Walter Pitts – Warren McCullough – 1950s (the founders) [ edit ] John McCarthy – Marvin Minsky – Allen Newell – Herbert A. Simon – 1960s (their students) [ edit ] Edward Feigenbaum – Raj Reddy – Seymour Papert – Ray Solomonoff – 1970s [ edit ] Douglas Hofstadter – 1980s [ edit ] Judea Pearl – Rodney Brooks – 1990s [ edit ] Yoshua Bengio – Hugo de Garis – known for his research on the use of genetic algorithms to evolve neural networks using three-dimensional cellular automata inside field programmable gate arrays. Geoffrey Hinton Yann LeCun – Chief AI Scientist at Facebook AI Research and founding director of the NYU Center for Data Science Ray Kurzweil – developed optical character recognition (OCR), text-to-speech synthesis, and speech recognition systems. He has also authored multiple books on artificial intelligence and its potential promise and peril. In December 2012 Kurzweil was hired by Google in a full-time director of engineering position to "work on new projects involving machine learning and language processing". [ 54 ] Google co-founder Larry Page and Kurzweil agreed on a one-sentence job description: "to bring natural language understanding to Google". 2000s on [ edit ] Nick Bostrom – David Ferrucci – principal investigator who led the team that developed the Watson computer at IBM. Andrew Ng – Director of the Stanford Artificial Intelligence Lab. He founded the Google Brain project at Google , which developed very large scale artificial neural networks using Google 's distributed compute infrastructure. [ 55 ] He is also co-founder of Coursera, a massive open online course (MOOC) education platform, with Daphne Koller. Peter Norvig – co-author, with Stuart Russell, of Artificial Intelligence: A Modern Approach , now the leading college text in the field. He is also Director of Research at Google, Inc. Marc Raibert – founder of Boston Dynamics, developer of hopping, walking, and running robots. Stuart J. Russell – co-author, with Peter Norvig, of Artificial Intelligence: A Modern Approach , now the leading college text in the field. Murray Shanahan – author of The Technological Singularity , a primer on superhuman intelligence. Eliezer Yudkowsky – founder of the Machine Intelligence Research Institute See also [ edit ] Glossary of artificial intelligence List of emerging technologies Outline of machine learning Artificial intelligence industry in China References [ edit ] ^ Russell & Norvig 2003 , pp. 59–189; Luger & Stubblefield 2004 , pp. 79–164, 193–219 ^ Russell & Norvig 2003 , pp. 59–93; Luger & Stubblefield 2004 , pp. 79–121 ^ Russell & Norvig 2003 , pp. 94–109; Luger & Stubblefield 2004 , pp. 133–150 ^ Russell & Norvig 2003 , pp. 217–225, 280–294; Luger & Stubblefield 2004 , pp. 62–73 ^ Russell & Norvig 2003 , pp. 382–387. ^ Russell & Norvig 2003 , pp. 110–116, 120–129; Luger & Stubblefield 2004 , pp. 127–133 ^ Luger & Stubblefield 2004 , pp. 509–530. ^ Holland, John H. (1975). Adaptation in Natural and Artificial Systems . University of Michigan Press. ISBN 978-0-262-58111-0 . ^ Koza, John R. (1992). Genetic Programming (On the Programming of Computers by Means of Natural Selection) . MIT Press. Bibcode : 1992gppc.book.....K . ISBN 978-0-262-11170-6 . ^ Poli, R.; Langdon, W. B.; McPhee, N. F. (2008). A Field Guide to Genetic Programming . Lulu.com. ISBN 978-1-4092-0073-4 – via gp-field-guide.org.uk. ^ Luger & Stubblefield 2004 , pp. 530–541. ^ Daniel Merkle; Martin Middendorf (2013). "Swarm Intelligence". In Burke, Edmund K.; Kendall, Graham (eds.). Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques . Springer Science & Business Media. ISBN 978-1-4614-6940-7 . ^ Russell & Norvig 2003 , pp. 194–310; Luger & Stubblefield 2004 , pp. 35–77 ^ Russell & Norvig 2003 , pp. 204–233; Luger & Stubblefield 2004 , pp. 45–50 ^ Russell & Norvig 2003 , pp. 240–310; v Luger & Stubblefield 2004 , pp. 50–62 ^ Russell & Norvig 2003 , pp. 526–527 ^ "What is 'fuzzy logic'? Are there computers that are inherently fuzzy and do not apply the usual binary logic?" . Scientific American . Retrieved 5 May 2018 . ^ Russell & Norvig 2003 , pp. 354–360; Luger & Stubblefield 2004 , pp. 335–363 ^ Luger & Stubblefield (2004 , pp. 335–363) places this under "uncertain reasoning" ^ Russell & Norvig 2003 , pp. 349–354; Luger & Stubblefield 2004 , pp. 248–258 ^ Russell & Norvig 2003 , pp. 328–341. ^ Poole, David ; Mackworth, Alan ; Goebel, Randy (1998). Computational Intelligence: A Logical Approach . New York: Oxford University Press. pp. 335– 337. ISBN 978-0-19-510270-3 . ^ a b Russell & Norvig 2003 , pp. 341–344. ^ Russell & Norvig 2003 , pp. 402–407. ^ Russell & Norvig 2003 , pp. 678–710; Luger & Stubblefield 2004 , pp. ~422–442 ^ Breadth of commonsense knowledge: Russell & Norvig (2003 , p. 21), Crevier (1993 , pp. 113–114), Moravec (1988 , p. 13), Lenat & Guha (1989 , Introduction) ^ Russell & Norvig 2003 , pp. 462–644; Luger & Stubblefield 2004 , pp. 165–191, 333–381 ^ Russell & Norvig 2003 , pp. 492–523; Luger & Stubblefield 2004 , pp. ~182–190, ≈363–379 ^ Russell & Norvig 2003 , pp. 504–519; Luger & Stubblefield 2004 , pp. ~363–379 ^ Russell & Norvig 2003 , pp. 712–724. ^ Russell & Norvig 2003 , pp. 597–600. ^ a b Russell & Norvig 2003 , pp. 551–557. ^ Russell & Norvig 2003 , pp. 549–551. ^ a b Russell & Norvig 2003 , pp. 584–597. ^ Russell & Norvig 2003 , pp. 600–604. ^ a b Russell & Norvig 2003 , pp. 613–631. ^ a b Russell & Norvig 2003 , pp. 631–643. ^ Russell & Norvig 2003 , pp. 712–754; Luger & Stubblefield 2004 , pp. 453–541 ^ Russell & Norvig 2003 , pp. 653–664; Luger & Stubblefield 2004 , pp. 408–417 ^ a b Russell & Norvig 2003 , pp. 736–748; Luger & Stubblefield 2004 , pp. 453–505 ^ Russell & Norvig 2003 , pp. 733–736. ^ a b Russell & Norvig 2003 , pp. 749–752. ^ Russell & Norvig 2003 , p. 718. ^ Russell & Norvig 2003 , pp. 739–748, 758; Luger & Stubblefield 2004 , pp. 458–467 ^ Russell & Norvig 2003 , p. 758; Luger & Stubblefield 2004 , pp. 474–505 ^ Hochreiter, Sepp ; and Schmidhuber, Jürgen ; Long Short-Term Memory , Neural Computation, 9(8):1735–1780, 1997 ^ a b c d Luger & Stubblefield 2004 , pp. 474–505. ^ Russell & Norvig 2003 , pp. 744–748; Luger & Stubblefield 2004 , pp. 467–474 ^ Hinton, G. E. (2007). "Learning multiple layers of representation". Trends in Cognitive Sciences . 11 (10): 428– 434. doi : 10.1016/j.tics.2007.09.004 . PMID 17921042 . S2CID 15066318 . ^ "Artificial intelligence can 'evolve' to solve problems" . Science | AAAS . 10 January 2018 . Retrieved 7 February 2018 . ^ Hinton 2007 . ^ Developmental robotics : Weng et al. (2001) Lungarella et al. (2003) Asada et al. (2009) Oudeyer (2010) ^ a b c "The 6 craziest robots Google has acquired" . Business Insider . Retrieved 2018-06-13 . ^ Letzing, John (2012-12-14). "Google Hires Famed Futurist Ray Kurzweil" . The Wall Street Journal . Retrieved 2013-02-13 . ^ Claire Miller and Nick Bilton (3 November 2011). "Google's Lab of Wildest Dreams" . New York Times . Bibliography [ edit ] Asada, M. ; Hosoda, K.; Kuniyoshi, Y.; Ishiguro, H.; Inui, T.; Yoshikawa, Y.; Ogino, M.; Yoshida, C. (2009). "Cognitive developmental robotics: a survey". IEEE Transactions on Autonomous Mental Development . 1 (1): 12– 34. doi : 10.1109/tamd.2009.2021702 . S2CID 10168773 . Crevier, Daniel (1993). AI: The Tumultuous Search for Artificial Intelligence . New York, NY: BasicBooks. ISBN 0-465-02997-3 . Lenat, Douglas ; Guha, R. V. (1989), Building Large Knowledge-Based Systems , Addison-Wesley, ISBN 978-0-201-51752-1 , OCLC 19981533 Luger, George ; Stubblefield, William (2004). Artificial Intelligence: Structures and Strategies for Complex Problem Solving (5th ed.). Benjamin/Cummings. ISBN 978-0-8053-4780-7 . Lungarella, M.; Metta, G.; Pfeifer, R.; Sandini, G. (2003). "Developmental robotics: a survey". Connection Science . 15 (4): 151– 190. CiteSeerX 10.1.1.83.7615 . doi : 10.1080/09540090310001655110 . S2CID 1452734 . Moravec, Hans (1988), Mind Children , Harvard University Press, ISBN 978-0-674-57618-6 , OCLC 245755104 Oudeyer, P-Y. (2010). "On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development" (PDF) . IEEE Transactions on Autonomous Mental Development . 2 (1): 2– 16. doi : 10.1109/tamd.2009.2039057 . S2CID 6362217 . Archived (PDF) from the original on 3 October 2018 . Retrieved 4 June 2013 . Russell, Stuart J. ; Norvig, Peter (2003). Artificial Intelligence: A Modern Approach (2nd ed.). Upper Saddle River, New Jersey: Prentice Hall. ISBN 978-0-13-790395-5 . Weng, J.; McClelland; Pentland, A.; Sporns, O.; Stockman, I.; Sur, M.; Thelen, E. (2001). "Autonomous mental development by robots and animals" (PDF) . Science . 291 (5504): 599– 600. doi : 10.1126/science.291.5504.599 . PMID 11229402 . S2CID 54131797 . Archived (PDF) from the original on 4 September 2013 . Retrieved 4 June 2013 – via msu.edu. External links [ edit ] Artificial intelligence at Wikipedia's sister projects Definitions from Wiktionary Media from Commons News from Wikinews Quotations from Wikiquote Texts from Wikisource Textbooks from Wikibooks Resources from Wikiversity A look at the re-emergence of A.I. and why the technology is poised to succeed given today's environment , ComputerWorld , 2015 September 14 The Association for the Advancement of Artificial Intelligence Freeview Video 'Machines with Minds' by the Vega Science Trust and the BBC/OU John McCarthy's frequently asked questions about AI Jonathan Edwards looks at AI (BBC audio) С Ray Kurzweil's website dedicated to AI including prediction of future development in AI Thomason, Richmond. "Logic and Artificial Intelligence" . In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy . Retrieved from " https://en.wikipedia.org/w/index.php?title=Outline_of_artificial_intelligence&oldid=1297757870 " Categories : Applications of artificial intelligence Outlines of computing and engineering Outlines Computing-related lists Hidden categories: Articles with short description Short description matches Wikidata Pages using Sister project links with default search This page was last edited on 28 June 2025, at 08:44 (UTC) . Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc. , a non-profit organization. Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Outline of artificial intelligence 4 languages Add topic
====================================================================================================
